{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"cdSet\" in globals():\n",
    "    %cd -q ..\n",
    "    cdSet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "------------ Options -------------\n",
      "batchSize: 4\n",
      "batch_size: 4\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ../data/cityscapes/\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "ganFeat_loss: True\n",
      "gpu_ids: [0]\n",
      "input_nc: 1\n",
      "isTrain: True\n",
      "label_nc: 34\n",
      "lambda_feat: 10.0\n",
      "loadSize: 512\n",
      "load_features: False\n",
      "load_pretrain: ./checkpoints/label2face_512p\n",
      "local_rank: 0\n",
      "lr: 5e-05\n",
      "lsgan: True\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: label2face_512p\n",
      "ndf: 64\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_html: False\n",
      "no_instance: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 16\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "vae_path: ../../CelebAMask-HQ/MaskGAN_demo/checkpoint_vae/000070.pt\n",
      "verbose: False\n",
      "vgg_loss: True\n",
      "weight_decay: 0.0001\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(34, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (21): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (24): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (27): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (30): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (33): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (34): Tanh()\n",
      "  )\n",
      "  (enc_style): StyleEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_middle): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_last): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Conv2d(64, 16384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sft1): SFTLayer(\n",
      "      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_scale_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sft2): SFTLayer(\n",
      "      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_scale_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (enc_label): LabelEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(34, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_last): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (3): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiscaleDiscriminator(\n",
      "  (scale0_layer0): Sequential(\n",
      "    (0): Conv2d(37, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (scale1_layer0): Sequential(\n",
      "    (0): Conv2d(37, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
      ")\n",
      "BlendGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(6, 32, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (17): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (20): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (21): ReLU(inplace=True)\n",
      "    (22): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (23): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (26): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (27): Sigmoid()\n",
      "  )\n",
      ")\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Disable automatic optimization with the trainer flag is deprecated and will be removed in v1.3.0!Please use the property on the LightningModule for disabling automatic optimization\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Set SLURM handle signals.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I1121 20:30:35.281708 47779410960128 slurm_connector.py:80] Set SLURM handle signals.\n",
      "\n",
      "  | Name          | Type                    | Params\n",
      "----------------------------------------------------------\n",
      "0 | netVAE        | VAE                     | 170 M \n",
      "1 | netG          | GlobalGenerator         | 89.8 M\n",
      "2 | netD          | MultiscaleDiscriminator | 5.6 M \n",
      "3 | netB          | BlendGenerator          | 4.3 M \n",
      "4 | criterionGAN  | GANLoss                 | 0     \n",
      "5 | criterionFeat | L1Loss                  | 0     \n",
      "6 | criterionVGG  | VGGLoss                 | 12.9 M\n",
      "I1121 20:30:35.295281 47779410960128 lightning.py:1488] \n",
      "  | Name          | Type                    | Params\n",
      "----------------------------------------------------------\n",
      "0 | netVAE        | VAE                     | 170 M \n",
      "1 | netG          | GlobalGenerator         | 89.8 M\n",
      "2 | netD          | MultiscaleDiscriminator | 5.6 M \n",
      "3 | netB          | BlendGenerator          | 4.3 M \n",
      "4 | criterionGAN  | GANLoss                 | 0     \n",
      "5 | criterionFeat | L1Loss                  | 0     \n",
      "6 | criterionVGG  | VGGLoss                 | 12.9 M\n",
      "/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:   0%|                                          | 0/744 [00:00<?, ?it/s]loss_g:   tensor(5959.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(4.4632, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   0%|       | 1/744 [00:07<1:28:20,  7.13s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6410.7876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(3.5242, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|       | 2/744 [00:12<1:16:13,  6.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6155.4111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(3.3633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   0%|       | 3/744 [00:16<1:09:11,  5.60s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6795.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(3.1328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   1%|       | 4/744 [00:21<1:05:38,  5.32s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6830.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.9630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   1%|       | 5/744 [00:25<1:04:00,  5.20s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6684.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.8472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   1%|       | 6/744 [00:30<1:02:08,  5.05s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6497.3755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.5474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   1%|       | 7/744 [00:34<1:01:20,  4.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6650.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.5254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   1%|       | 8/744 [00:39<1:00:41,  4.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7008.8306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.3202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   1%|       | 9/744 [00:44<1:00:01,  4.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6486.5522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.5486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   1%|        | 10/744 [00:48<59:29,  4.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6768.8076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.4453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   1%|        | 11/744 [00:53<58:56,  4.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6525.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.5633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   2%|▏       | 12/744 [00:57<58:11,  4.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6786.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.2015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   2%|▏       | 13/744 [01:01<57:34,  4.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6845.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.5087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   2%|▏       | 14/744 [01:05<57:14,  4.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(5941.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.4301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   2%|▏       | 15/744 [01:10<56:52,  4.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6374.4507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.4530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   2%|▏       | 16/744 [01:14<56:33,  4.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(4814.4731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.5287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   2%|▏       | 17/744 [01:19<56:21,  4.65s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6306.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.4204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   2%|▏       | 18/744 [01:23<56:15,  4.65s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6179.4580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.4606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   3%|▏       | 19/744 [01:28<56:08,  4.65s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6168.5356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.7154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   3%|▏       | 20/744 [01:32<55:55,  4.64s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(5619.3296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.3133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   3%|▏       | 21/744 [01:37<55:39,  4.62s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6657.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.4723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   3%|▏       | 22/744 [01:41<55:42,  4.63s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(5586.4385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.3835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   3%|▏       | 23/744 [01:46<55:37,  4.63s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6510.5659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.6626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   3%|▎       | 24/744 [01:50<55:22,  4.62s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7296.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.2788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   3%|▎       | 25/744 [01:55<55:13,  4.61s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7141.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.5060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   3%|▎       | 26/744 [01:59<55:06,  4.61s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7171.8193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.3764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   4%|▎       | 27/744 [02:04<54:56,  4.60s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7544.8340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.8152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   4%|▎       | 28/744 [02:08<54:43,  4.59s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(5802.6260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.2784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   4%|▎       | 29/744 [02:12<54:31,  4.58s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6683.8193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.4622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   4%|▎       | 30/744 [02:17<54:21,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7109.8081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.1845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   4%|▎       | 31/744 [02:21<54:25,  4.58s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6172.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.5157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   4%|▎       | 32/744 [02:26<54:24,  4.59s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6921.3101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.1034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   4%|▎       | 33/744 [02:31<54:15,  4.58s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6091.3301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.5017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   5%|▎       | 34/744 [02:35<54:12,  4.58s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7217.8560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.2045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   5%|▍       | 35/744 [02:40<54:07,  4.58s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6952.4233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.3778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   5%|▍       | 36/744 [02:44<54:02,  4.58s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6353.2158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.1645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   5%|▍       | 37/744 [02:48<53:47,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(5995.6733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.1564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   5%|▍       | 38/744 [02:53<53:46,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6371.2607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.1991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   5%|▍       | 39/744 [02:57<53:35,  4.56s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6452.6260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.3051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   5%|▍       | 40/744 [03:02<53:26,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6439.1436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.3175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   6%|▍       | 41/744 [03:06<53:20,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6866.7749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.2312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   6%|▍       | 42/744 [03:11<53:14,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6331.6899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.0969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   6%|▍       | 43/744 [03:15<53:03,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6186.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.0566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   6%|▍       | 44/744 [03:19<53:00,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6437.3213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.9763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   6%|▍       | 45/744 [03:24<52:52,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6174.0127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.0952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   6%|▍       | 46/744 [03:28<52:48,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7100.5405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   6%|▌       | 47/744 [03:33<52:41,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6706.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.1041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   6%|▌       | 48/744 [03:37<52:38,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7118.0669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.0295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   7%|▌       | 49/744 [03:42<52:35,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6216.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(2.0387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   7%|▌       | 50/744 [03:47<52:34,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7397.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   7%|▌       | 51/744 [03:52<52:35,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6636.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.7484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   7%|▌       | 52/744 [03:56<52:32,  4.56s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6366.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.7535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   7%|▌       | 53/744 [04:01<52:33,  4.56s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6869.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.9619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   7%|▌       | 54/744 [04:06<52:29,  4.56s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6338.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8893, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   7%|▌       | 55/744 [04:10<52:18,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6372.4150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   8%|▌       | 56/744 [04:15<52:12,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6276.7334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8632, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   8%|▌       | 57/744 [04:19<52:03,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6971.6377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   8%|▌       | 58/744 [04:23<51:58,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6173.7646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   8%|▋       | 59/744 [04:28<51:56,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7491.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   8%|▋       | 60/744 [04:32<51:51,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6398.6772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   8%|▋       | 61/744 [04:37<51:45,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6384.2007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   8%|▋       | 62/744 [04:41<51:36,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7150.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   8%|▋       | 63/744 [04:45<51:29,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6634.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.7798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   9%|▋       | 64/744 [04:55<52:19,  4.62s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7055.7275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.9184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   9%|▋       | 65/744 [05:01<52:33,  4.64s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(5965.3208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.7781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   9%|▋       | 66/744 [05:08<52:48,  4.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6414.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   9%|▋       | 67/744 [05:13<52:42,  4.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6541.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   9%|▋       | 68/744 [05:17<52:31,  4.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6651.5581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5885, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   9%|▋       | 69/744 [05:21<52:25,  4.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6612.3428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.7299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:   9%|▊       | 70/744 [05:26<52:20,  4.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6362.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  10%|▊       | 71/744 [05:30<52:13,  4.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(5688.8643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  10%|▊       | 72/744 [05:35<52:07,  4.65s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7250.2012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  10%|▊       | 73/744 [05:39<52:01,  4.65s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6618.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.7489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  10%|▊       | 74/744 [05:43<51:52,  4.65s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6333.4463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.7645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  10%|▊       | 75/744 [05:47<51:42,  4.64s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7797.6938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  10%|▊       | 76/744 [05:51<51:33,  4.63s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7575.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  10%|▊       | 77/744 [05:56<51:24,  4.63s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6970.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6582, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|▊       | 78/744 [06:00<51:16,  4.62s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8268.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  11%|▊       | 79/744 [06:04<51:11,  4.62s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7032.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.7796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  11%|▊       | 80/744 [06:08<51:01,  4.61s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7528.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  11%|▊       | 81/744 [06:13<51:00,  4.62s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7690.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.7924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  11%|▉       | 82/744 [06:18<50:51,  4.61s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7950.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  11%|▉       | 83/744 [06:22<50:49,  4.61s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6316.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.7098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  11%|▉       | 84/744 [06:27<50:44,  4.61s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7095.8911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.8968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  11%|▉       | 85/744 [06:31<50:38,  4.61s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7271.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  12%|▉       | 86/744 [06:36<50:31,  4.61s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6574.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  12%|▉       | 87/744 [06:40<50:24,  4.60s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6985.4443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  12%|▉       | 88/744 [06:44<50:18,  4.60s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7629.5942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  12%|▉       | 89/744 [06:49<50:13,  4.60s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6792.3076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  12%|▉       | 90/744 [06:53<50:05,  4.60s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6616.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  12%|▉       | 91/744 [06:58<49:59,  4.59s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6908.9126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  12%|▉       | 92/744 [07:02<49:53,  4.59s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8047.0962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  12%|█       | 93/744 [07:06<49:46,  4.59s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6781.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  13%|█       | 94/744 [07:11<49:41,  4.59s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6913.5322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  13%|█       | 95/744 [07:15<49:33,  4.58s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6481.9170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  13%|█       | 96/744 [07:19<49:27,  4.58s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7144.3506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  13%|█       | 97/744 [07:24<49:22,  4.58s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6981.7373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  13%|█       | 98/744 [07:28<49:18,  4.58s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7520.6616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  13%|█       | 99/744 [07:32<49:10,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7388.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  13%|▉      | 100/744 [07:37<49:04,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6584.5400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  14%|▉      | 101/744 [07:41<48:58,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7741.6714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  14%|▉      | 102/744 [07:45<48:52,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8089.7153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4080, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  14%|▉      | 103/744 [07:50<48:47,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7292.5259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  14%|▉      | 104/744 [07:55<48:44,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6766.7490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  14%|▉      | 105/744 [07:59<48:38,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6779.1260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  14%|▉      | 106/744 [08:04<48:33,  4.57s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7073.5010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  14%|█      | 107/744 [08:08<48:26,  4.56s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7463.5444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  15%|█      | 108/744 [08:12<48:20,  4.56s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7630.2627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  15%|█      | 109/744 [08:16<48:13,  4.56s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7526.5806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  15%|█      | 110/744 [08:21<48:10,  4.56s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6677.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  15%|█      | 111/744 [08:25<48:05,  4.56s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6923.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  15%|█      | 112/744 [08:29<47:56,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7339.0093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  15%|█      | 113/744 [08:34<47:52,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8093.8730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  15%|█      | 114/744 [08:38<47:45,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7211.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  15%|█      | 115/744 [08:43<47:41,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7577.8135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  16%|█      | 116/744 [08:47<47:34,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7746.1450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  16%|█      | 117/744 [08:51<47:28,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7067.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  16%|█      | 118/744 [08:56<47:25,  4.55s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7732.9438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.6376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  16%|█      | 119/744 [09:00<47:19,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7319.1631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  16%|█▏     | 120/744 [09:05<47:14,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7588.1846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  16%|█▏     | 121/744 [09:09<47:06,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8107.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  16%|█▏     | 122/744 [09:13<47:02,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6962.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  17%|█▏     | 123/744 [09:18<46:57,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6353.8569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  17%|█▏     | 124/744 [09:22<46:51,  4.54s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7548.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  17%|█▏     | 125/744 [09:26<46:46,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7293.2939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  17%|█▏     | 126/744 [09:31<46:41,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7931.3564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  17%|█▏     | 127/744 [09:35<46:36,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7610.2900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  17%|█▏     | 128/744 [09:39<46:30,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8276.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  17%|█▏     | 129/744 [09:44<46:26,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8781.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  17%|█▏     | 130/744 [09:48<46:21,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7939.0522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  18%|█▏     | 131/744 [09:53<46:15,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6878.0850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  18%|█▏     | 132/744 [09:57<46:11,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7587.3433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  18%|█▎     | 133/744 [10:02<46:05,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7135.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  18%|█▎     | 134/744 [10:07<46:03,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8162.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  18%|█▎     | 135/744 [10:10<45:56,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8408.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  18%|█▎     | 136/744 [10:15<45:50,  4.52s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8242.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  18%|█▎     | 137/744 [10:19<45:43,  4.52s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7869.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  19%|█▎     | 138/744 [10:23<45:37,  4.52s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8170.0420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  19%|█▎     | 139/744 [10:27<45:31,  4.51s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7152.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  19%|█▎     | 140/744 [10:31<45:25,  4.51s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6672.8135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  19%|█▎     | 141/744 [10:36<45:20,  4.51s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7492.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  19%|█▎     | 142/744 [10:40<45:15,  4.51s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7925.7622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  19%|█▎     | 143/744 [10:44<45:10,  4.51s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6181.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  19%|█▎     | 144/744 [10:49<45:05,  4.51s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8361.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  19%|█▎     | 145/744 [10:53<45:01,  4.51s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7188.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  20%|█▎     | 146/744 [10:58<44:55,  4.51s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8186.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  20%|█▍     | 147/744 [11:02<44:49,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7653.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  20%|█▍     | 148/744 [11:06<44:44,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7158.8999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  20%|█▍     | 149/744 [11:11<44:40,  4.51s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7846.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  20%|█▍     | 150/744 [11:15<44:34,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8406.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  20%|█▍     | 151/744 [11:19<44:28,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8487.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  20%|█▍     | 152/744 [11:24<44:25,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7765.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  21%|█▍     | 153/744 [11:28<44:20,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7634.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2779, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  21%|█▍     | 154/744 [11:32<44:14,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8121.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  21%|█▍     | 155/744 [11:37<44:10,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7367.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  21%|█▍     | 156/744 [11:41<44:04,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8609.6357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  21%|█▍     | 157/744 [11:45<43:59,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7871.0576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  21%|█▍     | 158/744 [11:50<43:55,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8593.2490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  21%|█▍     | 159/744 [11:54<43:50,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8218.4160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  22%|█▌     | 160/744 [11:59<43:44,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7232.2607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  22%|█▌     | 161/744 [12:03<43:41,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8982.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  22%|█▌     | 162/744 [12:08<43:36,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8193.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  22%|█▌     | 163/744 [12:12<43:31,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7620.7446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  22%|█▌     | 164/744 [12:16<43:26,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8596.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  22%|█▌     | 165/744 [12:21<43:21,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7124.8184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  22%|█▌     | 166/744 [12:25<43:16,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7664.4482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  22%|█▌     | 167/744 [12:29<43:11,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7461.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  23%|█▌     | 168/744 [12:34<43:05,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7919.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  23%|█▌     | 169/744 [12:38<43:01,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8442.7139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  23%|█▌     | 170/744 [12:42<42:56,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8487.7686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  23%|█▌     | 171/744 [12:47<42:50,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7726.1284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  23%|█▌     | 172/744 [12:51<42:47,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7622.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  23%|█▋     | 173/744 [12:56<42:42,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7686.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  23%|█▋     | 174/744 [13:00<42:37,  4.49s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8383.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  24%|█▋     | 175/744 [13:04<42:31,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8181.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  24%|█▋     | 176/744 [13:09<42:26,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8049.8564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  24%|█▋     | 177/744 [13:13<42:22,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8660.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  24%|█▋     | 178/744 [13:18<42:17,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8052.6494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  24%|█▋     | 179/744 [13:22<42:13,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8029.4033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  24%|█▋     | 180/744 [13:27<42:09,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8692.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  24%|█▋     | 181/744 [13:31<42:04,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8025.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.5560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  24%|█▋     | 182/744 [13:36<42:00,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8564.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  25%|█▋     | 183/744 [13:40<41:55,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8120.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  25%|█▋     | 184/744 [13:45<41:51,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7473.6279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  25%|█▋     | 185/744 [13:49<41:45,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8473.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  25%|█▊     | 186/744 [13:53<41:41,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8581.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  25%|█▊     | 187/744 [13:57<41:35,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8182.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  25%|█▊     | 188/744 [14:02<41:30,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9787.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  25%|█▊     | 189/744 [14:06<41:25,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7865.6616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  26%|█▊     | 190/744 [14:10<41:20,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8693.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  26%|█▊     | 191/744 [14:15<41:16,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8247.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  26%|█▊     | 192/744 [14:19<41:10,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8327.3027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  26%|█▊     | 193/744 [14:23<41:05,  4.48s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9042.1572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  26%|█▊     | 194/744 [14:27<41:00,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8078.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  26%|█▊     | 195/744 [14:32<40:56,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9210.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  26%|█▊     | 196/744 [14:36<40:50,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8925.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  26%|█▊     | 197/744 [14:40<40:44,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8284.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  27%|█▊     | 198/744 [14:44<40:39,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7915.5029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  27%|█▊     | 199/744 [14:48<40:34,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8956.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  27%|█▉     | 200/744 [14:53<40:30,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8774.7803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  27%|█▉     | 201/744 [14:58<40:26,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7883.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  27%|█▉     | 202/744 [15:02<40:22,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8794.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  27%|█▉     | 203/744 [15:07<40:17,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7850.1177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  27%|█▉     | 204/744 [15:11<40:13,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(6330.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  28%|█▉     | 205/744 [15:15<40:07,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9200.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  28%|█▉     | 206/744 [15:19<40:02,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8476.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  28%|█▉     | 207/744 [15:24<39:57,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7946.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  28%|█▉     | 208/744 [15:28<39:53,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8174.5488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  28%|█▉     | 209/744 [15:33<39:49,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9227.5566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  28%|█▉     | 210/744 [15:37<39:45,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8841.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  28%|█▉     | 211/744 [15:42<39:41,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8966.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  28%|█▉     | 212/744 [15:47<39:37,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7504.0708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  29%|██     | 213/744 [15:51<39:32,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7282.8198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  29%|██     | 214/744 [15:55<39:27,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9020.1025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  29%|██     | 215/744 [16:00<39:22,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9381.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  29%|██     | 216/744 [16:04<39:17,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9332.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  29%|██     | 217/744 [16:08<39:12,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8281.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  29%|██     | 218/744 [16:13<39:07,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9007.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  29%|██     | 219/744 [16:17<39:03,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8836.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  30%|██     | 220/744 [16:21<38:57,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8619.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  30%|██     | 221/744 [16:25<38:52,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7356.5464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  30%|██     | 222/744 [16:30<38:48,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9424.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  30%|██     | 223/744 [16:34<38:44,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9887.5010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  30%|██     | 224/744 [16:39<38:39,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8919.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  30%|██     | 225/744 [16:43<38:34,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9309.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  30%|██▏    | 226/744 [16:47<38:29,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8188.6733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  31%|██▏    | 227/744 [16:52<38:25,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9479.6943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  31%|██▏    | 228/744 [16:56<38:20,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8096.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  31%|██▏    | 229/744 [17:01<38:16,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7917.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2224, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  31%|██▏    | 230/744 [17:05<38:12,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8844.9795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  31%|██▏    | 231/744 [17:09<38:07,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8104.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  31%|██▏    | 232/744 [17:14<38:03,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8892.2793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  31%|██▏    | 233/744 [17:18<37:58,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9035.6846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3725, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  31%|██▏    | 234/744 [17:23<37:53,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8209.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  32%|██▏    | 235/744 [17:27<37:48,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8853.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  32%|██▏    | 236/744 [17:31<37:43,  4.46s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9506.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  32%|██▏    | 237/744 [17:35<37:38,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8203.8115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  32%|██▏    | 238/744 [17:40<37:34,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8304.1162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  32%|██▏    | 239/744 [17:44<37:29,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9200.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  32%|██▎    | 240/744 [17:48<37:24,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8093.7725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  32%|██▎    | 241/744 [17:53<37:19,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8293.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  33%|██▎    | 242/744 [17:57<37:15,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8093.8135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  33%|██▎    | 243/744 [18:02<37:10,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9268.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  33%|██▎    | 244/744 [18:06<37:05,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7670.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  33%|██▎    | 245/744 [18:10<37:01,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8469.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  33%|██▎    | 246/744 [18:14<36:56,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8316.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  33%|██▎    | 247/744 [18:19<36:51,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8479.9043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  33%|██▎    | 248/744 [18:23<36:46,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8185.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  33%|██▎    | 249/744 [18:27<36:41,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9341.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  34%|██▎    | 250/744 [18:31<36:36,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9313.6416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  34%|██▎    | 251/744 [18:36<36:32,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8733.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  34%|██▎    | 252/744 [18:40<36:27,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8255.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  34%|██▍    | 253/744 [18:44<36:22,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8130.0244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  34%|██▍    | 254/744 [18:49<36:18,  4.45s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9626.9150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  34%|██▍    | 255/744 [18:53<36:12,  4.44s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9946.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  34%|██▍    | 256/744 [18:57<36:07,  4.44s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9173.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  35%|██▍    | 257/744 [19:01<36:02,  4.44s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9444.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  35%|██▍    | 258/744 [19:05<35:58,  4.44s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8850.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  35%|██▍    | 259/744 [19:10<35:53,  4.44s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7854.1924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  35%|██▍    | 260/744 [19:14<35:49,  4.44s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8839.8037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  35%|██▍    | 261/744 [19:18<35:43,  4.44s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9878.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  35%|██▍    | 262/744 [19:22<35:38,  4.44s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8363.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  35%|██▍    | 263/744 [19:26<35:33,  4.44s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8747.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  35%|██▍    | 264/744 [19:30<35:28,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8818.1553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  36%|██▍    | 265/744 [19:34<35:23,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8766.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  36%|██▌    | 266/744 [19:38<35:18,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8934.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  36%|██▌    | 267/744 [19:43<35:14,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9085.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  36%|██▌    | 268/744 [19:47<35:09,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7801.4653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  36%|██▌    | 269/744 [19:52<35:05,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9025.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  36%|██▌    | 270/744 [19:56<35:00,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9764.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  36%|██▌    | 271/744 [20:00<34:55,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9083.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  37%|██▌    | 272/744 [20:04<34:50,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7985.1299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  37%|██▌    | 273/744 [20:09<34:46,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9719.8174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  37%|██▌    | 274/744 [20:13<34:41,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8605.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  37%|██▌    | 275/744 [20:18<34:37,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10730.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  37%|██▌    | 276/744 [20:22<34:32,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8982.8975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  37%|██▌    | 277/744 [20:27<34:29,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8303.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  37%|██▌    | 278/744 [20:32<34:25,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8983.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  38%|██▋    | 279/744 [20:36<34:20,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9459.6963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  38%|██▋    | 280/744 [20:40<34:16,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9828.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  38%|██▋    | 281/744 [20:45<34:11,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9243.6113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  38%|██▋    | 282/744 [20:49<34:07,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9104.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  38%|██▋    | 283/744 [20:53<34:02,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9537.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  38%|██▋    | 284/744 [20:58<33:58,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8011.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  38%|██▋    | 285/744 [21:02<33:53,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10637.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  38%|██▋    | 286/744 [21:06<33:48,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9298.7627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  39%|██▋    | 287/744 [21:11<33:44,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9073.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  39%|██▋    | 288/744 [21:15<33:40,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8991.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  39%|██▋    | 289/744 [21:20<33:35,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8217.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  39%|██▋    | 290/744 [21:25<33:31,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9782.8105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  39%|██▋    | 291/744 [21:29<33:27,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10006.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  39%|██▋    | 292/744 [21:33<33:22,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10746.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  39%|██▊    | 293/744 [21:38<33:17,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8131.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  40%|██▊    | 294/744 [21:42<33:13,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9613.4229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  40%|██▊    | 295/744 [21:46<33:08,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10040.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  40%|██▊    | 296/744 [21:50<33:04,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8721.8975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  40%|██▊    | 297/744 [21:55<32:59,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9966.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  40%|██▊    | 298/744 [21:59<32:55,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8497.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9863, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  40%|██▊    | 299/744 [22:03<32:49,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8764.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  40%|██▊    | 300/744 [22:07<32:44,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9559.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  40%|██▊    | 301/744 [22:12<32:40,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8533.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9958, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  41%|██▊    | 302/744 [22:16<32:36,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8701.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  41%|██▊    | 303/744 [22:20<32:31,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9041.2432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  41%|██▊    | 304/744 [22:25<32:26,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9959.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  41%|██▊    | 305/744 [22:29<32:22,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10777.7412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0494, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  41%|██▉    | 306/744 [22:33<32:17,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8599.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  41%|██▉    | 307/744 [22:38<32:13,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8376.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  41%|██▉    | 308/744 [22:42<32:08,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8961.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  42%|██▉    | 309/744 [22:47<32:04,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8791.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  42%|██▉    | 310/744 [22:51<32:00,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7525.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  42%|██▉    | 311/744 [22:55<31:55,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8847.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  42%|██▉    | 312/744 [23:00<31:50,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8144.3857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  42%|██▉    | 313/744 [23:04<31:46,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9176.3799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  42%|██▉    | 314/744 [23:08<31:41,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9709.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  42%|██▉    | 315/744 [23:12<31:36,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9498.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  42%|██▉    | 316/744 [23:17<31:32,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9796.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  43%|██▉    | 317/744 [23:21<31:28,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8407.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  43%|██▉    | 318/744 [23:25<31:22,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(7985.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  43%|███    | 319/744 [23:29<31:18,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9929.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  43%|███    | 320/744 [23:33<31:13,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10289.7402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  43%|███    | 321/744 [23:37<31:08,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9305.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  43%|███    | 322/744 [23:42<31:04,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10871.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  43%|███    | 323/744 [23:46<30:59,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8741.4355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  44%|███    | 324/744 [23:50<30:54,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9267.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  44%|███    | 325/744 [23:54<30:49,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8863.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  44%|███    | 326/744 [23:59<30:45,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9720.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  44%|███    | 327/744 [24:03<30:40,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10228.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  44%|███    | 328/744 [24:08<30:36,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9244.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  44%|███    | 329/744 [24:12<30:32,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8654.9043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  44%|███    | 330/744 [24:17<30:28,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9220.4600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  44%|███    | 331/744 [24:21<30:23,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9337.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  45%|███    | 332/744 [24:26<30:19,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8946.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  45%|███▏   | 333/744 [24:30<30:14,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10807.1299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  45%|███▏   | 334/744 [24:34<30:10,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10628.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  45%|███▏   | 335/744 [24:39<30:05,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9110.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  45%|███▏   | 336/744 [24:43<30:01,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10038.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  45%|███▏   | 337/744 [24:47<29:56,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9578.7822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  45%|███▏   | 338/744 [24:51<29:51,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8777.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  46%|███▏   | 339/744 [24:55<29:47,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8577.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  46%|███▏   | 340/744 [25:00<29:42,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9768.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  46%|███▏   | 341/744 [25:04<29:38,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9864.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  46%|███▏   | 342/744 [25:08<29:33,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8867.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  46%|███▏   | 343/744 [25:12<29:28,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8569.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  46%|███▏   | 344/744 [25:17<29:23,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9704.8350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  46%|███▏   | 345/744 [25:21<29:19,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8996.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  47%|███▎   | 346/744 [25:25<29:15,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9741.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  47%|███▎   | 347/744 [25:29<29:10,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8978.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  47%|███▎   | 348/744 [25:34<29:05,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10693.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0769, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  47%|███▎   | 349/744 [25:38<29:00,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10174.9424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  47%|███▎   | 350/744 [25:42<28:56,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9580.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  47%|███▎   | 351/744 [25:46<28:51,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9127.5303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  47%|███▎   | 352/744 [25:51<28:47,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10652.8584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  47%|███▎   | 353/744 [25:55<28:43,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9718.2354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  48%|███▎   | 354/744 [25:59<28:38,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11082.8135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  48%|███▎   | 355/744 [26:04<28:33,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11061.4326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  48%|███▎   | 356/744 [26:08<28:29,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9853.4033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  48%|███▎   | 357/744 [26:13<28:25,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11153.3721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  48%|███▎   | 358/744 [26:17<28:20,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9769.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  48%|███▍   | 359/744 [26:21<28:16,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10338.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  48%|███▍   | 360/744 [26:26<28:12,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9503.7139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  49%|███▍   | 361/744 [26:30<28:07,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9269.8730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  49%|███▍   | 362/744 [26:34<28:02,  4.41s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10163.2314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  49%|███▍   | 363/744 [26:38<27:58,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10822.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  49%|███▍   | 364/744 [26:43<27:53,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9729.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  49%|███▍   | 365/744 [26:47<27:49,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10844.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  49%|███▍   | 366/744 [26:51<27:44,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10540.1846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  49%|███▍   | 367/744 [26:55<27:39,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9134.2900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  49%|███▍   | 368/744 [27:00<27:35,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10975.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  50%|███▍   | 369/744 [27:04<27:30,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9676.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  50%|███▍   | 370/744 [27:08<27:26,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8386.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  50%|███▍   | 371/744 [27:12<27:21,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10358.4033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  50%|███▌   | 372/744 [27:16<27:16,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9133.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  50%|███▌   | 373/744 [27:20<27:11,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9625.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  50%|███▌   | 374/744 [27:25<27:07,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10586.8545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  50%|███▌   | 375/744 [27:29<27:02,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11505.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  51%|███▌   | 376/744 [27:33<26:58,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9279.3506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  51%|███▌   | 377/744 [27:37<26:53,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9262.5166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  51%|███▌   | 378/744 [27:41<26:49,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9267.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  51%|███▌   | 379/744 [27:46<26:44,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10295.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  51%|███▌   | 380/744 [27:50<26:40,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10195.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  51%|███▌   | 381/744 [27:54<26:35,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10431.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3084, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  51%|███▌   | 382/744 [27:59<26:31,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9566.2217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  51%|███▌   | 383/744 [28:03<26:26,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9979.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  52%|███▌   | 384/744 [28:07<26:21,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10272.0869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  52%|███▌   | 385/744 [28:11<26:17,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10055.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  52%|███▋   | 386/744 [28:15<26:12,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9982.0732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  52%|███▋   | 387/744 [28:20<26:08,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10655.6748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  52%|███▋   | 388/744 [28:24<26:03,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12206.5439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  52%|███▋   | 389/744 [28:28<25:59,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9670.8916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  52%|███▋   | 390/744 [28:32<25:54,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10458.3701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  53%|███▋   | 391/744 [28:37<25:50,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10111.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  53%|███▋   | 392/744 [28:41<25:45,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10220.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  53%|███▋   | 393/744 [28:45<25:41,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9788.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  53%|███▋   | 394/744 [28:49<25:36,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9793.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  53%|███▋   | 395/744 [28:54<25:32,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10427.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  53%|███▋   | 396/744 [28:58<25:27,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9355.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  53%|███▋   | 397/744 [29:02<25:23,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9787.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  53%|███▋   | 398/744 [29:06<25:18,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9684.4971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  54%|███▊   | 399/744 [29:11<25:14,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10670.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  54%|███▊   | 400/744 [29:15<25:09,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10692.4600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  54%|███▊   | 401/744 [29:19<25:05,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10551.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  54%|███▊   | 402/744 [29:24<25:01,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10650.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  54%|███▊   | 403/744 [29:28<24:56,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10991.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  54%|███▊   | 404/744 [29:33<24:52,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11509.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  54%|███▊   | 405/744 [29:37<24:48,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9957.5947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  55%|███▊   | 406/744 [29:42<24:43,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10536.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  55%|███▊   | 407/744 [29:46<24:39,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10459.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  55%|███▊   | 408/744 [29:50<24:34,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11076.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  55%|███▊   | 409/744 [29:54<24:30,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10605.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  55%|███▊   | 410/744 [29:59<24:25,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9041.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  55%|███▊   | 411/744 [30:03<24:21,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10755.4980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  55%|███▉   | 412/744 [30:07<24:16,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10716.4541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  56%|███▉   | 413/744 [30:12<24:12,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11024.3418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  56%|███▉   | 414/744 [30:16<24:08,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9736.0693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  56%|███▉   | 415/744 [30:20<24:03,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10662.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  56%|███▉   | 416/744 [30:24<23:58,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9929.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.4178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  56%|███▉   | 417/744 [30:29<23:54,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9645.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  56%|███▉   | 418/744 [30:33<23:50,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11185.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  56%|███▉   | 419/744 [30:38<23:46,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11683.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2886, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  56%|███▉   | 420/744 [30:42<23:41,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9817.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  57%|███▉   | 421/744 [30:47<23:37,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11721.9561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  57%|███▉   | 422/744 [30:51<23:32,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10179.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  57%|███▉   | 423/744 [30:55<23:28,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11379.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  57%|███▉   | 424/744 [31:00<23:23,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10380.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  57%|███▉   | 425/744 [31:04<23:19,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10162.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  57%|████   | 426/744 [31:08<23:15,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11392.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0843, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  57%|████   | 427/744 [31:13<23:10,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12023.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  58%|████   | 428/744 [31:18<23:06,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11051.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  58%|████   | 429/744 [31:22<23:02,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11359.3027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  58%|████   | 430/744 [31:26<22:57,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10489.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  58%|████   | 431/744 [31:31<22:53,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10894.6748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  58%|████   | 432/744 [31:35<22:49,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10513.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  58%|████   | 433/744 [31:40<22:45,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10700.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  58%|████   | 434/744 [31:44<22:40,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10078.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  58%|████   | 435/744 [31:49<22:36,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9964.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  59%|████   | 436/744 [31:53<22:31,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9982.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  59%|████   | 437/744 [31:57<22:27,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10535.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  59%|████   | 438/744 [32:01<22:22,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10111.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  59%|████▏  | 439/744 [32:05<22:17,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10667.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  59%|████▏  | 440/744 [32:09<22:13,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11311.3330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  59%|████▏  | 441/744 [32:13<22:08,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10517.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  59%|████▏  | 442/744 [32:18<22:04,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9819.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  60%|████▏  | 443/744 [32:22<21:59,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8846.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  60%|████▏  | 444/744 [32:26<21:55,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11140.3076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  60%|████▏  | 445/744 [32:30<21:50,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10178.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  60%|████▏  | 446/744 [32:35<21:46,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10634.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  60%|████▏  | 447/744 [32:39<21:42,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11829.2715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  60%|████▏  | 448/744 [32:44<21:37,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10904.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  60%|████▏  | 449/744 [32:48<21:33,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11152.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  60%|████▏  | 450/744 [32:51<21:28,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11619.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  61%|████▏  | 451/744 [32:56<21:23,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11083.7744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0203, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  61%|████▎  | 452/744 [32:59<21:19,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10453.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  61%|████▎  | 453/744 [33:04<21:14,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10758.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  61%|████▎  | 454/744 [33:08<21:10,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11840.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  61%|████▎  | 455/744 [33:13<21:06,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10348.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  61%|████▎  | 456/744 [33:17<21:01,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10305.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  61%|████▎  | 457/744 [33:21<20:57,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11109.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2455, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  62%|████▎  | 458/744 [33:26<20:52,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11302.7705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  62%|████▎  | 459/744 [33:30<20:48,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9830.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  62%|████▎  | 460/744 [33:34<20:43,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11355.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  62%|████▎  | 461/744 [33:39<20:39,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11563.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  62%|████▎  | 462/744 [33:43<20:34,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10202.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  62%|████▎  | 463/744 [33:46<20:30,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11447.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  62%|████▎  | 464/744 [33:51<20:25,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10520.1553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  62%|████▍  | 465/744 [33:55<20:21,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12343.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  63%|████▍  | 466/744 [33:59<20:16,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11001.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  63%|████▍  | 467/744 [34:04<20:12,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11342.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  63%|████▍  | 468/744 [34:07<20:07,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9942.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  63%|████▍  | 469/744 [34:11<20:03,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10352.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  63%|████▍  | 470/744 [34:16<19:58,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10237.2041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  63%|████▍  | 471/744 [34:20<19:54,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12087.1768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  63%|████▍  | 472/744 [34:24<19:49,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10592.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  64%|████▍  | 473/744 [34:28<19:45,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12015.0166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  64%|████▍  | 474/744 [34:33<19:40,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(8862.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  64%|████▍  | 475/744 [34:37<19:36,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10254.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  64%|████▍  | 476/744 [34:41<19:32,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11935.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  64%|████▍  | 477/744 [34:46<19:27,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10574.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  64%|████▍  | 478/744 [34:50<19:23,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11331.9014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  64%|████▌  | 479/744 [34:55<19:19,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9690.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  65%|████▌  | 480/744 [34:59<19:14,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11926.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  65%|████▌  | 481/744 [35:03<19:10,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10110.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  65%|████▌  | 482/744 [35:08<19:05,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10927.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  65%|████▌  | 483/744 [35:12<19:01,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11764.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  65%|████▌  | 484/744 [35:17<18:57,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11057.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  65%|████▌  | 485/744 [35:21<18:52,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12714.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  65%|████▌  | 486/744 [35:26<18:48,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10233.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  65%|████▌  | 487/744 [35:30<18:44,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11258.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  66%|████▌  | 488/744 [35:34<18:39,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11082.6729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  66%|████▌  | 489/744 [35:40<18:36,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9953.7900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  66%|████▌  | 490/744 [35:44<18:31,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11894.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  66%|████▌  | 491/744 [35:49<18:27,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11033.9365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  66%|████▋  | 492/744 [35:53<18:23,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10738.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  66%|████▋  | 493/744 [35:57<18:18,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12465.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  66%|████▋  | 494/744 [36:02<18:14,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11186.3027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  67%|████▋  | 495/744 [36:06<18:09,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10982.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0577, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|████▋  | 496/744 [36:11<18:05,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10848.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  67%|████▋  | 497/744 [36:15<18:01,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12383.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  67%|████▋  | 498/744 [36:19<17:56,  4.38s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10622.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  67%|████▋  | 499/744 [36:22<17:51,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9657.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  67%|████▋  | 500/744 [36:27<17:47,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11750.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  67%|████▋  | 501/744 [36:31<17:42,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12503.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  67%|████▋  | 502/744 [36:35<17:38,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11500.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  68%|████▋  | 503/744 [36:39<17:33,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9754.1553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  68%|████▋  | 504/744 [36:43<17:29,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10777.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  68%|████▊  | 505/744 [36:47<17:24,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9758.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  68%|████▊  | 506/744 [36:52<17:20,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10093.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  68%|████▊  | 507/744 [36:56<17:16,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11715.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  68%|████▊  | 508/744 [37:00<17:11,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12160.1689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9203, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  68%|████▊  | 509/744 [37:05<17:07,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11622.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  69%|████▊  | 510/744 [37:09<17:02,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12127.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  69%|████▊  | 511/744 [37:13<16:58,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11138.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  69%|████▊  | 512/744 [37:17<16:53,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12529.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  69%|████▊  | 513/744 [37:21<16:49,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11708.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  69%|████▊  | 514/744 [37:25<16:45,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11941.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  69%|████▊  | 515/744 [37:30<16:40,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11206.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  69%|████▊  | 516/744 [37:34<16:36,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12597.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  69%|████▊  | 517/744 [37:38<16:31,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10936.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  70%|████▊  | 518/744 [37:42<16:27,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12304.6006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  70%|████▉  | 519/744 [37:46<16:22,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11009.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1715, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  70%|████▉  | 520/744 [37:51<16:18,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11283.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  70%|████▉  | 521/744 [37:55<16:14,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13036.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  70%|████▉  | 522/744 [38:00<16:09,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12329.3027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  70%|████▉  | 523/744 [38:04<16:05,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12619.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  70%|████▉  | 524/744 [38:08<16:00,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11645.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0148, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  71%|████▉  | 525/744 [38:12<15:56,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11041.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  71%|████▉  | 526/744 [38:16<15:51,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11436.2041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  71%|████▉  | 527/744 [38:20<15:47,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11995.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  71%|████▉  | 528/744 [38:25<15:43,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12063.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  71%|████▉  | 529/744 [38:29<15:38,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13651.2256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  71%|████▉  | 530/744 [38:33<15:34,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12041.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  71%|████▉  | 531/744 [38:38<15:29,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11000.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  72%|█████  | 532/744 [38:42<15:25,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12822.6299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  72%|█████  | 533/744 [38:46<15:21,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11770.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9954, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  72%|█████  | 534/744 [38:51<15:16,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12321.9189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  72%|█████  | 535/744 [38:55<15:12,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12161.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  72%|█████  | 536/744 [39:00<15:08,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10957.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  72%|█████  | 537/744 [39:04<15:03,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11144.5322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  72%|█████  | 538/744 [39:08<14:59,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12227.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  72%|█████  | 539/744 [39:12<14:54,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11142.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  73%|█████  | 540/744 [39:17<14:50,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12158.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  73%|█████  | 541/744 [39:21<14:46,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11419.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  73%|█████  | 542/744 [39:25<14:41,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11120.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  73%|█████  | 543/744 [39:30<14:37,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11926.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  73%|█████  | 544/744 [39:34<14:33,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10761.9131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  73%|█████▏ | 545/744 [39:39<14:28,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11811.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  73%|█████▏ | 546/744 [39:43<14:24,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11407.6904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  74%|█████▏ | 547/744 [39:47<14:20,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10530.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  74%|█████▏ | 548/744 [39:51<14:15,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12979.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  74%|█████▏ | 549/744 [39:55<14:10,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13285.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  74%|█████▏ | 550/744 [39:59<14:06,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11910.2158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  74%|█████▏ | 551/744 [40:03<14:01,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12074.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  74%|█████▏ | 552/744 [40:08<13:57,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11572.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  74%|█████▏ | 553/744 [40:12<13:53,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13207.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  74%|█████▏ | 554/744 [40:17<13:48,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11132.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  75%|█████▏ | 555/744 [40:21<13:44,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12535.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  75%|█████▏ | 556/744 [40:25<13:40,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12287.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  75%|█████▏ | 557/744 [40:29<13:35,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11111.5381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  75%|█████▎ | 558/744 [40:33<13:31,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12077.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  75%|█████▎ | 559/744 [40:38<13:26,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13219.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  75%|█████▎ | 560/744 [40:42<13:22,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11554.4600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  75%|█████▎ | 561/744 [40:51<13:19,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13415.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  76%|█████▎ | 562/744 [40:55<13:15,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11913.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  76%|█████▎ | 563/744 [40:59<13:10,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11478.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  76%|█████▎ | 564/744 [41:04<13:06,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12702.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  76%|█████▎ | 565/744 [41:08<13:02,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11139.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  76%|█████▎ | 566/744 [41:12<12:57,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13077.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  76%|█████▎ | 567/744 [41:17<12:53,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14406.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  76%|█████▎ | 568/744 [41:21<12:48,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10915.8291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  76%|█████▎ | 569/744 [41:25<12:44,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12101.8252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  77%|█████▎ | 570/744 [41:29<12:39,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12761.0576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  77%|█████▎ | 571/744 [41:33<12:35,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12334.9365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2446, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  77%|█████▍ | 572/744 [41:38<12:31,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11123.1045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  77%|█████▍ | 573/744 [41:42<12:26,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12006.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  77%|█████▍ | 574/744 [41:46<12:22,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12188.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  77%|█████▍ | 575/744 [41:50<12:17,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12250.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  77%|█████▍ | 576/744 [41:55<12:13,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12590.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  78%|█████▍ | 577/744 [41:59<12:09,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11992.7139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  78%|█████▍ | 578/744 [42:03<12:04,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11113.6885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  78%|█████▍ | 579/744 [42:07<12:00,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11735.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  78%|█████▍ | 580/744 [42:11<11:55,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12524.1768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  78%|█████▍ | 581/744 [42:16<11:51,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12369.8955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  78%|█████▍ | 582/744 [42:20<11:47,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11841.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  78%|█████▍ | 583/744 [42:24<11:42,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12862.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  78%|█████▍ | 584/744 [42:29<11:38,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12020.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  79%|█████▌ | 585/744 [42:33<11:34,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13767.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  79%|█████▌ | 586/744 [42:40<11:30,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12240.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  79%|█████▌ | 587/744 [42:44<11:25,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(9511.7490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  79%|█████▌ | 588/744 [42:48<11:21,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11243.5566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  79%|█████▌ | 589/744 [42:53<11:17,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11324.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  79%|█████▌ | 590/744 [42:57<11:12,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12029.6592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  79%|█████▌ | 591/744 [43:01<11:08,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12001.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  80%|█████▌ | 592/744 [43:05<11:03,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11848.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  80%|█████▌ | 593/744 [43:10<10:59,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13679.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  80%|█████▌ | 594/744 [43:14<10:55,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11768.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  80%|█████▌ | 595/744 [43:18<10:50,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12258.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  80%|█████▌ | 596/744 [43:22<10:46,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12822.4189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  80%|█████▌ | 597/744 [43:26<10:41,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12772.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  80%|█████▋ | 598/744 [43:30<10:37,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13278.5488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  81%|█████▋ | 599/744 [43:35<10:33,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11821.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  81%|█████▋ | 600/744 [43:39<10:28,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11339.8271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  81%|█████▋ | 601/744 [43:43<10:24,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12374.8564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  81%|█████▋ | 602/744 [43:48<10:19,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14185.8916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  81%|█████▋ | 603/744 [43:52<10:15,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12742.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  81%|█████▋ | 604/744 [43:56<10:11,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11278.1279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  81%|█████▋ | 605/744 [44:00<10:06,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12032.7705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  81%|█████▋ | 606/744 [44:04<10:02,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12543.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  82%|█████▋ | 607/744 [44:09<09:58,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11741.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  82%|█████▋ | 608/744 [44:13<09:53,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12350.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  82%|█████▋ | 609/744 [44:18<09:49,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13642.6533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0149, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  82%|█████▋ | 610/744 [44:22<09:44,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11886.1504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  82%|█████▋ | 611/744 [44:27<09:40,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11872.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  82%|█████▊ | 612/744 [44:31<09:36,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13394.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  82%|█████▊ | 613/744 [44:35<09:31,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13408.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  83%|█████▊ | 614/744 [44:40<09:27,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12834.0498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  83%|█████▊ | 615/744 [44:44<09:23,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11951.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  83%|█████▊ | 616/744 [44:48<09:18,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11084.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  83%|█████▊ | 617/744 [44:53<09:14,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11594.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  83%|█████▊ | 618/744 [44:57<09:09,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12393.7178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  83%|█████▊ | 619/744 [45:01<09:05,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12491.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  83%|█████▊ | 620/744 [45:05<09:01,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13481.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  83%|█████▊ | 621/744 [45:10<08:56,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13682.2998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  84%|█████▊ | 622/744 [45:14<08:52,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12554.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  84%|█████▊ | 623/744 [45:19<08:48,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14002.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  84%|█████▊ | 624/744 [45:23<08:43,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12319.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  84%|█████▉ | 625/744 [45:27<08:39,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10483.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  84%|█████▉ | 626/744 [45:32<08:35,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13058.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  84%|█████▉ | 627/744 [45:36<08:30,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12884.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  84%|█████▉ | 628/744 [45:40<08:26,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13159.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  85%|█████▉ | 629/744 [45:45<08:21,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11821.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  85%|█████▉ | 630/744 [45:49<08:17,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12438.0869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  85%|█████▉ | 631/744 [45:53<08:13,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12071.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  85%|█████▉ | 632/744 [45:58<08:08,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12438.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  85%|█████▉ | 633/744 [46:02<08:04,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13049.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  85%|█████▉ | 634/744 [46:07<08:00,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13170.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  85%|█████▉ | 635/744 [46:11<07:55,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13809.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  85%|█████▉ | 636/744 [46:15<07:51,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10489.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  86%|█████▉ | 637/744 [46:19<07:46,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12214.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  86%|██████ | 638/744 [46:24<07:42,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12357.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  86%|██████ | 639/744 [46:29<07:38,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12750.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  86%|██████ | 640/744 [46:33<07:33,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13155.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  86%|██████ | 641/744 [46:37<07:29,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12320.0068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  86%|██████ | 642/744 [46:42<07:25,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12956.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  86%|██████ | 643/744 [46:46<07:20,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13514.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  87%|██████ | 644/744 [46:50<07:16,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13850.7178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  87%|██████ | 645/744 [46:55<07:12,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12842.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  87%|██████ | 646/744 [46:59<07:07,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12121.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  87%|██████ | 647/744 [47:03<07:03,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12998.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0610, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  87%|██████ | 648/744 [47:07<06:58,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14477.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  87%|██████ | 649/744 [47:12<06:54,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10169.7646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  87%|██████ | 650/744 [47:16<06:50,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13846.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  88%|██████▏| 651/744 [47:20<06:45,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11473.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  88%|██████▏| 652/744 [47:24<06:41,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13493.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  88%|██████▏| 653/744 [47:28<06:36,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(10842.2061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  88%|██████▏| 654/744 [47:32<06:32,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13540.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  88%|██████▏| 655/744 [47:36<06:28,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12466.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  88%|██████▏| 656/744 [47:40<06:23,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14231.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  88%|██████▏| 657/744 [47:44<06:19,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12735.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  88%|██████▏| 658/744 [47:49<06:14,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13810.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  89%|██████▏| 659/744 [47:53<06:10,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11589.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  89%|██████▏| 660/744 [47:58<06:06,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13450.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  89%|██████▏| 661/744 [48:03<06:02,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14087.8037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  89%|██████▏| 662/744 [48:07<05:57,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14979.6416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  89%|██████▏| 663/744 [48:11<05:53,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13281.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  89%|██████▏| 664/744 [48:15<05:48,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12202.2373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  89%|██████▎| 665/744 [48:19<05:44,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11712.6260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  90%|██████▎| 666/744 [48:24<05:40,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13689.3350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  90%|██████▎| 667/744 [48:29<05:35,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11963.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  90%|██████▎| 668/744 [48:33<05:31,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13338.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  90%|██████▎| 669/744 [48:37<05:27,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12207.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  90%|██████▎| 670/744 [48:41<05:22,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12175.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  90%|██████▎| 671/744 [48:46<05:18,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12932.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  90%|██████▎| 672/744 [48:49<05:13,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13122.8037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  90%|██████▎| 673/744 [48:53<05:09,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12553.9971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  91%|██████▎| 674/744 [48:57<05:05,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14215.2080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  91%|██████▎| 675/744 [49:01<05:00,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13085.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  91%|██████▎| 676/744 [49:05<04:56,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14482.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  91%|██████▎| 677/744 [49:09<04:51,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11259.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  91%|██████▍| 678/744 [49:13<04:47,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12795.4287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  91%|██████▍| 679/744 [49:18<04:43,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13643.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  91%|██████▍| 680/744 [49:22<04:38,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13031.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  92%|██████▍| 681/744 [49:26<04:34,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15012.7627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  92%|██████▍| 682/744 [49:31<04:30,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13741.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  92%|██████▍| 683/744 [49:35<04:25,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13731.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0277, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  92%|██████▍| 684/744 [49:39<04:21,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12740.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  92%|██████▍| 685/744 [49:43<04:16,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13335.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  92%|██████▍| 686/744 [49:48<04:12,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13688.1709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  92%|██████▍| 687/744 [49:52<04:08,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13666.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  92%|██████▍| 688/744 [49:56<04:03,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13835.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  93%|██████▍| 689/744 [50:00<03:59,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13012.9346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  93%|██████▍| 690/744 [50:04<03:55,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13208.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  93%|██████▌| 691/744 [50:08<03:50,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14857.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  93%|██████▌| 692/744 [50:13<03:46,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13818.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  93%|██████▌| 693/744 [50:17<03:42,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13144.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  93%|██████▌| 694/744 [50:21<03:37,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12996.0420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  93%|██████▌| 695/744 [50:25<03:33,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11373.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  94%|██████▌| 696/744 [50:29<03:28,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13786.9717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  94%|██████▌| 697/744 [50:34<03:24,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13320.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  94%|██████▌| 698/744 [50:38<03:20,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14742.9014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  94%|██████▌| 699/744 [50:42<03:15,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13864.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  94%|██████▌| 700/744 [50:46<03:11,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11705.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  94%|██████▌| 701/744 [50:50<03:07,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13732.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  94%|██████▌| 702/744 [50:54<03:02,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13872.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  94%|██████▌| 703/744 [50:58<02:58,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15316.5439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  95%|██████▌| 704/744 [51:02<02:54,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12651.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  95%|██████▋| 705/744 [51:07<02:49,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12329.5771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  95%|██████▋| 706/744 [51:11<02:45,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13967.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  95%|██████▋| 707/744 [51:16<02:40,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13169.5518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  95%|██████▋| 708/744 [51:20<02:36,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12517.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  95%|██████▋| 709/744 [51:24<02:32,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14078.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  95%|██████▋| 710/744 [51:29<02:27,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13211.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  96%|██████▋| 711/744 [51:33<02:23,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14629.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  96%|██████▋| 712/744 [51:37<02:19,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12618.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  96%|██████▋| 713/744 [51:41<02:14,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15385.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  96%|██████▋| 714/744 [51:45<02:10,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13017.1084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  96%|██████▋| 715/744 [51:50<02:06,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14235.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  96%|██████▋| 716/744 [51:54<02:01,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14193.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  96%|██████▋| 717/744 [51:59<01:57,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14065.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  97%|██████▊| 718/744 [52:03<01:53,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13703.1846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  97%|██████▊| 719/744 [52:07<01:48,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12951.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  97%|██████▊| 720/744 [52:14<01:44,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14817.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  97%|██████▊| 721/744 [52:18<01:40,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12985.3574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  97%|██████▊| 722/744 [52:22<01:35,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14551.5293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  97%|██████▊| 723/744 [52:27<01:31,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14380.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9555, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97%|██████▊| 724/744 [52:31<01:27,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14022.3564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  97%|██████▊| 725/744 [52:36<01:22,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14249.6729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  98%|██████▊| 726/744 [52:40<01:18,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12154.3027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  98%|██████▊| 727/744 [52:44<01:14,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13915.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  98%|██████▊| 728/744 [52:49<01:09,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13842.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  98%|██████▊| 729/744 [52:53<01:05,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14160.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  98%|██████▊| 730/744 [52:57<01:00,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13316.8896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  98%|██████▉| 731/744 [53:01<00:56,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13338.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  98%|██████▉| 732/744 [53:05<00:52,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14120.0596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  99%|██████▉| 733/744 [53:09<00:47,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13731.6943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  99%|██████▉| 734/744 [53:14<00:43,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14735.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  99%|██████▉| 735/744 [53:18<00:39,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13219.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  99%|██████▉| 736/744 [53:22<00:34,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13726.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  99%|██████▉| 737/744 [53:26<00:30,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12849.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  99%|██████▉| 738/744 [53:31<00:26,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15250.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  99%|██████▉| 739/744 [53:35<00:21,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14976.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0203, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0:  99%|██████▉| 740/744 [53:39<00:17,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14223.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0: 100%|██████▉| 741/744 [53:43<00:13,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14504.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0: 100%|██████▉| 742/744 [53:47<00:08,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(11603.8467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0: 100%|██████▉| 743/744 [53:51<00:04,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12385.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   0%|                 | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(14741.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   0%|       | 1/744 [00:06<1:19:34,  6.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13228.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   0%|       | 2/744 [00:10<1:04:18,  5.20s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14209.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   0%|         | 3/744 [00:14<58:45,  4.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12786.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   1%|         | 4/744 [00:18<56:56,  4.62s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14251.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1593, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   1%|         | 5/744 [00:23<57:58,  4.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12833.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   1%|         | 6/744 [00:27<57:15,  4.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15274.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   1%|         | 7/744 [00:32<56:25,  4.59s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13997.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   1%|         | 8/744 [00:36<55:14,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14748.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   1%|         | 9/744 [00:40<54:43,  4.47s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13970.0186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   1%|        | 10/744 [00:44<54:02,  4.42s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13613.0674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   1%|        | 11/744 [00:48<53:38,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13659.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0316, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   2%|▏       | 12/744 [00:52<53:42,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15184.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   2%|▏       | 13/744 [00:57<53:36,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14091.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   2%|▏       | 14/744 [01:01<53:11,  4.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15719.9150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9984, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   2%|▏       | 15/744 [01:05<52:49,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13428.9775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   2%|▏       | 16/744 [01:09<52:54,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13646.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   2%|▏       | 17/744 [01:13<52:35,  4.34s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14633.5654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1194, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏       | 18/744 [01:17<52:15,  4.32s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12914.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   3%|▏       | 19/744 [01:21<52:07,  4.31s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14688.8721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   3%|▏       | 20/744 [01:26<52:04,  4.32s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15942.3311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   3%|▏       | 21/744 [01:30<51:47,  4.30s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14889.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   3%|▏       | 22/744 [01:34<51:40,  4.29s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15020.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   3%|▏       | 23/744 [01:38<51:38,  4.30s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13199.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   3%|▎       | 24/744 [01:42<51:24,  4.28s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14887.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   3%|▎       | 25/744 [01:47<51:20,  4.28s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13703.3301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   3%|▎       | 26/744 [01:51<51:12,  4.28s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12475.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   4%|▎       | 27/744 [01:55<50:59,  4.27s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14208.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   4%|▎       | 28/744 [01:59<50:55,  4.27s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15189.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   4%|▎       | 29/744 [02:03<50:45,  4.26s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14258.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   4%|▎       | 30/744 [02:07<50:32,  4.25s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14633.6230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   4%|▎       | 31/744 [02:11<50:27,  4.25s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14463.4834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   4%|▎       | 32/744 [02:15<50:24,  4.25s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15138.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   4%|▎       | 33/744 [02:20<50:18,  4.24s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15558.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   5%|▎       | 34/744 [02:23<50:06,  4.23s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14258.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   5%|▍       | 35/744 [02:28<50:02,  4.24s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14047.2490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   5%|▍       | 36/744 [02:32<49:56,  4.23s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13964.6709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9740, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   5%|▍       | 37/744 [02:36<49:52,  4.23s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13450.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   5%|▍       | 38/744 [02:40<49:46,  4.23s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14789.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   5%|▍       | 39/744 [02:44<49:36,  4.22s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13691.3447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   5%|▍       | 40/744 [02:48<49:28,  4.22s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13233.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   6%|▍       | 41/744 [02:52<49:23,  4.22s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14541.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   6%|▍       | 42/744 [02:56<49:12,  4.21s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13232.6963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   6%|▍       | 43/744 [03:00<49:01,  4.20s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15142.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   6%|▍       | 44/744 [03:04<48:55,  4.19s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12673.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   6%|▍       | 45/744 [03:08<48:54,  4.20s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16297.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   6%|▍       | 46/744 [03:13<48:49,  4.20s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14480.3936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   6%|▌       | 47/744 [03:17<48:44,  4.20s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13530.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   6%|▌       | 48/744 [03:21<48:39,  4.19s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15905.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   7%|▌       | 49/744 [03:25<48:28,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13178.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   7%|▌       | 50/744 [03:28<48:19,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13652.8115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   7%|▌       | 51/744 [03:32<48:09,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13175.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   7%|▌       | 52/744 [03:36<48:02,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13921.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   7%|▌       | 53/744 [03:40<48:00,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14054.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   7%|▌       | 54/744 [03:45<47:58,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14908.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   7%|▌       | 55/744 [03:49<47:55,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13341.9229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1193, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▌       | 56/744 [03:53<47:50,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12875.0615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   8%|▌       | 57/744 [03:57<47:43,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13528.3418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   8%|▌       | 58/744 [04:01<47:40,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14679.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   8%|▋       | 59/744 [04:05<47:33,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14141.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   8%|▋       | 60/744 [04:09<47:28,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15379.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   8%|▋       | 61/744 [04:13<47:21,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15460.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   8%|▋       | 62/744 [04:17<47:17,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14914.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   8%|▋       | 63/744 [04:22<47:17,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15636.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   9%|▋       | 64/744 [04:26<47:10,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14882.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   9%|▋       | 65/744 [04:30<47:01,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16502.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   9%|▋       | 66/744 [04:34<46:57,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13242.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   9%|▋       | 67/744 [04:38<46:53,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14053.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   9%|▋       | 68/744 [04:42<46:50,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13556.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   9%|▋       | 69/744 [04:46<46:47,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14917.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:   9%|▊       | 70/744 [04:51<46:44,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14848.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  10%|▊       | 71/744 [04:55<46:41,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15648.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  10%|▊       | 72/744 [04:59<46:38,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15857.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  10%|▊       | 73/744 [05:04<46:38,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13465.5186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  10%|▊       | 74/744 [05:08<46:34,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15389.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  10%|▊       | 75/744 [05:13<46:32,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14501.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  10%|▊       | 76/744 [05:17<46:28,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15792.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  10%|▊       | 77/744 [05:21<46:26,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15178.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  10%|▊       | 78/744 [05:25<46:19,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16623.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  11%|▊       | 79/744 [05:30<46:20,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14493.7744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  11%|▊       | 80/744 [05:34<46:16,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13620.4160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  11%|▊       | 81/744 [05:38<46:14,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15276.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  11%|▉       | 82/744 [05:42<46:08,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16174.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0070, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  11%|▉       | 83/744 [05:46<46:02,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15729.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  11%|▉       | 84/744 [05:50<45:57,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13910.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  11%|▉       | 85/744 [05:55<45:53,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15503.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  12%|▉       | 86/744 [05:59<45:49,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15002.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  12%|▉       | 87/744 [06:03<45:47,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15360.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  12%|▉       | 88/744 [06:07<45:41,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13566.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  12%|▉       | 89/744 [06:12<45:39,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15163.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  12%|▉       | 90/744 [06:16<45:35,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15449.7822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  12%|▉       | 91/744 [06:20<45:32,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17098.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  12%|▉       | 92/744 [06:24<45:25,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13496.5293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  12%|█       | 93/744 [06:28<45:20,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12843.2129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1955, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█       | 94/744 [06:33<45:18,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13932.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  13%|█       | 95/744 [06:37<45:15,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15794.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  13%|█       | 96/744 [06:41<45:13,  4.19s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15473.4590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  13%|█       | 97/744 [06:46<45:09,  4.19s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15906.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  13%|█       | 98/744 [06:50<45:04,  4.19s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17235.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  13%|█       | 99/744 [06:54<44:59,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13867.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  13%|▉      | 100/744 [06:58<44:54,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16036.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  14%|▉      | 101/744 [07:02<44:48,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15254.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  14%|▉      | 102/744 [07:06<44:44,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13431.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  14%|▉      | 103/744 [07:10<44:38,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13306.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  14%|▉      | 104/744 [07:14<44:36,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14035.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  14%|▉      | 105/744 [07:19<44:32,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13247.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  14%|▉      | 106/744 [07:23<44:29,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15730.2334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  14%|█      | 107/744 [07:27<44:23,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14749.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  15%|█      | 108/744 [07:31<44:18,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14752.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  15%|█      | 109/744 [07:35<44:13,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15414.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  15%|█      | 110/744 [07:39<44:08,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13362.1787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  15%|█      | 111/744 [07:43<44:04,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16609.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  15%|█      | 112/744 [07:47<43:59,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15129.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  15%|█      | 113/744 [07:52<43:56,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15900.6689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  15%|█      | 114/744 [07:55<43:50,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15881.4326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  15%|█      | 115/744 [08:00<43:46,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14413.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  16%|█      | 116/744 [08:04<43:41,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15006.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  16%|█      | 117/744 [08:08<43:37,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14044.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  16%|█      | 118/744 [08:12<43:31,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13170.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  16%|█      | 119/744 [08:16<43:27,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14951.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  16%|█▏     | 120/744 [08:20<43:22,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16549.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  16%|█▏     | 121/744 [08:24<43:18,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16031.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  16%|█▏     | 122/744 [08:28<43:12,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14397.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  17%|█▏     | 123/744 [08:32<43:08,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15209.2686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1103, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  17%|█▏     | 124/744 [08:37<43:05,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17220.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  17%|█▏     | 125/744 [08:41<43:02,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14302.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  17%|█▏     | 126/744 [08:45<42:58,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14997.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  17%|█▏     | 127/744 [08:49<42:54,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14185.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  17%|█▏     | 128/744 [08:54<42:50,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15118.9775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  17%|█▏     | 129/744 [08:58<42:45,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15710.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  17%|█▏     | 130/744 [09:02<42:42,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16748.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  18%|█▏     | 131/744 [09:06<42:36,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16476.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0368, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  18%|█▏     | 132/744 [09:09<42:29,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14598.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  18%|█▎     | 133/744 [09:14<42:26,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16169.7080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  18%|█▎     | 134/744 [09:18<42:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15528.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  18%|█▎     | 135/744 [09:22<42:18,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14535.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  18%|█▎     | 136/744 [09:26<42:14,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15535.9795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  18%|█▎     | 137/744 [09:31<42:13,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15165.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  19%|█▎     | 138/744 [09:35<42:08,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14948.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  19%|█▎     | 139/744 [09:40<42:04,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14929.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  19%|█▎     | 140/744 [09:44<42:01,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17149.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  19%|█▎     | 141/744 [09:48<41:56,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16113.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  19%|█▎     | 142/744 [09:52<41:51,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14470.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  19%|█▎     | 143/744 [09:56<41:46,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15315.8135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  19%|█▎     | 144/744 [10:00<41:42,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17652.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  19%|█▎     | 145/744 [10:04<41:38,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14833.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  20%|█▎     | 146/744 [10:09<41:35,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15090.5908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  20%|█▍     | 147/744 [10:13<41:32,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15639.6592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  20%|█▍     | 148/744 [10:17<41:27,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15601.6689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  20%|█▍     | 149/744 [10:21<41:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13855.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  20%|█▍     | 150/744 [10:26<41:19,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14919.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  20%|█▍     | 151/744 [10:30<41:16,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16163.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  20%|█▍     | 152/744 [10:34<41:11,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15522.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  21%|█▍     | 153/744 [10:38<41:07,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15968.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  21%|█▍     | 154/744 [10:43<41:03,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16122.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  21%|█▍     | 155/744 [10:47<41:00,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15355.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  21%|█▍     | 156/744 [10:51<40:55,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16802.8652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  21%|█▍     | 157/744 [10:55<40:50,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16625.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  21%|█▍     | 158/744 [10:59<40:46,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16046.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  21%|█▍     | 159/744 [11:03<40:42,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15081.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  22%|█▌     | 160/744 [11:08<40:38,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14889.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0601, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  22%|█▌     | 161/744 [11:11<40:31,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15505.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  22%|█▌     | 162/744 [11:15<40:27,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16339.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  22%|█▌     | 163/744 [11:20<40:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14077.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  22%|█▌     | 164/744 [11:24<40:19,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17052.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  22%|█▌     | 165/744 [11:27<40:14,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16910.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  22%|█▌     | 166/744 [11:31<40:08,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17045.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  22%|█▌     | 167/744 [11:35<40:04,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16003.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  23%|█▌     | 168/744 [11:40<40:01,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16179.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  23%|█▌     | 169/744 [11:44<39:57,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15547.7549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1744, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  23%|█▌     | 170/744 [11:48<39:52,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14993.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  23%|█▌     | 171/744 [11:52<39:48,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(12776.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  23%|█▌     | 172/744 [11:56<39:44,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15470.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  23%|█▋     | 173/744 [12:01<39:40,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15030.2705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  23%|█▋     | 174/744 [12:05<39:36,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16349.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  24%|█▋     | 175/744 [12:09<39:32,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14500.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  24%|█▋     | 176/744 [12:13<39:27,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16809.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  24%|█▋     | 177/744 [12:17<39:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15546.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  24%|█▋     | 178/744 [12:21<39:18,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15944.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  24%|█▋     | 179/744 [12:25<39:13,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14698.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  24%|█▋     | 180/744 [12:29<39:09,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14664.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  24%|█▋     | 181/744 [12:34<39:05,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14342.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  24%|█▋     | 182/744 [12:38<39:02,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16179.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  25%|█▋     | 183/744 [12:42<38:58,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16218.9482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  25%|█▋     | 184/744 [12:46<38:54,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16175.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  25%|█▋     | 185/744 [12:51<38:50,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14776.8311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  25%|█▊     | 186/744 [12:55<38:45,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15569.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  25%|█▊     | 187/744 [12:59<38:41,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16744.9043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  25%|█▊     | 188/744 [13:03<38:37,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17310.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  25%|█▊     | 189/744 [13:07<38:33,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13957.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  26%|█▊     | 190/744 [13:12<38:30,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16922.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  26%|█▊     | 191/744 [13:16<38:27,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16055.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  26%|█▊     | 192/744 [13:21<38:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15224.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  26%|█▊     | 193/744 [13:25<38:19,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14712.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  26%|█▊     | 194/744 [13:29<38:15,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15334.8057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  26%|█▊     | 195/744 [13:33<38:10,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14169.7119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  26%|█▊     | 196/744 [13:37<38:05,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15371.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  26%|█▊     | 197/744 [13:41<38:01,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16781.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  27%|█▊     | 198/744 [13:45<37:56,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17411.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  27%|█▊     | 199/744 [13:49<37:51,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15470.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  27%|█▉     | 200/744 [13:53<37:47,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16246.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  27%|█▉     | 201/744 [13:57<37:42,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14041.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  27%|█▉     | 202/744 [14:01<37:37,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15003.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  27%|█▉     | 203/744 [14:05<37:33,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15618.8730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  27%|█▉     | 204/744 [14:09<37:29,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16602.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  28%|█▉     | 205/744 [14:13<37:25,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16971.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  28%|█▉     | 206/744 [14:18<37:21,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15594.6982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.3205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  28%|█▉     | 207/744 [14:22<37:17,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13873.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9833, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  28%|█▉     | 208/744 [14:26<37:12,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15040.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  28%|█▉     | 209/744 [14:30<37:08,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16982.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  28%|█▉     | 210/744 [14:35<37:05,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16556.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  28%|█▉     | 211/744 [14:38<37:00,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15239.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  28%|█▉     | 212/744 [14:43<36:56,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16367.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  29%|██     | 213/744 [14:47<36:51,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15269.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  29%|██     | 214/744 [14:51<36:47,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16136.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  29%|██     | 215/744 [14:55<36:43,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15220.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  29%|██     | 216/744 [14:59<36:38,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17945.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  29%|██     | 217/744 [15:03<36:33,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14882.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  29%|██     | 218/744 [15:07<36:29,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15616.8271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  29%|██     | 219/744 [15:11<36:25,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17378.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  30%|██     | 220/744 [15:16<36:22,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16236.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  30%|██     | 221/744 [15:20<36:18,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15926.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  30%|██     | 222/744 [15:25<36:16,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16251.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  30%|██     | 223/744 [15:30<36:12,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17662.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  30%|██     | 224/744 [15:34<36:09,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18121.4980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  30%|██     | 225/744 [15:38<36:05,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15415.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  30%|██▏    | 226/744 [15:42<36:01,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15330.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  31%|██▏    | 227/744 [15:47<35:56,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15926.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  31%|██▏    | 228/744 [15:51<35:52,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13606.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  31%|██▏    | 229/744 [15:55<35:48,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14799.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  31%|██▏    | 230/744 [15:59<35:44,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16123.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  31%|██▏    | 231/744 [16:03<35:40,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13991.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  31%|██▏    | 232/744 [16:07<35:34,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14835.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  31%|██▏    | 233/744 [16:11<35:31,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14954.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  31%|██▏    | 234/744 [16:16<35:27,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15853.8330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  32%|██▏    | 235/744 [16:20<35:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17936.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  32%|██▏    | 236/744 [16:24<35:19,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17631.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  32%|██▏    | 237/744 [16:28<35:15,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15846.6357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  32%|██▏    | 238/744 [16:33<35:11,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14940.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  32%|██▏    | 239/744 [16:37<35:07,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16424.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  32%|██▎    | 240/744 [16:42<35:04,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16031.3174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  32%|██▎    | 241/744 [16:46<35:00,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15786.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  33%|██▎    | 242/744 [16:50<34:55,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16508.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  33%|██▎    | 243/744 [16:54<34:51,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16118.4971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  33%|██▎    | 244/744 [16:58<34:46,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(13216.8662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  33%|██▎    | 245/744 [17:02<34:42,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17365.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1353, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  33%|██▎    | 246/744 [17:07<34:39,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18654.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  33%|██▎    | 247/744 [17:11<34:35,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17081.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  33%|██▎    | 248/744 [17:15<34:30,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16208.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  33%|██▎    | 249/744 [17:19<34:25,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15138.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  34%|██▎    | 250/744 [17:23<34:21,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14799.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  34%|██▎    | 251/744 [17:27<34:16,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15314.2842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  34%|██▎    | 252/744 [17:31<34:12,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16506.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  34%|██▍    | 253/744 [17:35<34:09,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14609.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  34%|██▍    | 254/744 [17:40<34:04,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16079.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  34%|██▍    | 255/744 [17:44<34:01,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16876.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  34%|██▍    | 256/744 [17:48<33:56,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14910.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  35%|██▍    | 257/744 [17:52<33:52,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16996.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  35%|██▍    | 258/744 [17:56<33:48,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15474.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  35%|██▍    | 259/744 [18:00<33:43,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15064.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  35%|██▍    | 260/744 [18:04<33:39,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17800.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  35%|██▍    | 261/744 [18:09<33:35,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16855.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  35%|██▍    | 262/744 [18:13<33:31,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15849.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  35%|██▍    | 263/744 [18:17<33:27,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16108.2920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  35%|██▍    | 264/744 [18:21<33:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15085.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  36%|██▍    | 265/744 [18:25<33:18,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16344.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  36%|██▌    | 266/744 [18:29<33:14,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18491.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  36%|██▌    | 267/744 [18:34<33:10,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18032.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  36%|██▌    | 268/744 [18:37<33:05,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17302.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  36%|██▌    | 269/744 [18:42<33:01,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14392.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  36%|██▌    | 270/744 [18:46<32:57,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17055.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  36%|██▌    | 271/744 [18:50<32:53,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16025.4033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  37%|██▌    | 272/744 [18:54<32:48,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17221.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  37%|██▌    | 273/744 [18:58<32:44,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17913.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  37%|██▌    | 274/744 [19:03<32:41,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17036.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  37%|██▌    | 275/744 [19:07<32:36,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14757.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  37%|██▌    | 276/744 [19:11<32:32,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15001.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  37%|██▌    | 277/744 [19:15<32:27,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17241.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  37%|██▌    | 278/744 [19:19<32:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16083.2021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  38%|██▋    | 279/744 [19:23<32:19,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14797.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  38%|██▋    | 280/744 [19:27<32:14,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14777.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  38%|██▋    | 281/744 [19:31<32:10,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15838.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  38%|██▋    | 282/744 [19:35<32:06,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16277.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  38%|██▋    | 283/744 [19:40<32:02,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18288.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1448, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  38%|██▋    | 284/744 [19:43<31:57,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17061.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  38%|██▋    | 285/744 [19:48<31:53,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15355.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  38%|██▋    | 286/744 [19:52<31:49,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17539.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  39%|██▋    | 287/744 [19:56<31:45,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15103.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  39%|██▋    | 288/744 [20:00<31:41,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16247.1279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  39%|██▋    | 289/744 [20:04<31:36,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15200.6943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  39%|██▋    | 290/744 [20:09<31:32,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17494.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  39%|██▋    | 291/744 [20:13<31:28,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14257.5439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  39%|██▋    | 292/744 [20:17<31:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15244.0615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  39%|██▊    | 293/744 [20:21<31:20,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16822.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  40%|██▊    | 294/744 [20:25<31:15,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20442.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  40%|██▊    | 295/744 [20:29<31:11,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15382.8311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  40%|██▊    | 296/744 [20:33<31:07,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17708.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  40%|██▊    | 297/744 [20:37<31:02,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18729.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0958, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  40%|██▊    | 298/744 [20:41<30:58,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16546.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  40%|██▊    | 299/744 [20:45<30:53,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16937.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  40%|██▊    | 300/744 [20:49<30:49,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15841.6621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  40%|██▊    | 301/744 [20:53<30:45,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16218.1865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  41%|██▊    | 302/744 [20:57<30:40,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15732.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  41%|██▊    | 303/744 [21:01<30:36,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15807.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  41%|██▊    | 304/744 [21:05<30:32,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15567.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  41%|██▊    | 305/744 [21:10<30:28,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16527.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  41%|██▉    | 306/744 [21:13<30:23,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15974.9678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  41%|██▉    | 307/744 [21:17<30:19,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15829.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  41%|██▉    | 308/744 [21:22<30:14,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16994.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  42%|██▉    | 309/744 [21:26<30:10,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17892.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  42%|██▉    | 310/744 [21:30<30:06,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17710.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  42%|██▉    | 311/744 [21:34<30:02,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17754.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  42%|██▉    | 312/744 [21:38<29:58,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18094.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  42%|██▉    | 313/744 [21:43<29:54,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17069.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  42%|██▉    | 314/744 [21:47<29:50,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16036.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  42%|██▉    | 315/744 [21:51<29:45,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14495.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  42%|██▉    | 316/744 [21:55<29:41,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16563.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  43%|██▉    | 317/744 [21:59<29:37,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17637.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  43%|██▉    | 318/744 [22:03<29:33,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17248.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  43%|███    | 319/744 [22:08<29:29,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17711.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  43%|███    | 320/744 [22:12<29:26,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19056.5801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  43%|███    | 321/744 [22:17<29:21,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15585.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0753, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  43%|███    | 322/744 [22:21<29:17,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16829.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  43%|███    | 323/744 [22:25<29:13,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18098.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  44%|███    | 324/744 [22:29<29:09,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16758.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  44%|███    | 325/744 [22:33<29:05,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18784.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  44%|███    | 326/744 [22:38<29:01,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17626.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  44%|███    | 327/744 [22:42<28:57,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16930.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  44%|███    | 328/744 [22:46<28:52,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17130.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  44%|███    | 329/744 [22:50<28:48,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15767.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  44%|███    | 330/744 [22:54<28:44,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15889.2041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  44%|███    | 331/744 [22:58<28:39,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18496.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0769, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  45%|███    | 332/744 [23:02<28:35,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14903.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  45%|███▏   | 333/744 [23:06<28:31,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15738.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  45%|███▏   | 334/744 [23:10<28:27,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18805.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  45%|███▏   | 335/744 [23:14<28:22,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17522.7402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  45%|███▏   | 336/744 [23:19<28:18,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18142.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1593, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  45%|███▏   | 337/744 [23:23<28:14,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18030.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  45%|███▏   | 338/744 [23:27<28:10,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17628.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  46%|███▏   | 339/744 [23:31<28:06,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14476.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  46%|███▏   | 340/744 [23:35<28:02,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16282.6943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  46%|███▏   | 341/744 [23:39<27:58,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17473.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  46%|███▏   | 342/744 [23:44<27:54,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15153.1865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  46%|███▏   | 343/744 [23:48<27:49,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16186.8252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  46%|███▏   | 344/744 [23:52<27:45,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18110.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  46%|███▏   | 345/744 [23:56<27:41,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16055.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  47%|███▎   | 346/744 [24:00<27:37,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15772.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  47%|███▎   | 347/744 [24:04<27:32,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17910.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  47%|███▎   | 348/744 [24:08<27:28,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17224.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  47%|███▎   | 349/744 [24:12<27:24,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15542.7607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  47%|███▎   | 350/744 [24:16<27:19,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15438.0635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  47%|███▎   | 351/744 [24:20<27:15,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17212.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  47%|███▎   | 352/744 [24:24<27:11,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18273.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  47%|███▎   | 353/744 [24:29<27:07,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16902.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  48%|███▎   | 354/744 [24:33<27:02,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17605.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  48%|███▎   | 355/744 [24:37<26:58,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17046.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  48%|███▎   | 356/744 [24:41<26:54,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17485.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  48%|███▎   | 357/744 [24:45<26:50,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17961.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  48%|███▎   | 358/744 [24:49<26:46,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17878.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  48%|███▍   | 359/744 [24:54<26:42,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18427.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1188, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  48%|███▍   | 360/744 [24:58<26:38,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16569.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  49%|███▍   | 361/744 [25:02<26:34,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18521.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  49%|███▍   | 362/744 [25:06<26:30,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16494.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  49%|███▍   | 363/744 [25:11<26:26,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17712.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  49%|███▍   | 364/744 [25:15<26:22,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18306.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  49%|███▍   | 365/744 [25:19<26:18,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18601.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  49%|███▍   | 366/744 [25:24<26:14,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17192.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  49%|███▍   | 367/744 [25:27<26:09,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16931.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  49%|███▍   | 368/744 [25:31<26:05,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16202.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  50%|███▍   | 369/744 [25:36<26:01,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16522.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  50%|███▍   | 370/744 [25:40<25:57,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15491.6416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  50%|███▍   | 371/744 [25:44<25:53,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15872.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  50%|███▌   | 372/744 [25:49<25:49,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17602.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  50%|███▌   | 373/744 [25:53<25:45,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17398.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2108, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  50%|███▌   | 374/744 [25:57<25:40,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18756.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  50%|███▌   | 375/744 [26:01<25:36,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18079.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  51%|███▌   | 376/744 [26:06<25:33,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17867.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  51%|███▌   | 377/744 [26:10<25:28,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17868.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  51%|███▌   | 378/744 [26:15<25:25,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18209.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  51%|███▌   | 379/744 [26:19<25:21,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17972.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  51%|███▌   | 380/744 [26:23<25:17,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16167.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  51%|███▌   | 381/744 [26:28<25:13,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14379.9795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  51%|███▌   | 382/744 [26:32<25:09,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16967.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  51%|███▌   | 383/744 [26:36<25:05,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16476.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  52%|███▌   | 384/744 [26:41<25:01,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19904.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  52%|███▌   | 385/744 [26:45<24:56,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15182.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  52%|███▋   | 386/744 [26:49<24:52,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18329.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  52%|███▋   | 387/744 [26:53<24:48,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15940.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  52%|███▋   | 388/744 [26:57<24:44,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16119.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  52%|███▋   | 389/744 [27:01<24:39,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16759.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  52%|███▋   | 390/744 [27:05<24:35,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18044.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  53%|███▋   | 391/744 [27:09<24:31,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18791.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  53%|███▋   | 392/744 [27:14<24:27,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18430.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  53%|███▋   | 393/744 [27:18<24:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16161.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  53%|███▋   | 394/744 [27:22<24:18,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15510.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  53%|███▋   | 395/744 [27:26<24:15,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18014.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9893, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  53%|███▋   | 396/744 [27:31<24:10,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18307.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  53%|███▋   | 397/744 [27:35<24:06,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16859.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0270, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  53%|███▋   | 398/744 [27:39<24:02,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16066.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  54%|███▊   | 399/744 [27:45<23:59,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16155.7998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  54%|███▊   | 400/744 [27:49<23:55,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17862.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  54%|███▊   | 401/744 [27:52<23:50,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18546.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  54%|███▊   | 402/744 [27:56<23:46,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17243.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  54%|███▊   | 403/744 [28:00<23:41,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18812.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  54%|███▊   | 404/744 [28:05<23:38,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16200.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  54%|███▊   | 405/744 [28:09<23:33,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17933.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  55%|███▊   | 406/744 [28:13<23:29,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18099.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  55%|███▊   | 407/744 [28:17<23:25,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14494.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  55%|███▊   | 408/744 [28:21<23:21,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17758.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  55%|███▊   | 409/744 [28:25<23:16,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16973.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  55%|███▊   | 410/744 [28:29<23:12,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16380.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  55%|███▊   | 411/744 [28:33<23:08,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18673.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  55%|███▉   | 412/744 [28:37<23:03,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16406.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  56%|███▉   | 413/744 [28:41<22:59,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16847.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  56%|███▉   | 414/744 [28:45<22:55,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15940.7471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  56%|███▉   | 415/744 [28:49<22:50,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17717.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  56%|███▉   | 416/744 [28:53<22:46,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18264.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  56%|███▉   | 417/744 [28:57<22:42,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17144.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  56%|███▉   | 418/744 [29:01<22:38,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17221.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  56%|███▉   | 419/744 [29:05<22:33,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16599.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  56%|███▉   | 420/744 [29:09<22:29,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19120.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  57%|███▉   | 421/744 [29:13<22:25,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18255.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  57%|███▉   | 422/744 [29:18<22:21,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16788.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  57%|███▉   | 423/744 [29:22<22:17,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17667.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  57%|███▉   | 424/744 [29:26<22:12,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18676.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  57%|███▉   | 425/744 [29:30<22:08,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17136.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  57%|████   | 426/744 [29:34<22:04,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18066.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  57%|████   | 427/744 [29:38<22:00,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19483.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  58%|████   | 428/744 [29:42<21:55,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18307.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  58%|████   | 429/744 [29:46<21:51,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16468.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  58%|████   | 430/744 [29:50<21:47,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17567.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  58%|████   | 431/744 [29:54<21:43,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16682.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  58%|████   | 432/744 [29:58<21:38,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16915.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0807, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  58%|████   | 433/744 [30:02<21:34,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16321.6064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.2058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  58%|████   | 434/744 [30:06<21:30,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16774.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  58%|████   | 435/744 [30:10<21:25,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18033.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1026, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  59%|████   | 436/744 [30:14<21:21,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17379.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  59%|████   | 437/744 [30:18<21:17,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18325.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1853, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  59%|████   | 438/744 [30:22<21:13,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14908.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  59%|████▏  | 439/744 [30:26<21:08,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17463.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  59%|████▏  | 440/744 [30:30<21:04,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17028.4941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  59%|████▏  | 441/744 [30:34<21:00,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17295.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  59%|████▏  | 442/744 [30:39<20:56,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17313.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  60%|████▏  | 443/744 [30:43<20:52,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18226.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  60%|████▏  | 444/744 [30:47<20:48,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16653.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  60%|████▏  | 445/744 [30:51<20:44,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17634.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  60%|████▏  | 446/744 [30:56<20:40,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17190.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  60%|████▏  | 447/744 [30:59<20:35,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17963.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  60%|████▏  | 448/744 [31:04<20:31,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16985.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  60%|████▏  | 449/744 [31:08<20:27,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17798.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  60%|████▏  | 450/744 [31:12<20:23,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18362.0684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  61%|████▏  | 451/744 [31:16<20:19,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16378.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  61%|████▎  | 452/744 [31:21<20:15,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18315.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  61%|████▎  | 453/744 [31:25<20:11,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17073.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  61%|████▎  | 454/744 [31:29<20:06,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18284.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  61%|████▎  | 455/744 [31:33<20:02,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18800.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  61%|████▎  | 456/744 [31:38<19:58,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19832.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  61%|████▎  | 457/744 [31:42<19:54,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19923.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  62%|████▎  | 458/744 [31:46<19:50,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18560.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  62%|████▎  | 459/744 [31:50<19:45,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18986.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  62%|████▎  | 460/744 [31:54<19:41,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18452.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  62%|████▎  | 461/744 [31:58<19:37,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18381.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  62%|████▎  | 462/744 [32:02<19:33,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19047.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  62%|████▎  | 463/744 [32:07<19:29,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19049.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  62%|████▎  | 464/744 [32:11<19:25,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17374.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  62%|████▍  | 465/744 [32:15<19:21,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15710.8721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  63%|████▍  | 466/744 [32:19<19:17,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19976.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  63%|████▍  | 467/744 [32:24<19:13,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17903.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  63%|████▍  | 468/744 [32:27<19:08,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15837.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  63%|████▍  | 469/744 [32:32<19:04,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19167.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  63%|████▍  | 470/744 [32:36<19:00,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18137.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  63%|████▍  | 471/744 [32:40<18:56,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16151.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  63%|████▍  | 472/744 [32:44<18:52,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(14529.8896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  64%|████▍  | 473/744 [32:48<18:47,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15692.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0960, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  64%|████▍  | 474/744 [32:52<18:43,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20511.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  64%|████▍  | 475/744 [32:57<18:39,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18934.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  64%|████▍  | 476/744 [33:01<18:35,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19400.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  64%|████▍  | 477/744 [33:05<18:31,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17175.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  64%|████▍  | 478/744 [33:09<18:27,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18677.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  64%|████▌  | 479/744 [33:13<18:23,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17056.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  65%|████▌  | 480/744 [33:17<18:18,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18696.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  65%|████▌  | 481/744 [33:21<18:14,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17417.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  65%|████▌  | 482/744 [33:25<18:10,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17371.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  65%|████▌  | 483/744 [33:30<18:06,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18299.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  65%|████▌  | 484/744 [33:34<18:02,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17860.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  65%|████▌  | 485/744 [33:38<17:57,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15006.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  65%|████▌  | 486/744 [33:42<17:53,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18529.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  65%|████▌  | 487/744 [33:46<17:49,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15646.6904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  66%|████▌  | 488/744 [33:50<17:45,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17985.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  66%|████▌  | 489/744 [33:54<17:40,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17839.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  66%|████▌  | 490/744 [33:58<17:36,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19091.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  66%|████▌  | 491/744 [34:02<17:32,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17938.4590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  66%|████▋  | 492/744 [34:06<17:28,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17580.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  66%|████▋  | 493/744 [34:10<17:23,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15681.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  66%|████▋  | 494/744 [34:14<17:19,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19744.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  67%|████▋  | 495/744 [34:18<17:15,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19153.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  67%|████▋  | 496/744 [34:22<17:11,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16148.9404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  67%|████▋  | 497/744 [34:26<17:07,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18772.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  67%|████▋  | 498/744 [34:30<17:02,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18088.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  67%|████▋  | 499/744 [34:34<16:58,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18779.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  67%|████▋  | 500/744 [34:38<16:54,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17030.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  67%|████▋  | 501/744 [34:43<16:50,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19511.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  67%|████▋  | 502/744 [34:47<16:46,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20363.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  68%|████▋  | 503/744 [34:51<16:42,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18104.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  68%|████▋  | 504/744 [34:55<16:37,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17478.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  68%|████▊  | 505/744 [34:59<16:33,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19045.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  68%|████▊  | 506/744 [35:03<16:29,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17607.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  68%|████▊  | 507/744 [35:07<16:25,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17331.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  68%|████▊  | 508/744 [35:11<16:20,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19559.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  68%|████▊  | 509/744 [35:15<16:16,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18224.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  69%|████▊  | 510/744 [35:19<16:12,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18040.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  69%|████▊  | 511/744 [35:24<16:08,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18947.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1102, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  69%|████▊  | 512/744 [35:28<16:04,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18464.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  69%|████▊  | 513/744 [35:32<16:00,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19586.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  69%|████▊  | 514/744 [35:36<15:56,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18243.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  69%|████▊  | 515/744 [35:40<15:51,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15591.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0593, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  69%|████▊  | 516/744 [35:45<15:47,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18191.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  69%|████▊  | 517/744 [35:48<15:43,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18349.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  70%|████▊  | 518/744 [35:53<15:39,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18746.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  70%|████▉  | 519/744 [35:57<15:35,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17066.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  70%|████▉  | 520/744 [36:01<15:31,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19032.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  70%|████▉  | 521/744 [36:05<15:26,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17807.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  70%|████▉  | 522/744 [36:09<15:22,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18491.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  70%|████▉  | 523/744 [36:13<15:18,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18729.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  70%|████▉  | 524/744 [36:17<15:14,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16376.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  71%|████▉  | 525/744 [36:21<15:10,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17192.4941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  71%|████▉  | 526/744 [36:25<15:05,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17916.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  71%|████▉  | 527/744 [36:29<15:01,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19644.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  71%|████▉  | 528/744 [36:33<14:57,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17914.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  71%|████▉  | 529/744 [36:37<14:53,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16933.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  71%|████▉  | 530/744 [36:41<14:49,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17748.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  71%|████▉  | 531/744 [36:45<14:44,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16591.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  72%|█████  | 532/744 [36:49<14:40,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18837.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  72%|█████  | 533/744 [36:53<14:36,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19034.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  72%|█████  | 534/744 [36:57<14:32,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17878.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  72%|█████  | 535/744 [37:01<14:27,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16191.9277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  72%|█████  | 536/744 [37:06<14:24,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19072.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  72%|█████  | 537/744 [37:10<14:19,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20568.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  72%|█████  | 538/744 [37:14<14:15,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18258.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  72%|█████  | 539/744 [37:18<14:11,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20175.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  73%|█████  | 540/744 [37:22<14:07,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19765.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  73%|█████  | 541/744 [37:26<14:02,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20185.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  73%|█████  | 542/744 [37:30<13:58,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18899.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  73%|█████  | 543/744 [37:34<13:54,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19370.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  73%|█████  | 544/744 [37:38<13:50,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17924.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  73%|█████▏ | 545/744 [37:42<13:46,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16157.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  73%|█████▏ | 546/744 [37:46<13:42,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15731.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  74%|█████▏ | 547/744 [37:51<13:37,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19122.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  74%|█████▏ | 548/744 [37:55<13:33,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18922.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  74%|█████▏ | 549/744 [37:59<13:29,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17242.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8851, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  74%|█████▏ | 550/744 [38:03<13:25,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17891.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  74%|█████▏ | 551/744 [38:07<13:21,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19181.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  74%|█████▏ | 552/744 [38:11<13:16,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17161.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  74%|█████▏ | 553/744 [38:15<13:12,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19715.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  74%|█████▏ | 554/744 [38:19<13:08,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19564.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  75%|█████▏ | 555/744 [38:23<13:04,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18928.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  75%|█████▏ | 556/744 [38:27<13:00,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19059.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  75%|█████▏ | 557/744 [38:31<12:55,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16922.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  75%|█████▎ | 558/744 [38:35<12:51,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18702.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  75%|█████▎ | 559/744 [38:39<12:47,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19356.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  75%|█████▎ | 560/744 [38:43<12:43,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18418.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  75%|█████▎ | 561/744 [38:47<12:39,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18052.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  76%|█████▎ | 562/744 [38:51<12:35,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17509.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  76%|█████▎ | 563/744 [38:55<12:30,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18511.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  76%|█████▎ | 564/744 [38:59<12:26,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16384.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  76%|█████▎ | 565/744 [39:03<12:22,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(15406.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  76%|█████▎ | 566/744 [39:07<12:18,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19391.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  76%|█████▎ | 567/744 [39:11<12:14,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16964.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  76%|█████▎ | 568/744 [39:15<12:09,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19235.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  76%|█████▎ | 569/744 [39:19<12:05,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18101.0684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  77%|█████▎ | 570/744 [39:23<12:01,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18258.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  77%|█████▎ | 571/744 [39:27<11:57,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18005.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  77%|█████▍ | 572/744 [39:32<11:53,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16909.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  77%|█████▍ | 573/744 [39:36<11:49,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19279.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  77%|█████▍ | 574/744 [39:40<11:44,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20764.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  77%|█████▍ | 575/744 [39:44<11:40,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18603.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  77%|█████▍ | 576/744 [39:48<11:36,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18345.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  78%|█████▍ | 577/744 [39:52<11:32,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16923.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  78%|█████▍ | 578/744 [39:57<11:28,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18610.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  78%|█████▍ | 579/744 [40:01<11:24,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16883.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  78%|█████▍ | 580/744 [40:05<11:20,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19035.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  78%|█████▍ | 581/744 [40:09<11:15,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19710.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  78%|█████▍ | 582/744 [40:13<11:11,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18866.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  78%|█████▍ | 583/744 [40:17<11:07,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17868.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  78%|█████▍ | 584/744 [40:21<11:03,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18340.0684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  79%|█████▌ | 585/744 [40:26<10:59,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19080.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  79%|█████▌ | 586/744 [40:29<10:55,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17941.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  79%|█████▌ | 587/744 [40:34<10:51,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19563.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0474, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  79%|█████▌ | 588/744 [40:38<10:46,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17044.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  79%|█████▌ | 589/744 [40:42<10:42,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17823.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  79%|█████▌ | 590/744 [40:46<10:38,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18281.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  79%|█████▌ | 591/744 [40:50<10:34,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17368.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  80%|█████▌ | 592/744 [40:55<10:30,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18660.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  80%|█████▌ | 593/744 [40:59<10:26,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18283.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  80%|█████▌ | 594/744 [41:03<10:22,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17962.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  80%|█████▌ | 595/744 [41:08<10:18,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19401.2793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  80%|█████▌ | 596/744 [41:12<10:13,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20900.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  80%|█████▌ | 597/744 [41:16<10:09,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19761.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  80%|█████▋ | 598/744 [41:21<10:05,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17142.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  81%|█████▋ | 599/744 [41:25<10:01,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18738.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  81%|█████▋ | 600/744 [41:29<09:57,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20293.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9885, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  81%|█████▋ | 601/744 [41:33<09:53,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19294.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  81%|█████▋ | 602/744 [41:37<09:49,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19822.3574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  81%|█████▋ | 603/744 [41:41<09:44,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18310.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  81%|█████▋ | 604/744 [41:45<09:40,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20061.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  81%|█████▋ | 605/744 [41:49<09:36,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18043.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  81%|█████▋ | 606/744 [41:54<09:32,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18714.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  82%|█████▋ | 607/744 [41:58<09:28,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17965.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  82%|█████▋ | 608/744 [42:02<09:24,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18226.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  82%|█████▋ | 609/744 [42:06<09:20,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19497.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  82%|█████▋ | 610/744 [42:10<09:15,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18699.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  82%|█████▋ | 611/744 [42:14<09:11,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19419.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  82%|█████▊ | 612/744 [42:18<09:07,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19012.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  82%|█████▊ | 613/744 [42:22<09:03,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17857.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  83%|█████▊ | 614/744 [42:26<08:59,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17091.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  83%|█████▊ | 615/744 [42:30<08:55,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19863.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  83%|█████▊ | 616/744 [42:35<08:50,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19784.7676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  83%|█████▊ | 617/744 [42:39<08:46,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19625.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  83%|█████▊ | 618/744 [42:43<08:42,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19021.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  83%|█████▊ | 619/744 [42:47<08:38,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16647.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  83%|█████▊ | 620/744 [42:51<08:34,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19954.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  83%|█████▊ | 621/744 [42:55<08:30,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19676.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  84%|█████▊ | 622/744 [42:59<08:25,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19561.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  84%|█████▊ | 623/744 [43:04<08:21,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19864.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  84%|█████▊ | 624/744 [43:08<08:17,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19335.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  84%|█████▉ | 625/744 [43:12<08:13,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19553.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9410, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  84%|█████▉ | 626/744 [43:16<08:09,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18438.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  84%|█████▉ | 627/744 [43:20<08:05,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19811.4590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  84%|█████▉ | 628/744 [43:24<08:01,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21380.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  85%|█████▉ | 629/744 [43:28<07:56,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19590.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  85%|█████▉ | 630/744 [43:33<07:52,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17659.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  85%|█████▉ | 631/744 [43:37<07:48,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21240.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  85%|█████▉ | 632/744 [43:41<07:44,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18904.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  85%|█████▉ | 633/744 [43:45<07:40,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21941.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  85%|█████▉ | 634/744 [43:49<07:36,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19877.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  85%|█████▉ | 635/744 [43:53<07:32,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21566.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  85%|█████▉ | 636/744 [43:57<07:27,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19451.8926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  86%|█████▉ | 637/744 [44:01<07:23,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20606.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  86%|██████ | 638/744 [44:05<07:19,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20451.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  86%|██████ | 639/744 [44:09<07:15,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19656.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  86%|██████ | 640/744 [44:13<07:11,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18195.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  86%|██████ | 641/744 [44:17<07:07,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18772.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  86%|██████ | 642/744 [44:21<07:02,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18852.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  86%|██████ | 643/744 [44:25<06:58,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19581.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  87%|██████ | 644/744 [44:30<06:54,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18939.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  87%|██████ | 645/744 [44:34<06:50,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19337.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  87%|██████ | 646/744 [44:37<06:46,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21596.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  87%|██████ | 647/744 [44:41<06:42,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19820.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  87%|██████ | 648/744 [44:46<06:37,  4.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18262.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  87%|██████ | 649/744 [44:49<06:33,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20299.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  87%|██████ | 650/744 [44:54<06:29,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20860.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  88%|██████▏| 651/744 [44:58<06:25,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20070.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  88%|██████▏| 652/744 [45:02<06:21,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18921.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  88%|██████▏| 653/744 [45:06<06:17,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19496.4355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  88%|██████▏| 654/744 [45:10<06:13,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19968.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  88%|██████▏| 655/744 [45:14<06:08,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18452.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  88%|██████▏| 656/744 [45:18<06:04,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20936.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8998, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  88%|██████▏| 657/744 [45:22<06:00,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20668.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  88%|██████▏| 658/744 [45:27<05:56,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19155.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  89%|██████▏| 659/744 [45:31<05:52,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21549.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  89%|██████▏| 660/744 [45:35<05:48,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20452.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  89%|██████▏| 661/744 [45:39<05:43,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17480.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  89%|██████▏| 662/744 [45:43<05:39,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20954.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  89%|██████▏| 663/744 [45:47<05:35,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18932.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9671, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  89%|██████▏| 664/744 [45:51<05:31,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20463.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  89%|██████▎| 665/744 [45:55<05:27,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18593.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  90%|██████▎| 666/744 [45:59<05:23,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19905.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  90%|██████▎| 667/744 [46:03<05:19,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20545.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  90%|██████▎| 668/744 [46:07<05:14,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19821.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  90%|██████▎| 669/744 [46:11<05:10,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19968.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  90%|██████▎| 670/744 [46:15<05:06,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17266.6230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  90%|██████▎| 671/744 [46:19<05:02,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18607.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  90%|██████▎| 672/744 [46:23<04:58,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20960.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  90%|██████▎| 673/744 [46:28<04:54,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16991.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  91%|██████▎| 674/744 [46:32<04:50,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20575.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  91%|██████▎| 675/744 [46:36<04:45,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16734.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  91%|██████▎| 676/744 [46:40<04:41,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17993.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  91%|██████▎| 677/744 [46:44<04:37,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19576.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  91%|██████▍| 678/744 [46:48<04:33,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19245.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  91%|██████▍| 679/744 [46:52<04:29,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19946.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  91%|██████▍| 680/744 [46:56<04:25,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20750.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  92%|██████▍| 681/744 [47:00<04:20,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20948.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  92%|██████▍| 682/744 [47:05<04:16,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20281.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  92%|██████▍| 683/744 [47:09<04:12,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20876.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  92%|██████▍| 684/744 [47:13<04:08,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17705.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  92%|██████▍| 685/744 [47:17<04:04,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20269.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  92%|██████▍| 686/744 [47:21<04:00,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21708.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  92%|██████▍| 687/744 [47:25<03:56,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20872.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  92%|██████▍| 688/744 [47:29<03:51,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21246.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  93%|██████▍| 689/744 [47:33<03:47,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18904.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  93%|██████▍| 690/744 [47:37<03:43,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19397.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  93%|██████▌| 691/744 [47:42<03:39,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20767.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  93%|██████▌| 692/744 [47:46<03:35,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20560.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  93%|██████▌| 693/744 [47:50<03:31,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18485.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  93%|██████▌| 694/744 [47:55<03:27,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20127.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  93%|██████▌| 695/744 [47:59<03:22,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21299.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  94%|██████▌| 696/744 [48:02<03:18,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19052.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0694, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  94%|██████▌| 697/744 [48:07<03:14,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20677.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  94%|██████▌| 698/744 [48:11<03:10,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18754.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  94%|██████▌| 699/744 [48:15<03:06,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19722.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  94%|██████▌| 700/744 [48:19<03:02,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20906.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  94%|██████▌| 701/744 [48:23<02:58,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19890.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0127, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  94%|██████▌| 702/744 [48:27<02:53,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17663.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  94%|██████▌| 703/744 [48:31<02:49,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17111.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  95%|██████▌| 704/744 [48:35<02:45,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21171.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  95%|██████▋| 705/744 [48:39<02:41,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20728.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  95%|██████▋| 706/744 [48:43<02:37,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19842.6113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  95%|██████▋| 707/744 [48:47<02:33,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21836.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  95%|██████▋| 708/744 [48:51<02:29,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17501.4355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  95%|██████▋| 709/744 [48:56<02:24,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20436.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  95%|██████▋| 710/744 [48:59<02:20,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21939.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  96%|██████▋| 711/744 [49:03<02:16,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19591.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  96%|██████▋| 712/744 [49:07<02:12,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19184.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  96%|██████▋| 713/744 [49:11<02:08,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19004.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  96%|██████▋| 714/744 [49:16<02:04,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22283.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  96%|██████▋| 715/744 [49:19<02:00,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18152.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  96%|██████▋| 716/744 [49:24<01:55,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21219.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  96%|██████▋| 717/744 [49:27<01:51,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21366.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  97%|██████▊| 718/744 [49:31<01:47,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20185.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  97%|██████▊| 719/744 [49:36<01:43,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20325.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  97%|██████▊| 720/744 [49:40<01:39,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18775.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  97%|██████▊| 721/744 [49:44<01:35,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18761.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  97%|██████▊| 722/744 [49:48<01:31,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18330.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  97%|██████▊| 723/744 [49:52<01:26,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21414.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  97%|██████▊| 724/744 [49:56<01:22,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18854.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  97%|██████▊| 725/744 [50:00<01:18,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20412.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  98%|██████▊| 726/744 [50:04<01:14,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20474.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  98%|██████▊| 727/744 [50:08<01:10,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19727.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  98%|██████▊| 728/744 [50:12<01:06,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20189.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  98%|██████▊| 729/744 [50:16<01:02,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18896.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  98%|██████▊| 730/744 [50:20<00:57,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17525.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  98%|██████▉| 731/744 [50:24<00:53,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20614.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  98%|██████▉| 732/744 [50:28<00:49,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19852.5488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  99%|██████▉| 733/744 [50:33<00:45,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18695.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  99%|██████▉| 734/744 [50:37<00:41,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19293.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0643, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  99%|██████▉| 735/744 [50:41<00:37,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17261.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  99%|██████▉| 736/744 [50:45<00:33,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19317.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  99%|██████▉| 737/744 [50:49<00:28,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21108.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  99%|██████▉| 738/744 [50:53<00:24,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20963.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1:  99%|██████▉| 739/744 [50:58<00:20,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20219.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9786, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  99%|██████▉| 740/744 [51:02<00:16,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20442.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1: 100%|██████▉| 741/744 [51:06<00:12,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20045.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1: 100%|██████▉| 742/744 [51:10<00:08,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21025.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1: 100%|██████▉| 743/744 [51:13<00:04,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19425.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   0%|                 | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(20019.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   0%|       | 1/744 [00:06<1:15:32,  6.10s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18282.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   0%|       | 2/744 [00:10<1:02:57,  5.09s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20551.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   0%|         | 3/744 [00:14<59:02,  4.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21082.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   1%|         | 4/744 [00:18<56:50,  4.61s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18558.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   1%|         | 5/744 [00:22<55:34,  4.51s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21566.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   1%|         | 6/744 [00:26<54:08,  4.40s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20513.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   1%|         | 7/744 [00:30<53:08,  4.33s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17790.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   1%|         | 8/744 [00:34<52:35,  4.29s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21884.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   1%|         | 9/744 [00:39<53:18,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20551.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   1%|        | 10/744 [00:43<52:49,  4.32s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20019.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9893, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   1%|        | 11/744 [00:47<52:47,  4.32s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19155.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   2%|▏       | 12/744 [00:51<52:15,  4.28s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18181.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   2%|▏       | 13/744 [00:55<51:37,  4.24s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19557.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   2%|▏       | 14/744 [00:58<51:15,  4.21s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22375.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   2%|▏       | 15/744 [01:02<50:45,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22009.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   2%|▏       | 16/744 [01:06<50:34,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19257.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   2%|▏       | 17/744 [01:10<50:24,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21168.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   2%|▏       | 18/744 [01:14<50:06,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19503.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   3%|▏       | 19/744 [01:18<49:44,  4.12s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19667.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   3%|▏       | 20/744 [01:22<49:36,  4.11s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20965.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   3%|▏       | 21/744 [01:26<49:29,  4.11s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21767.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   3%|▏       | 22/744 [01:30<49:28,  4.11s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19656.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   3%|▏       | 23/744 [01:34<49:19,  4.10s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19333.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   3%|▎       | 24/744 [01:38<49:04,  4.09s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20027.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   3%|▎       | 25/744 [01:42<48:57,  4.09s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19857.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   3%|▎       | 26/744 [01:46<48:53,  4.09s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20768.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   4%|▎       | 27/744 [01:50<48:47,  4.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22344.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   4%|▎       | 28/744 [01:54<48:39,  4.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20251.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   4%|▎       | 29/744 [01:58<48:37,  4.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21495.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   4%|▎       | 30/744 [02:02<48:30,  4.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20771.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   4%|▎       | 31/744 [02:06<48:25,  4.07s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20461.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   4%|▎       | 32/744 [02:10<48:16,  4.07s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20495.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   4%|▎       | 33/744 [02:14<48:08,  4.06s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19395.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9746, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   5%|▎       | 34/744 [02:17<48:00,  4.06s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20093.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   5%|▍       | 35/744 [02:21<47:47,  4.04s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21207.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   5%|▍       | 36/744 [02:25<47:49,  4.05s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17918.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   5%|▍       | 37/744 [02:29<47:39,  4.04s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19218.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   5%|▍       | 38/744 [02:33<47:28,  4.04s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20185.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   5%|▍       | 39/744 [02:36<47:16,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16281.5732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   5%|▍       | 40/744 [02:41<47:14,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20443.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   6%|▍       | 41/744 [02:44<47:09,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18823.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   6%|▍       | 42/744 [02:48<46:58,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20134.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   6%|▍       | 43/744 [02:52<46:49,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20465.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   6%|▍       | 44/744 [02:56<46:47,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19571.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   6%|▍       | 45/744 [03:00<46:43,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16413.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   6%|▍       | 46/744 [03:04<46:37,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21658.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   6%|▌       | 47/744 [03:08<46:36,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20509.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   6%|▌       | 48/744 [03:12<46:34,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20103.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   7%|▌       | 49/744 [03:16<46:25,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18481.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   7%|▌       | 50/744 [03:20<46:23,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19798.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   7%|▌       | 51/744 [03:24<46:15,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17744.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   7%|▌       | 52/744 [03:28<46:14,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19856.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   7%|▌       | 53/744 [03:32<46:14,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21522.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   7%|▌       | 54/744 [03:36<46:07,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18658.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   7%|▌       | 55/744 [03:40<46:03,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21422.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   8%|▌       | 56/744 [03:44<45:57,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21230.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   8%|▌       | 57/744 [03:48<45:56,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21131.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   8%|▌       | 58/744 [03:52<45:54,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19613.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   8%|▋       | 59/744 [03:56<45:48,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21524.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   8%|▋       | 60/744 [04:00<45:45,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21315.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   8%|▋       | 61/744 [04:05<45:43,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20380.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   8%|▋       | 62/744 [04:09<45:41,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20145.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   8%|▋       | 63/744 [04:12<45:33,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21280.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   9%|▋       | 64/744 [04:16<45:30,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19433.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   9%|▋       | 65/744 [04:20<45:26,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20887.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   9%|▋       | 66/744 [04:24<45:21,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19658.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   9%|▋       | 67/744 [04:28<45:17,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19557.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   9%|▋       | 68/744 [04:32<45:10,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19696.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   9%|▋       | 69/744 [04:36<45:08,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20932.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:   9%|▊       | 70/744 [04:40<45:04,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17920.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  10%|▊       | 71/744 [04:44<44:58,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16603.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9573, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  10%|▊       | 72/744 [04:48<44:53,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20389.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  10%|▊       | 73/744 [04:52<44:49,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19897.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  10%|▊       | 74/744 [04:56<44:45,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20651.2012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  10%|▊       | 75/744 [05:01<44:45,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19702.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  10%|▊       | 76/744 [05:05<44:44,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20738.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  10%|▊       | 77/744 [05:09<44:43,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20437.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  10%|▊       | 78/744 [05:14<44:42,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18476.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  11%|▊       | 79/744 [05:18<44:40,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20848.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  11%|▊       | 80/744 [05:22<44:37,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(16705.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  11%|▊       | 81/744 [05:26<44:33,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21611.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  11%|▉       | 82/744 [05:30<44:28,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21337.5293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  11%|▉       | 83/744 [05:34<44:22,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17160.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  11%|▉       | 84/744 [05:38<44:20,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21356.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  11%|▉       | 85/744 [05:42<44:14,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20125.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  12%|▉       | 86/744 [05:46<44:09,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22949.1934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  12%|▉       | 87/744 [05:50<44:07,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20154.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  12%|▉       | 88/744 [05:54<44:03,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18867.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  12%|▉       | 89/744 [05:58<43:58,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20645.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  12%|▉       | 90/744 [06:02<43:53,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22178.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  12%|▉       | 91/744 [06:06<43:48,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22114.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  12%|▉       | 92/744 [06:10<43:45,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20587.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  12%|█       | 93/744 [06:14<43:40,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21916.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  13%|█       | 94/744 [06:18<43:35,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18682.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  13%|█       | 95/744 [06:22<43:30,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19973.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  13%|█       | 96/744 [06:26<43:26,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20505.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  13%|█       | 97/744 [06:30<43:21,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20203.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  13%|█       | 98/744 [06:34<43:17,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22087.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  13%|█       | 99/744 [06:38<43:14,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21429.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  13%|▉      | 100/744 [06:41<43:08,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20005.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  14%|▉      | 101/744 [06:45<43:04,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20639.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  14%|▉      | 102/744 [06:49<43:00,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19293.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  14%|▉      | 103/744 [06:53<42:55,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21286.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  14%|▉      | 104/744 [06:57<42:51,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22223.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  14%|▉      | 105/744 [07:02<42:48,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20905.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  14%|▉      | 106/744 [07:06<42:44,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21771.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  14%|█      | 107/744 [07:09<42:38,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22160.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  15%|█      | 108/744 [07:13<42:34,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21126.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  15%|█      | 109/744 [07:18<42:31,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20117.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9818, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  15%|█      | 110/744 [07:21<42:27,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22319.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  15%|█      | 111/744 [07:25<42:22,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19957.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  15%|█      | 112/744 [07:30<42:19,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21862.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  15%|█      | 113/744 [07:34<42:17,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21430.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  15%|█      | 114/744 [07:38<42:14,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21086.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  15%|█      | 115/744 [07:42<42:10,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21972.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  16%|█      | 116/744 [07:46<42:06,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22258.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  16%|█      | 117/744 [07:50<42:02,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21815.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  16%|█      | 118/744 [07:54<41:56,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19820.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  16%|█      | 119/744 [07:58<41:52,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20217.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  16%|█▏     | 120/744 [08:02<41:47,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22798.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  16%|█▏     | 121/744 [08:06<41:43,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21183.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  16%|█▏     | 122/744 [08:10<41:39,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20171.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  17%|█▏     | 123/744 [08:14<41:36,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21210.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  17%|█▏     | 124/744 [08:18<41:32,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20508.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  17%|█▏     | 125/744 [08:22<41:27,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18415.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  17%|█▏     | 126/744 [08:26<41:24,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19918.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  17%|█▏     | 127/744 [08:30<41:20,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20990.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9632, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  17%|█▏     | 128/744 [08:34<41:16,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22247.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  17%|█▏     | 129/744 [08:38<41:12,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23651.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  17%|█▏     | 130/744 [08:42<41:09,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21572.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  18%|█▏     | 131/744 [08:46<41:05,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20825.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  18%|█▏     | 132/744 [08:50<41:00,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20852.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  18%|█▎     | 133/744 [08:54<40:56,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20388.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  18%|█▎     | 134/744 [08:58<40:52,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19032.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  18%|█▎     | 135/744 [09:03<40:49,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18934.6621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  18%|█▎     | 136/744 [09:07<40:46,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18693.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9958, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  18%|█▎     | 137/744 [09:11<40:43,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22807.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  19%|█▎     | 138/744 [09:15<40:39,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20484.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  19%|█▎     | 139/744 [09:19<40:35,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19247.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8774, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  19%|█▎     | 140/744 [09:23<40:31,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21654.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  19%|█▎     | 141/744 [09:27<40:25,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21809.8105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  19%|█▎     | 142/744 [09:31<40:21,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22768.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  19%|█▎     | 143/744 [09:34<40:16,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20795.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  19%|█▎     | 144/744 [09:38<40:10,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21258.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  19%|█▎     | 145/744 [09:42<40:06,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21212.5840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  20%|█▎     | 146/744 [09:46<40:03,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22611.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  20%|█▍     | 147/744 [09:50<39:58,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22279.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9460, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  20%|█▍     | 148/744 [09:54<39:54,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23925.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  20%|█▍     | 149/744 [09:58<39:48,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21799.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  20%|█▍     | 150/744 [10:01<39:43,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20593.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  20%|█▍     | 151/744 [10:06<39:41,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21690.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  20%|█▍     | 152/744 [10:10<39:38,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21826.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  21%|█▍     | 153/744 [10:14<39:34,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21746.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  21%|█▍     | 154/744 [10:19<39:32,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19770.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9769, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  21%|█▍     | 155/744 [10:23<39:28,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22268.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  21%|█▍     | 156/744 [10:27<39:24,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19883.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  21%|█▍     | 157/744 [10:31<39:21,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22003.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  21%|█▍     | 158/744 [10:35<39:17,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19948.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  21%|█▍     | 159/744 [10:39<39:12,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22295.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  22%|█▌     | 160/744 [10:43<39:08,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20696.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  22%|█▌     | 161/744 [10:47<39:04,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19956.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  22%|█▌     | 162/744 [10:51<39:00,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21623.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  22%|█▌     | 163/744 [10:55<38:56,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22339.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  22%|█▌     | 164/744 [10:59<38:52,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21843.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  22%|█▌     | 165/744 [11:03<38:48,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21248.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  22%|█▌     | 166/744 [11:07<38:44,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22417.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0070, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  22%|█▌     | 167/744 [11:11<38:41,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21030.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  23%|█▌     | 168/744 [11:15<38:37,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21615.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  23%|█▌     | 169/744 [11:20<38:33,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21532.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  23%|█▌     | 170/744 [11:23<38:28,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22258.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8593, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  23%|█▌     | 171/744 [11:27<38:23,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18025.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  23%|█▌     | 172/744 [11:31<38:19,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19473.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  23%|█▋     | 173/744 [11:35<38:15,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20248.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  23%|█▋     | 174/744 [11:39<38:11,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20538.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  24%|█▋     | 175/744 [11:43<38:07,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21075.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  24%|█▋     | 176/744 [11:47<38:02,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20834.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  24%|█▋     | 177/744 [11:51<37:58,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22174.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  24%|█▋     | 178/744 [11:55<37:54,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20237.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  24%|█▋     | 179/744 [11:59<37:51,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22844.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  24%|█▋     | 180/744 [12:03<37:47,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19731.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  24%|█▋     | 181/744 [12:07<37:43,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21696.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  24%|█▋     | 182/744 [12:11<37:39,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21754.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  25%|█▋     | 183/744 [12:15<37:34,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21242.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0125, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  25%|█▋     | 184/744 [12:19<37:30,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19840.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  25%|█▋     | 185/744 [12:23<37:26,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19462.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9248, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  25%|█▊     | 186/744 [12:27<37:22,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23218.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  25%|█▊     | 187/744 [12:31<37:18,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20997.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  25%|█▊     | 188/744 [12:35<37:13,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22791.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  25%|█▊     | 189/744 [12:39<37:10,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21101.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  26%|█▊     | 190/744 [12:43<37:06,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20689.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  26%|█▊     | 191/744 [12:47<37:02,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21097.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  26%|█▊     | 192/744 [12:51<36:58,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22312.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  26%|█▊     | 193/744 [12:55<36:54,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22309.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  26%|█▊     | 194/744 [12:59<36:49,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22427.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  26%|█▊     | 195/744 [13:03<36:44,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23004.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  26%|█▊     | 196/744 [13:07<36:40,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21428.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  26%|█▊     | 197/744 [13:11<36:36,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20932.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  27%|█▊     | 198/744 [13:14<36:32,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23612.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  27%|█▊     | 199/744 [13:19<36:28,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23093.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  27%|█▉     | 200/744 [13:23<36:24,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21781.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  27%|█▉     | 201/744 [13:27<36:20,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22311.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  27%|█▉     | 202/744 [13:30<36:15,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21822.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  27%|█▉     | 203/744 [13:34<36:11,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19000.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  27%|█▉     | 204/744 [13:39<36:08,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19546.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  28%|█▉     | 205/744 [13:43<36:04,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23643.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  28%|█▉     | 206/744 [13:47<36:01,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24302.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  28%|█▉     | 207/744 [13:51<35:57,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20125.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  28%|█▉     | 208/744 [13:55<35:53,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20145.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9774, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  28%|█▉     | 209/744 [13:59<35:49,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22858.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  28%|█▉     | 210/744 [14:03<35:45,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20628.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  28%|█▉     | 211/744 [14:07<35:41,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22291.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  28%|█▉     | 212/744 [14:11<35:37,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20738.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  29%|██     | 213/744 [14:15<35:32,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19237.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  29%|██     | 214/744 [14:19<35:28,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22322.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  29%|██     | 215/744 [14:23<35:24,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22742.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  29%|██     | 216/744 [14:27<35:20,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21343.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  29%|██     | 217/744 [14:31<35:16,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20542.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  29%|██     | 218/744 [14:35<35:11,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22306.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  29%|██     | 219/744 [14:39<35:07,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21890.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  30%|██     | 220/744 [14:43<35:03,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21877.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  30%|██     | 221/744 [14:47<34:59,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20344.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  30%|██     | 222/744 [14:51<34:55,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22287.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  30%|██     | 223/744 [14:55<34:51,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21736.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8686, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  30%|██     | 224/744 [14:58<34:46,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23237.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  30%|██     | 225/744 [15:02<34:42,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20102.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  30%|██▏    | 226/744 [15:07<34:39,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23278.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  31%|██▏    | 227/744 [15:11<34:35,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21139.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  31%|██▏    | 228/744 [15:15<34:31,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22647.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  31%|██▏    | 229/744 [15:19<34:28,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19589.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  31%|██▏    | 230/744 [15:23<34:24,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21112.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  31%|██▏    | 231/744 [15:27<34:20,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19028.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9213, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  31%|██▏    | 232/744 [15:32<34:17,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21166.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  31%|██▏    | 233/744 [15:36<34:13,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20629.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  31%|██▏    | 234/744 [15:40<34:09,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22510.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  32%|██▏    | 235/744 [15:44<34:05,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23294.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  32%|██▏    | 236/744 [15:48<34:02,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22655.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  32%|██▏    | 237/744 [15:52<33:58,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22170.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  32%|██▏    | 238/744 [15:56<33:54,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19361.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  32%|██▏    | 239/744 [16:01<33:51,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21472.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  32%|██▎    | 240/744 [16:05<33:47,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22440.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  32%|██▎    | 241/744 [16:09<33:43,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21870.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  33%|██▎    | 242/744 [16:13<33:39,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23249.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  33%|██▎    | 243/744 [16:17<33:35,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19418.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  33%|██▎    | 244/744 [16:21<33:31,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22023.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  33%|██▎    | 245/744 [16:25<33:27,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22989.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  33%|██▎    | 246/744 [16:29<33:23,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20837.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  33%|██▎    | 247/744 [16:33<33:18,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22527.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  33%|██▎    | 248/744 [16:37<33:14,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22339.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  33%|██▎    | 249/744 [16:41<33:11,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23431.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9998, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  34%|██▎    | 250/744 [16:45<33:06,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23016.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  34%|██▎    | 251/744 [16:49<33:03,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23553.2129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  34%|██▎    | 252/744 [16:53<32:58,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20611.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  34%|██▍    | 253/744 [16:57<32:54,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23652.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  34%|██▍    | 254/744 [17:01<32:50,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21427.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  34%|██▍    | 255/744 [17:05<32:47,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22324.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  34%|██▍    | 256/744 [17:10<32:43,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19984.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  35%|██▍    | 257/744 [17:13<32:39,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23980.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  35%|██▍    | 258/744 [17:18<32:35,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19333.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  35%|██▍    | 259/744 [17:21<32:30,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19661.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  35%|██▍    | 260/744 [17:26<32:27,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18463.5801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  35%|██▍    | 261/744 [17:30<32:23,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24193.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9633, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  35%|██▍    | 262/744 [17:34<32:19,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22518.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  35%|██▍    | 263/744 [17:38<32:15,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22184.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  35%|██▍    | 264/744 [17:42<32:11,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19876.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  36%|██▍    | 265/744 [17:46<32:07,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21232.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  36%|██▌    | 266/744 [17:50<32:03,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24938.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  36%|██▌    | 267/744 [17:55<32:01,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23416.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  36%|██▌    | 268/744 [17:59<31:57,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(18587.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9885, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  36%|██▌    | 269/744 [18:03<31:53,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21610.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  36%|██▌    | 270/744 [18:07<31:49,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22574.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  36%|██▌    | 271/744 [18:12<31:46,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22504.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  37%|██▌    | 272/744 [18:15<31:41,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24007.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  37%|██▌    | 273/744 [18:19<31:36,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22783.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  37%|██▌    | 274/744 [18:23<31:32,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23391.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  37%|██▌    | 275/744 [18:27<31:28,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20626.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  37%|██▌    | 276/744 [18:31<31:24,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22997.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  37%|██▌    | 277/744 [18:35<31:20,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22389.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  37%|██▌    | 278/744 [18:39<31:17,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23778.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  38%|██▋    | 279/744 [18:43<31:13,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19641.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  38%|██▋    | 280/744 [18:48<31:09,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23048.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  38%|██▋    | 281/744 [18:52<31:05,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23415.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  38%|██▋    | 282/744 [18:56<31:01,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22327.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  38%|██▋    | 283/744 [19:00<30:57,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23673.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  38%|██▋    | 284/744 [19:04<30:53,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22060.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  38%|██▋    | 285/744 [19:08<30:49,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22894.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  38%|██▋    | 286/744 [19:12<30:45,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23719.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  39%|██▋    | 287/744 [19:16<30:41,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21619.5801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  39%|██▋    | 288/744 [19:20<30:37,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23898.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  39%|██▋    | 289/744 [19:24<30:33,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22074.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  39%|██▋    | 290/744 [19:28<30:28,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22844.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  39%|██▋    | 291/744 [19:32<30:24,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20744.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  39%|██▋    | 292/744 [19:36<30:21,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21180.5254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  39%|██▊    | 293/744 [19:40<30:17,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21395.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  40%|██▊    | 294/744 [19:44<30:12,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20809.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  40%|██▊    | 295/744 [19:47<30:08,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22566.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  40%|██▊    | 296/744 [19:52<30:04,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19724.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  40%|██▊    | 297/744 [19:56<30:00,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24537.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  40%|██▊    | 298/744 [20:00<29:56,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21065.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  40%|██▊    | 299/744 [20:03<29:51,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23439.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0036, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  40%|██▊    | 300/744 [20:08<29:48,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20314.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  40%|██▊    | 301/744 [20:12<29:44,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21466.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  41%|██▊    | 302/744 [20:16<29:40,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19656.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  41%|██▊    | 303/744 [20:20<29:36,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22720.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  41%|██▊    | 304/744 [20:24<29:32,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21819.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  41%|██▊    | 305/744 [20:28<29:28,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21265.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  41%|██▉    | 306/744 [20:32<29:24,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21681.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  41%|██▉    | 307/744 [20:36<29:20,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22348.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  41%|██▉    | 308/744 [20:40<29:15,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24175.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  42%|██▉    | 309/744 [20:44<29:11,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22758.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  42%|██▉    | 310/744 [20:48<29:08,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22838.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  42%|██▉    | 311/744 [20:52<29:03,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21221.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  42%|██▉    | 312/744 [20:56<29:00,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22944.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  42%|██▉    | 313/744 [21:00<28:55,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21886.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  42%|██▉    | 314/744 [21:04<28:51,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21478.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  42%|██▉    | 315/744 [21:08<28:47,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23559.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  42%|██▉    | 316/744 [21:12<28:43,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23135.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  43%|██▉    | 317/744 [21:16<28:39,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21982.2012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  43%|██▉    | 318/744 [21:20<28:35,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25161.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  43%|███    | 319/744 [21:24<28:31,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22602.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  43%|███    | 320/744 [21:28<28:27,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21664.8301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  43%|███    | 321/744 [21:32<28:22,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22293.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  43%|███    | 322/744 [21:36<28:18,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21818.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  43%|███    | 323/744 [21:40<28:14,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20667.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  44%|███    | 324/744 [21:44<28:10,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21792.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  44%|███    | 325/744 [21:48<28:06,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24022.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  44%|███    | 326/744 [21:52<28:02,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20170.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  44%|███    | 327/744 [21:56<27:58,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25165.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  44%|███    | 328/744 [22:00<27:54,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19317.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  44%|███    | 329/744 [22:04<27:50,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22642.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  44%|███    | 330/744 [22:07<27:45,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21345.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9673, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  44%|███    | 331/744 [22:11<27:41,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22423.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  45%|███    | 332/744 [22:15<27:37,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22965.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  45%|███▏   | 333/744 [22:19<27:33,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23265.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  45%|███▏   | 334/744 [22:23<27:29,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20216.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  45%|███▏   | 335/744 [22:27<27:25,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24311.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  45%|███▏   | 336/744 [22:31<27:21,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21322.9277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  45%|███▏   | 337/744 [22:35<27:17,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21074.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9058, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  45%|███▏   | 338/744 [22:39<27:12,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23372.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  46%|███▏   | 339/744 [22:43<27:08,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20069.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  46%|███▏   | 340/744 [22:47<27:04,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21213.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  46%|███▏   | 341/744 [22:50<27:00,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20046.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  46%|███▏   | 342/744 [22:55<26:56,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22347.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  46%|███▏   | 343/744 [22:58<26:52,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21757.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  46%|███▏   | 344/744 [23:02<26:47,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23474.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9740, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  46%|███▏   | 345/744 [23:06<26:43,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22465.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  47%|███▎   | 346/744 [23:10<26:39,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26015.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  47%|███▎   | 347/744 [23:14<26:35,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24814.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  47%|███▎   | 348/744 [23:18<26:31,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22966.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  47%|███▎   | 349/744 [23:22<26:27,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22321.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  47%|███▎   | 350/744 [23:26<26:23,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24230.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  47%|███▎   | 351/744 [23:30<26:19,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22619.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  47%|███▎   | 352/744 [23:34<26:15,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21425.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9316, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  47%|███▎   | 353/744 [23:38<26:11,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24064.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  48%|███▎   | 354/744 [23:42<26:06,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22705.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  48%|███▎   | 355/744 [23:46<26:02,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22652.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  48%|███▎   | 356/744 [23:50<25:58,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24053.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  48%|███▎   | 357/744 [23:54<25:54,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22587.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  48%|███▎   | 358/744 [23:58<25:50,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24957.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  48%|███▍   | 359/744 [24:02<25:46,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22129.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  48%|███▍   | 360/744 [24:06<25:42,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23226.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  49%|███▍   | 361/744 [24:10<25:38,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24284.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  49%|███▍   | 362/744 [24:14<25:34,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22397.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  49%|███▍   | 363/744 [24:17<25:30,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23762.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  49%|███▍   | 364/744 [24:22<25:26,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21334.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  49%|███▍   | 365/744 [24:26<25:22,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22010.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  49%|███▍   | 366/744 [24:30<25:18,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22587.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  49%|███▍   | 367/744 [24:34<25:14,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23251.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  49%|███▍   | 368/744 [24:38<25:10,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22379.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  50%|███▍   | 369/744 [24:42<25:06,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24274.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  50%|███▍   | 370/744 [24:46<25:02,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20805.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  50%|███▍   | 371/744 [24:50<24:58,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20910.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  50%|███▌   | 372/744 [24:54<24:54,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24446.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  50%|███▌   | 373/744 [24:58<24:50,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23159.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  50%|███▌   | 374/744 [25:02<24:46,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22686.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  50%|███▌   | 375/744 [25:06<24:42,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20906.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9256, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  51%|███▌   | 376/744 [25:10<24:37,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21481.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9277, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  51%|███▌   | 377/744 [25:14<24:33,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24334.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  51%|███▌   | 378/744 [25:17<24:29,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24759.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  51%|███▌   | 379/744 [25:22<24:25,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22736.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  51%|███▌   | 380/744 [25:26<24:22,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22397.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  51%|███▌   | 381/744 [25:30<24:18,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21209.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  51%|███▌   | 382/744 [25:34<24:14,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22812.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  51%|███▌   | 383/744 [25:38<24:09,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22364.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  52%|███▌   | 384/744 [25:42<24:06,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22255.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  52%|███▌   | 385/744 [25:46<24:01,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25114.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  52%|███▋   | 386/744 [25:50<23:57,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19121.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  52%|███▋   | 387/744 [25:54<23:53,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20926.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  52%|███▋   | 388/744 [25:58<23:49,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19578.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  52%|███▋   | 389/744 [26:02<23:45,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23507.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  52%|███▋   | 390/744 [26:06<23:41,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24943.1934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  53%|███▋   | 391/744 [26:10<23:37,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24542.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  53%|███▋   | 392/744 [26:14<23:33,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22901.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_g:   tensor(23017.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  56%|███▉   | 416/744 [27:47<21:54,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25573.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  56%|███▉   | 417/744 [27:51<21:50,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24089.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  56%|███▉   | 418/744 [27:55<21:46,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23083.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  56%|███▉   | 419/744 [27:59<21:42,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23676.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  56%|███▉   | 420/744 [28:03<21:38,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23230.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  57%|███▉   | 421/744 [28:07<21:34,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22930.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  57%|███▉   | 422/744 [28:11<21:30,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25283.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  57%|███▉   | 423/744 [28:16<21:27,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(17838.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  57%|███▉   | 424/744 [28:20<21:23,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22801.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  57%|███▉   | 425/744 [28:24<21:19,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23938.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  57%|████   | 426/744 [28:28<21:15,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20946.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  57%|████   | 427/744 [28:32<21:11,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24823.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  58%|████   | 428/744 [28:36<21:07,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24378.8926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  58%|████   | 429/744 [28:40<21:03,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21824.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  58%|████   | 430/744 [28:44<20:59,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22569.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  58%|████   | 431/744 [28:48<20:55,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23187.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  58%|████   | 432/744 [28:52<20:51,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23225.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  58%|████   | 433/744 [28:56<20:47,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25003.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  58%|████   | 434/744 [29:00<20:43,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25511.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  58%|████   | 435/744 [29:04<20:38,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24490.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  59%|████   | 436/744 [29:07<20:34,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21011.1367, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  59%|████   | 437/744 [29:12<20:30,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22521.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  59%|████   | 438/744 [29:15<20:26,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21751.2012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  59%|████▏  | 439/744 [29:20<20:22,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24285.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  59%|████▏  | 440/744 [29:24<20:18,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23713.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  59%|████▏  | 441/744 [29:28<20:14,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23013.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  59%|████▏  | 442/744 [29:32<20:10,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21318.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  60%|████▏  | 443/744 [29:35<20:06,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24421.2715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  60%|████▏  | 444/744 [29:39<20:02,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22168.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  60%|████▏  | 445/744 [29:43<19:58,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24071.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  60%|████▏  | 446/744 [29:47<19:54,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21260.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  60%|████▏  | 447/744 [29:51<19:50,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20180.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  60%|████▏  | 448/744 [29:55<19:46,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22427.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  60%|████▏  | 449/744 [29:59<19:42,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22000.5293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9673, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  60%|████▏  | 450/744 [30:03<19:38,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21774.4160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  61%|████▏  | 451/744 [30:07<19:34,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24932.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  61%|████▎  | 452/744 [30:11<19:30,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23376.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  61%|████▎  | 453/744 [30:15<19:26,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24429.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  61%|████▎  | 454/744 [30:19<19:22,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23090.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  61%|████▎  | 455/744 [30:23<19:17,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25231.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  61%|████▎  | 456/744 [30:27<19:14,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23313.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  61%|████▎  | 457/744 [30:31<19:10,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24103.6230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  62%|████▎  | 458/744 [30:35<19:06,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23244.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  62%|████▎  | 459/744 [30:39<19:02,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23452.2129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  62%|████▎  | 460/744 [30:43<18:58,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21211.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  62%|████▎  | 461/744 [30:47<18:53,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23442.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  62%|████▎  | 462/744 [30:51<18:49,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24057.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  62%|████▎  | 463/744 [30:55<18:45,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23258.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9694, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  62%|████▎  | 464/744 [30:59<18:41,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24164.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  62%|████▍  | 465/744 [31:03<18:38,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22595.2793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  63%|████▍  | 466/744 [31:07<18:34,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23205.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  63%|████▍  | 467/744 [31:11<18:30,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21655.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  63%|████▍  | 468/744 [31:15<18:26,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25299.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  63%|████▍  | 469/744 [31:19<18:22,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23582.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  63%|████▍  | 470/744 [31:23<18:17,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24306.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  63%|████▍  | 471/744 [31:27<18:13,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22376.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  63%|████▍  | 472/744 [31:31<18:09,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21390.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  64%|████▍  | 473/744 [31:35<18:05,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21634.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  64%|████▍  | 474/744 [31:38<18:01,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22611.5859, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  64%|████▍  | 475/744 [31:43<17:57,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25548.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  64%|████▍  | 476/744 [31:46<17:53,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25946.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  64%|████▍  | 477/744 [31:50<17:49,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24748.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  64%|████▍  | 478/744 [31:54<17:45,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23873.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  64%|████▌  | 479/744 [31:58<17:41,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25482.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  65%|████▌  | 480/744 [32:02<17:37,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23090.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  65%|████▌  | 481/744 [32:06<17:33,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23892.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  65%|████▌  | 482/744 [32:10<17:29,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21619.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  65%|████▌  | 483/744 [32:14<17:25,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25888.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  65%|████▌  | 484/744 [32:18<17:21,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24339.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  65%|████▌  | 485/744 [32:22<17:17,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23545.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  65%|████▌  | 486/744 [32:26<17:13,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24449.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  65%|████▌  | 487/744 [32:30<17:09,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21284.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  66%|████▌  | 488/744 [32:34<17:05,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25379.4043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  66%|████▌  | 489/744 [32:38<17:01,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21578.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  66%|████▌  | 490/744 [32:42<16:57,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22742.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  66%|████▌  | 491/744 [32:46<16:53,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23576.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  66%|████▋  | 492/744 [32:50<16:49,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24136.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  66%|████▋  | 493/744 [32:54<16:45,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23407.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  66%|████▋  | 494/744 [32:58<16:41,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23778.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  67%|████▋  | 495/744 [33:02<16:37,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24754.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  67%|████▋  | 496/744 [33:06<16:33,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23097.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  67%|████▋  | 497/744 [33:10<16:29,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23257.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  67%|████▋  | 498/744 [33:14<16:25,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25363.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  67%|████▋  | 499/744 [33:18<16:21,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23855.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  67%|████▋  | 500/744 [33:23<16:17,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25366.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  67%|████▋  | 501/744 [33:27<16:13,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25519.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  67%|████▋  | 502/744 [33:31<16:09,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24176.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  68%|████▋  | 503/744 [33:34<16:05,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23776.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  68%|████▋  | 504/744 [33:38<16:01,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24796.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  68%|████▊  | 505/744 [33:42<15:57,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24199.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  68%|████▊  | 506/744 [33:46<15:53,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23016.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  68%|████▊  | 507/744 [33:50<15:49,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22298.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  68%|████▊  | 508/744 [33:54<15:45,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23048.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  68%|████▊  | 509/744 [33:58<15:41,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25016.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  69%|████▊  | 510/744 [34:02<15:37,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21579.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  69%|████▊  | 511/744 [34:06<15:32,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21259.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  69%|████▊  | 512/744 [34:09<15:28,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25692.6055, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  69%|████▊  | 513/744 [34:13<15:24,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19140.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  69%|████▊  | 514/744 [34:17<15:20,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22482.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  69%|████▊  | 515/744 [34:21<15:16,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21526.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  69%|████▊  | 516/744 [34:25<15:12,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23177.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  69%|████▊  | 517/744 [34:29<15:08,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24080.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  70%|████▊  | 518/744 [34:33<15:04,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22082.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  70%|████▉  | 519/744 [34:37<15:00,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25691.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  70%|████▉  | 520/744 [34:41<14:56,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24004.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  70%|████▉  | 521/744 [34:45<14:52,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24966.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  70%|████▉  | 522/744 [34:49<14:48,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20230.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  70%|████▉  | 523/744 [34:53<14:44,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21501.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  70%|████▉  | 524/744 [34:56<14:40,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23986.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  71%|████▉  | 525/744 [35:00<14:36,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25816.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  71%|████▉  | 526/744 [35:04<14:32,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25332.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  71%|████▉  | 527/744 [35:08<14:28,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24499.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  71%|████▉  | 528/744 [35:12<14:24,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25264.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  71%|████▉  | 529/744 [35:16<14:20,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21562.8652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  71%|████▉  | 530/744 [35:20<14:16,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23182.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  71%|████▉  | 531/744 [35:24<14:12,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23688.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  72%|█████  | 532/744 [35:28<14:08,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21969.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  72%|█████  | 533/744 [35:32<14:04,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23340.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  72%|█████  | 534/744 [35:36<14:00,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20623.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  72%|█████  | 535/744 [35:41<13:56,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23338.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  72%|█████  | 536/744 [35:44<13:52,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22324.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  72%|█████  | 537/744 [35:48<13:48,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22820.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  72%|█████  | 538/744 [35:52<13:44,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24273.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  72%|█████  | 539/744 [35:56<13:40,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23300.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  73%|█████  | 540/744 [36:01<13:36,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25201.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  73%|█████  | 541/744 [36:05<13:32,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26152.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  73%|█████  | 542/744 [36:09<13:28,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20047.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  73%|█████  | 543/744 [36:13<13:24,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23082.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  73%|█████  | 544/744 [36:17<13:20,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24751.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  73%|█████▏ | 545/744 [36:21<13:16,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23995.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9715, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  73%|█████▏ | 546/744 [36:25<13:12,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22308.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  74%|█████▏ | 547/744 [36:28<13:08,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22415.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  74%|█████▏ | 548/744 [36:32<13:04,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25164.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  74%|█████▏ | 549/744 [36:36<13:00,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23440.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  74%|█████▏ | 550/744 [36:40<12:56,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21655.3770, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  74%|█████▏ | 551/744 [36:44<12:52,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22751.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  74%|█████▏ | 552/744 [36:48<12:48,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24982.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  74%|█████▏ | 553/744 [36:52<12:44,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24709.1660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  74%|█████▏ | 554/744 [36:56<12:40,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22396.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  75%|█████▏ | 555/744 [37:00<12:36,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22351.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  75%|█████▏ | 556/744 [37:04<12:32,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24232.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  75%|█████▏ | 557/744 [37:08<12:28,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26171.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  75%|█████▎ | 558/744 [37:12<12:24,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25209.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  75%|█████▎ | 559/744 [37:16<12:20,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25760.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  75%|█████▎ | 560/744 [37:20<12:16,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23540.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  75%|█████▎ | 561/744 [37:24<12:12,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25012.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  76%|█████▎ | 562/744 [37:28<12:08,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23876.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  76%|█████▎ | 563/744 [37:32<12:04,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22512.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  76%|█████▎ | 564/744 [37:35<11:59,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24333.3574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  76%|█████▎ | 565/744 [37:39<11:55,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23190.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  76%|█████▎ | 566/744 [37:43<11:51,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21559.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  76%|█████▎ | 567/744 [37:47<11:47,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23079.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  76%|█████▎ | 568/744 [37:51<11:43,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24146.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  76%|█████▎ | 569/744 [37:55<11:39,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22969.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  77%|█████▎ | 570/744 [37:59<11:35,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23725.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  77%|█████▎ | 571/744 [38:03<11:31,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23996.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  77%|█████▍ | 572/744 [38:07<11:27,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25105.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  77%|█████▍ | 573/744 [38:11<11:23,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19198.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  77%|█████▍ | 574/744 [38:15<11:19,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26702.5840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  77%|█████▍ | 575/744 [38:19<11:15,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24354.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  77%|█████▍ | 576/744 [38:23<11:11,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23169.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  78%|█████▍ | 577/744 [38:26<11:07,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25427.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  78%|█████▍ | 578/744 [38:30<11:03,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24838.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  78%|█████▍ | 579/744 [38:34<10:59,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27523.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  78%|█████▍ | 580/744 [38:38<10:55,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23559.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  78%|█████▍ | 581/744 [38:42<10:51,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24315.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  78%|█████▍ | 582/744 [38:46<10:47,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26494.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  78%|█████▍ | 583/744 [38:50<10:43,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23360.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  78%|█████▍ | 584/744 [38:54<10:39,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22698.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  79%|█████▌ | 585/744 [38:58<10:35,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24800.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  79%|█████▌ | 586/744 [39:02<10:31,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24257.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  79%|█████▌ | 587/744 [39:06<10:27,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25323.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  79%|█████▌ | 588/744 [39:10<10:23,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25394.0215, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  79%|█████▌ | 589/744 [39:14<10:19,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25662.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9843, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  79%|█████▌ | 590/744 [39:18<10:15,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23768.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  79%|█████▌ | 591/744 [39:22<10:11,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23164.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  80%|█████▌ | 592/744 [39:26<10:07,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(20898.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  80%|█████▌ | 593/744 [39:30<10:03,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23979.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  80%|█████▌ | 594/744 [39:34<09:59,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23582.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  80%|█████▌ | 595/744 [39:38<09:55,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25693.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  80%|█████▌ | 596/744 [39:42<09:51,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24805.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  80%|█████▌ | 597/744 [39:46<09:47,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21721.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  80%|█████▋ | 598/744 [39:50<09:43,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24784.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  81%|█████▋ | 599/744 [39:54<09:39,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22669.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  81%|█████▋ | 600/744 [39:58<09:35,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22986.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  81%|█████▋ | 601/744 [40:02<09:31,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23268.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  81%|█████▋ | 602/744 [40:06<09:27,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23157.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  81%|█████▋ | 603/744 [40:09<09:23,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26063.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  81%|█████▋ | 604/744 [40:13<09:19,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26153.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  81%|█████▋ | 605/744 [40:17<09:15,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23101.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  81%|█████▋ | 606/744 [40:22<09:11,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24536.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  82%|█████▋ | 607/744 [40:25<09:07,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24589.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  82%|█████▋ | 608/744 [40:29<09:03,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25556.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  82%|█████▋ | 609/744 [40:33<08:59,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27089.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  82%|█████▋ | 610/744 [40:37<08:55,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23394.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  82%|█████▋ | 611/744 [40:41<08:51,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25794.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  82%|█████▊ | 612/744 [40:46<08:47,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24678.3027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9710, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  82%|█████▊ | 613/744 [40:50<08:43,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25292.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  83%|█████▊ | 614/744 [40:54<08:39,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24503.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  83%|█████▊ | 615/744 [40:58<08:35,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25925.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  83%|█████▊ | 616/744 [41:02<08:31,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25342.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  83%|█████▊ | 617/744 [41:06<08:27,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26441.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  83%|█████▊ | 618/744 [41:10<08:23,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21738.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  83%|█████▊ | 619/744 [41:14<08:19,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25666.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  83%|█████▊ | 620/744 [41:18<08:15,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24854.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9652, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  83%|█████▊ | 621/744 [41:22<08:11,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26976.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  84%|█████▊ | 622/744 [41:26<08:07,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22875.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  84%|█████▊ | 623/744 [41:29<08:03,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25664.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  84%|█████▊ | 624/744 [41:33<07:59,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24954.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  84%|█████▉ | 625/744 [41:37<07:55,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22581.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  84%|█████▉ | 626/744 [41:41<07:51,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26530.5879, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  84%|█████▉ | 627/744 [41:45<07:47,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23019.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  84%|█████▉ | 628/744 [41:49<07:43,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24830.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  85%|█████▉ | 629/744 [41:53<07:39,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23663.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  85%|█████▉ | 630/744 [41:57<07:35,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22373.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  85%|█████▉ | 631/744 [42:01<07:31,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22208.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  85%|█████▉ | 632/744 [42:05<07:27,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22898.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  85%|█████▉ | 633/744 [42:09<07:23,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23204.6074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  85%|█████▉ | 634/744 [42:13<07:19,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26789.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  85%|█████▉ | 635/744 [42:17<07:15,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25301.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  85%|█████▉ | 636/744 [42:21<07:11,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(19426.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  86%|█████▉ | 637/744 [42:25<07:07,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25406.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  86%|██████ | 638/744 [42:29<07:03,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25078.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  86%|██████ | 639/744 [42:33<06:59,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24812.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  86%|██████ | 640/744 [42:37<06:55,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22114.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  86%|██████ | 641/744 [42:41<06:51,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26192.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  86%|██████ | 642/744 [42:45<06:47,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23772.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  86%|██████ | 643/744 [42:49<06:43,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26606.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  87%|██████ | 644/744 [42:53<06:39,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21254.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  87%|██████ | 645/744 [42:56<06:35,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23199.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  87%|██████ | 646/744 [43:01<06:31,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26327.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  87%|██████ | 647/744 [43:04<06:27,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23717.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  87%|██████ | 648/744 [43:08<06:23,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22902.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  87%|██████ | 649/744 [43:12<06:19,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24628.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  87%|██████ | 650/744 [43:16<06:15,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25485.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  88%|██████▏| 651/744 [43:20<06:11,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23194.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  88%|██████▏| 652/744 [43:24<06:07,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22523.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  88%|██████▏| 653/744 [43:28<06:03,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24830.7676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  88%|██████▏| 654/744 [43:32<05:59,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23942.3418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  88%|██████▏| 655/744 [43:36<05:55,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25625.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  88%|██████▏| 656/744 [43:42<05:51,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26980.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  88%|██████▏| 657/744 [43:46<05:47,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23753.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  88%|██████▏| 658/744 [43:50<05:43,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24865.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  89%|██████▏| 659/744 [43:54<05:39,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25751.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  89%|██████▏| 660/744 [43:58<05:35,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22823.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  89%|██████▏| 661/744 [44:02<05:31,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25721.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  89%|██████▏| 662/744 [44:05<05:27,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24202.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  89%|██████▏| 663/744 [44:09<05:23,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24158.6621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  89%|██████▏| 664/744 [44:13<05:19,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24518.5527, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  89%|██████▎| 665/744 [44:17<05:15,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23854.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9572, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  90%|██████▎| 666/744 [44:21<05:11,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24109.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  90%|██████▎| 667/744 [44:25<05:07,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22004.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  90%|██████▎| 668/744 [44:29<05:03,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24551.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  90%|██████▎| 669/744 [44:33<04:59,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24022.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  90%|██████▎| 670/744 [44:37<04:55,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24066.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  90%|██████▎| 671/744 [44:41<04:51,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28502.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  90%|██████▎| 672/744 [44:45<04:47,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25941.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  90%|██████▎| 673/744 [44:49<04:43,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24488.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  91%|██████▎| 674/744 [44:53<04:39,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25747.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  91%|██████▎| 675/744 [44:57<04:35,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23671.5566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  91%|██████▎| 676/744 [45:00<04:31,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22764.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  91%|██████▎| 677/744 [45:04<04:27,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21915.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  91%|██████▍| 678/744 [45:08<04:23,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22349.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  91%|██████▍| 679/744 [45:12<04:19,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25131.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  91%|██████▍| 680/744 [45:16<04:15,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24058.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  92%|██████▍| 681/744 [45:19<04:11,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27096.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  92%|██████▍| 682/744 [45:24<04:07,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23731.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  92%|██████▍| 683/744 [45:27<04:03,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23692.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  92%|██████▍| 684/744 [45:31<03:59,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24522.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  92%|██████▍| 685/744 [45:35<03:55,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24601.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  92%|██████▍| 686/744 [45:39<03:51,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23582.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  92%|██████▍| 687/744 [45:44<03:47,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22884.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  92%|██████▍| 688/744 [45:48<03:43,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24078.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  93%|██████▍| 689/744 [45:52<03:39,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27981.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  93%|██████▍| 690/744 [45:55<03:35,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24773.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  93%|██████▌| 691/744 [46:00<03:31,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29033.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  93%|██████▌| 692/744 [46:03<03:27,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23788.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9213, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  93%|██████▌| 693/744 [46:07<03:23,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23320.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  93%|██████▌| 694/744 [46:11<03:19,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25422.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  93%|██████▌| 695/744 [46:15<03:15,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27444.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  94%|██████▌| 696/744 [46:19<03:11,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22675.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  94%|██████▌| 697/744 [46:24<03:07,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25203.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  94%|██████▌| 698/744 [46:28<03:03,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27153.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  94%|██████▌| 699/744 [46:32<02:59,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24318.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  94%|██████▌| 700/744 [46:35<02:55,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23866.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  94%|██████▌| 701/744 [46:39<02:51,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24295.1113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  94%|██████▌| 702/744 [46:43<02:47,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25477.7852, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  94%|██████▌| 703/744 [46:47<02:43,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25470.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9213, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  95%|██████▌| 704/744 [46:51<02:39,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23563.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  95%|██████▋| 705/744 [46:55<02:35,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25365.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  95%|██████▋| 706/744 [46:59<02:31,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27116.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  95%|██████▋| 707/744 [47:03<02:27,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25384.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  95%|██████▋| 708/744 [47:07<02:23,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26611.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  95%|██████▋| 709/744 [47:11<02:19,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26996.8340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  95%|██████▋| 710/744 [47:15<02:15,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22381.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  96%|██████▋| 711/744 [47:19<02:11,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26177.8105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  96%|██████▋| 712/744 [47:23<02:07,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23009.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  96%|██████▋| 713/744 [47:27<02:03,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26397.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  96%|██████▋| 714/744 [47:31<01:59,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24193.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  96%|██████▋| 715/744 [47:35<01:55,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25791.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  96%|██████▋| 716/744 [47:38<01:51,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22435.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  96%|██████▋| 717/744 [47:42<01:47,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26402.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  97%|██████▊| 718/744 [47:46<01:43,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22180.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  97%|██████▊| 719/744 [47:50<01:39,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25331.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  97%|██████▊| 720/744 [47:54<01:35,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25117.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  97%|██████▊| 721/744 [47:58<01:31,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25066.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  97%|██████▊| 722/744 [48:02<01:27,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26598.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  97%|██████▊| 723/744 [48:06<01:23,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23060.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  97%|██████▊| 724/744 [48:10<01:19,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22541.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  97%|██████▊| 725/744 [48:14<01:15,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27388.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  98%|██████▊| 726/744 [48:18<01:11,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27108.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  98%|██████▊| 727/744 [48:22<01:07,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24747.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  98%|██████▊| 728/744 [48:26<01:03,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24015.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  98%|██████▊| 729/744 [48:29<00:59,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24997.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  98%|██████▊| 730/744 [48:33<00:55,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25853.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  98%|██████▉| 731/744 [48:37<00:51,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26446.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  98%|██████▉| 732/744 [48:41<00:47,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22737.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  99%|██████▉| 733/744 [48:45<00:43,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23973.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  99%|██████▉| 734/744 [48:49<00:39,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24519.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  99%|██████▉| 735/744 [48:53<00:35,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26376.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  99%|██████▉| 736/744 [48:57<00:31,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22061.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  99%|██████▉| 737/744 [49:00<00:27,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25248.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  99%|██████▉| 738/744 [49:04<00:23,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21523.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  99%|██████▉| 739/744 [49:08<00:19,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26641.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2:  99%|██████▉| 740/744 [49:12<00:15,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25690.1133, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2: 100%|██████▉| 741/744 [49:16<00:11,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22873.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2: 100%|██████▉| 742/744 [49:20<00:07,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24419.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2: 100%|██████▉| 743/744 [49:23<00:03,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25816.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   0%|                 | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(25415.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   0%|       | 1/744 [00:05<1:06:31,  5.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24686.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   0%|         | 2/744 [00:09<55:58,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27526.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   0%|         | 3/744 [00:12<52:47,  4.27s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24930.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   1%|         | 4/744 [00:16<51:33,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23973.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   1%|         | 5/744 [00:20<51:14,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26582.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   1%|         | 6/744 [00:24<50:09,  4.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25728.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   1%|         | 7/744 [00:28<49:53,  4.06s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26510.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   1%|         | 8/744 [00:32<49:15,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26017.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   1%|         | 9/744 [00:35<48:58,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24040.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   1%|        | 10/744 [00:39<48:45,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24850.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   1%|        | 11/744 [00:43<48:18,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28280.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   2%|▏       | 12/744 [00:47<48:31,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25376.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   2%|▏       | 13/744 [00:51<48:33,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26162.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   2%|▏       | 14/744 [00:55<48:19,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23487.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   2%|▏       | 15/744 [00:59<48:05,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23935.2715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   2%|▏       | 16/744 [01:03<48:04,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25992.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   2%|▏       | 17/744 [01:07<47:48,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24348.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   2%|▏       | 18/744 [01:11<47:45,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26275.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   3%|▏       | 19/744 [01:15<47:43,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23601.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   3%|▏       | 20/744 [01:18<47:35,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23306.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   3%|▏       | 21/744 [01:22<47:31,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26391.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   3%|▏       | 22/744 [01:27<47:36,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24519.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   3%|▏       | 23/744 [01:30<47:31,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25590.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9909, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   3%|▎       | 24/744 [01:34<47:28,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25249.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   3%|▎       | 25/744 [01:38<47:16,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27900.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   3%|▎       | 26/744 [01:42<47:09,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25108.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   4%|▎       | 27/744 [01:46<47:08,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26873.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   4%|▎       | 28/744 [01:50<46:55,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24551.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   4%|▎       | 29/744 [01:53<46:48,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24469.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   4%|▎       | 30/744 [01:57<46:47,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27752.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   4%|▎       | 31/744 [02:01<46:40,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23054.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   4%|▎       | 32/744 [02:06<46:44,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24493.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   4%|▎       | 33/744 [02:10<46:43,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24747.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   5%|▎       | 34/744 [02:14<46:40,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21306.3340, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   5%|▍       | 35/744 [02:17<46:31,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23019.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   5%|▍       | 36/744 [02:22<46:32,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26041.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   5%|▍       | 37/744 [02:25<46:27,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23254.1113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   5%|▍       | 38/744 [02:29<46:22,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23875.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   5%|▍       | 39/744 [02:33<46:21,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23983.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   5%|▍       | 40/744 [02:37<46:15,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24744.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   6%|▍       | 41/744 [02:41<46:13,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27198.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   6%|▍       | 42/744 [02:45<46:12,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23053.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   6%|▍       | 43/744 [02:50<46:11,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26750.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   6%|▍       | 44/744 [02:53<46:06,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27717.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   6%|▍       | 45/744 [02:57<46:00,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22881.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   6%|▍       | 46/744 [03:02<46:02,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27522.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   6%|▌       | 47/744 [03:05<45:54,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26311.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   6%|▌       | 48/744 [03:09<45:48,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26208.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   7%|▌       | 49/744 [03:13<45:41,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26737.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   7%|▌       | 50/744 [03:17<45:36,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23097.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   7%|▌       | 51/744 [03:20<45:31,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26527.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   7%|▌       | 52/744 [03:24<45:26,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24972.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   7%|▌       | 53/744 [03:28<45:21,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25946.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   7%|▌       | 54/744 [03:32<45:20,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25842.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   7%|▌       | 55/744 [03:36<45:15,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27637.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   8%|▌       | 56/744 [03:40<45:09,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27713.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   8%|▌       | 57/744 [03:44<45:04,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26787.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   8%|▌       | 58/744 [03:48<45:00,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25342.5488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   8%|▋       | 59/744 [03:52<44:55,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25380.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   8%|▋       | 60/744 [03:56<44:58,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26621.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   8%|▋       | 61/744 [04:00<44:53,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24479.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   8%|▋       | 62/744 [04:04<44:49,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24558.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   8%|▋       | 63/744 [04:08<44:43,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26103.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   9%|▋       | 64/744 [04:11<44:37,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25576.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   9%|▋       | 65/744 [04:16<44:34,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26570.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   9%|▋       | 66/744 [04:20<44:31,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23340.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   9%|▋       | 67/744 [04:24<44:28,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29739.7676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   9%|▋       | 68/744 [04:28<44:25,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24105.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   9%|▋       | 69/744 [04:32<44:22,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27166.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:   9%|▊       | 70/744 [04:35<44:15,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27981.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  10%|▊       | 71/744 [04:39<44:07,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24944.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  10%|▊       | 72/744 [04:42<44:01,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23260.6504, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  10%|▊       | 73/744 [04:47<43:59,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25356.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  10%|▊       | 74/744 [04:51<43:54,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27357.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  10%|▊       | 75/744 [04:55<43:51,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26060.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9213, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  10%|▊       | 76/744 [04:58<43:47,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27617.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  10%|▊       | 77/744 [05:02<43:41,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31195.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  10%|▊       | 78/744 [05:06<43:36,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23161.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  11%|▊       | 79/744 [05:10<43:33,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24025.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  11%|▊       | 80/744 [05:14<43:29,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25925.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  11%|▊       | 81/744 [05:18<43:24,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26700.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  11%|▉       | 82/744 [05:22<43:19,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25225.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  11%|▉       | 83/744 [05:25<43:15,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23346.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  11%|▉       | 84/744 [05:29<43:11,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28427.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  11%|▉       | 85/744 [05:33<43:07,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28424.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  12%|▉       | 86/744 [05:38<43:06,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24509.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  12%|▉       | 87/744 [05:41<43:01,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22446.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  12%|▉       | 88/744 [05:46<43:00,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26087.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  12%|▉       | 89/744 [05:50<42:56,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27441.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  12%|▉       | 90/744 [05:54<42:54,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23428.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  12%|▉       | 91/744 [05:58<42:51,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29330.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  12%|▉       | 92/744 [06:02<42:46,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25261.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  12%|█       | 93/744 [06:05<42:41,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28123.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  13%|█       | 94/744 [06:10<42:39,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21733.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  13%|█       | 95/744 [06:14<42:39,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28806.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  13%|█       | 96/744 [06:18<42:35,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26299.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  13%|█       | 97/744 [06:22<42:30,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25233.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  13%|█       | 98/744 [06:26<42:28,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23384.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  13%|█       | 99/744 [06:30<42:24,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24768.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  13%|▉      | 100/744 [06:34<42:19,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29255.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  14%|▉      | 101/744 [06:38<42:15,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23419.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  14%|▉      | 102/744 [06:42<42:11,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28210.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  14%|▉      | 103/744 [06:46<42:08,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26444.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  14%|▉      | 104/744 [06:50<42:03,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22897.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  14%|▉      | 105/744 [06:53<41:59,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25454.8926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  14%|▉      | 106/744 [06:57<41:55,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23937.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  14%|█      | 107/744 [07:01<41:49,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28005.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  15%|█      | 108/744 [07:05<41:45,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26040.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  15%|█      | 109/744 [07:09<41:39,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27573.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  15%|█      | 110/744 [07:12<41:35,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25611.3945, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  15%|█      | 111/744 [07:16<41:30,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24873.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  15%|█      | 112/744 [07:20<41:25,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28856.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  15%|█      | 113/744 [07:24<41:21,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24612.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  15%|█      | 114/744 [07:28<41:17,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30667.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  15%|█      | 115/744 [07:32<41:13,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24955.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  16%|█      | 116/744 [07:36<41:09,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28268.0684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  16%|█      | 117/744 [07:39<41:04,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26456.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  16%|█      | 118/744 [07:43<41:00,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27086.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  16%|█      | 119/744 [07:47<40:57,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25177.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  16%|█▏     | 120/744 [07:51<40:53,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24209.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  16%|█▏     | 121/744 [07:56<40:50,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26821.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  16%|█▏     | 122/744 [08:00<40:47,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26848.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  17%|█▏     | 123/744 [08:03<40:42,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23766.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  17%|█▏     | 124/744 [08:07<40:38,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27712.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  17%|█▏     | 125/744 [08:11<40:33,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27057.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  17%|█▏     | 126/744 [08:15<40:31,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27052.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  17%|█▏     | 127/744 [08:19<40:27,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28935.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  17%|█▏     | 128/744 [08:23<40:23,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22791.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  17%|█▏     | 129/744 [08:27<40:20,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27558.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  17%|█▏     | 130/744 [08:31<40:15,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27660.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  18%|█▏     | 131/744 [08:35<40:12,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25937.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  18%|█▏     | 132/744 [08:39<40:07,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25171.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  18%|█▎     | 133/744 [08:43<40:04,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28061.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  18%|█▎     | 134/744 [08:47<40:00,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23491.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  18%|█▎     | 135/744 [08:50<39:54,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28607.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  18%|█▎     | 136/744 [08:54<39:50,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25329.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  18%|█▎     | 137/744 [08:58<39:47,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(21932.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  19%|█▎     | 138/744 [09:02<39:43,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27008.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  19%|█▎     | 139/744 [09:06<39:39,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25046.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  19%|█▎     | 140/744 [09:10<39:35,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25285.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  19%|█▎     | 141/744 [09:14<39:31,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27432.7676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  19%|█▎     | 142/744 [09:18<39:27,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24316.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  19%|█▎     | 143/744 [09:22<39:24,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25442.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  19%|█▎     | 144/744 [09:26<39:20,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23408.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  19%|█▎     | 145/744 [09:30<39:16,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28028.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9694, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  20%|█▎     | 146/744 [09:34<39:12,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24501.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  20%|█▍     | 147/744 [09:38<39:07,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27689.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  20%|█▍     | 148/744 [09:41<39:03,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27905.2324, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  20%|█▍     | 149/744 [09:45<38:59,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28032.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  20%|█▍     | 150/744 [09:49<38:54,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27767.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  20%|█▍     | 151/744 [09:53<38:50,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27773.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  20%|█▍     | 152/744 [09:57<38:46,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25776.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  21%|█▍     | 153/744 [10:01<38:41,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(22665.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  21%|█▍     | 154/744 [10:04<38:37,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27197.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  21%|█▍     | 155/744 [10:08<38:33,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27271.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  21%|█▍     | 156/744 [10:12<38:29,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28090.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  21%|█▍     | 157/744 [10:16<38:26,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24183.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  21%|█▍     | 158/744 [10:20<38:21,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26870.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  21%|█▍     | 159/744 [10:24<38:17,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24409.8105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  22%|█▌     | 160/744 [10:28<38:14,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26314.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  22%|█▌     | 161/744 [10:32<38:10,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24565.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  22%|█▌     | 162/744 [10:36<38:06,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25738.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  22%|█▌     | 163/744 [10:39<38:01,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28993.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  22%|█▌     | 164/744 [10:43<37:56,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29770.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  22%|█▌     | 165/744 [10:47<37:53,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25823.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  22%|█▌     | 166/744 [10:51<37:48,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26907.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  22%|█▌     | 167/744 [10:55<37:44,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26174.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  23%|█▌     | 168/744 [10:59<37:40,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28046.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  23%|█▌     | 169/744 [11:03<37:36,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25254.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  23%|█▌     | 170/744 [11:07<37:32,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27000.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  23%|█▌     | 171/744 [11:10<37:28,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27803.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  23%|█▌     | 172/744 [11:14<37:23,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24031.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  23%|█▋     | 173/744 [11:18<37:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27170.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  23%|█▋     | 174/744 [11:22<37:15,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27563.5254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  24%|█▋     | 175/744 [11:26<37:10,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24668.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  24%|█▋     | 176/744 [11:30<37:08,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24630.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  24%|█▋     | 177/744 [11:34<37:05,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25416.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  24%|█▋     | 178/744 [11:38<37:01,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25871.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  24%|█▋     | 179/744 [11:42<36:57,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25443.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  24%|█▋     | 180/744 [11:46<36:53,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26259.5293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  24%|█▋     | 181/744 [11:50<36:49,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26044.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  24%|█▋     | 182/744 [11:54<36:46,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26966.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  25%|█▋     | 183/744 [11:58<36:41,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25719.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  25%|█▋     | 184/744 [12:01<36:36,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28962.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  25%|█▋     | 185/744 [12:05<36:32,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29023.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  25%|█▊     | 186/744 [12:09<36:27,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25999.9512, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  25%|█▊     | 187/744 [12:13<36:23,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28869.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  25%|█▊     | 188/744 [12:17<36:20,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27361.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  25%|█▊     | 189/744 [12:21<36:16,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24352.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  26%|█▊     | 190/744 [12:25<36:12,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26926.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  26%|█▊     | 191/744 [12:29<36:08,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25353.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  26%|█▊     | 192/744 [12:32<36:04,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24938.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  26%|█▊     | 193/744 [12:36<36:00,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26513.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  26%|█▊     | 194/744 [12:40<35:56,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24172.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  26%|█▊     | 195/744 [12:44<35:53,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28398.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  26%|█▊     | 196/744 [12:48<35:49,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27433.2793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  26%|█▊     | 197/744 [12:52<35:45,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27047.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  27%|█▊     | 198/744 [12:56<35:41,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29223.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  27%|█▊     | 199/744 [13:00<35:37,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27677.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  27%|█▉     | 200/744 [13:04<35:32,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26242.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  27%|█▉     | 201/744 [13:07<35:28,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25418.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  27%|█▉     | 202/744 [13:11<35:24,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29931.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  27%|█▉     | 203/744 [13:16<35:21,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25466.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  27%|█▉     | 204/744 [13:19<35:17,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27203.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  28%|█▉     | 205/744 [13:23<35:13,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25085.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  28%|█▉     | 206/744 [13:27<35:10,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27995.9277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9601, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  28%|█▉     | 207/744 [13:31<35:05,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26663.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  28%|█▉     | 208/744 [13:35<35:01,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26032.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  28%|█▉     | 209/744 [13:39<34:58,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28249.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  28%|█▉     | 210/744 [13:43<34:54,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29381.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  28%|█▉     | 211/744 [13:47<34:50,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26870.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  28%|█▉     | 212/744 [13:51<34:46,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25481.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  29%|██     | 213/744 [13:55<34:42,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25531.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  29%|██     | 214/744 [13:59<34:38,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27782.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  29%|██     | 215/744 [14:03<34:34,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26344.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  29%|██     | 216/744 [14:07<34:30,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24525.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  29%|██     | 217/744 [14:10<34:26,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24721.5254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  29%|██     | 218/744 [14:14<34:22,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25345.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  29%|██     | 219/744 [14:18<34:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26368.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  30%|██     | 220/744 [14:22<34:14,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27791.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  30%|██     | 221/744 [14:26<34:10,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24157.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  30%|██     | 222/744 [14:30<34:06,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27155.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  30%|██     | 223/744 [14:34<34:02,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25923.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  30%|██     | 224/744 [14:38<33:58,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28648.7793, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  30%|██     | 225/744 [14:42<33:54,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26188.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9893, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  30%|██▏    | 226/744 [14:46<33:51,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26532.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  31%|██▏    | 227/744 [14:50<33:47,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28214.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  31%|██▏    | 228/744 [14:54<33:43,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27586.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  31%|██▏    | 229/744 [14:57<33:39,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27419.2793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  31%|██▏    | 230/744 [15:01<33:35,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26983.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  31%|██▏    | 231/744 [15:05<33:31,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25668.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  31%|██▏    | 232/744 [15:09<33:27,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28348.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  31%|██▏    | 233/744 [15:13<33:23,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27660.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  31%|██▏    | 234/744 [15:17<33:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27343.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  32%|██▏    | 235/744 [15:21<33:15,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29250.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  32%|██▏    | 236/744 [15:25<33:12,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27306.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  32%|██▏    | 237/744 [15:29<33:08,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26357.2793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  32%|██▏    | 238/744 [15:33<33:04,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26154.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  32%|██▏    | 239/744 [15:37<33:00,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24866.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  32%|██▎    | 240/744 [15:41<32:56,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26184.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  32%|██▎    | 241/744 [15:45<32:53,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26165.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  33%|██▎    | 242/744 [15:49<32:49,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25672.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  33%|██▎    | 243/744 [15:53<32:45,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26137.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  33%|██▎    | 244/744 [15:57<32:42,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24255.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  33%|██▎    | 245/744 [16:01<32:38,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30110.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  33%|██▎    | 246/744 [16:05<32:34,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25942.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  33%|██▎    | 247/744 [16:09<32:30,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29678.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  33%|██▎    | 248/744 [16:13<32:26,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27282.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  33%|██▎    | 249/744 [16:17<32:22,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26049.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  34%|██▎    | 250/744 [16:20<32:17,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27011.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  34%|██▎    | 251/744 [16:24<32:13,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24638.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  34%|██▎    | 252/744 [16:28<32:09,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26026.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  34%|██▍    | 253/744 [16:32<32:05,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24941.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  34%|██▍    | 254/744 [16:36<32:01,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25234.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  34%|██▍    | 255/744 [16:40<31:57,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26461.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  34%|██▍    | 256/744 [16:44<31:53,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27730.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  35%|██▍    | 257/744 [16:47<31:49,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28365.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  35%|██▍    | 258/744 [16:51<31:45,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28515.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  35%|██▍    | 259/744 [16:55<31:42,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26769.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  35%|██▍    | 260/744 [16:59<31:37,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25474.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  35%|██▍    | 261/744 [17:03<31:33,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28589.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  35%|██▍    | 262/744 [17:07<31:30,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23588.5527, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  35%|██▍    | 263/744 [17:11<31:26,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28539.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  35%|██▍    | 264/744 [17:15<31:22,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28039.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  36%|██▍    | 265/744 [17:19<31:18,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26017.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  36%|██▌    | 266/744 [17:23<31:14,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29602.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  36%|██▌    | 267/744 [17:26<31:10,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30087.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  36%|██▌    | 268/744 [17:30<31:05,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25779.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  36%|██▌    | 269/744 [17:34<31:02,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26310.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  36%|██▌    | 270/744 [17:38<30:58,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24214.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  36%|██▌    | 271/744 [17:42<30:54,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24949.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  37%|██▌    | 272/744 [17:46<30:50,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24176.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  37%|██▌    | 273/744 [17:50<30:46,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27383.2129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  37%|██▌    | 274/744 [17:54<30:42,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26848.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  37%|██▌    | 275/744 [17:58<30:38,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27153.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  37%|██▌    | 276/744 [18:01<30:34,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27875.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  37%|██▌    | 277/744 [18:06<30:31,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30366.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  37%|██▌    | 278/744 [18:09<30:26,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27063.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  38%|██▋    | 279/744 [18:13<30:22,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29316.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  38%|██▋    | 280/744 [18:17<30:18,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29538.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  38%|██▋    | 281/744 [18:21<30:14,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27241.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  38%|██▋    | 282/744 [18:25<30:10,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25638.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  38%|██▋    | 283/744 [18:29<30:06,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27660.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9108, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  38%|██▋    | 284/744 [18:32<30:02,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29131.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  38%|██▋    | 285/744 [18:37<29:59,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27432.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  38%|██▋    | 286/744 [18:41<29:55,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30045.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  39%|██▋    | 287/744 [18:44<29:50,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27965., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  39%|██▋    | 288/744 [18:48<29:46,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27718.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  39%|██▋    | 289/744 [18:52<29:42,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29686.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  39%|██▋    | 290/744 [18:56<29:39,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29457.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  39%|██▋    | 291/744 [19:00<29:35,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26506.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  39%|██▋    | 292/744 [19:04<29:31,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24399.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  39%|██▊    | 293/744 [19:08<29:27,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26001.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  40%|██▊    | 294/744 [19:12<29:23,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29327.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  40%|██▊    | 295/744 [19:16<29:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24878.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  40%|██▊    | 296/744 [19:20<29:15,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26743.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  40%|██▊    | 297/744 [19:23<29:11,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25242.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  40%|██▊    | 298/744 [19:27<29:07,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24830.4355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  40%|██▊    | 299/744 [19:31<29:04,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26423.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  40%|██▊    | 300/744 [19:35<29:00,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27660.9043, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  40%|██▊    | 301/744 [19:39<28:56,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25841., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  41%|██▊    | 302/744 [19:43<28:52,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27050.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  41%|██▊    | 303/744 [19:47<28:48,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27122.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  41%|██▊    | 304/744 [19:51<28:45,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27144.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  41%|██▊    | 305/744 [19:55<28:40,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30250.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  41%|██▉    | 306/744 [19:59<28:36,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26826.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  41%|██▉    | 307/744 [20:03<28:33,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25918.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  41%|██▉    | 308/744 [20:07<28:29,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25899.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  42%|██▉    | 309/744 [20:11<28:25,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26595.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  42%|██▉    | 310/744 [20:15<28:21,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29021.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  42%|██▉    | 311/744 [20:19<28:17,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26940.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  42%|██▉    | 312/744 [20:23<28:14,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28548.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  42%|██▉    | 313/744 [20:27<28:10,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26483.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  42%|██▉    | 314/744 [20:31<28:06,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24510.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  42%|██▉    | 315/744 [20:35<28:02,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29052.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  42%|██▉    | 316/744 [20:39<27:58,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25750.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  43%|██▉    | 317/744 [20:42<27:54,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28199.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  43%|██▉    | 318/744 [20:46<27:50,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29927.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  43%|███    | 319/744 [20:50<27:46,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26758.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  43%|███    | 320/744 [20:54<27:42,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28800.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  43%|███    | 321/744 [20:58<27:38,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27854.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  43%|███    | 322/744 [21:02<27:34,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29040.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  43%|███    | 323/744 [21:06<27:31,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29035.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  44%|███    | 324/744 [21:10<27:27,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27808.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  44%|███    | 325/744 [21:14<27:22,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27541.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  44%|███    | 326/744 [21:18<27:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27925.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  44%|███    | 327/744 [21:22<27:15,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26754.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  44%|███    | 328/744 [21:26<27:11,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26352.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  44%|███    | 329/744 [21:30<27:07,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29153.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  44%|███    | 330/744 [21:34<27:04,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28061.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  44%|███    | 331/744 [21:38<27:00,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26251.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  45%|███    | 332/744 [21:42<26:55,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28620.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  45%|███▏   | 333/744 [21:46<26:51,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27972.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  45%|███▏   | 334/744 [21:50<26:48,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26638.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  45%|███▏   | 335/744 [21:53<26:44,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27778.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  45%|███▏   | 336/744 [21:57<26:40,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24519.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  45%|███▏   | 337/744 [22:01<26:35,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27751.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  45%|███▏   | 338/744 [22:05<26:31,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28446.3535, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  46%|███▏   | 339/744 [22:08<26:27,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25324.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  46%|███▏   | 340/744 [22:12<26:23,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28127.4590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  46%|███▏   | 341/744 [22:16<26:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29469.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  46%|███▏   | 342/744 [22:20<26:15,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26768.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  46%|███▏   | 343/744 [22:24<26:11,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29653.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  46%|███▏   | 344/744 [22:28<26:07,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28219.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  46%|███▏   | 345/744 [22:31<26:03,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28206.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  47%|███▎   | 346/744 [22:35<25:59,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28057.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  47%|███▎   | 347/744 [22:39<25:55,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26435.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  47%|███▎   | 348/744 [22:43<25:51,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26170.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  47%|███▎   | 349/744 [22:47<25:47,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25322.1504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  47%|███▎   | 350/744 [22:50<25:43,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29176.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  47%|███▎   | 351/744 [22:54<25:39,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29089.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  47%|███▎   | 352/744 [22:58<25:35,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28837.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  47%|███▎   | 353/744 [23:02<25:31,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29325.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  48%|███▎   | 354/744 [23:06<25:27,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28441.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  48%|███▎   | 355/744 [23:10<25:23,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29639.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  48%|███▎   | 356/744 [23:14<25:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27056.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  48%|███▎   | 357/744 [23:17<25:15,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24116.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  48%|███▎   | 358/744 [23:21<25:11,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23606.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9593, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  48%|███▍   | 359/744 [23:25<25:07,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27032.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  48%|███▍   | 360/744 [23:29<25:03,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32639.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  49%|███▍   | 361/744 [23:33<24:59,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28290.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  49%|███▍   | 362/744 [23:37<24:56,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28953.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  49%|███▍   | 363/744 [23:41<24:52,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25769.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  49%|███▍   | 364/744 [23:45<24:48,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26633.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  49%|███▍   | 365/744 [23:50<24:44,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29386.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  49%|███▍   | 366/744 [23:53<24:40,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27251.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  49%|███▍   | 367/744 [23:57<24:37,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28963.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  49%|███▍   | 368/744 [24:01<24:32,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28474.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  50%|███▍   | 369/744 [24:06<24:29,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28769.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  50%|███▍   | 370/744 [24:09<24:25,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29828.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  50%|███▍   | 371/744 [24:13<24:21,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26545.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  50%|███▌   | 372/744 [24:17<24:17,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27321.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  50%|███▌   | 373/744 [24:21<24:13,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28574.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  50%|███▌   | 374/744 [24:24<24:09,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26895.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  50%|███▌   | 375/744 [24:28<24:05,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28146.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  51%|███▌   | 376/744 [24:33<24:01,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29210.6367, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  51%|███▌   | 377/744 [24:37<23:57,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27058.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  51%|███▌   | 378/744 [24:40<23:53,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28774.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9080, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  51%|███▌   | 379/744 [24:44<23:49,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29664.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  51%|███▌   | 380/744 [24:48<23:45,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29466.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  51%|███▌   | 381/744 [24:52<23:41,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28226.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  51%|███▌   | 382/744 [24:56<23:37,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24828.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  51%|███▌   | 383/744 [24:59<23:33,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29756.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  52%|███▌   | 384/744 [25:03<23:29,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29259.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  52%|███▌   | 385/744 [25:07<23:25,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26189.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  52%|███▋   | 386/744 [25:11<23:22,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28463.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  52%|███▋   | 387/744 [25:15<23:18,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27037.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  52%|███▋   | 388/744 [25:19<23:14,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27438.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  52%|███▋   | 389/744 [25:23<23:09,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30183.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  52%|███▋   | 390/744 [25:27<23:06,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28994.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  53%|███▋   | 391/744 [25:31<23:02,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27593.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  53%|███▋   | 392/744 [25:35<22:58,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28392.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  53%|███▋   | 393/744 [25:39<22:54,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29030.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  53%|███▋   | 394/744 [25:43<22:50,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26355.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  53%|███▋   | 395/744 [25:47<22:46,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25035.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  53%|███▋   | 396/744 [25:51<22:43,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28170.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  53%|███▋   | 397/744 [25:55<22:39,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27859.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  53%|███▋   | 398/744 [25:59<22:35,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30715.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  54%|███▊   | 399/744 [26:03<22:31,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30533.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  54%|███▊   | 400/744 [26:06<22:27,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28716.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  54%|███▊   | 401/744 [26:10<22:23,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30626.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  54%|███▊   | 402/744 [26:14<22:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27260.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  54%|███▊   | 403/744 [26:18<22:15,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28243.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  54%|███▊   | 404/744 [26:22<22:11,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29530.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  54%|███▊   | 405/744 [26:25<22:07,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24988.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  55%|███▊   | 406/744 [26:29<22:03,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28958.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  55%|███▊   | 407/744 [26:33<21:59,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29082.9043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  55%|███▊   | 408/744 [26:37<21:55,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30803.8105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  55%|███▊   | 409/744 [26:40<21:51,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27759.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  55%|███▊   | 410/744 [26:44<21:47,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27210.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  55%|███▊   | 411/744 [26:48<21:43,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26636.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  55%|███▉   | 412/744 [26:52<21:39,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27149.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  56%|███▉   | 413/744 [26:56<21:35,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28141.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  56%|███▉   | 414/744 [27:00<21:31,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26147.2402, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  56%|███▉   | 415/744 [27:04<21:27,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25822.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  56%|███▉   | 416/744 [27:08<21:23,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26335.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  56%|███▉   | 417/744 [27:12<21:19,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24726.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  56%|███▉   | 418/744 [27:15<21:15,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27628.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  56%|███▉   | 419/744 [27:19<21:11,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26467.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8822, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  56%|███▉   | 420/744 [27:23<21:07,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28783.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  57%|███▉   | 421/744 [27:27<21:03,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30381.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  57%|███▉   | 422/744 [27:31<20:59,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28489.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  57%|███▉   | 423/744 [27:34<20:55,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29069.8301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  57%|███▉   | 424/744 [27:38<20:51,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28858.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  57%|███▉   | 425/744 [27:42<20:47,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26393.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  57%|████   | 426/744 [27:46<20:43,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31823.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  57%|████   | 427/744 [27:50<20:40,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28770.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  58%|████   | 428/744 [27:54<20:36,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24111.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  58%|████   | 429/744 [27:57<20:32,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30540.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  58%|████   | 430/744 [28:01<20:28,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27924.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  58%|████   | 431/744 [28:05<20:24,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30326.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  58%|████   | 432/744 [28:10<20:20,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26324.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  58%|████   | 433/744 [28:13<20:16,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28224.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  58%|████   | 434/744 [28:17<20:12,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27432.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  58%|████   | 435/744 [28:21<20:08,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29488.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  59%|████   | 436/744 [28:25<20:04,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26889.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  59%|████   | 437/744 [28:29<20:00,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29672.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  59%|████   | 438/744 [28:33<19:56,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29337.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  59%|████▏  | 439/744 [28:36<19:52,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30349.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  59%|████▏  | 440/744 [28:40<19:48,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29458.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  59%|████▏  | 441/744 [28:44<19:44,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30103.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  59%|████▏  | 442/744 [28:48<19:41,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30480.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  60%|████▏  | 443/744 [28:52<19:37,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29066.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  60%|████▏  | 444/744 [28:55<19:32,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27983.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  60%|████▏  | 445/744 [28:59<19:29,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29870.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  60%|████▏  | 446/744 [29:03<19:25,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28405.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  60%|████▏  | 447/744 [29:07<19:21,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30963.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  60%|████▏  | 448/744 [29:11<19:17,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26594.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  60%|████▏  | 449/744 [29:15<19:13,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29370.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  60%|████▏  | 450/744 [29:19<19:09,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28333.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  61%|████▏  | 451/744 [29:23<19:05,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28530.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  61%|████▎  | 452/744 [29:27<19:01,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28564.9316, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  61%|████▎  | 453/744 [29:31<18:58,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29414.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  61%|████▎  | 454/744 [29:35<18:54,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27617.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  61%|████▎  | 455/744 [29:39<18:50,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(23282.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  61%|████▎  | 456/744 [29:43<18:46,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29752.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  61%|████▎  | 457/744 [29:47<18:42,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28735.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  62%|████▎  | 458/744 [29:51<18:38,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30450.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  62%|████▎  | 459/744 [29:54<18:34,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28826.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  62%|████▎  | 460/744 [29:59<18:30,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26521.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  62%|████▎  | 461/744 [30:02<18:26,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26752.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  62%|████▎  | 462/744 [30:06<18:22,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27532.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  62%|████▎  | 463/744 [30:10<18:19,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28237.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  62%|████▎  | 464/744 [30:14<18:15,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29311.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  62%|████▍  | 465/744 [30:18<18:11,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28023.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  63%|████▍  | 466/744 [30:22<18:07,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31183.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  63%|████▍  | 467/744 [30:26<18:03,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31226.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  63%|████▍  | 468/744 [30:30<17:59,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28408.4355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  63%|████▍  | 469/744 [30:34<17:55,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28380.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  63%|████▍  | 470/744 [30:38<17:51,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25660.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  63%|████▍  | 471/744 [30:42<17:47,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26240.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  63%|████▍  | 472/744 [30:46<17:44,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28725.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  64%|████▍  | 473/744 [30:50<17:40,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27706.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  64%|████▍  | 474/744 [30:54<17:36,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27093.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  64%|████▍  | 475/744 [30:58<17:32,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28690.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  64%|████▍  | 476/744 [31:02<17:28,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29160.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9238, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  64%|████▍  | 477/744 [31:06<17:24,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29866.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  64%|████▍  | 478/744 [31:10<17:21,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28076.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  64%|████▌  | 479/744 [31:14<17:17,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29796.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  65%|████▌  | 480/744 [31:18<17:13,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29499.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  65%|████▌  | 481/744 [31:22<17:09,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29740.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  65%|████▌  | 482/744 [31:26<17:05,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26629.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  65%|████▌  | 483/744 [31:30<17:01,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32264.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  65%|████▌  | 484/744 [31:34<16:57,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32605.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  65%|████▌  | 485/744 [31:38<16:53,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29580.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  65%|████▌  | 486/744 [31:41<16:49,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27443.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  65%|████▌  | 487/744 [31:45<16:45,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26894.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  66%|████▌  | 488/744 [31:49<16:41,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31346.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  66%|████▌  | 489/744 [31:53<16:37,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30264.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  66%|████▌  | 490/744 [31:57<16:33,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32162.8789, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  66%|████▌  | 491/744 [32:01<16:30,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25920.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  66%|████▋  | 492/744 [32:05<16:26,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27155.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  66%|████▋  | 493/744 [32:09<16:22,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25177.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  66%|████▋  | 494/744 [32:13<16:18,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28889.2715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  67%|████▋  | 495/744 [32:17<16:14,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27919.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  67%|████▋  | 496/744 [32:21<16:10,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31334.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  67%|████▋  | 497/744 [32:24<16:06,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28916.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  67%|████▋  | 498/744 [32:28<16:02,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31240.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  67%|████▋  | 499/744 [32:33<15:58,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26691.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  67%|████▋  | 500/744 [32:36<15:54,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32280.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  67%|████▋  | 501/744 [32:40<15:51,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27023.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  67%|████▋  | 502/744 [32:44<15:47,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28416.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  68%|████▋  | 503/744 [32:48<15:43,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32683.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  68%|████▋  | 504/744 [32:52<15:39,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28810.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  68%|████▊  | 505/744 [32:55<15:35,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27860.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  68%|████▊  | 506/744 [33:00<15:31,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31491.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  68%|████▊  | 507/744 [33:03<15:27,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29197.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  68%|████▊  | 508/744 [33:08<15:23,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28157.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  68%|████▊  | 509/744 [33:11<15:19,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26915.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  69%|████▊  | 510/744 [33:15<15:15,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32077.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  69%|████▊  | 511/744 [33:19<15:11,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30239.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  69%|████▊  | 512/744 [33:23<15:07,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30787.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  69%|████▊  | 513/744 [33:26<15:03,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32164.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  69%|████▊  | 514/744 [33:30<14:59,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27781.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  69%|████▊  | 515/744 [33:34<14:55,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29217.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  69%|████▊  | 516/744 [33:38<14:51,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27144.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  69%|████▊  | 517/744 [33:42<14:48,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26325.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  70%|████▊  | 518/744 [33:46<14:44,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27982.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  70%|████▉  | 519/744 [33:50<14:40,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26250.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  70%|████▉  | 520/744 [33:54<14:36,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27856.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  70%|████▉  | 521/744 [33:58<14:32,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29349.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  70%|████▉  | 522/744 [34:02<14:28,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30361.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  70%|████▉  | 523/744 [34:05<14:24,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27786.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  70%|████▉  | 524/744 [34:09<14:20,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30777.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  71%|████▉  | 525/744 [34:13<14:16,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29522.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  71%|████▉  | 526/744 [34:17<14:12,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29061.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9632, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  71%|████▉  | 527/744 [34:21<14:08,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26235.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  71%|████▉  | 528/744 [34:25<14:04,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28280.1992, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  71%|████▉  | 529/744 [34:29<14:00,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31711.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  71%|████▉  | 530/744 [34:33<13:57,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29757.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  71%|████▉  | 531/744 [34:37<13:53,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30057.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  72%|█████  | 532/744 [34:40<13:49,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30689.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  72%|█████  | 533/744 [34:44<13:45,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28140.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  72%|█████  | 534/744 [34:48<13:41,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30478.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  72%|█████  | 535/744 [34:52<13:37,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24815.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  72%|█████  | 536/744 [34:56<13:33,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32398.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  72%|█████  | 537/744 [35:00<13:29,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28532.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  72%|█████  | 538/744 [35:03<13:25,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29043.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  72%|█████  | 539/744 [35:07<13:21,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26389.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  73%|█████  | 540/744 [35:11<13:17,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32237.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  73%|█████  | 541/744 [35:15<13:13,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31656.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  73%|█████  | 542/744 [35:19<13:09,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31543.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  73%|█████  | 543/744 [35:23<13:05,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30162.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  73%|█████  | 544/744 [35:27<13:02,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27237.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  73%|█████▏ | 545/744 [35:31<12:58,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29551.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  73%|█████▏ | 546/744 [35:35<12:54,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28378.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  74%|█████▏ | 547/744 [35:39<12:50,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28500.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  74%|█████▏ | 548/744 [35:43<12:46,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29614.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  74%|█████▏ | 549/744 [35:47<12:42,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30014.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  74%|█████▏ | 550/744 [35:51<12:38,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29099.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  74%|█████▏ | 551/744 [35:55<12:34,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27872.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  74%|█████▏ | 552/744 [35:59<12:31,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27761.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  74%|█████▏ | 553/744 [36:03<12:27,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31911.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  74%|█████▏ | 554/744 [36:07<12:23,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30758.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  75%|█████▏ | 555/744 [36:11<12:19,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25686.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  75%|█████▏ | 556/744 [36:15<12:15,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28488.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  75%|█████▏ | 557/744 [36:19<12:11,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27892.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  75%|█████▎ | 558/744 [36:23<12:07,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31118.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  75%|█████▎ | 559/744 [36:27<12:03,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28015.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  75%|█████▎ | 560/744 [36:30<11:59,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30020.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  75%|█████▎ | 561/744 [36:34<11:55,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26266.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  76%|█████▎ | 562/744 [36:38<11:52,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29440.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  76%|█████▎ | 563/744 [36:42<11:48,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31301.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  76%|█████▎ | 564/744 [36:46<11:44,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29416.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  76%|█████▎ | 565/744 [36:51<11:40,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31811.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  76%|█████▎ | 566/744 [36:55<11:36,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28850.1016, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  76%|█████▎ | 567/744 [36:59<11:32,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28056.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  76%|█████▎ | 568/744 [37:03<11:28,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25051.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  76%|█████▎ | 569/744 [37:07<11:24,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29415.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  77%|█████▎ | 570/744 [37:10<11:21,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28458.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  77%|█████▎ | 571/744 [37:14<11:17,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29266.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  77%|█████▍ | 572/744 [37:18<11:13,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27078.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  77%|█████▍ | 573/744 [37:22<11:09,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26999.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  77%|█████▍ | 574/744 [37:26<11:05,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30137.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  77%|█████▍ | 575/744 [37:30<11:01,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25063.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  77%|█████▍ | 576/744 [37:34<10:57,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25842.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  78%|█████▍ | 577/744 [37:38<10:53,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(34268.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  78%|█████▍ | 578/744 [37:41<10:49,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26864.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  78%|█████▍ | 579/744 [37:45<10:45,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31133.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  78%|█████▍ | 580/744 [37:49<10:41,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28259.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  78%|█████▍ | 581/744 [37:53<10:37,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31154.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  78%|█████▍ | 582/744 [37:57<10:33,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26012.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  78%|█████▍ | 583/744 [38:01<10:29,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29479.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  78%|█████▍ | 584/744 [38:05<10:26,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27212.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  79%|█████▌ | 585/744 [38:08<10:22,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28763.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  79%|█████▌ | 586/744 [38:12<10:18,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29237.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  79%|█████▌ | 587/744 [38:16<10:14,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25822.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  79%|█████▌ | 588/744 [38:20<10:10,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30941.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  79%|█████▌ | 589/744 [38:24<10:06,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29785.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  79%|█████▌ | 590/744 [38:28<10:02,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31790.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  79%|█████▌ | 591/744 [38:32<09:58,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28836.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  80%|█████▌ | 592/744 [38:35<09:54,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27359.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  80%|█████▌ | 593/744 [38:39<09:50,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29973.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  80%|█████▌ | 594/744 [38:43<09:46,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25199.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  80%|█████▌ | 595/744 [38:47<09:42,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31863.8301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  80%|█████▌ | 596/744 [38:51<09:38,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29429.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  80%|█████▌ | 597/744 [38:55<09:35,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32161.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  80%|█████▋ | 598/744 [38:59<09:31,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31616.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  81%|█████▋ | 599/744 [39:03<09:27,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31271.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  81%|█████▋ | 600/744 [39:06<09:23,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28140.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  81%|█████▋ | 601/744 [39:10<09:19,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29909.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  81%|█████▋ | 602/744 [39:14<09:15,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31530.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  81%|█████▋ | 603/744 [39:18<09:11,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30063.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  81%|█████▋ | 604/744 [39:22<09:07,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27962.6270, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  81%|█████▋ | 605/744 [39:26<09:03,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30281.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  81%|█████▋ | 606/744 [39:30<08:59,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32742.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  82%|█████▋ | 607/744 [39:34<08:55,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30079.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  82%|█████▋ | 608/744 [39:38<08:51,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31897.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  82%|█████▋ | 609/744 [39:41<08:47,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29040.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  82%|█████▋ | 610/744 [39:45<08:44,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30057.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  82%|█████▋ | 611/744 [39:49<08:40,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30017.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  82%|█████▊ | 612/744 [39:53<08:36,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27427.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  82%|█████▊ | 613/744 [39:57<08:32,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31800.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  83%|█████▊ | 614/744 [40:01<08:28,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30372.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  83%|█████▊ | 615/744 [40:04<08:24,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28521.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  83%|█████▊ | 616/744 [40:08<08:20,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29441.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  83%|█████▊ | 617/744 [40:12<08:16,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24075.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  83%|█████▊ | 618/744 [40:16<08:12,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26059.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  83%|█████▊ | 619/744 [40:20<08:08,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28442.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  83%|█████▊ | 620/744 [40:24<08:04,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30476.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  83%|█████▊ | 621/744 [40:27<08:00,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30317.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  84%|█████▊ | 622/744 [40:31<07:56,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32183.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  84%|█████▊ | 623/744 [40:35<07:53,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26319.5801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  84%|█████▊ | 624/744 [40:39<07:49,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32487.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  84%|█████▉ | 625/744 [40:44<07:45,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30945.6621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  84%|█████▉ | 626/744 [40:48<07:41,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29161.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  84%|█████▉ | 627/744 [40:52<07:37,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27829.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  84%|█████▉ | 628/744 [40:56<07:33,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30920.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  85%|█████▉ | 629/744 [41:00<07:29,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27674.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  85%|█████▉ | 630/744 [41:04<07:25,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30843.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  85%|█████▉ | 631/744 [41:08<07:22,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27667.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  85%|█████▉ | 632/744 [41:12<07:18,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28986.3301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  85%|█████▉ | 633/744 [41:16<07:14,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31243.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  85%|█████▉ | 634/744 [41:20<07:10,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30965.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  85%|█████▉ | 635/744 [41:24<07:06,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27045.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  85%|█████▉ | 636/744 [41:28<07:02,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31394.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  86%|█████▉ | 637/744 [41:32<06:58,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28923.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  86%|██████ | 638/744 [41:36<06:54,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31099.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  86%|██████ | 639/744 [41:40<06:50,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28302.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  86%|██████ | 640/744 [41:44<06:46,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26914.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  86%|██████ | 641/744 [41:47<06:42,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28709.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  86%|██████ | 642/744 [41:51<06:39,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30286.4805, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  86%|██████ | 643/744 [41:55<06:35,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29231.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  87%|██████ | 644/744 [41:59<06:31,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32897.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  87%|██████ | 645/744 [42:03<06:27,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28603.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  87%|██████ | 646/744 [42:07<06:23,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28449.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  87%|██████ | 647/744 [42:11<06:19,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27113.3574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  87%|██████ | 648/744 [42:15<06:15,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31958.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  87%|██████ | 649/744 [42:19<06:11,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29595.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  87%|██████ | 650/744 [42:22<06:07,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30500.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  88%|██████▏| 651/744 [42:26<06:03,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31228.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  88%|██████▏| 652/744 [42:31<05:59,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30957.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  88%|██████▏| 653/744 [42:34<05:56,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30931.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  88%|██████▏| 654/744 [42:38<05:52,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30852.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  88%|██████▏| 655/744 [42:42<05:48,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31071.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  88%|██████▏| 656/744 [42:46<05:44,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32902.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  88%|██████▏| 657/744 [42:50<05:40,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28297.6074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  88%|██████▏| 658/744 [42:54<05:36,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31645.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  89%|██████▏| 659/744 [42:58<05:32,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29207.4160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  89%|██████▏| 660/744 [43:02<05:28,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32362.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  89%|██████▏| 661/744 [43:06<05:24,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32305.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  89%|██████▏| 662/744 [43:10<05:20,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28888.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  89%|██████▏| 663/744 [43:14<05:16,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(26439.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  89%|██████▏| 664/744 [43:18<05:13,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30380.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  89%|██████▎| 665/744 [43:22<05:09,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28595.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  90%|██████▎| 666/744 [43:25<05:05,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28877.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  90%|██████▎| 667/744 [43:29<05:01,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30232.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  90%|██████▎| 668/744 [43:33<04:57,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27996.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  90%|██████▎| 669/744 [43:38<04:53,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(33022.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  90%|██████▎| 670/744 [43:41<04:49,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30515.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  90%|██████▎| 671/744 [43:45<04:45,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32357.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  90%|██████▎| 672/744 [43:49<04:41,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31146.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  90%|██████▎| 673/744 [43:53<04:37,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27543.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  91%|██████▎| 674/744 [43:57<04:33,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27922.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  91%|██████▎| 675/744 [44:01<04:30,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32081.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  91%|██████▎| 676/744 [44:05<04:26,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32366.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  91%|██████▎| 677/744 [44:09<04:22,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31398.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  91%|██████▍| 678/744 [44:13<04:18,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(33467.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  91%|██████▍| 679/744 [44:17<04:14,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24933.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  91%|██████▍| 680/744 [44:20<04:10,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30284.9922, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  92%|██████▍| 681/744 [44:24<04:06,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29042.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  92%|██████▍| 682/744 [44:28<04:02,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28871.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  92%|██████▍| 683/744 [44:32<03:58,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28809.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  92%|██████▍| 684/744 [44:36<03:54,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32268.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  92%|██████▍| 685/744 [44:40<03:50,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29700.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  92%|██████▍| 686/744 [44:43<03:46,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29683.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  92%|██████▍| 687/744 [44:47<03:43,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30392.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  92%|██████▍| 688/744 [44:51<03:39,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32129.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  93%|██████▍| 689/744 [44:55<03:35,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(24295.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  93%|██████▍| 690/744 [44:59<03:31,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29691.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  93%|██████▌| 691/744 [45:03<03:27,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30075.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  93%|██████▌| 692/744 [45:07<03:23,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31752.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  93%|██████▌| 693/744 [45:10<03:19,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29578.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  93%|██████▌| 694/744 [45:14<03:15,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(25607.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  93%|██████▌| 695/744 [45:18<03:11,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(31970.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  94%|██████▌| 696/744 [45:22<03:07,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28561.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  94%|██████▌| 697/744 [45:26<03:03,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(33146.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  94%|██████▌| 698/744 [45:30<02:59,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28431.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  94%|██████▌| 699/744 [45:34<02:56,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30505.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  94%|██████▌| 700/744 [45:38<02:52,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30745.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  94%|██████▌| 701/744 [45:42<02:48,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27050.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  94%|██████▌| 702/744 [45:46<02:44,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30154.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  94%|██████▌| 703/744 [45:50<02:40,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29476.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  95%|██████▌| 704/744 [45:54<02:36,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32271.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9108, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  95%|██████▋| 705/744 [45:58<02:32,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30417.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  95%|██████▋| 706/744 [46:02<02:28,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32270.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  95%|██████▋| 707/744 [46:06<02:24,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(27569.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  95%|██████▋| 708/744 [46:10<02:20,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29400.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  95%|██████▋| 709/744 [46:14<02:16,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(28496.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3:  95%|██████▋| 710/744 [46:18<02:13,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(30941.6719, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_g:   tensor(33155., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  58%|████   | 435/744 [28:37<20:19,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41264.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  59%|████   | 436/744 [28:41<20:15,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(34638.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  59%|████   | 437/744 [28:45<20:12,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36204.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  59%|████   | 438/744 [28:49<20:07,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40116.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  59%|████▏  | 439/744 [28:53<20:04,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36661.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  59%|████▏  | 440/744 [28:56<20:00,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37183.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  59%|████▏  | 441/744 [29:01<19:56,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40064.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  59%|████▏  | 442/744 [29:05<19:52,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38042., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  60%|████▏  | 443/744 [29:08<19:48,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37094.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  60%|████▏  | 444/744 [29:12<19:44,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36987.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  60%|████▏  | 445/744 [29:16<19:40,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40485.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  60%|████▏  | 446/744 [29:20<19:36,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42741.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  60%|████▏  | 447/744 [29:24<19:32,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41347.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  60%|████▏  | 448/744 [29:28<19:28,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40006.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  60%|████▏  | 449/744 [29:32<19:24,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38287.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  60%|████▏  | 450/744 [29:36<19:20,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40143.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  61%|████▏  | 451/744 [29:40<19:16,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38401.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  61%|████▎  | 452/744 [29:43<19:12,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(29533.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  61%|████▎  | 453/744 [29:47<19:08,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40797.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  61%|████▎  | 454/744 [29:52<19:04,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40491.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  61%|████▎  | 455/744 [29:56<19:00,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44532.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  61%|████▎  | 456/744 [29:59<18:56,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41289.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  61%|████▎  | 457/744 [30:03<18:52,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(34789.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  62%|████▎  | 458/744 [30:07<18:48,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38776.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  62%|████▎  | 459/744 [30:11<18:44,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(33859.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  62%|████▎  | 460/744 [30:15<18:40,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38818.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  62%|████▎  | 461/744 [30:19<18:36,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(34697.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  62%|████▎  | 462/744 [30:23<18:32,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40110., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  62%|████▎  | 463/744 [30:27<18:28,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40034.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  62%|████▎  | 464/744 [30:30<18:24,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38126.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  62%|████▍  | 465/744 [30:34<18:20,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40468.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  63%|████▍  | 466/744 [30:38<18:16,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(33974.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  63%|████▍  | 467/744 [30:42<18:13,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39902.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  63%|████▍  | 468/744 [30:46<18:09,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42507.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  63%|████▍  | 469/744 [30:50<18:05,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40490.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  63%|████▍  | 470/744 [30:55<18:01,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37784.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  63%|████▍  | 471/744 [30:58<17:57,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39888.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  63%|████▍  | 472/744 [31:02<17:53,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41856.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  64%|████▍  | 473/744 [31:06<17:49,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38741.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  64%|████▍  | 474/744 [31:10<17:45,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40517.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8710, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  64%|████▍  | 475/744 [31:14<17:41,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36376.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  64%|████▍  | 476/744 [31:18<17:37,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41773.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  64%|████▍  | 477/744 [31:22<17:33,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39904.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  64%|████▍  | 478/744 [31:26<17:29,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35971.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  64%|████▌  | 479/744 [31:30<17:25,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38734.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  65%|████▌  | 480/744 [31:34<17:21,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38274.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  65%|████▌  | 481/744 [31:38<17:17,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42136.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  65%|████▌  | 482/744 [31:42<17:14,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36809.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  65%|████▌  | 483/744 [31:46<17:10,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37033.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  65%|████▌  | 484/744 [31:50<17:06,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35443.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  65%|████▌  | 485/744 [31:54<17:02,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42139.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  65%|████▌  | 486/744 [31:58<16:58,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45231.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  65%|████▌  | 487/744 [32:02<16:54,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45841.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  66%|████▌  | 488/744 [32:06<16:50,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39494.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  66%|████▌  | 489/744 [32:10<16:46,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40280.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  66%|████▌  | 490/744 [32:15<16:43,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38267.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  66%|████▌  | 491/744 [32:18<16:39,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38077.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  66%|████▋  | 492/744 [32:22<16:35,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41935.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  66%|████▋  | 493/744 [32:26<16:31,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39214.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  66%|████▋  | 494/744 [32:30<16:27,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36528.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  67%|████▋  | 495/744 [32:34<16:23,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42440.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  67%|████▋  | 496/744 [32:38<16:19,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37401.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  67%|████▋  | 497/744 [32:42<16:15,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40716.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  67%|████▋  | 498/744 [32:46<16:11,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35816.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  67%|████▋  | 499/744 [32:50<16:07,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39267.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  67%|████▋  | 500/744 [32:54<16:03,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41479.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  67%|████▋  | 501/744 [32:58<15:59,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41912.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  67%|████▋  | 502/744 [33:02<15:55,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36883.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  68%|████▋  | 503/744 [33:06<15:51,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40919.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  68%|████▋  | 504/744 [33:10<15:47,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43511.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  68%|████▊  | 505/744 [33:14<15:43,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37581.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  68%|████▊  | 506/744 [33:18<15:39,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39015.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  68%|████▊  | 507/744 [33:22<15:35,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42326.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  68%|████▊  | 508/744 [33:26<15:32,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41336.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  68%|████▊  | 509/744 [33:29<15:27,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38995.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0208, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  69%|████▊  | 510/744 [33:33<15:23,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38847.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  69%|████▊  | 511/744 [33:37<15:19,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39540.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  69%|████▊  | 512/744 [33:41<15:15,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39606.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  69%|████▊  | 513/744 [33:45<15:11,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37761.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  69%|████▊  | 514/744 [33:49<15:08,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41924.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  69%|████▊  | 515/744 [33:53<15:04,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39237.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  69%|████▊  | 516/744 [33:56<15:00,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41596.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  69%|████▊  | 517/744 [34:00<14:56,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38010.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  70%|████▊  | 518/744 [34:04<14:52,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41494.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  70%|████▉  | 519/744 [34:08<14:48,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39169.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  70%|████▉  | 520/744 [34:13<14:44,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38354.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  70%|████▉  | 521/744 [34:16<14:40,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36894.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  70%|████▉  | 522/744 [34:20<14:36,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40783.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  70%|████▉  | 523/744 [34:24<14:32,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43740.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  70%|████▉  | 524/744 [34:28<14:28,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40645.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  71%|████▉  | 525/744 [34:33<14:24,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39089.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9853, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  71%|████▉  | 526/744 [34:37<14:20,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40323.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  71%|████▉  | 527/744 [34:40<14:16,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43834.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  71%|████▉  | 528/744 [34:44<14:12,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38733.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  71%|████▉  | 529/744 [34:48<14:08,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40071.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  71%|████▉  | 530/744 [34:52<14:04,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40338.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  71%|████▉  | 531/744 [34:56<14:00,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40394.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  72%|█████  | 532/744 [34:59<13:56,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40834.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  72%|█████  | 533/744 [35:04<13:52,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37403.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  72%|█████  | 534/744 [35:08<13:49,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38490.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  72%|█████  | 535/744 [35:12<13:45,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41621.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  72%|█████  | 536/744 [35:16<13:41,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38381.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  72%|█████  | 537/744 [35:19<13:37,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41938.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  72%|█████  | 538/744 [35:23<13:33,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41295.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  72%|█████  | 539/744 [35:27<13:29,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41015.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  73%|█████  | 540/744 [35:31<13:25,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35478.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  73%|█████  | 541/744 [35:35<13:21,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38566.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  73%|█████  | 542/744 [35:39<13:17,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42104.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  73%|█████  | 543/744 [35:43<13:13,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37981.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  73%|█████  | 544/744 [35:47<13:09,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39717.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  73%|█████▏ | 545/744 [35:51<13:05,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42898.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  73%|█████▏ | 546/744 [35:55<13:01,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37242.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  74%|█████▏ | 547/744 [35:59<12:57,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41582.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9091, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  74%|█████▏ | 548/744 [36:03<12:53,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40506.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  74%|█████▏ | 549/744 [36:07<12:49,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43049.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  74%|█████▏ | 550/744 [36:11<12:45,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35484.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  74%|█████▏ | 551/744 [36:15<12:42,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41825.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  74%|█████▏ | 552/744 [36:19<12:38,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44309.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  74%|█████▏ | 553/744 [36:23<12:34,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39595.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  74%|█████▏ | 554/744 [36:27<12:30,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37563.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  75%|█████▏ | 555/744 [36:31<12:26,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37878.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  75%|█████▏ | 556/744 [36:35<12:22,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39323.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  75%|█████▏ | 557/744 [36:39<12:18,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37681.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  75%|█████▎ | 558/744 [36:43<12:14,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42842.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  75%|█████▎ | 559/744 [36:47<12:10,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40151.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  75%|█████▎ | 560/744 [36:51<12:06,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42783.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  75%|█████▎ | 561/744 [36:55<12:02,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42426.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  76%|█████▎ | 562/744 [36:59<11:58,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42054.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  76%|█████▎ | 563/744 [37:03<11:54,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43305.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  76%|█████▎ | 564/744 [37:07<11:50,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42211.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  76%|█████▎ | 565/744 [37:11<11:46,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37562.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  76%|█████▎ | 566/744 [37:15<11:42,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37708.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  76%|█████▎ | 567/744 [37:19<11:38,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43378.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  76%|█████▎ | 568/744 [37:23<11:35,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41252.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  76%|█████▎ | 569/744 [37:27<11:31,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36601.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  77%|█████▎ | 570/744 [37:31<11:27,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40837.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  77%|█████▎ | 571/744 [37:35<11:23,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41966.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  77%|█████▍ | 572/744 [37:39<11:19,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41388.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  77%|█████▍ | 573/744 [37:43<11:15,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36073.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  77%|█████▍ | 574/744 [37:47<11:11,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39527.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  77%|█████▍ | 575/744 [37:51<11:07,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40248.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  77%|█████▍ | 576/744 [37:54<11:03,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42365.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  78%|█████▍ | 577/744 [37:59<10:59,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39018.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  78%|█████▍ | 578/744 [38:03<10:55,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45399.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  78%|█████▍ | 579/744 [38:07<10:51,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37781.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  78%|█████▍ | 580/744 [38:10<10:47,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(34559.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  78%|█████▍ | 581/744 [38:14<10:43,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41919.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  78%|█████▍ | 582/744 [38:18<10:39,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42892.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  78%|█████▍ | 583/744 [38:22<10:35,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37666.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  78%|█████▍ | 584/744 [38:26<10:31,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41476.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  79%|█████▌ | 585/744 [38:30<10:28,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39993.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9323, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  79%|█████▌ | 586/744 [38:34<10:24,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39034.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  79%|█████▌ | 587/744 [38:38<10:20,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42751.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  79%|█████▌ | 588/744 [38:42<10:16,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40426.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  79%|█████▌ | 589/744 [38:46<10:12,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40585.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  79%|█████▌ | 590/744 [38:50<10:08,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41660.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  79%|█████▌ | 591/744 [38:54<10:04,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40549.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  80%|█████▌ | 592/744 [38:58<10:00,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37541.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  80%|█████▌ | 593/744 [39:02<09:56,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42730.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  80%|█████▌ | 594/744 [39:06<09:52,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43827.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  80%|█████▌ | 595/744 [39:10<09:48,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35533.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  80%|█████▌ | 596/744 [39:14<09:44,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37437.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  80%|█████▌ | 597/744 [39:18<09:40,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38599.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  80%|█████▋ | 598/744 [39:22<09:36,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37798.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  81%|█████▋ | 599/744 [39:26<09:32,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41634.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  81%|█████▋ | 600/744 [39:30<09:28,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40373.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  81%|█████▋ | 601/744 [39:34<09:24,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42826.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  81%|█████▋ | 602/744 [39:38<09:20,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43061.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  81%|█████▋ | 603/744 [39:42<09:17,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41671.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  81%|█████▋ | 604/744 [39:46<09:13,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38033.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  81%|█████▋ | 605/744 [39:50<09:09,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37800.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  81%|█████▋ | 606/744 [39:54<09:05,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35250.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  82%|█████▋ | 607/744 [39:58<09:01,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43809.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  82%|█████▋ | 608/744 [40:02<08:57,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41985.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  82%|█████▋ | 609/744 [40:06<08:53,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43165.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  82%|█████▋ | 610/744 [40:10<08:49,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43519.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  82%|█████▋ | 611/744 [40:14<08:45,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37867.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  82%|█████▊ | 612/744 [40:18<08:41,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39771.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  82%|█████▊ | 613/744 [40:22<08:37,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43392.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  83%|█████▊ | 614/744 [40:26<08:33,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42555.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  83%|█████▊ | 615/744 [40:29<08:29,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43265.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  83%|█████▊ | 616/744 [40:33<08:25,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41561.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  83%|█████▊ | 617/744 [40:37<08:21,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42304.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  83%|█████▊ | 618/744 [40:41<08:17,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38627.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  83%|█████▊ | 619/744 [40:45<08:13,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40581.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  83%|█████▊ | 620/744 [40:49<08:09,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42415.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  83%|█████▊ | 621/744 [40:53<08:06,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42224.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  84%|█████▊ | 622/744 [40:58<08:02,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42207.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  84%|█████▊ | 623/744 [41:02<07:58,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39609.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9479, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  84%|█████▊ | 624/744 [41:06<07:54,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38902.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  84%|█████▉ | 625/744 [41:09<07:50,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40644.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  84%|█████▉ | 626/744 [41:13<07:46,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43760.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  84%|█████▉ | 627/744 [41:17<07:42,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42703.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  84%|█████▉ | 628/744 [41:21<07:38,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(33494.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  85%|█████▉ | 629/744 [41:26<07:34,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43770.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  85%|█████▉ | 630/744 [41:29<07:30,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38717.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  85%|█████▉ | 631/744 [41:33<07:26,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41221.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  85%|█████▉ | 632/744 [41:37<07:22,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42277.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  85%|█████▉ | 633/744 [41:41<07:18,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40590.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  85%|█████▉ | 634/744 [41:45<07:14,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41253.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  85%|█████▉ | 635/744 [41:49<07:10,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37829.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  85%|█████▉ | 636/744 [41:53<07:06,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38514.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  86%|█████▉ | 637/744 [41:57<07:02,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45760.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  86%|██████ | 638/744 [42:01<06:58,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37118.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  86%|██████ | 639/744 [42:05<06:54,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40196.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  86%|██████ | 640/744 [42:09<06:51,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38836.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  86%|██████ | 641/744 [42:13<06:47,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40767.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  86%|██████ | 642/744 [42:17<06:43,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43554.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  86%|██████ | 643/744 [42:21<06:39,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39267.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  87%|██████ | 644/744 [42:25<06:35,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43377.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  87%|██████ | 645/744 [42:28<06:31,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41282.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  87%|██████ | 646/744 [42:32<06:27,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40873.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  87%|██████ | 647/744 [42:36<06:23,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43658.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  87%|██████ | 648/744 [42:40<06:19,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39594.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  87%|██████ | 649/744 [42:43<06:15,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41923.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  87%|██████ | 650/744 [42:48<06:11,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45668.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  88%|██████▏| 651/744 [42:52<06:07,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40021.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  88%|██████▏| 652/744 [42:56<06:03,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35845.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  88%|██████▏| 653/744 [43:00<05:59,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37674.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  88%|██████▏| 654/744 [43:04<05:55,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38454.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  88%|██████▏| 655/744 [43:07<05:51,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45893.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  88%|██████▏| 656/744 [43:11<05:47,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42795.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  88%|██████▏| 657/744 [43:15<05:43,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38076.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  88%|██████▏| 658/744 [43:19<05:39,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38711.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  89%|██████▏| 659/744 [43:23<05:35,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40042.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  89%|██████▏| 660/744 [43:27<05:31,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39653.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  89%|██████▏| 661/744 [43:30<05:27,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41166.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  89%|██████▏| 662/744 [43:34<05:23,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(32915.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  89%|██████▏| 663/744 [43:38<05:19,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(34799.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  89%|██████▏| 664/744 [43:42<05:15,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44366.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  89%|██████▎| 665/744 [43:46<05:12,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42458.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  90%|██████▎| 666/744 [43:50<05:08,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40980.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  90%|██████▎| 667/744 [43:54<05:04,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40606.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8819, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  90%|██████▎| 668/744 [43:58<05:00,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42413.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8673, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  90%|██████▎| 669/744 [44:02<04:56,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38474.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  90%|██████▎| 670/744 [44:06<04:52,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39394.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  90%|██████▎| 671/744 [44:10<04:48,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39608.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  90%|██████▎| 672/744 [44:14<04:44,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41401.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  90%|██████▎| 673/744 [44:18<04:40,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45406.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  91%|██████▎| 674/744 [44:22<04:36,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40958.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  91%|██████▎| 675/744 [44:25<04:32,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42245.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  91%|██████▎| 676/744 [44:29<04:28,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36968.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  91%|██████▎| 677/744 [44:33<04:24,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38133.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  91%|██████▍| 678/744 [44:37<04:20,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41531.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  91%|██████▍| 679/744 [44:41<04:16,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38975.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  91%|██████▍| 680/744 [44:45<04:12,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45451.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  92%|██████▍| 681/744 [44:49<04:08,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39925.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  92%|██████▍| 682/744 [44:53<04:04,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39116.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  92%|██████▍| 683/744 [44:57<04:00,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35735.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  92%|██████▍| 684/744 [45:01<03:56,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41801.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  92%|██████▍| 685/744 [45:04<03:52,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39735.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  92%|██████▍| 686/744 [45:08<03:49,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39968.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  92%|██████▍| 687/744 [45:12<03:45,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42322.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  92%|██████▍| 688/744 [45:16<03:41,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38725.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  93%|██████▍| 689/744 [45:20<03:37,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42897.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  93%|██████▍| 690/744 [45:24<03:33,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42616.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  93%|██████▌| 691/744 [45:28<03:29,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41152.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  93%|██████▌| 692/744 [45:32<03:25,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41391.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  93%|██████▌| 693/744 [45:36<03:21,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41744.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  93%|██████▌| 694/744 [45:40<03:17,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39000.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  93%|██████▌| 695/744 [45:44<03:13,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45826.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  94%|██████▌| 696/744 [45:48<03:09,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44730.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  94%|██████▌| 697/744 [45:52<03:05,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44159.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  94%|██████▌| 698/744 [45:55<03:01,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46065.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  94%|██████▌| 699/744 [45:59<02:57,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43073.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9816, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  94%|██████▌| 700/744 [46:03<02:53,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36429.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  94%|██████▌| 701/744 [46:07<02:49,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45064.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  94%|██████▌| 702/744 [46:11<02:45,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41896.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  94%|██████▌| 703/744 [46:15<02:41,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39605.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  95%|██████▌| 704/744 [46:19<02:37,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40429.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  95%|██████▋| 705/744 [46:23<02:33,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44259.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  95%|██████▋| 706/744 [46:27<02:30,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41051.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  95%|██████▋| 707/744 [46:31<02:26,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41657.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  95%|██████▋| 708/744 [46:35<02:22,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43985.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  95%|██████▋| 709/744 [46:39<02:18,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42231.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  95%|██████▋| 710/744 [46:43<02:14,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44193.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  96%|██████▋| 711/744 [46:47<02:10,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40832.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  96%|██████▋| 712/744 [46:51<02:06,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41367.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  96%|██████▋| 713/744 [46:55<02:02,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37036.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  96%|██████▋| 714/744 [46:59<01:58,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45785.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  96%|██████▋| 715/744 [47:03<01:54,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45925.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  96%|██████▋| 716/744 [47:07<01:50,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45357.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  96%|██████▋| 717/744 [47:10<01:46,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41313.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  97%|██████▊| 718/744 [47:14<01:42,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44401.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  97%|██████▊| 719/744 [47:19<01:38,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36959.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  97%|██████▊| 720/744 [47:23<01:34,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38762.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  97%|██████▊| 721/744 [47:27<01:30,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42566.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  97%|██████▊| 722/744 [47:31<01:26,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42719.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  97%|██████▊| 723/744 [47:34<01:22,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38522.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  97%|██████▊| 724/744 [47:38<01:18,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44711.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  97%|██████▊| 725/744 [47:42<01:15,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40897.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  98%|██████▊| 726/744 [47:46<01:11,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40657.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  98%|██████▊| 727/744 [47:50<01:07,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42315.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  98%|██████▊| 728/744 [47:54<01:03,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43565.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  98%|██████▊| 729/744 [47:58<00:59,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40565.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  98%|██████▊| 730/744 [48:02<00:55,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45376.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  98%|██████▉| 731/744 [48:06<00:51,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38575.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  98%|██████▉| 732/744 [48:10<00:47,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35043.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  99%|██████▉| 733/744 [48:14<00:43,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40543.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  99%|██████▉| 734/744 [48:18<00:39,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41919.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  99%|██████▉| 735/744 [48:21<00:35,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39311.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  99%|██████▉| 736/744 [48:25<00:31,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43298.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  99%|██████▉| 737/744 [48:29<00:27,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42264.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9790, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  99%|██████▉| 738/744 [48:33<00:23,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44619.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  99%|██████▉| 739/744 [48:37<00:19,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42195.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5:  99%|██████▉| 740/744 [48:41<00:15,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35872.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5: 100%|██████▉| 741/744 [48:45<00:11,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41399.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5: 100%|██████▉| 742/744 [48:49<00:07,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42011.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5: 100%|██████▉| 743/744 [48:53<00:03,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46346.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8885, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   0%|                 | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(39896.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8148, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   0%|       | 1/744 [00:05<1:11:48,  5.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35777.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   0%|       | 2/744 [00:09<1:01:13,  4.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43429.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   0%|         | 3/744 [00:13<57:00,  4.62s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42725.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   1%|         | 4/744 [00:17<54:40,  4.43s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37071.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   1%|         | 5/744 [00:21<53:12,  4.32s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43022.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   1%|         | 6/744 [00:25<52:34,  4.27s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38421.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   1%|         | 7/744 [00:29<51:53,  4.22s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37978.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   1%|         | 8/744 [00:33<51:22,  4.19s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42092.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   1%|         | 9/744 [00:37<51:11,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40144.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   1%|        | 10/744 [00:41<50:39,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37123.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   1%|        | 11/744 [00:45<50:19,  4.12s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42233.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   2%|▏       | 12/744 [00:49<50:12,  4.12s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46027.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   2%|▏       | 13/744 [00:53<49:42,  4.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41641.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   2%|▏       | 14/744 [00:57<49:55,  4.10s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43254.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   2%|▏       | 15/744 [01:01<49:37,  4.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43477.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   2%|▏       | 16/744 [01:05<49:31,  4.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44776.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   2%|▏       | 17/744 [01:09<49:22,  4.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41454.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   2%|▏       | 18/744 [01:13<49:06,  4.06s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41148.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   3%|▏       | 19/744 [01:16<48:48,  4.04s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40314.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   3%|▏       | 20/744 [01:20<48:37,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40240.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   3%|▏       | 21/744 [01:24<48:27,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41182.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   3%|▏       | 22/744 [01:28<48:25,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47160.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   3%|▏       | 23/744 [01:32<48:10,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41465.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   3%|▎       | 24/744 [01:36<48:03,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45360.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   3%|▎       | 25/744 [01:40<48:04,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43456.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   3%|▎       | 26/744 [01:44<47:58,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35804.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   4%|▎       | 27/744 [01:48<47:58,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43762.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   4%|▎       | 28/744 [01:52<47:45,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41706.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   4%|▎       | 29/744 [01:55<47:39,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44688.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   4%|▎       | 30/744 [01:59<47:33,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42208.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   4%|▎       | 31/744 [02:03<47:30,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40294.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9090, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:   4%|▎       | 32/744 [02:07<47:26,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40314.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   4%|▎       | 33/744 [02:11<47:23,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43983.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   5%|▎       | 34/744 [02:15<47:13,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38336.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   5%|▍       | 35/744 [02:19<47:06,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42575.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   5%|▍       | 36/744 [02:23<47:00,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40671.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   5%|▍       | 37/744 [02:27<46:53,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44012.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   5%|▍       | 38/744 [02:31<46:53,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41208.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   5%|▍       | 39/744 [02:35<46:49,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39348.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8710, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   5%|▍       | 40/744 [02:39<46:44,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41113.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   6%|▍       | 41/744 [02:43<46:37,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45911.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   6%|▍       | 42/744 [02:46<46:29,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39055.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   6%|▍       | 43/744 [02:51<46:28,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37494.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   6%|▍       | 44/744 [02:55<46:28,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39965.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   6%|▍       | 45/744 [02:59<46:21,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44443.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   6%|▍       | 46/744 [03:02<46:15,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39206.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   6%|▌       | 47/744 [03:06<46:06,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36021.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   6%|▌       | 48/744 [03:10<46:05,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44082.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   7%|▌       | 49/744 [03:14<46:00,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43373.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   7%|▌       | 50/744 [03:18<45:56,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44951.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   7%|▌       | 51/744 [03:22<45:52,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42584.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   7%|▌       | 52/744 [03:26<45:51,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39499.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   7%|▌       | 53/744 [03:30<45:46,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40331.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   7%|▌       | 54/744 [03:34<45:41,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44956.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   7%|▌       | 55/744 [03:38<45:33,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41094.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   8%|▌       | 56/744 [03:42<45:28,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42447.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   8%|▌       | 57/744 [03:46<45:24,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42501.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   8%|▌       | 58/744 [03:50<45:22,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39207.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   8%|▋       | 59/744 [03:54<45:19,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44216.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   8%|▋       | 60/744 [03:58<45:15,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41307.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   8%|▋       | 61/744 [04:02<45:10,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39137.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   8%|▋       | 62/744 [04:05<45:02,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41394.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   8%|▋       | 63/744 [04:09<44:58,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45445.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   9%|▋       | 64/744 [04:13<44:54,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42596.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   9%|▋       | 65/744 [04:17<44:47,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45525.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   9%|▋       | 66/744 [04:21<44:44,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39296.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   9%|▋       | 67/744 [04:24<44:37,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42550.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   9%|▋       | 68/744 [04:29<44:36,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41716.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:   9%|▋       | 69/744 [04:33<44:32,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44988.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9331, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:   9%|▊       | 70/744 [04:37<44:28,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44203.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  10%|▊       | 71/744 [04:41<44:24,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42180.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  10%|▊       | 72/744 [04:44<44:19,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40228.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  10%|▊       | 73/744 [04:48<44:14,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44862.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  10%|▊       | 74/744 [04:52<44:11,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42334.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  10%|▊       | 75/744 [04:57<44:09,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40481.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  10%|▊       | 76/744 [05:01<44:09,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38981.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  10%|▊       | 77/744 [05:05<44:04,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37866.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  10%|▊       | 78/744 [05:09<44:03,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42178.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  11%|▊       | 79/744 [05:13<43:57,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44915.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  11%|▊       | 80/744 [05:17<43:51,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39578.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  11%|▊       | 81/744 [05:21<43:47,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37037.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  11%|▉       | 82/744 [05:24<43:42,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42229.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  11%|▉       | 83/744 [05:28<43:39,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45829.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  11%|▉       | 84/744 [05:32<43:34,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45574.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  11%|▉       | 85/744 [05:36<43:28,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45780.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  12%|▉       | 86/744 [05:40<43:26,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38625.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  12%|▉       | 87/744 [05:44<43:20,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42773.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  12%|▉       | 88/744 [05:48<43:15,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45653.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  12%|▉       | 89/744 [05:52<43:11,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35820.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  12%|▉       | 90/744 [05:56<43:07,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43019.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  12%|▉       | 91/744 [06:00<43:06,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43931.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  12%|▉       | 92/744 [06:04<43:02,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45231.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  12%|█       | 93/744 [06:07<42:55,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42185.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  13%|█       | 94/744 [06:12<42:52,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41590.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  13%|█       | 95/744 [06:16<42:49,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42170.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  13%|█       | 96/744 [06:20<42:45,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42171.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  13%|█       | 97/744 [06:23<42:39,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40941.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  13%|█       | 98/744 [06:28<42:37,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41868.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  13%|█       | 99/744 [06:32<42:34,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42979.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  13%|▉      | 100/744 [06:36<42:30,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40860.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  14%|▉      | 101/744 [06:40<42:27,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44774.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  14%|▉      | 102/744 [06:43<42:22,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43205.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  14%|▉      | 103/744 [06:47<42:16,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37847.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  14%|▉      | 104/744 [06:51<42:12,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45367.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  14%|▉      | 105/744 [06:55<42:08,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47437.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  14%|▉      | 106/744 [06:59<42:05,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42476.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  14%|█      | 107/744 [07:03<42:01,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38591.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9085, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  15%|█      | 108/744 [07:07<41:58,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42055., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  15%|█      | 109/744 [07:11<41:53,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42927.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  15%|█      | 110/744 [07:15<41:48,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45475.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  15%|█      | 111/744 [07:19<41:47,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42132.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  15%|█      | 112/744 [07:23<41:42,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41827.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  15%|█      | 113/744 [07:27<41:39,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43263.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  15%|█      | 114/744 [07:31<41:35,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43312.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  15%|█      | 115/744 [07:35<41:32,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43062.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  16%|█      | 116/744 [07:39<41:27,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37416.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  16%|█      | 117/744 [07:43<41:23,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46405.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  16%|█      | 118/744 [07:47<41:21,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37780.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  16%|█      | 119/744 [07:51<41:16,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38355.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  16%|█▏     | 120/744 [07:55<41:14,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45234.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  16%|█▏     | 121/744 [08:00<41:11,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43277.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  16%|█▏     | 122/744 [08:03<41:07,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41352.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  17%|█▏     | 123/744 [08:08<41:04,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39799.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  17%|█▏     | 124/744 [08:12<41:00,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44871.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  17%|█▏     | 125/744 [08:16<40:56,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45425.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  17%|█▏     | 126/744 [08:19<40:51,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39833.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  17%|█▏     | 127/744 [08:23<40:47,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38063.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  17%|█▏     | 128/744 [08:28<40:45,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45611.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  17%|█▏     | 129/744 [08:32<40:41,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41787.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  17%|█▏     | 130/744 [08:37<40:44,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40894.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  18%|█▏     | 131/744 [08:41<40:40,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40541.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  18%|█▏     | 132/744 [08:45<40:36,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39509.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  18%|█▎     | 133/744 [08:49<40:34,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42816.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9694, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  18%|█▎     | 134/744 [08:53<40:29,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43812.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  18%|█▎     | 135/744 [08:58<40:30,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45216.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  18%|█▎     | 136/744 [09:02<40:25,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42409.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  18%|█▎     | 137/744 [09:06<40:20,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40706.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  19%|█▎     | 138/744 [09:09<40:14,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39260.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  19%|█▎     | 139/744 [09:14<40:11,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41656.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  19%|█▎     | 140/744 [09:17<40:07,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43246.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  19%|█▎     | 141/744 [09:21<40:02,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41634.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  19%|█▎     | 142/744 [09:25<39:59,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38629.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  19%|█▎     | 143/744 [09:29<39:54,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42791.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  19%|█▎     | 144/744 [09:33<39:50,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43627.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  19%|█▎     | 145/744 [09:37<39:45,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42215.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8575, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  20%|█▎     | 146/744 [09:41<39:41,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42414.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  20%|█▍     | 147/744 [09:45<39:37,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44520.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  20%|█▍     | 148/744 [09:49<39:33,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47002.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  20%|█▍     | 149/744 [09:53<39:28,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40777.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  20%|█▍     | 150/744 [09:56<39:23,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43367.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  20%|█▍     | 151/744 [10:00<39:18,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41572.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  20%|█▍     | 152/744 [10:04<39:13,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46047.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  21%|█▍     | 153/744 [10:08<39:09,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45883.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  21%|█▍     | 154/744 [10:12<39:06,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44767.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  21%|█▍     | 155/744 [10:16<39:02,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42590.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  21%|█▍     | 156/744 [10:20<38:58,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41383.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  21%|█▍     | 157/744 [10:24<38:53,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42560.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  21%|█▍     | 158/744 [10:28<38:50,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45044.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  21%|█▍     | 159/744 [10:32<38:46,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43340.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  22%|█▌     | 160/744 [10:36<38:42,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41155.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  22%|█▌     | 161/744 [10:39<38:37,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42804.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  22%|█▌     | 162/744 [10:43<38:32,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41540.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  22%|█▌     | 163/744 [10:47<38:28,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42877.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  22%|█▌     | 164/744 [10:51<38:24,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42027.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  22%|█▌     | 165/744 [10:55<38:20,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36720.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  22%|█▌     | 166/744 [10:59<38:16,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43169.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  22%|█▌     | 167/744 [11:03<38:12,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45419.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  23%|█▌     | 168/744 [11:07<38:08,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41921.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  23%|█▌     | 169/744 [11:11<38:05,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(36830.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  23%|█▌     | 170/744 [11:15<38:01,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43462.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  23%|█▌     | 171/744 [11:19<37:56,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41596.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  23%|█▌     | 172/744 [11:23<37:52,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43371.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  23%|█▋     | 173/744 [11:26<37:47,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45269.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  23%|█▋     | 174/744 [11:30<37:42,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47361.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  24%|█▋     | 175/744 [11:34<37:38,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44072.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  24%|█▋     | 176/744 [11:38<37:34,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42806.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  24%|█▋     | 177/744 [11:42<37:30,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38972.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  24%|█▋     | 178/744 [11:46<37:26,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48313.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  24%|█▋     | 179/744 [11:50<37:21,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44646.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  24%|█▋     | 180/744 [11:54<37:17,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43535.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  24%|█▋     | 181/744 [11:58<37:14,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44629.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  24%|█▋     | 182/744 [12:02<37:10,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42749.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  25%|█▋     | 183/744 [12:05<37:05,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44763.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9895, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  25%|█▋     | 184/744 [12:09<37:00,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41075.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  25%|█▋     | 185/744 [12:13<36:56,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42480.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  25%|█▊     | 186/744 [12:17<36:52,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39170.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  25%|█▊     | 187/744 [12:21<36:48,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45421.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  25%|█▊     | 188/744 [12:25<36:44,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42914.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  25%|█▊     | 189/744 [12:29<36:40,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47656.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  26%|█▊     | 190/744 [12:33<36:36,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42520.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  26%|█▊     | 191/744 [12:36<36:31,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38453.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  26%|█▊     | 192/744 [12:41<36:28,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45280.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  26%|█▊     | 193/744 [12:45<36:24,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42139.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  26%|█▊     | 194/744 [12:49<36:21,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45469.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  26%|█▊     | 195/744 [12:53<36:17,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38347.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  26%|█▊     | 196/744 [12:57<36:13,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42167.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  26%|█▊     | 197/744 [13:01<36:08,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41489.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  27%|█▊     | 198/744 [13:04<36:04,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40911.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  27%|█▊     | 199/744 [13:08<36:00,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42007.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  27%|█▉     | 200/744 [13:12<35:56,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44337.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  27%|█▉     | 201/744 [13:16<35:51,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42463.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  27%|█▉     | 202/744 [13:20<35:47,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45597.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  27%|█▉     | 203/744 [13:24<35:43,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(33061.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  27%|█▉     | 204/744 [13:28<35:39,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44802.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  28%|█▉     | 205/744 [13:32<35:35,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43244.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  28%|█▉     | 206/744 [13:36<35:31,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44268.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  28%|█▉     | 207/744 [13:40<35:28,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44616.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  28%|█▉     | 208/744 [13:44<35:23,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42325.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  28%|█▉     | 209/744 [13:48<35:19,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35939.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  28%|█▉     | 210/744 [13:52<35:16,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43135.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  28%|█▉     | 211/744 [13:56<35:12,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46730.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  28%|█▉     | 212/744 [14:00<35:08,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41945.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  29%|██     | 213/744 [14:04<35:04,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43898.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  29%|██     | 214/744 [14:08<35:00,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42413.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  29%|██     | 215/744 [14:11<34:55,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46955.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  29%|██     | 216/744 [14:15<34:51,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44692.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  29%|██     | 217/744 [14:19<34:46,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38113.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  29%|██     | 218/744 [14:23<34:42,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38809.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  29%|██     | 219/744 [14:26<34:37,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39670.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  30%|██     | 220/744 [14:30<34:34,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41389.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  30%|██     | 221/744 [14:34<34:29,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47617.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9485, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  30%|██     | 222/744 [14:38<34:25,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40420.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  30%|██     | 223/744 [14:42<34:21,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47523.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  30%|██     | 224/744 [14:46<34:17,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42595.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  30%|██     | 225/744 [14:50<34:13,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42601.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  30%|██▏    | 226/744 [14:54<34:09,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42445.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  31%|██▏    | 227/744 [14:57<34:05,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41723.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  31%|██▏    | 228/744 [15:01<34:00,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46787.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  31%|██▏    | 229/744 [15:05<33:56,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41405.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  31%|██▏    | 230/744 [15:09<33:52,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44878.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  31%|██▏    | 231/744 [15:13<33:48,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43525.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  31%|██▏    | 232/744 [15:17<33:44,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48911.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  31%|██▏    | 233/744 [15:21<33:40,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43463.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  31%|██▏    | 234/744 [15:25<33:36,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46883.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  32%|██▏    | 235/744 [15:29<33:33,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46488.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  32%|██▏    | 236/744 [15:33<33:29,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45226.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  32%|██▏    | 237/744 [15:37<33:25,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42181.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  32%|██▏    | 238/744 [15:41<33:21,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43338.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  32%|██▏    | 239/744 [15:45<33:17,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41813.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  32%|██▎    | 240/744 [15:49<33:13,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37067.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  32%|██▎    | 241/744 [15:53<33:09,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44677.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  33%|██▎    | 242/744 [15:57<33:05,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42935.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9673, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  33%|██▎    | 243/744 [16:01<33:01,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(35775.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  33%|██▎    | 244/744 [16:05<32:57,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44775.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  33%|██▎    | 245/744 [16:09<32:53,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42770.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  33%|██▎    | 246/744 [16:13<32:50,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37839.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  33%|██▎    | 247/744 [16:17<32:46,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47857.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  33%|██▎    | 248/744 [16:21<32:42,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40884.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  33%|██▎    | 249/744 [16:25<32:39,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44553.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  34%|██▎    | 250/744 [16:29<32:35,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48981.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  34%|██▎    | 251/744 [16:33<32:31,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49346.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  34%|██▎    | 252/744 [16:37<32:27,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43593.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  34%|██▍    | 253/744 [16:41<32:24,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41261.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  34%|██▍    | 254/744 [16:45<32:20,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43391.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  34%|██▍    | 255/744 [16:49<32:15,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42212.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  34%|██▍    | 256/744 [16:53<32:11,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42941.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  35%|██▍    | 257/744 [16:57<32:07,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42516.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9822, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  35%|██▍    | 258/744 [17:01<32:04,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42655.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  35%|██▍    | 259/744 [17:05<31:59,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45769.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0029, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  35%|██▍    | 260/744 [17:09<31:55,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42812.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  35%|██▍    | 261/744 [17:13<31:52,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39340.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  35%|██▍    | 262/744 [17:17<31:49,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38757.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  35%|██▍    | 263/744 [17:21<31:45,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43140.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  35%|██▍    | 264/744 [17:25<31:40,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42606.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  36%|██▍    | 265/744 [17:29<31:36,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47744.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  36%|██▌    | 266/744 [17:33<31:33,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46066.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  36%|██▌    | 267/744 [17:37<31:29,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44182.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  36%|██▌    | 268/744 [17:41<31:25,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47452.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  36%|██▌    | 269/744 [17:46<31:23,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46467.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  36%|██▌    | 270/744 [17:50<31:19,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41862.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  36%|██▌    | 271/744 [17:54<31:15,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40594.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  37%|██▌    | 272/744 [17:58<31:12,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38457.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  37%|██▌    | 273/744 [18:03<31:09,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46671.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  37%|██▌    | 274/744 [18:07<31:05,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46998.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  37%|██▌    | 275/744 [18:11<31:01,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41818.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  37%|██▌    | 276/744 [18:15<30:57,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45806.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  37%|██▌    | 277/744 [18:19<30:53,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38531.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  37%|██▌    | 278/744 [18:23<30:49,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44373.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  38%|██▋    | 279/744 [18:27<30:45,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39527.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  38%|██▋    | 280/744 [18:31<30:41,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46368.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  38%|██▋    | 281/744 [18:35<30:37,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43330.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  38%|██▋    | 282/744 [18:39<30:34,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45371.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  38%|██▋    | 283/744 [18:43<30:30,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42197.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  38%|██▋    | 284/744 [18:48<30:27,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41054.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  38%|██▋    | 285/744 [18:52<30:24,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44928.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  38%|██▋    | 286/744 [18:56<30:19,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41528.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  39%|██▋    | 287/744 [19:00<30:15,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47654.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  39%|██▋    | 288/744 [19:03<30:11,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42841.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  39%|██▋    | 289/744 [19:07<30:07,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45950.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  39%|██▋    | 290/744 [19:13<30:05,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43788.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8863, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  39%|██▋    | 291/744 [19:17<30:01,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44786.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  39%|██▋    | 292/744 [19:22<29:59,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43028.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  39%|██▊    | 293/744 [19:26<29:54,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42971.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  40%|██▊    | 294/744 [19:30<29:50,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44522.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  40%|██▊    | 295/744 [19:33<29:46,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40501.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  40%|██▊    | 296/744 [19:37<29:42,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42440.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  40%|██▊    | 297/744 [19:41<29:38,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41772.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0312, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  40%|██▊    | 298/744 [19:45<29:34,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41029.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  40%|██▊    | 299/744 [19:50<29:31,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41890.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  40%|██▊    | 300/744 [19:54<29:28,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43287.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  40%|██▊    | 301/744 [19:58<29:24,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48787.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  41%|██▊    | 302/744 [20:02<29:20,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44055.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  41%|██▊    | 303/744 [20:07<29:17,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47354.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  41%|██▊    | 304/744 [20:11<29:14,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43572.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  41%|██▊    | 305/744 [20:15<29:10,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43178.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  41%|██▉    | 306/744 [20:20<29:06,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44758.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  41%|██▉    | 307/744 [20:23<29:02,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48841.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  41%|██▉    | 308/744 [20:28<28:58,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49124.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  42%|██▉    | 309/744 [20:32<28:55,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40982.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  42%|██▉    | 310/744 [20:36<28:51,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44137.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  42%|██▉    | 311/744 [20:40<28:47,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42058.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  42%|██▉    | 312/744 [20:44<28:43,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40511.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  42%|██▉    | 313/744 [20:48<28:39,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46091.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  42%|██▉    | 314/744 [20:52<28:35,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44514.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  42%|██▉    | 315/744 [20:56<28:31,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41409.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9108, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  42%|██▉    | 316/744 [21:00<28:27,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44228.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  43%|██▉    | 317/744 [21:04<28:23,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43536.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  43%|██▉    | 318/744 [21:08<28:19,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38665.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  43%|███    | 319/744 [21:12<28:15,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41929.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  43%|███    | 320/744 [21:16<28:11,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42672.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  43%|███    | 321/744 [21:20<28:06,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41055.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  43%|███    | 322/744 [21:23<28:02,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45839.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  43%|███    | 323/744 [21:27<27:58,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48988.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  44%|███    | 324/744 [21:31<27:54,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44071.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  44%|███    | 325/744 [21:35<27:50,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44501.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  44%|███    | 326/744 [21:39<27:46,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38777.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  44%|███    | 327/744 [21:43<27:42,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43485.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  44%|███    | 328/744 [21:47<27:38,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46551.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  44%|███    | 329/744 [21:51<27:34,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43611.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  44%|███    | 330/744 [21:55<27:30,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42565.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  44%|███    | 331/744 [21:59<27:26,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46609.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  45%|███    | 332/744 [22:03<27:22,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46352.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8572, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  45%|███▏   | 333/744 [22:07<27:18,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49335.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  45%|███▏   | 334/744 [22:11<27:15,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49006.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  45%|███▏   | 335/744 [22:15<27:10,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44122.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9576, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  45%|███▏   | 336/744 [22:19<27:06,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40374.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  45%|███▏   | 337/744 [22:23<27:02,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38270.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  45%|███▏   | 338/744 [22:27<26:58,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47284.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  46%|███▏   | 339/744 [22:31<26:55,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42889.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  46%|███▏   | 340/744 [22:35<26:50,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45824.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  46%|███▏   | 341/744 [22:39<26:46,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44191.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  46%|███▏   | 342/744 [22:43<26:42,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49087.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  46%|███▏   | 343/744 [22:47<26:38,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45509.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  46%|███▏   | 344/744 [22:50<26:34,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43709.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  46%|███▏   | 345/744 [22:54<26:29,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42264.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  47%|███▎   | 346/744 [22:58<26:25,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45317.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  47%|███▎   | 347/744 [23:02<26:21,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42130.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  47%|███▎   | 348/744 [23:06<26:17,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47332.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  47%|███▎   | 349/744 [23:09<26:13,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50443.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  47%|███▎   | 350/744 [23:13<26:09,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43809.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  47%|███▎   | 351/744 [23:17<26:05,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39128.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  47%|███▎   | 352/744 [23:22<26:01,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42541.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  47%|███▎   | 353/744 [23:25<25:57,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41831.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  48%|███▎   | 354/744 [23:30<25:53,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42949.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  48%|███▎   | 355/744 [23:33<25:49,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50997.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  48%|███▎   | 356/744 [23:37<25:45,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42697.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  48%|███▎   | 357/744 [23:41<25:41,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46698.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  48%|███▎   | 358/744 [23:45<25:37,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43226.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  48%|███▍   | 359/744 [23:49<25:33,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39934.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  48%|███▍   | 360/744 [23:53<25:29,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44574.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  49%|███▍   | 361/744 [23:57<25:25,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44403.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  49%|███▍   | 362/744 [24:01<25:21,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43179.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  49%|███▍   | 363/744 [24:05<25:17,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41428.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  49%|███▍   | 364/744 [24:09<25:12,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46252.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  49%|███▍   | 365/744 [24:13<25:08,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44181.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  49%|███▍   | 366/744 [24:17<25:04,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46511.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  49%|███▍   | 367/744 [24:21<25:00,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46055.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  49%|███▍   | 368/744 [24:24<24:56,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47334.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9609, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  50%|███▍   | 369/744 [24:28<24:52,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42047.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  50%|███▍   | 370/744 [24:32<24:48,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43763.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  50%|███▍   | 371/744 [24:36<24:44,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42121.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  50%|███▌   | 372/744 [24:40<24:40,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43452.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  50%|███▌   | 373/744 [24:44<24:36,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43811.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9274, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|███▌   | 374/744 [24:48<24:32,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42596.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  50%|███▌   | 375/744 [24:52<24:28,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46322.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  51%|███▌   | 376/744 [24:56<24:25,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47389.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  51%|███▌   | 377/744 [25:01<24:21,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44571.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  51%|███▌   | 378/744 [25:05<24:17,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44755.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  51%|███▌   | 379/744 [25:10<24:14,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45314.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  51%|███▌   | 380/744 [25:14<24:10,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43931.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  51%|███▌   | 381/744 [25:17<24:06,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47948.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  51%|███▌   | 382/744 [25:21<24:01,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48565.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  51%|███▌   | 383/744 [25:25<23:58,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40690.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  52%|███▌   | 384/744 [25:29<23:54,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42968.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  52%|███▌   | 385/744 [25:34<23:50,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41661.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  52%|███▋   | 386/744 [25:38<23:46,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44584.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  52%|███▋   | 387/744 [25:41<23:42,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39738.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  52%|███▋   | 388/744 [25:46<23:38,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44399.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  52%|███▋   | 389/744 [25:50<23:34,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40040.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  52%|███▋   | 390/744 [25:55<23:31,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46374.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  53%|███▋   | 391/744 [25:59<23:27,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44734.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  53%|███▋   | 392/744 [26:03<23:24,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47546.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  53%|███▋   | 393/744 [26:07<23:19,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46889.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  53%|███▋   | 394/744 [26:11<23:16,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43528.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  53%|███▋   | 395/744 [26:15<23:11,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47526.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  53%|███▋   | 396/744 [26:19<23:07,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40886.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  53%|███▋   | 397/744 [26:24<23:04,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50474.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  53%|███▋   | 398/744 [26:28<23:00,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44669.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  54%|███▊   | 399/744 [26:32<22:56,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45526.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  54%|███▊   | 400/744 [26:36<22:52,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41818.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  54%|███▊   | 401/744 [26:40<22:49,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38442.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  54%|███▊   | 402/744 [26:44<22:45,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44294.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  54%|███▊   | 403/744 [26:48<22:41,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44532.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  54%|███▊   | 404/744 [26:52<22:36,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45165.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  54%|███▊   | 405/744 [26:56<22:33,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41204.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  55%|███▊   | 406/744 [27:00<22:29,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46312.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  55%|███▊   | 407/744 [27:04<22:25,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43275.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  55%|███▊   | 408/744 [27:08<22:21,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46999.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  55%|███▊   | 409/744 [27:13<22:17,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47099.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  55%|███▊   | 410/744 [27:17<22:13,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42779.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  55%|███▊   | 411/744 [27:21<22:09,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50367.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0394, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  55%|███▉   | 412/744 [27:25<22:05,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49095.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  56%|███▉   | 413/744 [27:29<22:01,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43800.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  56%|███▉   | 414/744 [27:33<21:57,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45104.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  56%|███▉   | 415/744 [27:37<21:53,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48001.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  56%|███▉   | 416/744 [27:40<21:49,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48692., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  56%|███▉   | 417/744 [27:44<21:45,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45671.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  56%|███▉   | 418/744 [27:48<21:41,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46357.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  56%|███▉   | 419/744 [27:52<21:37,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48874.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  56%|███▉   | 420/744 [27:56<21:33,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47682.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  57%|███▉   | 421/744 [28:00<21:29,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46010.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  57%|███▉   | 422/744 [28:04<21:24,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50164.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  57%|███▉   | 423/744 [28:07<21:20,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42506.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  57%|███▉   | 424/744 [28:11<21:16,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45569.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  57%|███▉   | 425/744 [28:15<21:12,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44499.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  57%|████   | 426/744 [28:19<21:08,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46009.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  57%|████   | 427/744 [28:23<21:04,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47459.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  58%|████   | 428/744 [28:27<21:00,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44696.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  58%|████   | 429/744 [28:31<20:56,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45474.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  58%|████   | 430/744 [28:35<20:52,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42664.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  58%|████   | 431/744 [28:39<20:48,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41224.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  58%|████   | 432/744 [28:43<20:44,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42213.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  58%|████   | 433/744 [28:47<20:40,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46694.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  58%|████   | 434/744 [28:51<20:36,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45849.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  58%|████   | 435/744 [28:55<20:32,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39885.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  59%|████   | 436/744 [28:59<20:28,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45418.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  59%|████   | 437/744 [29:03<20:24,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45441.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  59%|████   | 438/744 [29:07<20:20,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43970.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  59%|████▏  | 439/744 [29:11<20:16,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38566.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  59%|████▏  | 440/744 [29:14<20:12,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45068.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  59%|████▏  | 441/744 [29:18<20:08,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44240.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  59%|████▏  | 442/744 [29:22<20:04,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46740.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  60%|████▏  | 443/744 [29:26<20:00,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39847.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  60%|████▏  | 444/744 [29:31<19:56,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48369.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  60%|████▏  | 445/744 [29:34<19:52,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47356.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  60%|████▏  | 446/744 [29:38<19:48,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49648.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  60%|████▏  | 447/744 [29:43<19:44,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48827.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  60%|████▏  | 448/744 [29:46<19:40,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43781.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  60%|████▏  | 449/744 [29:50<19:36,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45286.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8969, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  60%|████▏  | 450/744 [29:54<19:32,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43473.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  61%|████▏  | 451/744 [29:58<19:28,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42959.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  61%|████▎  | 452/744 [30:02<19:24,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47747.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  61%|████▎  | 453/744 [30:06<19:20,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46039.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  61%|████▎  | 454/744 [30:10<19:16,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44538.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  61%|████▎  | 455/744 [30:14<19:12,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42822.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  61%|████▎  | 456/744 [30:18<19:08,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52311.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  61%|████▎  | 457/744 [30:22<19:04,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38397.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  62%|████▎  | 458/744 [30:25<19:00,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39859.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  62%|████▎  | 459/744 [30:29<18:56,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43140.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  62%|████▎  | 460/744 [30:33<18:52,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41103.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  62%|████▎  | 461/744 [30:39<18:48,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41623.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  62%|████▎  | 462/744 [30:43<18:45,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49530.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  62%|████▎  | 463/744 [30:47<18:41,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45481.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  62%|████▎  | 464/744 [30:51<18:37,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47080.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  62%|████▍  | 465/744 [30:55<18:33,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47940.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  63%|████▍  | 466/744 [30:59<18:29,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43700.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  63%|████▍  | 467/744 [31:03<18:25,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44453.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  63%|████▍  | 468/744 [31:07<18:21,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44114.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  63%|████▍  | 469/744 [31:11<18:17,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46552.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  63%|████▍  | 470/744 [31:15<18:13,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39975.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  63%|████▍  | 471/744 [31:19<18:09,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49755.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  63%|████▍  | 472/744 [31:23<18:05,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45668.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  64%|████▍  | 473/744 [31:27<18:01,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44212.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  64%|████▍  | 474/744 [31:31<17:57,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46807.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  64%|████▍  | 475/744 [31:34<17:52,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49097.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  64%|████▍  | 476/744 [31:38<17:49,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45199.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  64%|████▍  | 477/744 [31:42<17:45,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48893.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  64%|████▍  | 478/744 [31:46<17:41,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48518.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  64%|████▌  | 479/744 [31:51<17:37,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43418.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  65%|████▌  | 480/744 [31:54<17:33,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47527.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  65%|████▌  | 481/744 [31:58<17:29,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41038.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  65%|████▌  | 482/744 [32:02<17:25,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45065.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  65%|████▌  | 483/744 [32:06<17:21,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48333.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  65%|████▌  | 484/744 [32:10<17:17,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46448.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  65%|████▌  | 485/744 [32:14<17:13,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44215.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  65%|████▌  | 486/744 [32:18<17:09,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51773.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  65%|████▌  | 487/744 [32:22<17:05,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46292.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8948, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  66%|████▌  | 488/744 [32:26<17:01,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46682.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  66%|████▌  | 489/744 [32:30<16:57,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44724.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  66%|████▌  | 490/744 [32:34<16:53,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45845.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  66%|████▌  | 491/744 [32:38<16:49,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48012.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  66%|████▋  | 492/744 [32:42<16:45,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46351.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  66%|████▋  | 493/744 [32:46<16:41,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49586.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  66%|████▋  | 494/744 [32:50<16:36,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40504.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  67%|████▋  | 495/744 [32:53<16:32,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39797.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  67%|████▋  | 496/744 [32:57<16:28,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48277.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  67%|████▋  | 497/744 [33:01<16:24,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43353.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  67%|████▋  | 498/744 [33:05<16:21,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51155.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  67%|████▋  | 499/744 [33:09<16:16,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49385.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  67%|████▋  | 500/744 [33:13<16:12,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43144.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  67%|████▋  | 501/744 [33:17<16:08,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48351.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  67%|████▋  | 502/744 [33:21<16:05,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42476.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  68%|████▋  | 503/744 [33:25<16:01,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45381.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  68%|████▋  | 504/744 [33:29<15:57,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42869.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  68%|████▊  | 505/744 [33:33<15:53,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46205.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  68%|████▊  | 506/744 [33:37<15:49,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39127.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  68%|████▊  | 507/744 [33:41<15:45,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43534.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  68%|████▊  | 508/744 [33:45<15:41,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46535.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  68%|████▊  | 509/744 [33:49<15:37,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43873.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  69%|████▊  | 510/744 [33:53<15:33,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42837.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  69%|████▊  | 511/744 [33:57<15:29,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45732.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  69%|████▊  | 512/744 [34:01<15:25,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40600.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  69%|████▊  | 513/744 [34:05<15:21,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45872.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  69%|████▊  | 514/744 [34:09<15:17,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49033.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  69%|████▊  | 515/744 [34:13<15:13,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43738.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  69%|████▊  | 516/744 [34:17<15:09,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43653.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  69%|████▊  | 517/744 [34:21<15:04,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45838.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  70%|████▊  | 518/744 [34:24<15:00,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43044.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  70%|████▉  | 519/744 [34:28<14:56,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45315.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  70%|████▉  | 520/744 [34:32<14:52,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42299.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  70%|████▉  | 521/744 [34:36<14:48,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45175.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  70%|████▉  | 522/744 [34:40<14:44,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50378.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  70%|████▉  | 523/744 [34:44<14:40,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49810.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  70%|████▉  | 524/744 [34:48<14:36,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44519.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  71%|████▉  | 525/744 [34:52<14:32,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47204.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9328, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  71%|████▉  | 526/744 [34:56<14:28,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43551.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  71%|████▉  | 527/744 [34:59<14:24,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44821.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  71%|████▉  | 528/744 [35:03<14:20,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47163.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  71%|████▉  | 529/744 [35:08<14:16,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44761.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  71%|████▉  | 530/744 [35:12<14:12,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45013.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  71%|████▉  | 531/744 [35:15<14:08,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44993.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  72%|█████  | 532/744 [35:19<14:04,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50189.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  72%|█████  | 533/744 [35:23<14:00,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48008.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  72%|█████  | 534/744 [35:27<13:56,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51788.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  72%|█████  | 535/744 [35:31<13:52,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45780.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  72%|█████  | 536/744 [35:35<13:48,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43082.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  72%|█████  | 537/744 [35:39<13:44,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49630.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  72%|█████  | 538/744 [35:43<13:40,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46469.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  72%|█████  | 539/744 [35:47<13:36,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41471.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  73%|█████  | 540/744 [35:51<13:32,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47413.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  73%|█████  | 541/744 [35:55<13:28,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42832.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  73%|█████  | 542/744 [35:59<13:24,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44019.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  73%|█████  | 543/744 [36:04<13:21,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45275.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  73%|█████  | 544/744 [36:08<13:17,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45636.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  73%|█████▏ | 545/744 [36:11<13:13,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46823.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  73%|█████▏ | 546/744 [36:15<13:09,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44658.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  74%|█████▏ | 547/744 [36:20<13:05,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46765.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  74%|█████▏ | 548/744 [36:24<13:01,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47394.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  74%|█████▏ | 549/744 [36:27<12:57,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42935.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  74%|█████▏ | 550/744 [36:31<12:53,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41109.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  74%|█████▏ | 551/744 [36:35<12:49,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43743.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  74%|█████▏ | 552/744 [36:39<12:44,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42045.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  74%|█████▏ | 553/744 [36:43<12:41,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49890.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  74%|█████▏ | 554/744 [36:47<12:37,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48529.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  75%|█████▏ | 555/744 [36:51<12:33,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50167.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  75%|█████▏ | 556/744 [36:55<12:29,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46335.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  75%|█████▏ | 557/744 [36:59<12:25,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47379.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  75%|█████▎ | 558/744 [37:03<12:21,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42219., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  75%|█████▎ | 559/744 [37:06<12:16,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42812.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  75%|█████▎ | 560/744 [37:10<12:12,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47271.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  75%|█████▎ | 561/744 [37:14<12:08,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48362.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  76%|█████▎ | 562/744 [37:18<12:04,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45969.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  76%|█████▎ | 563/744 [37:22<12:00,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42472.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8832, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  76%|█████▎ | 564/744 [37:26<11:56,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48781.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  76%|█████▎ | 565/744 [37:30<11:52,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45466.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  76%|█████▎ | 566/744 [37:33<11:48,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44024.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  76%|█████▎ | 567/744 [37:37<11:44,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47419.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  76%|█████▎ | 568/744 [37:41<11:40,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46132.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  76%|█████▎ | 569/744 [37:45<11:36,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46889.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  77%|█████▎ | 570/744 [37:49<11:32,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46438.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  77%|█████▎ | 571/744 [37:53<11:28,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46407.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  77%|█████▍ | 572/744 [37:57<11:24,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50817.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  77%|█████▍ | 573/744 [38:01<11:20,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(37396.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  77%|█████▍ | 574/744 [38:05<11:16,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43046.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  77%|█████▍ | 575/744 [38:09<11:12,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42970.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  77%|█████▍ | 576/744 [38:13<11:08,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45644.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  78%|█████▍ | 577/744 [38:17<11:04,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47298.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  78%|█████▍ | 578/744 [38:21<11:00,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45621.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  78%|█████▍ | 579/744 [38:25<10:56,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48105.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  78%|█████▍ | 580/744 [38:29<10:52,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43243.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  78%|█████▍ | 581/744 [38:33<10:49,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48583.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  78%|█████▍ | 582/744 [38:37<10:45,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43130.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  78%|█████▍ | 583/744 [38:41<10:41,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45342.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  78%|█████▍ | 584/744 [38:45<10:37,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43741.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  79%|█████▌ | 585/744 [38:49<10:33,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44909.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  79%|█████▌ | 586/744 [38:53<10:29,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48217.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  79%|█████▌ | 587/744 [38:57<10:25,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44269.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  79%|█████▌ | 588/744 [39:01<10:21,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45606.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  79%|█████▌ | 589/744 [39:05<10:17,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48302.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  79%|█████▌ | 590/744 [39:09<10:13,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44142.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  79%|█████▌ | 591/744 [39:13<10:09,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46137.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  80%|█████▌ | 592/744 [39:16<10:05,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47526.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  80%|█████▌ | 593/744 [39:20<10:01,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39263.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  80%|█████▌ | 594/744 [39:24<09:57,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42851.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  80%|█████▌ | 595/744 [39:28<09:53,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(38670.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  80%|█████▌ | 596/744 [39:32<09:49,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40975.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  80%|█████▌ | 597/744 [39:35<09:45,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42571.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  80%|█████▋ | 598/744 [39:39<09:41,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43955.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  81%|█████▋ | 599/744 [39:43<09:37,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45368.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  81%|█████▋ | 600/744 [39:47<09:33,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45491.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  81%|█████▋ | 601/744 [39:51<09:29,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41821.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0013, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  81%|█████▋ | 602/744 [39:55<09:25,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47290.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  81%|█████▋ | 603/744 [39:59<09:21,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46504.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  81%|█████▋ | 604/744 [40:03<09:17,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46801.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  81%|█████▋ | 605/744 [40:07<09:13,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48324.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  81%|█████▋ | 606/744 [40:11<09:09,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(41696.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  82%|█████▋ | 607/744 [40:15<09:05,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45319.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  82%|█████▋ | 608/744 [40:19<09:01,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40138.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  82%|█████▋ | 609/744 [40:23<08:57,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48277.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  82%|█████▋ | 610/744 [40:26<08:53,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46773.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9148, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  82%|█████▋ | 611/744 [40:30<08:49,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45237.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  82%|█████▊ | 612/744 [40:34<08:45,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46866.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  82%|█████▊ | 613/744 [40:38<08:41,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46231.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  83%|█████▊ | 614/744 [40:42<08:37,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40829.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  83%|█████▊ | 615/744 [40:46<08:33,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44156.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  83%|█████▊ | 616/744 [40:49<08:29,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47322.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  83%|█████▊ | 617/744 [40:53<08:25,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43523.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  83%|█████▊ | 618/744 [40:57<08:21,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51061.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  83%|█████▊ | 619/744 [41:01<08:17,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44295.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9984, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  83%|█████▊ | 620/744 [41:05<08:13,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48699.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  83%|█████▊ | 621/744 [41:09<08:09,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46505.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  84%|█████▊ | 622/744 [41:13<08:05,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49188.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  84%|█████▊ | 623/744 [41:17<08:01,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44858.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8807, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  84%|█████▊ | 624/744 [41:21<07:57,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44915.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  84%|█████▉ | 625/744 [41:25<07:53,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48951.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  84%|█████▉ | 626/744 [41:28<07:49,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44101.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  84%|█████▉ | 627/744 [41:33<07:45,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47386.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  84%|█████▉ | 628/744 [41:37<07:41,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46395.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  85%|█████▉ | 629/744 [41:41<07:37,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45149.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  85%|█████▉ | 630/744 [41:45<07:33,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48068.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  85%|█████▉ | 631/744 [41:49<07:29,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43233.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  85%|█████▉ | 632/744 [41:53<07:25,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49603.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  85%|█████▉ | 633/744 [41:57<07:21,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46561.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  85%|█████▉ | 634/744 [42:01<07:17,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46621.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  85%|█████▉ | 635/744 [42:05<07:13,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45700.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  85%|█████▉ | 636/744 [42:09<07:09,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44875.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  86%|█████▉ | 637/744 [42:13<07:05,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47460.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  86%|██████ | 638/744 [42:17<07:01,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45051.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  86%|██████ | 639/744 [42:21<06:57,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45405.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9818, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  86%|██████ | 640/744 [42:25<06:53,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46311.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  86%|██████ | 641/744 [42:29<06:49,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47017.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  86%|██████ | 642/744 [42:33<06:45,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44069.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  86%|██████ | 643/744 [42:37<06:41,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48145.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  87%|██████ | 644/744 [42:41<06:37,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45133.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  87%|██████ | 645/744 [42:45<06:33,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48371.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  87%|██████ | 646/744 [42:49<06:29,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40325.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  87%|██████ | 647/744 [42:53<06:25,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46582.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  87%|██████ | 648/744 [42:56<06:21,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42082.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  87%|██████ | 649/744 [43:01<06:17,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45031.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  87%|██████ | 650/744 [43:04<06:13,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46289.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  88%|██████▏| 651/744 [43:08<06:09,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48279.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  88%|██████▏| 652/744 [43:12<06:05,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46840.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  88%|██████▏| 653/744 [43:16<06:01,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48623.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  88%|██████▏| 654/744 [43:20<05:57,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47695.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  88%|██████▏| 655/744 [43:24<05:53,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48204.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  88%|██████▏| 656/744 [43:28<05:49,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46975.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  88%|██████▏| 657/744 [43:32<05:45,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49124.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  88%|██████▏| 658/744 [43:36<05:41,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49073.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  89%|██████▏| 659/744 [43:39<05:37,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46126.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9125, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  89%|██████▏| 660/744 [43:43<05:33,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47683.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  89%|██████▏| 661/744 [43:47<05:29,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49691.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  89%|██████▏| 662/744 [43:51<05:25,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(39916.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  89%|██████▏| 663/744 [43:55<05:22,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44979.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  89%|██████▏| 664/744 [43:59<05:18,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44237.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  89%|██████▎| 665/744 [44:03<05:14,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45393.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  90%|██████▎| 666/744 [44:07<05:10,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44941.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  90%|██████▎| 667/744 [44:11<05:06,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48121.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  90%|██████▎| 668/744 [44:15<05:02,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44878.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  90%|██████▎| 669/744 [44:19<04:58,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44658.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  90%|██████▎| 670/744 [44:23<04:54,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45956.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  90%|██████▎| 671/744 [44:27<04:50,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46208.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  90%|██████▎| 672/744 [44:31<04:46,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49662.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  90%|██████▎| 673/744 [44:35<04:42,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49303.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  91%|██████▎| 674/744 [44:39<04:38,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50948.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  91%|██████▎| 675/744 [44:43<04:34,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48047.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  91%|██████▎| 676/744 [44:47<04:30,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49063.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  91%|██████▎| 677/744 [44:51<04:26,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46386.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8854, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  91%|██████▍| 678/744 [44:55<04:22,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48003.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  91%|██████▍| 679/744 [44:59<04:18,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49654.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  91%|██████▍| 680/744 [45:04<04:14,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46807.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  92%|██████▍| 681/744 [45:08<04:10,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43919.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  92%|██████▍| 682/744 [45:12<04:06,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44188.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  92%|██████▍| 683/744 [45:16<04:02,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50908.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  92%|██████▍| 684/744 [45:20<03:58,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45996.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  92%|██████▍| 685/744 [45:23<03:54,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44233.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  92%|██████▍| 686/744 [45:27<03:50,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46335.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  92%|██████▍| 687/744 [45:31<03:46,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52614.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  92%|██████▍| 688/744 [45:35<03:42,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(40644.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  93%|██████▍| 689/744 [45:39<03:38,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50335.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  93%|██████▍| 690/744 [45:43<03:34,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48201.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  93%|██████▌| 691/744 [45:47<03:30,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43132.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  93%|██████▌| 692/744 [45:51<03:26,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48717.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  93%|██████▌| 693/744 [45:56<03:22,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52414.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9080, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  93%|██████▌| 694/744 [46:00<03:18,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44408.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  93%|██████▌| 695/744 [46:04<03:14,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47001.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  94%|██████▌| 696/744 [46:08<03:10,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46744.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  94%|██████▌| 697/744 [46:12<03:06,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44561.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8791, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  94%|██████▌| 698/744 [46:16<03:02,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44574.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  94%|██████▌| 699/744 [46:20<02:58,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47941.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  94%|██████▌| 700/744 [46:24<02:54,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47347.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  94%|██████▌| 701/744 [46:27<02:50,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45611.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  94%|██████▌| 702/744 [46:31<02:47,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50306.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  94%|██████▌| 703/744 [46:35<02:43,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46941.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  95%|██████▌| 704/744 [46:39<02:39,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48743.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  95%|██████▋| 705/744 [46:43<02:35,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47775.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  95%|██████▋| 706/744 [46:47<02:31,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50084.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  95%|██████▋| 707/744 [46:51<02:27,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52161.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  95%|██████▋| 708/744 [46:55<02:23,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52740.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  95%|██████▋| 709/744 [46:58<02:19,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47525.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  95%|██████▋| 710/744 [47:02<02:15,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48086.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  96%|██████▋| 711/744 [47:06<02:11,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46478.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  96%|██████▋| 712/744 [47:10<02:07,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47664.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  96%|██████▋| 713/744 [47:14<02:03,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48243.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  96%|██████▋| 714/744 [47:18<01:59,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(44712.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  96%|██████▋| 715/744 [47:22<01:55,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47807.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9418, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  96%|██████▋| 716/744 [47:25<01:51,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45827.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  96%|██████▋| 717/744 [47:29<01:47,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45028.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  97%|██████▊| 718/744 [47:33<01:43,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49654.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  97%|██████▊| 719/744 [47:37<01:39,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43962.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  97%|██████▊| 720/744 [47:41<01:35,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51393.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  97%|██████▊| 721/744 [47:45<01:31,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51175.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  97%|██████▊| 722/744 [47:49<01:27,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48644.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  97%|██████▊| 723/744 [47:53<01:23,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43752.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  97%|██████▊| 724/744 [47:57<01:19,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46835.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  97%|██████▊| 725/744 [48:01<01:15,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46187.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  98%|██████▊| 726/744 [48:05<01:11,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49685.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  98%|██████▊| 727/744 [48:08<01:07,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(45573.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  98%|██████▊| 728/744 [48:13<01:03,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(46491.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  98%|██████▊| 729/744 [48:17<00:59,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(43352.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  98%|██████▊| 730/744 [48:20<00:55,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42615.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  98%|██████▉| 731/744 [48:25<00:51,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(42622.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8774, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  98%|██████▉| 732/744 [48:29<00:47,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47967.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6:  99%|██████▉| 733/744 [48:32<00:43,  3.97s/it, loss=nan, v_num=5.48e+7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  61%|████▏  | 451/744 [29:16<19:01,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59449.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  61%|████▎  | 452/744 [29:20<18:57,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60701.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  61%|████▎  | 453/744 [29:24<18:53,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52313.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  61%|████▎  | 454/744 [29:28<18:49,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55329.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  61%|████▎  | 455/744 [29:32<18:45,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53411.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  61%|████▎  | 456/744 [29:36<18:41,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55261.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  61%|████▎  | 457/744 [29:40<18:37,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54131.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  62%|████▎  | 458/744 [29:43<18:33,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61393.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  62%|████▎  | 459/744 [29:47<18:30,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61718.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  62%|████▎  | 460/744 [29:51<18:26,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55422.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  62%|████▎  | 461/744 [29:55<18:22,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51723.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  62%|████▎  | 462/744 [29:59<18:18,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61743.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  62%|████▎  | 463/744 [30:03<18:14,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56875.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  62%|████▎  | 464/744 [30:07<18:10,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52617.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  62%|████▍  | 465/744 [30:11<18:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51608.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  63%|████▍  | 466/744 [30:14<18:02,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59971.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  63%|████▍  | 467/744 [30:18<17:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55240.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9673, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  63%|████▍  | 468/744 [30:22<17:55,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62032.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  63%|████▍  | 469/744 [30:26<17:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58689.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  63%|████▍  | 470/744 [30:30<17:47,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58260.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  63%|████▍  | 471/744 [30:34<17:43,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58074.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  63%|████▍  | 472/744 [30:38<17:39,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59137.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  64%|████▍  | 473/744 [30:42<17:35,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55809.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  64%|████▍  | 474/744 [30:45<17:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54000.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  64%|████▍  | 475/744 [30:50<17:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61749.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  64%|████▍  | 476/744 [30:54<17:23,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62847.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  64%|████▍  | 477/744 [30:57<17:19,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60055.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  64%|████▍  | 478/744 [31:01<17:16,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54640.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  64%|████▌  | 479/744 [31:05<17:12,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58473.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  65%|████▌  | 480/744 [31:09<17:08,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58653.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  65%|████▌  | 481/744 [31:13<17:04,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50013.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  65%|████▌  | 482/744 [31:17<17:00,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58121.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  65%|████▌  | 483/744 [31:21<16:56,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51960.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  65%|████▌  | 484/744 [31:25<16:52,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57181.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  65%|████▌  | 485/744 [31:29<16:49,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54947.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  65%|████▌  | 486/744 [31:33<16:45,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54506.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  65%|████▌  | 487/744 [31:37<16:41,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56335.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  66%|████▌  | 488/744 [31:41<16:37,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58729.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7929, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  66%|████▌  | 489/744 [31:45<16:33,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49920.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  66%|████▌  | 490/744 [31:49<16:29,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50396.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  66%|████▌  | 491/744 [31:53<16:25,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53555.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  66%|████▋  | 492/744 [31:57<16:22,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55717.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  66%|████▋  | 493/744 [32:01<16:18,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54612.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  66%|████▋  | 494/744 [32:05<16:14,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55661.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  67%|████▋  | 495/744 [32:09<16:10,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58678.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  67%|████▋  | 496/744 [32:13<16:06,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56009.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  67%|████▋  | 497/744 [32:16<16:02,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56957.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  67%|████▋  | 498/744 [32:20<15:58,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59734.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  67%|████▋  | 499/744 [32:24<15:54,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60534.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  67%|████▋  | 500/744 [32:28<15:50,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60221.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  67%|████▋  | 501/744 [32:32<15:47,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62927.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  67%|████▋  | 502/744 [32:36<15:43,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54873.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  68%|████▋  | 503/744 [32:40<15:39,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57466.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  68%|████▋  | 504/744 [32:44<15:35,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60017.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  68%|████▊  | 505/744 [32:48<15:31,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58524.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  68%|████▊  | 506/744 [32:52<15:27,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57560.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  68%|████▊  | 507/744 [32:55<15:23,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58515.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  68%|████▊  | 508/744 [32:59<15:19,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58492.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  68%|████▊  | 509/744 [33:03<15:15,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57928.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  69%|████▊  | 510/744 [33:07<15:11,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55234.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  69%|████▊  | 511/744 [33:11<15:07,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58506.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  69%|████▊  | 512/744 [33:15<15:04,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54287.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  69%|████▊  | 513/744 [33:19<15:00,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54995.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  69%|████▊  | 514/744 [33:23<14:56,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53555.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  69%|████▊  | 515/744 [33:27<14:52,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58076.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  69%|████▊  | 516/744 [33:31<14:48,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57190.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  69%|████▊  | 517/744 [33:35<14:44,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54993.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  70%|████▊  | 518/744 [33:38<14:40,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59912.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  70%|████▉  | 519/744 [33:43<14:37,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55346.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  70%|████▉  | 520/744 [33:47<14:33,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53757.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  70%|████▉  | 521/744 [33:50<14:29,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57876.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  70%|████▉  | 522/744 [33:54<14:25,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59956.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  70%|████▉  | 523/744 [33:58<14:21,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56194.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  70%|████▉  | 524/744 [34:01<14:17,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60807.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  71%|████▉  | 525/744 [34:05<14:13,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55896.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  71%|████▉  | 526/744 [34:09<14:09,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55828.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  71%|████▉  | 527/744 [34:13<14:05,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56364.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  71%|████▉  | 528/744 [34:17<14:01,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61984.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  71%|████▉  | 529/744 [34:21<13:57,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54705.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  71%|████▉  | 530/744 [34:25<13:53,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60431.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  71%|████▉  | 531/744 [34:29<13:50,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62034.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  72%|█████  | 532/744 [34:33<13:46,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48893.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  72%|█████  | 533/744 [34:37<13:42,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55989.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  72%|█████  | 534/744 [34:40<13:38,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56975.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  72%|█████  | 535/744 [34:44<13:34,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58517.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  72%|█████  | 536/744 [34:48<13:30,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54134.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  72%|█████  | 537/744 [34:52<13:26,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56184.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  72%|█████  | 538/744 [34:56<13:22,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53540.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  72%|█████  | 539/744 [35:00<13:18,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56997.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  73%|█████  | 540/744 [35:04<13:14,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62024.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  73%|█████  | 541/744 [35:08<13:11,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52576.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  73%|█████  | 542/744 [35:12<13:07,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54276.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  73%|█████  | 543/744 [35:15<13:03,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55610.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  73%|█████  | 544/744 [35:19<12:59,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51952.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  73%|█████▏ | 545/744 [35:23<12:55,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53605.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  73%|█████▏ | 546/744 [35:27<12:51,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55026.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  74%|█████▏ | 547/744 [35:31<12:47,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57779.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  74%|█████▏ | 548/744 [35:35<12:43,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51456.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  74%|█████▏ | 549/744 [35:39<12:39,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55221.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  74%|█████▏ | 550/744 [35:43<12:36,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57219.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8080, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  74%|█████▏ | 551/744 [35:47<12:32,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54031.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  74%|█████▏ | 552/744 [35:51<12:28,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61798.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  74%|█████▏ | 553/744 [35:55<12:24,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62342.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  74%|█████▏ | 554/744 [35:58<12:20,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57545.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  75%|█████▏ | 555/744 [36:02<12:16,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57960.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  75%|█████▏ | 556/744 [36:06<12:12,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62780.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  75%|█████▏ | 557/744 [36:10<12:08,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57544.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  75%|█████▎ | 558/744 [36:14<12:04,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53393.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  75%|█████▎ | 559/744 [36:18<12:01,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55352.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  75%|█████▎ | 560/744 [36:22<11:57,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62265.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  75%|█████▎ | 561/744 [36:26<11:53,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53439.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  76%|█████▎ | 562/744 [36:29<11:49,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54147.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  76%|█████▎ | 563/744 [36:33<11:45,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58557.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  76%|█████▎ | 564/744 [36:37<11:41,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56449.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8297, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  76%|█████▎ | 565/744 [36:41<11:37,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60329.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  76%|█████▎ | 566/744 [36:45<11:33,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62494.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  76%|█████▎ | 567/744 [36:49<11:29,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64334.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  76%|█████▎ | 568/744 [36:53<11:25,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57605.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  76%|█████▎ | 569/744 [36:56<11:21,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59152.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  77%|█████▎ | 570/744 [37:00<11:17,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57609.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  77%|█████▎ | 571/744 [37:04<11:14,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58332.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  77%|█████▍ | 572/744 [37:08<11:10,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54894.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  77%|█████▍ | 573/744 [37:12<11:06,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57893.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  77%|█████▍ | 574/744 [37:16<11:02,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54268.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  77%|█████▍ | 575/744 [37:20<10:58,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56273.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  77%|█████▍ | 576/744 [37:24<10:54,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55833.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  78%|█████▍ | 577/744 [37:28<10:50,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54453.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  78%|█████▍ | 578/744 [37:32<10:46,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58062.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  78%|█████▍ | 579/744 [37:36<10:43,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57172.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  78%|█████▍ | 580/744 [37:40<10:39,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60086.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  78%|█████▍ | 581/744 [37:44<10:35,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55143.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  78%|█████▍ | 582/744 [37:48<10:31,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57293.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8593, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  78%|█████▍ | 583/744 [37:52<10:27,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56377.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  78%|█████▍ | 584/744 [37:56<10:23,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54832.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  79%|█████▌ | 585/744 [38:00<10:19,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56664.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  79%|█████▌ | 586/744 [38:03<10:15,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54117.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  79%|█████▌ | 587/744 [38:07<10:11,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58761.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  79%|█████▌ | 588/744 [38:11<10:07,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57509.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  79%|█████▌ | 589/744 [38:15<10:04,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58196.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  79%|█████▌ | 590/744 [38:19<10:00,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59629.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  79%|█████▌ | 591/744 [38:22<09:56,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55607.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  80%|█████▌ | 592/744 [38:26<09:52,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55773.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  80%|█████▌ | 593/744 [38:30<09:48,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57420.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  80%|█████▌ | 594/744 [38:34<09:44,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53289.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9148, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  80%|█████▌ | 595/744 [38:38<09:40,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59719.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  80%|█████▌ | 596/744 [38:41<09:36,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56666.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  80%|█████▌ | 597/744 [38:45<09:32,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58458.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  80%|█████▋ | 598/744 [38:49<09:28,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58809.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  81%|█████▋ | 599/744 [38:53<09:24,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50210.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  81%|█████▋ | 600/744 [38:57<09:20,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50610.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  81%|█████▋ | 601/744 [39:00<09:16,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60966.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  81%|█████▋ | 602/744 [39:04<09:13,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56274.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8655, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  81%|█████▋ | 603/744 [39:08<09:09,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57939.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8791, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  81%|█████▋ | 604/744 [39:12<09:05,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57382.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  81%|█████▋ | 605/744 [39:16<09:01,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55983.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  81%|█████▋ | 606/744 [39:20<08:57,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60865.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  82%|█████▋ | 607/744 [39:24<08:53,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54147.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  82%|█████▋ | 608/744 [39:27<08:49,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56795.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  82%|█████▋ | 609/744 [39:31<08:45,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50628.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  82%|█████▋ | 610/744 [39:35<08:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56715.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8238, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  82%|█████▋ | 611/744 [39:39<08:37,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57848.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  82%|█████▊ | 612/744 [39:43<08:33,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61213.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  82%|█████▊ | 613/744 [39:46<08:30,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59475.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  83%|█████▊ | 614/744 [39:50<08:26,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53822.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  83%|█████▊ | 615/744 [39:54<08:22,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58775.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  83%|█████▊ | 616/744 [39:58<08:18,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60584.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  83%|█████▊ | 617/744 [40:01<08:14,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57026., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  83%|█████▊ | 618/744 [40:05<08:10,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56879.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  83%|█████▊ | 619/744 [40:09<08:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54770.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  83%|█████▊ | 620/744 [40:13<08:02,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54293.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  83%|█████▊ | 621/744 [40:17<07:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59319.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  84%|█████▊ | 622/744 [40:21<07:54,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56646.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  84%|█████▊ | 623/744 [40:25<07:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60984.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  84%|█████▊ | 624/744 [40:28<07:47,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49064.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  84%|█████▉ | 625/744 [40:32<07:43,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59470.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  84%|█████▉ | 626/744 [40:36<07:39,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61035.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  84%|█████▉ | 627/744 [40:40<07:35,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56469.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  84%|█████▉ | 628/744 [40:44<07:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59440.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  85%|█████▉ | 629/744 [40:48<07:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57671.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  85%|█████▉ | 630/744 [40:53<07:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58823.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  85%|█████▉ | 631/744 [40:56<07:19,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53559.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  85%|█████▉ | 632/744 [41:00<07:16,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53119.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  85%|█████▉ | 633/744 [41:04<07:12,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59054.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  85%|█████▉ | 634/744 [41:08<07:08,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55641.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  85%|█████▉ | 635/744 [41:13<07:04,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53822.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  85%|█████▉ | 636/744 [41:17<07:00,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60070.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8739, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  86%|█████▉ | 637/744 [41:21<06:56,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56592.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  86%|██████ | 638/744 [41:24<06:52,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60555.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  86%|██████ | 639/744 [41:29<06:49,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51865.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  86%|██████ | 640/744 [41:32<06:45,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58294.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8517, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  86%|██████ | 641/744 [41:36<06:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59190.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  86%|██████ | 642/744 [41:40<06:37,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59351.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  86%|██████ | 643/744 [41:44<06:33,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52593.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  87%|██████ | 644/744 [41:47<06:29,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58447.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  87%|██████ | 645/744 [41:51<06:25,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56461.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  87%|██████ | 646/744 [41:55<06:21,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52847.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  87%|██████ | 647/744 [41:59<06:17,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59008.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  87%|██████ | 648/744 [42:03<06:13,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61530.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  87%|██████ | 649/744 [42:07<06:09,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58805.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  87%|██████ | 650/744 [42:11<06:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60155.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  88%|██████▏| 651/744 [42:14<06:02,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55497.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  88%|██████▏| 652/744 [42:18<05:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(48859.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  88%|██████▏| 653/744 [42:22<05:54,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62073.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  88%|██████▏| 654/744 [42:26<05:50,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55876.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  88%|██████▏| 655/744 [42:30<05:46,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60146.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  88%|██████▏| 656/744 [42:34<05:42,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62996.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  88%|██████▏| 657/744 [42:38<05:38,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58693.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  88%|██████▏| 658/744 [42:41<05:34,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58250.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  89%|██████▏| 659/744 [42:45<05:30,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59464.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  89%|██████▏| 660/744 [42:49<05:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59616.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  89%|██████▏| 661/744 [42:53<05:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53109.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  89%|██████▏| 662/744 [42:57<05:19,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61900.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  89%|██████▏| 663/744 [43:01<05:15,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61062.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  89%|██████▏| 664/744 [43:05<05:11,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63750.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  89%|██████▎| 665/744 [43:09<05:07,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49921.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  90%|██████▎| 666/744 [43:13<05:03,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59644.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  90%|██████▎| 667/744 [43:17<04:59,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60716.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  90%|██████▎| 668/744 [43:21<04:55,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61934.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  90%|██████▎| 669/744 [43:24<04:52,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60380.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  90%|██████▎| 670/744 [43:29<04:48,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61497.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  90%|██████▎| 671/744 [43:32<04:44,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53634.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  90%|██████▎| 672/744 [43:36<04:40,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51735.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  90%|██████▎| 673/744 [43:40<04:36,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53850.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  91%|██████▎| 674/744 [43:44<04:32,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60132.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  91%|██████▎| 675/744 [43:48<04:28,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60063.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  91%|██████▎| 676/744 [43:52<04:24,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57628.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  91%|██████▎| 677/744 [43:56<04:20,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58855.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  91%|██████▍| 678/744 [43:59<04:16,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59235.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8151, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  91%|██████▍| 679/744 [44:03<04:13,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55232.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  91%|██████▍| 680/744 [44:08<04:09,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56308.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  92%|██████▍| 681/744 [44:11<04:05,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57389.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  92%|██████▍| 682/744 [44:15<04:01,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59648.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  92%|██████▍| 683/744 [44:19<03:57,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57534.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  92%|██████▍| 684/744 [44:23<03:53,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63379.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  92%|██████▍| 685/744 [44:27<03:49,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57244.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  92%|██████▍| 686/744 [44:31<03:45,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61075.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  92%|██████▍| 687/744 [44:35<03:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59139.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  92%|██████▍| 688/744 [44:39<03:38,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53834.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  93%|██████▍| 689/744 [44:42<03:34,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56090.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  93%|██████▍| 690/744 [44:46<03:30,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54695.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  93%|██████▌| 691/744 [44:50<03:26,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59482.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  93%|██████▌| 692/744 [44:54<03:22,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53484.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  93%|██████▌| 693/744 [44:58<03:18,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55898.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  93%|██████▌| 694/744 [45:02<03:14,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63203.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  93%|██████▌| 695/744 [45:06<03:10,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62557.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  94%|██████▌| 696/744 [45:09<03:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60090.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  94%|██████▌| 697/744 [45:13<03:03,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62506.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  94%|██████▌| 698/744 [45:17<02:59,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61616.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  94%|██████▌| 699/744 [45:21<02:55,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61344.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  94%|██████▌| 700/744 [45:25<02:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56986.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8080, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  94%|██████▌| 701/744 [45:29<02:47,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58793.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  94%|██████▌| 702/744 [45:33<02:43,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55674.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  94%|██████▌| 703/744 [45:37<02:39,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47612.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  95%|██████▌| 704/744 [45:41<02:35,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59803.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  95%|██████▋| 705/744 [45:44<02:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52809.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  95%|██████▋| 706/744 [45:48<02:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63321.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  95%|██████▋| 707/744 [45:52<02:24,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65342.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  95%|██████▋| 708/744 [45:56<02:20,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60002.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  95%|██████▋| 709/744 [46:00<02:16,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57145.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  95%|██████▋| 710/744 [46:04<02:12,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57449.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  96%|██████▋| 711/744 [46:08<02:08,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62224.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  96%|██████▋| 712/744 [46:12<02:04,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54341.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  96%|██████▋| 713/744 [46:16<02:00,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62304.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  96%|██████▋| 714/744 [46:20<01:56,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58424.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  96%|██████▋| 715/744 [46:24<01:52,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57580.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  96%|██████▋| 716/744 [46:28<01:49,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59881.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8174, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  96%|██████▋| 717/744 [46:31<01:45,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61499.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  97%|██████▊| 718/744 [46:35<01:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49620.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  97%|██████▊| 719/744 [46:39<01:37,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59727.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  97%|██████▊| 720/744 [46:43<01:33,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53378.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  97%|██████▊| 721/744 [46:47<01:29,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56929.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  97%|██████▊| 722/744 [46:51<01:25,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55354.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  97%|██████▊| 723/744 [46:55<01:21,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62305.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  97%|██████▊| 724/744 [46:58<01:17,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63364.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  97%|██████▊| 725/744 [47:02<01:13,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60699.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  98%|██████▊| 726/744 [47:06<01:10,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65151.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  98%|██████▊| 727/744 [47:10<01:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55763.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  98%|██████▊| 728/744 [47:14<01:02,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52528.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  98%|██████▊| 729/744 [47:17<00:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52710.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  98%|██████▊| 730/744 [47:22<00:54,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51813.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  98%|██████▉| 731/744 [47:26<00:50,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58429., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  98%|██████▉| 732/744 [47:29<00:46,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60015.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  99%|██████▉| 733/744 [47:33<00:42,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57437.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  99%|██████▉| 734/744 [47:38<00:38,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59213.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  99%|██████▉| 735/744 [47:41<00:35,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63878.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  99%|██████▉| 736/744 [47:45<00:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58828.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  99%|██████▉| 737/744 [47:49<00:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63948.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  99%|██████▉| 738/744 [47:53<00:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63765.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  99%|██████▉| 739/744 [47:57<00:19,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66113., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8:  99%|██████▉| 740/744 [48:01<00:15,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57430.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8609, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8: 100%|██████▉| 741/744 [48:05<00:11,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54463.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8: 100%|██████▉| 742/744 [48:09<00:07,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59753.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8: 100%|██████▉| 743/744 [48:13<00:03,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61396.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   0%|                 | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(55514.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   0%|       | 1/744 [00:05<1:06:14,  5.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64385.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   0%|         | 2/744 [00:09<57:11,  4.62s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60703.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   0%|         | 3/744 [00:13<53:38,  4.34s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56233.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   1%|         | 4/744 [00:17<52:34,  4.26s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55781.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   1%|         | 5/744 [00:20<51:41,  4.20s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55927.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   1%|         | 6/744 [00:25<51:27,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60797.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8774, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   1%|         | 7/744 [00:29<51:03,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62786.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   1%|         | 8/744 [00:32<50:23,  4.11s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58085.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   1%|         | 9/744 [00:36<49:53,  4.07s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61646.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   1%|        | 10/744 [00:40<49:39,  4.06s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54203.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9088, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:   1%|        | 11/744 [00:44<49:25,  4.05s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64332.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   2%|▏       | 12/744 [00:48<49:06,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56478.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   2%|▏       | 13/744 [00:52<49:00,  4.02s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62799.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   2%|▏       | 14/744 [00:55<48:37,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56690.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   2%|▏       | 15/744 [00:59<48:32,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56606.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   2%|▏       | 16/744 [01:03<48:17,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56039.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   2%|▏       | 17/744 [01:07<48:01,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53809.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   2%|▏       | 18/744 [01:10<47:42,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60511.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   3%|▏       | 19/744 [01:14<47:37,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56706.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   3%|▏       | 20/744 [01:18<47:25,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56505.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   3%|▏       | 21/744 [01:22<47:08,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55380.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   3%|▏       | 22/744 [01:26<47:11,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65683.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   3%|▏       | 23/744 [01:29<47:00,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64837.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   3%|▎       | 24/744 [01:34<47:01,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57505.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   3%|▎       | 25/744 [01:37<46:55,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60596.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   3%|▎       | 26/744 [01:41<46:45,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62537.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   4%|▎       | 27/744 [01:45<46:43,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61407.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   4%|▎       | 28/744 [01:49<46:43,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60134.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   4%|▎       | 29/744 [01:53<46:34,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59622.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   4%|▎       | 30/744 [01:57<46:31,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54861.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   4%|▎       | 31/744 [02:01<46:26,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59665.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   4%|▎       | 32/744 [02:05<46:23,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55326.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   4%|▎       | 33/744 [02:08<46:12,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59854.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   5%|▎       | 34/744 [02:13<46:19,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60722.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   5%|▍       | 35/744 [02:16<46:11,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62105.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   5%|▍       | 36/744 [02:20<46:02,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61066.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   5%|▍       | 37/744 [02:24<45:53,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59893.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   5%|▍       | 38/744 [02:27<45:47,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60127.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   5%|▍       | 39/744 [02:31<45:42,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62983.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   5%|▍       | 40/744 [02:35<45:37,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58052.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   6%|▍       | 41/744 [02:39<45:33,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62197.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   6%|▍       | 42/744 [02:43<45:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56724.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   6%|▍       | 43/744 [02:47<45:25,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58932.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   6%|▍       | 44/744 [02:50<45:18,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63109.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   6%|▍       | 45/744 [02:54<45:11,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62177.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   6%|▍       | 46/744 [02:58<45:09,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59174.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   6%|▌       | 47/744 [03:02<45:04,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65476.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   6%|▌       | 48/744 [03:06<45:05,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56929.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8685, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:   7%|▌       | 49/744 [03:10<44:58,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59859.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   7%|▌       | 50/744 [03:14<44:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59953.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   7%|▌       | 51/744 [03:18<44:51,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59760.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   7%|▌       | 52/744 [03:21<44:42,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54136.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   7%|▌       | 53/744 [03:25<44:37,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57516.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   7%|▌       | 54/744 [03:29<44:31,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55846.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   7%|▌       | 55/744 [03:32<44:27,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58165.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   8%|▌       | 56/744 [03:36<44:23,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58485.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   8%|▌       | 57/744 [03:40<44:19,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53974.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8819, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   8%|▌       | 58/744 [03:44<44:17,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62112.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   8%|▋       | 59/744 [03:48<44:14,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57699.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   8%|▋       | 60/744 [03:52<44:10,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59687.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7822, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   8%|▋       | 61/744 [03:56<44:07,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51298.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   8%|▋       | 62/744 [04:00<44:06,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56772.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   8%|▋       | 63/744 [04:04<44:04,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57245.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   9%|▋       | 64/744 [04:08<44:00,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56872.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   9%|▋       | 65/744 [04:12<43:57,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59741.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   9%|▋       | 66/744 [04:16<43:53,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57996.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   9%|▋       | 67/744 [04:20<43:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63980.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   9%|▋       | 68/744 [04:24<43:48,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57626.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   9%|▋       | 69/744 [04:28<43:46,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62437.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:   9%|▊       | 70/744 [04:32<43:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64788.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  10%|▊       | 71/744 [04:36<43:36,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62381.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  10%|▊       | 72/744 [04:40<43:33,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64942.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  10%|▊       | 73/744 [04:43<43:30,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57718.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  10%|▊       | 74/744 [04:48<43:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58108.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  10%|▊       | 75/744 [04:52<43:24,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61553.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  10%|▊       | 76/744 [04:55<43:21,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58525.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  10%|▊       | 77/744 [04:59<43:15,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57257.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  10%|▊       | 78/744 [05:03<43:13,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56003.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  11%|▊       | 79/744 [05:08<43:15,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56448.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  11%|▊       | 80/744 [05:11<43:08,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61284.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  11%|▊       | 81/744 [05:15<43:05,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61596.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  11%|▉       | 82/744 [05:19<43:03,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61452.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  11%|▉       | 83/744 [05:24<43:05,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62344.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  11%|▉       | 84/744 [05:28<42:59,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55193.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  11%|▉       | 85/744 [05:32<42:56,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64089.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  12%|▉       | 86/744 [05:36<42:54,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63256.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9077, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  12%|▉       | 87/744 [05:40<42:51,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60600.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0070, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  12%|▉       | 88/744 [05:45<42:52,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62570.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  12%|▉       | 89/744 [05:49<42:52,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58696.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  12%|▉       | 90/744 [05:53<42:48,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61588.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  12%|▉       | 91/744 [05:57<42:48,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62572.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  12%|▉       | 92/744 [06:01<42:43,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60630.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  12%|█       | 93/744 [06:05<42:40,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62590.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  13%|█       | 94/744 [06:10<42:40,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61912.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  13%|█       | 95/744 [06:14<42:35,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61451.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  13%|█       | 96/744 [06:17<42:30,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61064.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  13%|█       | 97/744 [06:21<42:26,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57007.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  13%|█       | 98/744 [06:25<42:23,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62492.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  13%|█       | 99/744 [06:29<42:17,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58394.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  13%|▉      | 100/744 [06:33<42:16,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(49979.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  14%|▉      | 101/744 [06:38<42:14,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64816.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  14%|▉      | 102/744 [06:42<42:11,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57497.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  14%|▉      | 103/744 [06:46<42:07,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(50908.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  14%|▉      | 104/744 [06:50<42:06,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66734.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  14%|▉      | 105/744 [06:54<42:03,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62539.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  14%|▉      | 106/744 [06:59<42:03,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58915.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  14%|█      | 107/744 [07:03<41:58,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57492.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  15%|█      | 108/744 [07:07<41:59,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56450.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  15%|█      | 109/744 [07:11<41:54,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54603.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  15%|█      | 110/744 [07:15<41:49,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58888.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  15%|█      | 111/744 [07:19<41:44,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62373.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  15%|█      | 112/744 [07:23<41:40,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60957.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  15%|█      | 113/744 [07:26<41:35,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62579.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  15%|█      | 114/744 [07:30<41:31,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56493.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  15%|█      | 115/744 [07:34<41:27,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60547.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  16%|█      | 116/744 [07:38<41:22,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57702.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  16%|█      | 117/744 [07:42<41:18,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55306.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  16%|█      | 118/744 [07:46<41:13,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58280.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  16%|█      | 119/744 [07:49<41:08,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57957.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  16%|█▏     | 120/744 [07:53<41:03,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54231.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  16%|█▏     | 121/744 [07:57<40:57,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63164.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  16%|█▏     | 122/744 [08:01<40:52,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55916.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  17%|█▏     | 123/744 [08:05<40:49,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58898.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  17%|█▏     | 124/744 [08:09<40:45,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55826.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  17%|█▏     | 125/744 [08:13<40:41,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58983.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  17%|█▏     | 126/744 [08:16<40:37,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62924.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  17%|█▏     | 127/744 [08:21<40:34,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55658.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  17%|█▏     | 128/744 [08:25<40:31,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60530.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  17%|█▏     | 129/744 [08:29<40:28,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52584.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  17%|█▏     | 130/744 [08:32<40:22,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63422.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  18%|█▏     | 131/744 [08:36<40:18,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57674.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  18%|█▏     | 132/744 [08:40<40:13,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62137.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  18%|█▎     | 133/744 [08:44<40:09,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60847.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  18%|█▎     | 134/744 [08:48<40:04,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62920.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  18%|█▎     | 135/744 [08:52<40:01,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59988.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  18%|█▎     | 136/744 [08:56<39:57,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63655.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  18%|█▎     | 137/744 [09:00<39:52,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61673.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  19%|█▎     | 138/744 [09:03<39:48,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56187.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  19%|█▎     | 139/744 [09:07<39:44,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62777.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  19%|█▎     | 140/744 [09:11<39:40,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61036.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  19%|█▎     | 141/744 [09:15<39:34,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61262.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  19%|█▎     | 142/744 [09:19<39:29,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64866.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  19%|█▎     | 143/744 [09:23<39:26,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59685.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  19%|█▎     | 144/744 [09:26<39:22,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54136.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  19%|█▎     | 145/744 [09:30<39:17,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67814.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  20%|█▎     | 146/744 [09:34<39:12,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64024.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  20%|█▍     | 147/744 [09:38<39:08,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65188.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  20%|█▍     | 148/744 [09:42<39:03,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63442.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  20%|█▍     | 149/744 [09:46<39:00,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52882.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  20%|█▍     | 150/744 [09:50<38:56,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54176.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  20%|█▍     | 151/744 [09:54<38:53,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56531.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  20%|█▍     | 152/744 [09:58<38:49,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59573.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  21%|█▍     | 153/744 [10:01<38:44,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60960.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  21%|█▍     | 154/744 [10:05<38:40,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61158.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  21%|█▍     | 155/744 [10:09<38:36,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58534.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  21%|█▍     | 156/744 [10:13<38:33,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70429.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  21%|█▍     | 157/744 [10:17<38:29,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54823.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  21%|█▍     | 158/744 [10:21<38:25,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64498.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  21%|█▍     | 159/744 [10:25<38:21,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63393.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  22%|█▌     | 160/744 [10:29<38:17,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63384.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  22%|█▌     | 161/744 [10:33<38:13,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55303.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  22%|█▌     | 162/744 [10:37<38:10,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64430.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8663, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  22%|█▌     | 163/744 [10:41<38:05,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56846.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  22%|█▌     | 164/744 [10:45<38:01,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57126.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  22%|█▌     | 165/744 [10:48<37:57,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60608.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  22%|█▌     | 166/744 [10:52<37:53,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59451.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  22%|█▌     | 167/744 [10:56<37:48,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61706.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  23%|█▌     | 168/744 [11:00<37:44,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56860.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  23%|█▌     | 169/744 [11:04<37:40,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58876.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  23%|█▌     | 170/744 [11:08<37:36,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58206.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  23%|█▌     | 171/744 [11:12<37:33,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63002.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  23%|█▌     | 172/744 [11:16<37:29,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58373.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  23%|█▋     | 173/744 [11:20<37:25,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57900.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  23%|█▋     | 174/744 [11:24<37:21,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53079.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  24%|█▋     | 175/744 [11:28<37:17,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57037.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  24%|█▋     | 176/744 [11:32<37:13,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66229.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  24%|█▋     | 177/744 [11:35<37:09,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63333.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  24%|█▋     | 178/744 [11:39<37:04,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64342.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  24%|█▋     | 179/744 [11:43<37:00,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56076.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  24%|█▋     | 180/744 [11:47<36:56,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57852.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  24%|█▋     | 181/744 [11:51<36:53,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67344.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  24%|█▋     | 182/744 [11:55<36:49,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62868.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  25%|█▋     | 183/744 [11:59<36:45,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51419.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  25%|█▋     | 184/744 [12:03<36:41,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59654.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  25%|█▋     | 185/744 [12:07<36:36,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56524.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  25%|█▊     | 186/744 [12:10<36:32,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57255.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  25%|█▊     | 187/744 [12:14<36:28,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63453.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  25%|█▊     | 188/744 [12:18<36:24,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54881.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  25%|█▊     | 189/744 [12:22<36:19,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65204.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  26%|█▊     | 190/744 [12:26<36:15,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66075.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  26%|█▊     | 191/744 [12:30<36:11,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61939.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  26%|█▊     | 192/744 [12:34<36:07,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64538.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8694, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  26%|█▊     | 193/744 [12:37<36:03,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61936.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  26%|█▊     | 194/744 [12:41<36:00,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60599.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  26%|█▊     | 195/744 [12:45<35:55,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64925.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  26%|█▊     | 196/744 [12:49<35:51,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60763.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  26%|█▊     | 197/744 [12:53<35:46,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(47395.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  27%|█▊     | 198/744 [12:57<35:42,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61409.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  27%|█▊     | 199/744 [13:01<35:38,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66414.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  27%|█▉     | 200/744 [13:04<35:34,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64662.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9363, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  27%|█▉     | 201/744 [13:08<35:30,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57501.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  27%|█▉     | 202/744 [13:12<35:26,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61352.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  27%|█▉     | 203/744 [13:16<35:22,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56084.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  27%|█▉     | 204/744 [13:20<35:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58417.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  28%|█▉     | 205/744 [13:24<35:15,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56064.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  28%|█▉     | 206/744 [13:28<35:11,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58305.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  28%|█▉     | 207/744 [13:32<35:07,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56729.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  28%|█▉     | 208/744 [13:36<35:03,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60122.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  28%|█▉     | 209/744 [13:40<34:59,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56320.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  28%|█▉     | 210/744 [13:44<34:55,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61990.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  28%|█▉     | 211/744 [13:48<34:52,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58872.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  28%|█▉     | 212/744 [13:51<34:47,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61616.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  29%|██     | 213/744 [13:55<34:43,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67347.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  29%|██     | 214/744 [13:59<34:38,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55226.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  29%|██     | 215/744 [14:03<34:34,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59265.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  29%|██     | 216/744 [14:06<34:30,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56881.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  29%|██     | 217/744 [14:10<34:26,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58422.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  29%|██     | 218/744 [14:14<34:22,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60959.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  29%|██     | 219/744 [14:18<34:18,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52600.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  30%|██     | 220/744 [14:22<34:14,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59090.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  30%|██     | 221/744 [14:26<34:10,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64548.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  30%|██     | 222/744 [14:30<34:07,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55150.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  30%|██     | 223/744 [14:34<34:03,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65276.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  30%|██     | 224/744 [14:38<33:59,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53810.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  30%|██     | 225/744 [14:42<33:55,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57606.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  30%|██▏    | 226/744 [14:46<33:51,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63486.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  31%|██▏    | 227/744 [14:50<33:47,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64439.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  31%|██▏    | 228/744 [14:53<33:42,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61323.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  31%|██▏    | 229/744 [14:57<33:39,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58561.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  31%|██▏    | 230/744 [15:01<33:34,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64290.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  31%|██▏    | 231/744 [15:05<33:30,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71023.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  31%|██▏    | 232/744 [15:09<33:26,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57640.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  31%|██▏    | 233/744 [15:13<33:23,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57964.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  31%|██▏    | 234/744 [15:17<33:20,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62605.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  32%|██▏    | 235/744 [15:21<33:16,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58311.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  32%|██▏    | 236/744 [15:25<33:12,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54175.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  32%|██▏    | 237/744 [15:29<33:09,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64568.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  32%|██▏    | 238/744 [15:33<33:04,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63590.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8069, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  32%|██▏    | 239/744 [15:37<33:00,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66456.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  32%|██▎    | 240/744 [15:41<32:56,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56543.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  32%|██▎    | 241/744 [15:45<32:52,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61187.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  33%|██▎    | 242/744 [15:48<32:48,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57224.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  33%|██▎    | 243/744 [15:52<32:44,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62075.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  33%|██▎    | 244/744 [15:56<32:40,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58536.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  33%|██▎    | 245/744 [16:00<32:37,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58203.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  33%|██▎    | 246/744 [16:04<32:32,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63990.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  33%|██▎    | 247/744 [16:08<32:28,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61793.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  33%|██▎    | 248/744 [16:12<32:25,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62899.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  33%|██▎    | 249/744 [16:16<32:21,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60799.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  34%|██▎    | 250/744 [16:20<32:17,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64089.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  34%|██▎    | 251/744 [16:24<32:13,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63911.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  34%|██▎    | 252/744 [16:28<32:09,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62753.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  34%|██▍    | 253/744 [16:32<32:06,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64144.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  34%|██▍    | 254/744 [16:36<32:02,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61215.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  34%|██▍    | 255/744 [16:40<31:58,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63966.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9601, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  34%|██▍    | 256/744 [16:44<31:55,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67180.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  35%|██▍    | 257/744 [16:48<31:51,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58897.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  35%|██▍    | 258/744 [16:52<31:46,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64608.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  35%|██▍    | 259/744 [16:56<31:43,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59931.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  35%|██▍    | 260/744 [17:00<31:38,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63577.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  35%|██▍    | 261/744 [17:03<31:34,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60234.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  35%|██▍    | 262/744 [17:07<31:30,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58839.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  35%|██▍    | 263/744 [17:11<31:27,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59759.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  35%|██▍    | 264/744 [17:15<31:22,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56633.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  36%|██▍    | 265/744 [17:19<31:18,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65048.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  36%|██▌    | 266/744 [17:23<31:14,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55707.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  36%|██▌    | 267/744 [17:27<31:11,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63248.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  36%|██▌    | 268/744 [17:31<31:07,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59414.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  36%|██▌    | 269/744 [17:35<31:03,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55195.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  36%|██▌    | 270/744 [17:38<30:59,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58441.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  36%|██▌    | 271/744 [17:42<30:54,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61088.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  37%|██▌    | 272/744 [17:46<30:50,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60394.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  37%|██▌    | 273/744 [17:50<30:46,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61575.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  37%|██▌    | 274/744 [17:54<30:42,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67089.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  37%|██▌    | 275/744 [17:58<30:38,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59112.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  37%|██▌    | 276/744 [18:02<30:34,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62780.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8628, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  37%|██▌    | 277/744 [18:05<30:30,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57567.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  37%|██▌    | 278/744 [18:10<30:27,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66516., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  38%|██▋    | 279/744 [18:13<30:22,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54304.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  38%|██▋    | 280/744 [18:17<30:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60301.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  38%|██▋    | 281/744 [18:21<30:15,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60650.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  38%|██▋    | 282/744 [18:25<30:11,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64257.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  38%|██▋    | 283/744 [18:29<30:07,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58965.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  38%|██▋    | 284/744 [18:33<30:02,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66029.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  38%|██▋    | 285/744 [18:37<29:59,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64080.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  38%|██▋    | 286/744 [18:41<29:55,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(51899.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  39%|██▋    | 287/744 [18:45<29:51,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59865.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  39%|██▋    | 288/744 [18:48<29:47,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66662.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  39%|██▋    | 289/744 [18:52<29:43,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62205.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  39%|██▋    | 290/744 [18:56<29:39,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61344.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  39%|██▋    | 291/744 [19:00<29:35,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60936.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  39%|██▋    | 292/744 [19:04<29:31,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58524.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  39%|██▊    | 293/744 [19:08<29:27,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71702.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  40%|██▊    | 294/744 [19:12<29:23,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58633.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  40%|██▊    | 295/744 [19:16<29:19,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57408.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  40%|██▊    | 296/744 [19:19<29:15,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53929.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  40%|██▊    | 297/744 [19:23<29:11,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66625.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  40%|██▊    | 298/744 [19:27<29:07,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63689.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8822, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  40%|██▊    | 299/744 [19:31<29:03,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62337.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  40%|██▊    | 300/744 [19:35<28:59,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64328.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  40%|██▊    | 301/744 [19:39<28:55,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65915.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  41%|██▊    | 302/744 [19:42<28:51,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60783.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  41%|██▊    | 303/744 [19:46<28:46,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56780.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  41%|██▊    | 304/744 [19:50<28:42,  3.92s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64628.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  41%|██▊    | 305/744 [19:54<28:38,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62802.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  41%|██▉    | 306/744 [19:57<28:34,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65720.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  41%|██▉    | 307/744 [20:01<28:30,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64371.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  41%|██▉    | 308/744 [20:05<28:26,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63963.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  42%|██▉    | 309/744 [20:09<28:22,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58659.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  42%|██▉    | 310/744 [20:12<28:18,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55598.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  42%|██▉    | 311/744 [20:17<28:14,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65642.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  42%|██▉    | 312/744 [20:20<28:10,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64839.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  42%|██▉    | 313/744 [20:24<28:06,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61267.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  42%|██▉    | 314/744 [20:28<28:02,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62621.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9209, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  42%|██▉    | 315/744 [20:32<27:58,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57926.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  42%|██▉    | 316/744 [20:36<27:54,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60856.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  43%|██▉    | 317/744 [20:40<27:50,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60766.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  43%|██▉    | 318/744 [20:44<27:46,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64083.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  43%|███    | 319/744 [20:48<27:42,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52124.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  43%|███    | 320/744 [20:51<27:38,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64507.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  43%|███    | 321/744 [20:55<27:34,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59524.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  43%|███    | 322/744 [20:59<27:30,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65757.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8148, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  43%|███    | 323/744 [21:03<27:26,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64953.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  44%|███    | 324/744 [21:06<27:22,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60603.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  44%|███    | 325/744 [21:10<27:18,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54097.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  44%|███    | 326/744 [21:14<27:13,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59560.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  44%|███    | 327/744 [21:18<27:09,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54472.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  44%|███    | 328/744 [21:21<27:05,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62037.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  44%|███    | 329/744 [21:25<27:01,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63366.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  44%|███    | 330/744 [21:29<26:57,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59763.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  44%|███    | 331/744 [21:33<26:53,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61849.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  45%|███    | 332/744 [21:37<26:49,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61465.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  45%|███▏   | 333/744 [21:40<26:45,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62560.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  45%|███▏   | 334/744 [21:44<26:41,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61914.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  45%|███▏   | 335/744 [21:48<26:37,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57863.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  45%|███▏   | 336/744 [21:52<26:33,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57066.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  45%|███▏   | 337/744 [21:56<26:29,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60577.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  45%|███▏   | 338/744 [22:00<26:25,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63720.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  46%|███▏   | 339/744 [22:03<26:21,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61998.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  46%|███▏   | 340/744 [22:07<26:17,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63119.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  46%|███▏   | 341/744 [22:11<26:14,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65624.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  46%|███▏   | 342/744 [22:15<26:10,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63588.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  46%|███▏   | 343/744 [22:19<26:06,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60507.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  46%|███▏   | 344/744 [22:23<26:02,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57823.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  46%|███▏   | 345/744 [22:27<25:58,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61784.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  47%|███▎   | 346/744 [22:31<25:54,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54753.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  47%|███▎   | 347/744 [22:34<25:50,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59461.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  47%|███▎   | 348/744 [22:38<25:46,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58611.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  47%|███▎   | 349/744 [22:42<25:42,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62128.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  47%|███▎   | 350/744 [22:46<25:38,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59541.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  47%|███▎   | 351/744 [22:50<25:34,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60748.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  47%|███▎   | 352/744 [22:54<25:30,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58476.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8959, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  47%|███▎   | 353/744 [22:58<25:26,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61948.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  48%|███▎   | 354/744 [23:01<25:22,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63883.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  48%|███▎   | 355/744 [23:05<25:18,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58902.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  48%|███▎   | 356/744 [23:09<25:14,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66339.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  48%|███▎   | 357/744 [23:13<25:10,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62066.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  48%|███▎   | 358/744 [23:17<25:06,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57952.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  48%|███▍   | 359/744 [23:21<25:02,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61622.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  48%|███▍   | 360/744 [23:25<24:58,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62339.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  49%|███▍   | 361/744 [23:29<24:55,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60751.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  49%|███▍   | 362/744 [23:33<24:51,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61725.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  49%|███▍   | 363/744 [23:37<24:47,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61705.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  49%|███▍   | 364/744 [23:40<24:43,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64175.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8984, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  49%|███▍   | 365/744 [23:44<24:39,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64874.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  49%|███▍   | 366/744 [23:48<24:35,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57646.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  49%|███▍   | 367/744 [23:52<24:31,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64141.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  49%|███▍   | 368/744 [23:56<24:27,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63552.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  50%|███▍   | 369/744 [24:00<24:23,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59604.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  50%|███▍   | 370/744 [24:03<24:19,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65206.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  50%|███▍   | 371/744 [24:07<24:15,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57191.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  50%|███▌   | 372/744 [24:11<24:11,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60049.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8572, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  50%|███▌   | 373/744 [24:15<24:07,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64080.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  50%|███▌   | 374/744 [24:19<24:03,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55203.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  50%|███▌   | 375/744 [24:22<23:59,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60965.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  51%|███▌   | 376/744 [24:26<23:55,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61425.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  51%|███▌   | 377/744 [24:30<23:51,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58623.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  51%|███▌   | 378/744 [24:34<23:47,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65511.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  51%|███▌   | 379/744 [24:38<23:43,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59248.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9203, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  51%|███▌   | 380/744 [24:41<23:39,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59835.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  51%|███▌   | 381/744 [24:45<23:35,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62567.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  51%|███▌   | 382/744 [24:49<23:31,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55894.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  51%|███▌   | 383/744 [24:53<23:27,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61340.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  52%|███▌   | 384/744 [24:57<23:23,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61056.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  52%|███▌   | 385/744 [25:01<23:19,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58077.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  52%|███▋   | 386/744 [25:05<23:15,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64753.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  52%|███▋   | 387/744 [25:08<23:11,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65787.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  52%|███▋   | 388/744 [25:12<23:07,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69055.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  52%|███▋   | 389/744 [25:16<23:04,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66483.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  52%|███▋   | 390/744 [25:20<23:00,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68584.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8660, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  53%|███▋   | 391/744 [25:24<22:56,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60916.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  53%|███▋   | 392/744 [25:28<22:52,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53351.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  53%|███▋   | 393/744 [25:32<22:48,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58620.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  53%|███▋   | 394/744 [25:36<22:44,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57129.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  53%|███▋   | 395/744 [25:39<22:40,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60460.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  53%|███▋   | 396/744 [25:43<22:36,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56243.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  53%|███▋   | 397/744 [25:48<22:33,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57594.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  53%|███▋   | 398/744 [25:51<22:29,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61440.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  54%|███▊   | 399/744 [25:55<22:25,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63244.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  54%|███▊   | 400/744 [25:59<22:21,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58114.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  54%|███▊   | 401/744 [26:03<22:17,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62582.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  54%|███▊   | 402/744 [26:07<22:13,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54791.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  54%|███▊   | 403/744 [26:11<22:09,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58365.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  54%|███▊   | 404/744 [26:15<22:05,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56197.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  54%|███▊   | 405/744 [26:19<22:01,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67690.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  55%|███▊   | 406/744 [26:22<21:57,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59651.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  55%|███▊   | 407/744 [26:27<21:54,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62247.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8822, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  55%|███▊   | 408/744 [26:31<21:50,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69621.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8694, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  55%|███▊   | 409/744 [26:34<21:46,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63873.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  55%|███▊   | 410/744 [26:38<21:42,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61677.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  55%|███▊   | 411/744 [26:42<21:38,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66146.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  55%|███▉   | 412/744 [26:46<21:34,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63186.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  56%|███▉   | 413/744 [26:50<21:30,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56722.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  56%|███▉   | 414/744 [26:53<21:26,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62389.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  56%|███▉   | 415/744 [26:57<21:22,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60804.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  56%|███▉   | 416/744 [27:01<21:18,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58697.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  56%|███▉   | 417/744 [27:05<21:14,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59106.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  56%|███▉   | 418/744 [27:09<21:10,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64569.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  56%|███▉   | 419/744 [27:13<21:06,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62206.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  56%|███▉   | 420/744 [27:17<21:03,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61954.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  57%|███▉   | 421/744 [27:21<20:59,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55978.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  57%|███▉   | 422/744 [27:25<20:55,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59626.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  57%|███▉   | 423/744 [27:28<20:51,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58149.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  57%|███▉   | 424/744 [27:32<20:47,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63960.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  57%|███▉   | 425/744 [27:36<20:43,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54591.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  57%|████   | 426/744 [27:40<20:39,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61294.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  57%|████   | 427/744 [27:44<20:35,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62115.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  58%|████   | 428/744 [27:48<20:31,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57711.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7975, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  58%|████   | 429/744 [27:52<20:27,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62512.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  58%|████   | 430/744 [27:56<20:24,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68121.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  58%|████   | 431/744 [27:59<20:19,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56236.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  58%|████   | 432/744 [28:03<20:16,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60277.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  58%|████   | 433/744 [28:07<20:12,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57284.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  58%|████   | 434/744 [28:11<20:08,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55288.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  58%|████   | 435/744 [28:15<20:04,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70741.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  59%|████   | 436/744 [28:19<20:00,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60096.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  59%|████   | 437/744 [28:23<19:56,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68760.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  59%|████   | 438/744 [28:27<19:52,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53441.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  59%|████▏  | 439/744 [28:30<19:48,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58563.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  59%|████▏  | 440/744 [28:34<19:44,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60069.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  59%|████▏  | 441/744 [28:38<19:40,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57135.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  59%|████▏  | 442/744 [28:42<19:36,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65714.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  60%|████▏  | 443/744 [28:46<19:32,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55047.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  60%|████▏  | 444/744 [28:49<19:28,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55537.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  60%|████▏  | 445/744 [28:53<19:24,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63328.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  60%|████▏  | 446/744 [28:57<19:20,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63481.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  60%|████▏  | 447/744 [29:01<19:16,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60138.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  60%|████▏  | 448/744 [29:05<19:13,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62646.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  60%|████▏  | 449/744 [29:09<19:09,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67170.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  60%|████▏  | 450/744 [29:13<19:05,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58769.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  61%|████▏  | 451/744 [29:17<19:01,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73349.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  61%|████▎  | 452/744 [29:21<18:57,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60096.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  61%|████▎  | 453/744 [29:25<18:53,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65959.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  61%|████▎  | 454/744 [29:28<18:49,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60719.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  61%|████▎  | 455/744 [29:32<18:45,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64767.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  61%|████▎  | 456/744 [29:36<18:42,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60051.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  61%|████▎  | 457/744 [29:40<18:38,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57768.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  62%|████▎  | 458/744 [29:44<18:34,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61756.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  62%|████▎  | 459/744 [29:48<18:30,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67061.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  62%|████▎  | 460/744 [29:52<18:26,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55281.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  62%|████▎  | 461/744 [29:55<18:22,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62749.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  62%|████▎  | 462/744 [29:59<18:18,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62917.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  62%|████▎  | 463/744 [30:03<18:14,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61261.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  62%|████▎  | 464/744 [30:07<18:10,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64210., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  62%|████▍  | 465/744 [30:11<18:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56469.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  63%|████▍  | 466/744 [30:15<18:02,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67558.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8135, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  63%|████▍  | 467/744 [30:18<17:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63908.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  63%|████▍  | 468/744 [30:22<17:55,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52567.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  63%|████▍  | 469/744 [30:26<17:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59654.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  63%|████▍  | 470/744 [30:30<17:47,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62343.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  63%|████▍  | 471/744 [30:34<17:43,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61576.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  63%|████▍  | 472/744 [30:37<17:39,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67005.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  64%|████▍  | 473/744 [30:41<17:35,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63681.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  64%|████▍  | 474/744 [30:45<17:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63165.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  64%|████▍  | 475/744 [30:49<17:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67039.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  64%|████▍  | 476/744 [30:53<17:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62607.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  64%|████▍  | 477/744 [30:56<17:19,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60465., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  64%|████▍  | 478/744 [31:00<17:15,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67816.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  64%|████▌  | 479/744 [31:04<17:11,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64706.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  65%|████▌  | 480/744 [31:08<17:07,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57346.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  65%|████▌  | 481/744 [31:12<17:03,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57729.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  65%|████▌  | 482/744 [31:16<16:59,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63956.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  65%|████▌  | 483/744 [31:20<16:55,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68088.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  65%|████▌  | 484/744 [31:23<16:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62476.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  65%|████▌  | 485/744 [31:27<16:48,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61406.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  65%|████▌  | 486/744 [31:31<16:44,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64395.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  65%|████▌  | 487/744 [31:35<16:40,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60260.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  66%|████▌  | 488/744 [31:39<16:36,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55577.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  66%|████▌  | 489/744 [31:43<16:32,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66498.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  66%|████▌  | 490/744 [31:47<16:28,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66920.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  66%|████▌  | 491/744 [31:51<16:24,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61632.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  66%|████▋  | 492/744 [31:55<16:21,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59820.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  66%|████▋  | 493/744 [31:59<16:17,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64943.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  66%|████▋  | 494/744 [32:03<16:13,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64426.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  67%|████▋  | 495/744 [32:06<16:09,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64767.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  67%|████▋  | 496/744 [32:10<16:05,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63126.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8213, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  67%|████▋  | 497/744 [32:14<16:01,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58400.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  67%|████▋  | 498/744 [32:18<15:57,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(54466.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  67%|████▋  | 499/744 [32:22<15:53,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65633.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  67%|████▋  | 500/744 [32:26<15:49,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66765.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  67%|████▋  | 501/744 [32:30<15:45,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66028.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  67%|████▋  | 502/744 [32:33<15:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60884.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  68%|████▋  | 503/744 [32:37<15:37,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58655.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  68%|████▋  | 504/744 [32:41<15:34,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63072.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8683, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  68%|████▊  | 505/744 [32:45<15:30,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61099.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  68%|████▊  | 506/744 [32:49<15:26,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63917.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  68%|████▊  | 507/744 [32:53<15:22,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64849.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  68%|████▊  | 508/744 [32:57<15:18,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64991.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  68%|████▊  | 509/744 [33:01<15:14,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58831.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  69%|████▊  | 510/744 [33:05<15:10,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61695.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  69%|████▊  | 511/744 [33:09<15:07,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65015.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  69%|████▊  | 512/744 [33:13<15:03,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64921.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  69%|████▊  | 513/744 [33:16<14:59,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65605.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  69%|████▊  | 514/744 [33:20<14:55,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60886.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  69%|████▊  | 515/744 [33:24<14:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61930.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  69%|████▊  | 516/744 [33:27<14:47,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64563.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  69%|████▊  | 517/744 [33:31<14:43,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61402.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  70%|████▊  | 518/744 [33:35<14:39,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68377.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  70%|████▉  | 519/744 [33:39<14:35,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64002.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  70%|████▉  | 520/744 [33:43<14:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58604.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  70%|████▉  | 521/744 [33:47<14:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70024.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  70%|████▉  | 522/744 [33:51<14:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58909.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  70%|████▉  | 523/744 [33:55<14:20,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61654.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  70%|████▉  | 524/744 [33:59<14:16,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61751.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  71%|████▉  | 525/744 [34:02<14:12,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63221.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  71%|████▉  | 526/744 [34:06<14:08,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67321.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  71%|████▉  | 527/744 [34:10<14:04,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66757.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  71%|████▉  | 528/744 [34:14<14:00,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67801.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  71%|████▉  | 529/744 [34:18<13:56,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61594.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9740, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  71%|████▉  | 530/744 [34:22<13:52,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67283.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  71%|████▉  | 531/744 [34:26<13:48,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65858.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  72%|█████  | 532/744 [34:30<13:44,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65586.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  72%|█████  | 533/744 [34:33<13:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61139.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  72%|█████  | 534/744 [34:37<13:37,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62705.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  72%|█████  | 535/744 [34:41<13:33,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64343.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  72%|█████  | 536/744 [34:45<13:29,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64081.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  72%|█████  | 537/744 [34:49<13:25,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59937.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  72%|█████  | 538/744 [34:53<13:21,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64423.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  72%|█████  | 539/744 [34:57<13:17,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64380.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  73%|█████  | 540/744 [35:01<13:13,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56150.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  73%|█████  | 541/744 [35:04<13:09,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73254.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  73%|█████  | 542/744 [35:08<13:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59683.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8310, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  73%|█████  | 543/744 [35:12<13:02,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66525.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  73%|█████  | 544/744 [35:16<12:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64196.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  73%|█████▏ | 545/744 [35:20<12:54,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61136.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  73%|█████▏ | 546/744 [35:24<12:50,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(53995.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  74%|█████▏ | 547/744 [35:28<12:46,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64227.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  74%|█████▏ | 548/744 [35:32<12:42,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69551.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  74%|█████▏ | 549/744 [35:36<12:38,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62164.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  74%|█████▏ | 550/744 [35:40<12:34,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60647.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  74%|█████▏ | 551/744 [35:44<12:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60268.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  74%|█████▏ | 552/744 [35:48<12:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65717.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  74%|█████▏ | 553/744 [35:51<12:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63802.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  74%|█████▏ | 554/744 [35:55<12:19,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66329.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  75%|█████▏ | 555/744 [35:59<12:15,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63120.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  75%|█████▏ | 556/744 [36:03<12:11,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60156.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  75%|█████▏ | 557/744 [36:07<12:07,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68624.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  75%|█████▎ | 558/744 [36:11<12:03,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61445.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  75%|█████▎ | 559/744 [36:15<11:59,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63548.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  75%|█████▎ | 560/744 [36:18<11:55,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57282.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  75%|█████▎ | 561/744 [36:22<11:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61592.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  76%|█████▎ | 562/744 [36:26<11:48,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64016.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  76%|█████▎ | 563/744 [36:30<11:44,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63537.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  76%|█████▎ | 564/744 [36:33<11:40,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63415.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  76%|█████▎ | 565/744 [36:37<11:36,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68060.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  76%|█████▎ | 566/744 [36:41<11:32,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55499.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  76%|█████▎ | 567/744 [36:45<11:28,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63052.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  76%|█████▎ | 568/744 [36:49<11:24,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63924.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  76%|█████▎ | 569/744 [36:52<11:20,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66997.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  77%|█████▎ | 570/744 [36:56<11:16,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55344.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  77%|█████▎ | 571/744 [37:00<11:12,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65725.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  77%|█████▍ | 572/744 [37:04<11:08,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66209.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  77%|█████▍ | 573/744 [37:08<11:05,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65052.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  77%|█████▍ | 574/744 [37:12<11:01,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66495.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  77%|█████▍ | 575/744 [37:16<10:57,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61682.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  77%|█████▍ | 576/744 [37:20<10:53,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62396.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  78%|█████▍ | 577/744 [37:24<10:49,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61593.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  78%|█████▍ | 578/744 [37:28<10:45,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63766.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  78%|█████▍ | 579/744 [37:32<10:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68195.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  78%|█████▍ | 580/744 [37:36<10:38,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64374.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8655, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  78%|█████▍ | 581/744 [37:40<10:34,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63706.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  78%|█████▍ | 582/744 [37:43<10:30,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59096.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  78%|█████▍ | 583/744 [37:47<10:26,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60979.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  78%|█████▍ | 584/744 [37:51<10:22,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68005.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  79%|█████▌ | 585/744 [37:55<10:18,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71053.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  79%|█████▌ | 586/744 [37:59<10:14,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62664.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  79%|█████▌ | 587/744 [38:03<10:10,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63350.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  79%|█████▌ | 588/744 [38:07<10:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57137.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  79%|█████▌ | 589/744 [38:10<10:02,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68898.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  79%|█████▌ | 590/744 [38:14<09:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64446.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  79%|█████▌ | 591/744 [38:18<09:55,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63623.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  80%|█████▌ | 592/744 [38:22<09:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72463.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  80%|█████▌ | 593/744 [38:26<09:47,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67694.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  80%|█████▌ | 594/744 [38:30<09:43,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68192.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  80%|█████▌ | 595/744 [38:34<09:39,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65049.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  80%|█████▌ | 596/744 [38:38<09:35,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60652.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  80%|█████▌ | 597/744 [38:42<09:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56398.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  80%|█████▋ | 598/744 [38:45<09:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67928.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  81%|█████▋ | 599/744 [38:49<09:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(52882.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  81%|█████▋ | 600/744 [38:54<09:20,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62251.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  81%|█████▋ | 601/744 [38:58<09:16,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63385.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  81%|█████▋ | 602/744 [39:01<09:12,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64191.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  81%|█████▋ | 603/744 [39:05<09:08,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58382.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  81%|█████▋ | 604/744 [39:09<09:04,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64115.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  81%|█████▋ | 605/744 [39:13<09:00,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66124.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  81%|█████▋ | 606/744 [39:17<08:56,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68532.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  82%|█████▋ | 607/744 [39:21<08:52,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61815.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  82%|█████▋ | 608/744 [39:24<08:49,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65300.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  82%|█████▋ | 609/744 [39:28<08:45,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60726.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  82%|█████▋ | 610/744 [39:32<08:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63189.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  82%|█████▋ | 611/744 [39:36<08:37,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63738.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  82%|█████▊ | 612/744 [39:40<08:33,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72635.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  82%|█████▊ | 613/744 [39:44<08:29,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68284.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  83%|█████▊ | 614/744 [39:48<08:25,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63129.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  83%|█████▊ | 615/744 [39:52<08:21,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59225.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  83%|█████▊ | 616/744 [39:56<08:17,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68570.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  83%|█████▊ | 617/744 [40:00<08:14,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70231.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  83%|█████▊ | 618/744 [40:04<08:10,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69644.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8253, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  83%|█████▊ | 619/744 [40:08<08:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56831.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  83%|█████▊ | 620/744 [40:12<08:02,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63174.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  83%|█████▊ | 621/744 [40:15<07:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70432.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  84%|█████▊ | 622/744 [40:19<07:54,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64856.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  84%|█████▊ | 623/744 [40:23<07:50,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65819.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  84%|█████▊ | 624/744 [40:27<07:46,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67037.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  84%|█████▉ | 625/744 [40:31<07:42,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60437.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  84%|█████▉ | 626/744 [40:34<07:38,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60120.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  84%|█████▉ | 627/744 [40:38<07:35,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59517.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  84%|█████▉ | 628/744 [40:42<07:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69265.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  85%|█████▉ | 629/744 [40:46<07:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70876.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  85%|█████▉ | 630/744 [40:50<07:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72001.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  85%|█████▉ | 631/744 [40:54<07:19,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57625.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  85%|█████▉ | 632/744 [40:58<07:15,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65116.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  85%|█████▉ | 633/744 [41:02<07:11,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58759.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  85%|█████▉ | 634/744 [41:05<07:07,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68880.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  85%|█████▉ | 635/744 [41:09<07:03,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65323.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  85%|█████▉ | 636/744 [41:13<07:00,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61134.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  86%|█████▉ | 637/744 [41:17<06:56,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57636.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  86%|██████ | 638/744 [41:21<06:52,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61281.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  86%|██████ | 639/744 [41:25<06:48,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59223.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  86%|██████ | 640/744 [41:28<06:44,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64941.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  86%|██████ | 641/744 [41:32<06:40,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71314.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  86%|██████ | 642/744 [41:37<06:36,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63086.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  86%|██████ | 643/744 [41:40<06:32,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69093.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  87%|██████ | 644/744 [41:44<06:28,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66515.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  87%|██████ | 645/744 [41:48<06:25,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60498.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  87%|██████ | 646/744 [41:52<06:21,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60484.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  87%|██████ | 647/744 [41:56<06:17,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59820.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  87%|██████ | 648/744 [41:59<06:13,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62116.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  87%|██████ | 649/744 [42:03<06:09,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60089.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  87%|██████ | 650/744 [42:07<06:05,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62409.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  88%|██████▏| 651/744 [42:11<06:01,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65715.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  88%|██████▏| 652/744 [42:15<05:57,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59734.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  88%|██████▏| 653/744 [42:19<05:53,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65839.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  88%|██████▏| 654/744 [42:22<05:49,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59291.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  88%|██████▏| 655/744 [42:26<05:46,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62894.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  88%|██████▏| 656/744 [42:30<05:42,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63486.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8626, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  88%|██████▏| 657/744 [42:34<05:38,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59740.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  88%|██████▏| 658/744 [42:38<05:34,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63093.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  89%|██████▏| 659/744 [42:41<05:30,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62992.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  89%|██████▏| 660/744 [42:45<05:26,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68007.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  89%|██████▏| 661/744 [42:49<05:22,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57851.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  89%|██████▏| 662/744 [42:53<05:18,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66566.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  89%|██████▏| 663/744 [42:57<05:14,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61827.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  89%|██████▏| 664/744 [43:01<05:10,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73807.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  89%|██████▎| 665/744 [43:05<05:07,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66964.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  90%|██████▎| 666/744 [43:09<05:03,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59705.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  90%|██████▎| 667/744 [43:12<04:59,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68222.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  90%|██████▎| 668/744 [43:16<04:55,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58015.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  90%|██████▎| 669/744 [43:20<04:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64312.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  90%|██████▎| 670/744 [43:24<04:47,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67612.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  90%|██████▎| 671/744 [43:28<04:43,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58893.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  90%|██████▎| 672/744 [43:31<04:39,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62061.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  90%|██████▎| 673/744 [43:35<04:35,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68830.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9739, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  91%|██████▎| 674/744 [43:40<04:32,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64577.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  91%|██████▎| 675/744 [43:43<04:28,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57638.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  91%|██████▎| 676/744 [43:47<04:24,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66302.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  91%|██████▎| 677/744 [43:51<04:20,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63530.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  91%|██████▍| 678/744 [43:55<04:16,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66220.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  91%|██████▍| 679/744 [43:59<04:12,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66083.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  91%|██████▍| 680/744 [44:03<04:08,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63661.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  92%|██████▍| 681/744 [44:06<04:04,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67787.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  92%|██████▍| 682/744 [44:10<04:00,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68665.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  92%|██████▍| 683/744 [44:14<03:57,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71026.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  92%|██████▍| 684/744 [44:18<03:53,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61911.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  92%|██████▍| 685/744 [44:22<03:49,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69301.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8885, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  92%|██████▍| 686/744 [44:26<03:45,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62848.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  92%|██████▍| 687/744 [44:30<03:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68003.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  92%|██████▍| 688/744 [44:34<03:37,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70969.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  93%|██████▍| 689/744 [44:38<03:33,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61748.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  93%|██████▍| 690/744 [44:42<03:29,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69170.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  93%|██████▌| 691/744 [44:46<03:26,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63262.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  93%|██████▌| 692/744 [44:50<03:22,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65918.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  93%|██████▌| 693/744 [44:53<03:18,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62202.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  93%|██████▌| 694/744 [44:57<03:14,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61068.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7622, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  93%|██████▌| 695/744 [45:01<03:10,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60336.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  94%|██████▌| 696/744 [45:05<03:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67782.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  94%|██████▌| 697/744 [45:09<03:02,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69083.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  94%|██████▌| 698/744 [45:13<02:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62923.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7652, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  94%|██████▌| 699/744 [45:17<02:54,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64233.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  94%|██████▌| 700/744 [45:21<02:51,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62408.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  94%|██████▌| 701/744 [45:25<02:47,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61899.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  94%|██████▌| 702/744 [45:29<02:43,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68803.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  94%|██████▌| 703/744 [45:33<02:39,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65079.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  95%|██████▌| 704/744 [45:37<02:35,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60565.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  95%|██████▋| 705/744 [45:41<02:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70615.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  95%|██████▋| 706/744 [45:44<02:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59457.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  95%|██████▋| 707/744 [45:48<02:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59140.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  95%|██████▋| 708/744 [45:52<02:19,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66731.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  95%|██████▋| 709/744 [45:56<02:16,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61718.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  95%|██████▋| 710/744 [46:00<02:12,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68067.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  96%|██████▋| 711/744 [46:04<02:08,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67421.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  96%|██████▋| 712/744 [46:08<02:04,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63233.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  96%|██████▋| 713/744 [46:12<02:00,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62594.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  96%|██████▋| 714/744 [46:16<01:56,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63375.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  96%|██████▋| 715/744 [46:20<01:52,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64814.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  96%|██████▋| 716/744 [46:24<01:48,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64424.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  96%|██████▋| 717/744 [46:28<01:44,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59694.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  97%|██████▊| 718/744 [46:32<01:41,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63373.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  97%|██████▊| 719/744 [46:36<01:37,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70089.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  97%|██████▊| 720/744 [46:40<01:33,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68214.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  97%|██████▊| 721/744 [46:43<01:29,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67364.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9710, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  97%|██████▊| 722/744 [46:47<01:25,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56900.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  97%|██████▊| 723/744 [46:51<01:21,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63548.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  97%|██████▊| 724/744 [46:55<01:17,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68721.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  97%|██████▊| 725/744 [46:59<01:13,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63377.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  98%|██████▊| 726/744 [47:03<01:09,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57672.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  98%|██████▊| 727/744 [47:06<01:06,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65996.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  98%|██████▊| 728/744 [47:10<01:02,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65858.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  98%|██████▊| 729/744 [47:14<00:58,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58709.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  98%|██████▊| 730/744 [47:18<00:54,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67152.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  98%|██████▉| 731/744 [47:21<00:50,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68998.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  98%|██████▉| 732/744 [47:25<00:46,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58890.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  99%|██████▉| 733/744 [47:29<00:42,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64899.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  99%|██████▉| 734/744 [47:33<00:38,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59365.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  99%|██████▉| 735/744 [47:37<00:34,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59827.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  99%|██████▉| 736/744 [47:41<00:31,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65139.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  99%|██████▉| 737/744 [47:45<00:27,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62794.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  99%|██████▉| 738/744 [47:49<00:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67209.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  99%|██████▉| 739/744 [47:52<00:19,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62371.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9:  99%|██████▉| 740/744 [47:56<00:15,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66912.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9: 100%|██████▉| 741/744 [48:00<00:11,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70407.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9: 100%|██████▉| 742/744 [48:03<00:07,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(57143.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9: 100%|██████▉| 743/744 [48:07<00:03,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(56605.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10:   0%|                | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(63400.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10:   0%|      | 1/744 [00:05<1:05:27,  5.29s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63147.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10:   0%|        | 2/744 [00:09<58:02,  4.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60337.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10:   0%|        | 3/744 [00:12<53:27,  4.33s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63893.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10:   1%|        | 4/744 [00:16<51:04,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66535.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10:   1%|        | 5/744 [00:20<49:52,  4.05s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(60610.9219, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  57%|███▍  | 427/744 [27:12<20:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71764.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  58%|███▍  | 428/744 [27:16<20:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71818.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  58%|███▍  | 429/744 [27:20<20:04,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69559.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  58%|███▍  | 430/744 [27:24<20:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74144.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  58%|███▍  | 431/744 [27:28<19:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76088.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  58%|███▍  | 432/744 [27:32<19:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68264.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  58%|███▍  | 433/744 [27:36<19:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75567.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  58%|███▌  | 434/744 [27:40<19:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72729.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  58%|███▌  | 435/744 [27:44<19:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66541.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  59%|███▌  | 436/744 [27:47<19:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78555.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  59%|███▌  | 437/744 [27:51<19:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77343.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  59%|███▌  | 438/744 [27:55<19:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73706.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  59%|███▌  | 439/744 [28:00<19:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76672.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  59%|███▌  | 440/744 [28:04<19:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61538.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  59%|███▌  | 441/744 [28:08<19:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72227.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  59%|███▌  | 442/744 [28:12<19:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69774.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  60%|███▌  | 443/744 [28:16<19:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72327.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  60%|███▌  | 444/744 [28:20<19:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69984.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  60%|███▌  | 445/744 [28:24<19:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72912.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  60%|███▌  | 446/744 [28:28<19:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74977.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  60%|███▌  | 447/744 [28:31<18:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71441.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  60%|███▌  | 448/744 [28:35<18:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72213.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  60%|███▌  | 449/744 [28:39<18:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68282.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  60%|███▋  | 450/744 [28:43<18:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68385.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  61%|███▋  | 451/744 [28:46<18:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72811.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  61%|███▋  | 452/744 [28:50<18:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68115.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  61%|███▋  | 453/744 [28:54<18:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70400.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  61%|███▋  | 454/744 [28:57<18:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77199.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  61%|███▋  | 455/744 [29:01<18:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81468.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  61%|███▋  | 456/744 [29:05<18:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73910.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  61%|███▋  | 457/744 [29:09<18:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71441.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  62%|███▋  | 458/744 [29:13<18:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73366.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  62%|███▋  | 459/744 [29:17<18:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74686.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  62%|███▋  | 460/744 [29:21<18:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76797.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  62%|███▋  | 461/744 [29:25<18:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82944.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  62%|███▋  | 462/744 [29:29<17:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73351.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  62%|███▋  | 463/744 [29:33<17:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77609.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  62%|███▋  | 464/744 [29:37<17:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74335.8984, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  62%|███▊  | 465/744 [29:41<17:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73950.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  63%|███▊  | 466/744 [29:45<17:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72270.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  63%|███▊  | 467/744 [29:50<17:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75110.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  63%|███▊  | 468/744 [29:54<17:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65023.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  63%|███▊  | 469/744 [29:58<17:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72887.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  63%|███▊  | 470/744 [30:02<17:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73581.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  63%|███▊  | 471/744 [30:06<17:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72335.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  63%|███▊  | 472/744 [30:10<17:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77461.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  64%|███▊  | 473/744 [30:13<17:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76241.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  64%|███▊  | 474/744 [30:17<17:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77407.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  64%|███▊  | 475/744 [30:21<17:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69071.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  64%|███▊  | 476/744 [30:25<17:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72129.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  64%|███▊  | 477/744 [30:29<17:04,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82403.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  64%|███▊  | 478/744 [30:33<17:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72027.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  64%|███▊  | 479/744 [30:37<16:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78710.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  65%|███▊  | 480/744 [30:41<16:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71324.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  65%|███▉  | 481/744 [30:45<16:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66349.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  65%|███▉  | 482/744 [30:49<16:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78746.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  65%|███▉  | 483/744 [30:53<16:41,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72911.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  65%|███▉  | 484/744 [30:58<16:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74320.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  65%|███▉  | 485/744 [31:02<16:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64465.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  65%|███▉  | 486/744 [31:05<16:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73818.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  65%|███▉  | 487/744 [31:09<16:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76741.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  66%|███▉  | 488/744 [31:13<16:22,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82628.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  66%|███▉  | 489/744 [31:16<16:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71250.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  66%|███▉  | 490/744 [31:20<16:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79527.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  66%|███▉  | 491/744 [31:24<16:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66327.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  66%|███▉  | 492/744 [31:28<16:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78157.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  66%|███▉  | 493/744 [31:31<16:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69718.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  66%|███▉  | 494/744 [31:35<15:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63662.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  67%|███▉  | 495/744 [31:39<15:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75393.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  67%|████  | 496/744 [31:43<15:51,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(61146.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  67%|████  | 497/744 [31:47<15:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78424.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  67%|████  | 498/744 [31:51<15:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73265.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  67%|████  | 499/744 [31:54<15:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71877.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  67%|████  | 500/744 [31:58<15:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75871.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  67%|████  | 501/744 [32:02<15:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67117.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  67%|████  | 502/744 [32:06<15:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73431.2422, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  68%|████  | 503/744 [32:10<15:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75356.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  68%|████  | 504/744 [32:14<15:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73427.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  68%|████  | 505/744 [32:17<15:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70874.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  68%|████  | 506/744 [32:21<15:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69927.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  68%|████  | 507/744 [32:25<15:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66803.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7739, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  68%|████  | 508/744 [32:29<15:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69833.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  68%|████  | 509/744 [32:33<15:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66223.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  69%|████  | 510/744 [32:37<14:57,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73789.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  69%|████  | 511/744 [32:41<14:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74101.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  69%|████▏ | 512/744 [32:44<14:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71643.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  69%|████▏ | 513/744 [32:48<14:46,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74695.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  69%|████▏ | 514/744 [32:52<14:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74266.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  69%|████▏ | 515/744 [32:56<14:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69967.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  69%|████▏ | 516/744 [33:00<14:35,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74746.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  69%|████▏ | 517/744 [33:04<14:31,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68537.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  70%|████▏ | 518/744 [33:08<14:27,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76841.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  70%|████▏ | 519/744 [33:12<14:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81546.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  70%|████▏ | 520/744 [33:16<14:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74382.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  70%|████▏ | 521/744 [33:20<14:16,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74176.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  70%|████▏ | 522/744 [33:24<14:12,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67694.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  70%|████▏ | 523/744 [33:28<14:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74809.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  70%|████▏ | 524/744 [33:32<14:04,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80455.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  71%|████▏ | 525/744 [33:36<14:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71076.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  71%|████▏ | 526/744 [33:39<13:57,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74056.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  71%|████▎ | 527/744 [33:43<13:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(55073.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  71%|████▎ | 528/744 [33:47<13:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65399.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  71%|████▎ | 529/744 [33:51<13:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70137.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  71%|████▎ | 530/744 [33:55<13:41,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76558.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  71%|████▎ | 531/744 [33:59<13:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78022.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  72%|████▎ | 532/744 [34:03<13:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79674.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  72%|████▎ | 533/744 [34:07<13:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75730.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  72%|████▎ | 534/744 [34:11<13:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82091.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  72%|████▎ | 535/744 [34:14<13:22,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72444.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  72%|████▎ | 536/744 [34:18<13:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74946.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  72%|████▎ | 537/744 [34:22<13:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77824.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  72%|████▎ | 538/744 [34:25<13:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78521.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  72%|████▎ | 539/744 [34:29<13:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74179.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  73%|████▎ | 540/744 [34:33<13:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81416.0156, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  73%|████▎ | 541/744 [34:37<12:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82228.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  73%|████▎ | 542/744 [34:40<12:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83891.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  73%|████▍ | 543/744 [34:44<12:51,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66720.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  73%|████▍ | 544/744 [34:48<12:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77633.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  73%|████▍ | 545/744 [34:52<12:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85362.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  73%|████▍ | 546/744 [34:56<12:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68326.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  74%|████▍ | 547/744 [35:00<12:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78990.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  74%|████▍ | 548/744 [35:03<12:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79403.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  74%|████▍ | 549/744 [35:07<12:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71014.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  74%|████▍ | 550/744 [35:11<12:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76807.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  74%|████▍ | 551/744 [35:15<12:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72969.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  74%|████▍ | 552/744 [35:19<12:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80555.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  74%|████▍ | 553/744 [35:22<12:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73056.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  74%|████▍ | 554/744 [35:26<12:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82629.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  75%|████▍ | 555/744 [35:30<12:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77967.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  75%|████▍ | 556/744 [35:34<12:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72834.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  75%|████▍ | 557/744 [35:38<11:57,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76424.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  75%|████▌ | 558/744 [35:41<11:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71646.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  75%|████▌ | 559/744 [35:45<11:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(59875.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  75%|████▌ | 560/744 [35:49<11:46,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82925.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  75%|████▌ | 561/744 [35:53<11:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74687.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  76%|████▌ | 562/744 [35:57<11:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70331.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  76%|████▌ | 563/744 [36:01<11:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77348.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  76%|████▌ | 564/744 [36:05<11:31,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62890.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  76%|████▌ | 565/744 [36:09<11:27,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77679.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  76%|████▌ | 566/744 [36:13<11:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76470.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  76%|████▌ | 567/744 [36:17<11:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71733.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  76%|████▌ | 568/744 [36:20<11:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71301.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  76%|████▌ | 569/744 [36:24<11:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66780.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  77%|████▌ | 570/744 [36:28<11:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70713.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  77%|████▌ | 571/744 [36:31<11:04,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74381.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  77%|████▌ | 572/744 [36:35<11:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79844.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  77%|████▌ | 573/744 [36:38<10:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73075.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  77%|████▋ | 574/744 [36:42<10:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72124.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  77%|████▋ | 575/744 [36:46<10:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68279.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  77%|████▋ | 576/744 [36:50<10:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78597.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  78%|████▋ | 577/744 [36:54<10:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86057.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  78%|████▋ | 578/744 [36:58<10:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76837., device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  78%|████▋ | 579/744 [37:01<10:33,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73099.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  78%|████▋ | 580/744 [37:05<10:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69430.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  78%|████▋ | 581/744 [37:09<10:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80324.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9070, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  78%|████▋ | 582/744 [37:13<10:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70457.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  78%|████▋ | 583/744 [37:16<10:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77408.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  78%|████▋ | 584/744 [37:20<10:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79088.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  79%|████▋ | 585/744 [37:24<10:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79736.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  79%|████▋ | 586/744 [37:28<10:06,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78600.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  79%|████▋ | 587/744 [37:32<10:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80312.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  79%|████▋ | 588/744 [37:36<09:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71948.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  79%|████▊ | 589/744 [37:40<09:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78837.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  79%|████▊ | 590/744 [37:43<09:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77313.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  79%|████▊ | 591/744 [37:48<09:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81941.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  80%|████▊ | 592/744 [37:53<09:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73062.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  80%|████▊ | 593/744 [37:56<09:39,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78245.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  80%|████▊ | 594/744 [38:00<09:35,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78261.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  80%|████▊ | 595/744 [38:04<09:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69790.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  80%|████▊ | 596/744 [38:08<09:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72217.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  80%|████▊ | 597/744 [38:12<09:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71633.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  80%|████▊ | 598/744 [38:15<09:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76003.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  81%|████▊ | 599/744 [38:19<09:16,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74311.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  81%|████▊ | 600/744 [38:23<09:12,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70580.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  81%|████▊ | 601/744 [38:27<09:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79840.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  81%|████▊ | 602/744 [38:31<09:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76566.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  81%|████▊ | 603/744 [38:34<09:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78548.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  81%|████▊ | 604/744 [38:38<08:57,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(63949.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  81%|████▉ | 605/744 [38:42<08:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72674.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  81%|████▉ | 606/744 [38:46<08:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78071.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  82%|████▉ | 607/744 [38:50<08:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78009.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  82%|████▉ | 608/744 [38:54<08:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83753.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  82%|████▉ | 609/744 [38:58<08:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75310.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  82%|████▉ | 610/744 [39:02<08:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76344.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  82%|████▉ | 611/744 [39:05<08:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72428.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  82%|████▉ | 612/744 [39:09<08:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77381.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  82%|████▉ | 613/744 [39:13<08:22,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76834.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  83%|████▉ | 614/744 [39:17<08:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77791.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  83%|████▉ | 615/744 [39:21<08:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75898.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  83%|████▉ | 616/744 [39:24<08:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76374.5391, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  83%|████▉ | 617/744 [39:28<08:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75008.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  83%|████▉ | 618/744 [39:32<08:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76550.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  83%|████▉ | 619/744 [39:36<07:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71462.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  83%|█████ | 620/744 [39:40<07:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73147.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  83%|█████ | 621/744 [39:44<07:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72044.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  84%|█████ | 622/744 [39:48<07:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75735.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  84%|█████ | 623/744 [39:56<07:45,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79719.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  84%|█████ | 624/744 [40:00<07:41,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74520.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  84%|█████ | 625/744 [40:03<07:37,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73767.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  84%|█████ | 626/744 [40:07<07:33,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78776.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  84%|█████ | 627/744 [40:11<07:29,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69888.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  84%|█████ | 628/744 [40:14<07:26,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68814.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  85%|█████ | 629/744 [40:18<07:22,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74141.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  85%|█████ | 630/744 [40:22<07:18,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79194.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  85%|█████ | 631/744 [40:26<07:14,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73337.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  85%|█████ | 632/744 [40:30<07:10,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77665.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  85%|█████ | 633/744 [40:34<07:06,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80807.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  85%|█████ | 634/744 [40:38<07:03,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75223., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  85%|█████ | 635/744 [40:42<06:59,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77875.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  85%|█████▏| 636/744 [40:46<06:55,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78888.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  86%|█████▏| 637/744 [40:50<06:51,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76471.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  86%|█████▏| 638/744 [40:53<06:47,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66467.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  86%|█████▏| 639/744 [40:57<06:43,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87364.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  86%|█████▏| 640/744 [41:01<06:40,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83195.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  86%|█████▏| 641/744 [41:05<06:36,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74741.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  86%|█████▏| 642/744 [41:09<06:32,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75119.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  86%|█████▏| 643/744 [41:13<06:28,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74632.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  87%|█████▏| 644/744 [41:16<06:24,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73309.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  87%|█████▏| 645/744 [41:20<06:20,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78629.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  87%|█████▏| 646/744 [41:24<06:16,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76300.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  87%|█████▏| 647/744 [41:28<06:13,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77457.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  87%|█████▏| 648/744 [41:32<06:09,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73227.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  87%|█████▏| 649/744 [41:36<06:05,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71643.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  87%|█████▏| 650/744 [41:39<06:01,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75586.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  88%|█████▎| 651/744 [41:43<05:57,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77604.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  88%|█████▎| 652/744 [41:47<05:53,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79414.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  88%|█████▎| 653/744 [41:51<05:50,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83869.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  88%|█████▎| 654/744 [41:55<05:46,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78708.5469, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  88%|█████▎| 655/744 [41:58<05:42,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76565.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  88%|█████▎| 656/744 [42:02<05:38,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76303.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  88%|█████▎| 657/744 [42:06<05:34,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79228.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  88%|█████▎| 658/744 [42:10<05:30,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76664.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  89%|█████▎| 659/744 [42:14<05:26,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74294.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  89%|█████▎| 660/744 [42:18<05:23,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81430.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  89%|█████▎| 661/744 [42:21<05:19,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76962.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  89%|█████▎| 662/744 [42:25<05:15,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78236.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  89%|█████▎| 663/744 [42:28<05:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81870.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  89%|█████▎| 664/744 [42:32<05:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79500.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  89%|█████▎| 665/744 [42:36<05:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76648.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  90%|█████▎| 666/744 [42:40<04:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81779.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  90%|█████▍| 667/744 [42:44<04:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78702.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9643, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  90%|█████▍| 668/744 [42:47<04:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72861.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  90%|█████▍| 669/744 [42:51<04:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71502.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  90%|█████▍| 670/744 [42:55<04:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81358.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  90%|█████▍| 671/744 [42:58<04:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73762.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  90%|█████▍| 672/744 [43:02<04:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74063.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  90%|█████▍| 673/744 [43:06<04:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77660.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  91%|█████▍| 674/744 [43:10<04:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81010.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  91%|█████▍| 675/744 [43:13<04:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79213.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  91%|█████▍| 676/744 [43:17<04:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83443.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  91%|█████▍| 677/744 [43:21<04:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80973.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  91%|█████▍| 678/744 [43:25<04:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79951.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  91%|█████▍| 679/744 [43:29<04:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80890.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  91%|█████▍| 680/744 [43:32<04:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71291.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  92%|█████▍| 681/744 [43:41<04:02,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79818.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  92%|█████▌| 682/744 [43:44<03:58,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84434.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  92%|█████▌| 683/744 [43:48<03:54,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88879.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  92%|█████▌| 684/744 [43:52<03:50,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80316.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  92%|█████▌| 685/744 [43:56<03:47,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80821., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  92%|█████▌| 686/744 [44:00<03:43,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73169.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  92%|█████▌| 687/744 [44:03<03:39,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88780.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  92%|█████▌| 688/744 [44:07<03:35,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71230.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  93%|█████▌| 689/744 [44:12<03:31,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75354.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  93%|█████▌| 690/744 [44:15<03:27,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73622.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  93%|█████▌| 691/744 [44:19<03:24,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73116.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  93%|█████▌| 692/744 [44:23<03:20,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70752.3125, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  93%|█████▌| 693/744 [44:27<03:16,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78050.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  93%|█████▌| 694/744 [44:31<03:12,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70166.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  93%|█████▌| 695/744 [44:35<03:08,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73765.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  94%|█████▌| 696/744 [44:38<03:04,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80529.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  94%|█████▌| 697/744 [44:43<03:00,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79001.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  94%|█████▋| 698/744 [44:47<02:57,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73533.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  94%|█████▋| 699/744 [44:50<02:53,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71739.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  94%|█████▋| 700/744 [44:54<02:49,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78795.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  94%|█████▋| 701/744 [44:58<02:45,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73280.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  94%|█████▋| 702/744 [45:02<02:41,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68635.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  94%|█████▋| 703/744 [45:05<02:37,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79058.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  95%|█████▋| 704/744 [45:09<02:33,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73218.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  95%|█████▋| 705/744 [45:13<02:30,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76118.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  95%|█████▋| 706/744 [45:16<02:26,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75718.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  95%|█████▋| 707/744 [45:20<02:22,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71253.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  95%|█████▋| 708/744 [45:24<02:18,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72420.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  95%|█████▋| 709/744 [45:28<02:14,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80674.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  95%|█████▋| 710/744 [45:32<02:10,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82396.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  96%|█████▋| 711/744 [45:35<02:06,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77052.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  96%|█████▋| 712/744 [45:39<02:03,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69361.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  96%|█████▊| 713/744 [45:43<01:59,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75746.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  96%|█████▊| 714/744 [45:47<01:55,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80099.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  96%|█████▊| 715/744 [45:51<01:51,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72585.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  96%|█████▊| 716/744 [45:55<01:47,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73763.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  96%|█████▊| 717/744 [45:58<01:43,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81098.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  97%|█████▊| 718/744 [46:02<01:40,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82925.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  97%|█████▊| 719/744 [46:06<01:36,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75217.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  97%|█████▊| 720/744 [46:10<01:32,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70427.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  97%|█████▊| 721/744 [46:14<01:28,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76015.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  97%|█████▊| 722/744 [46:18<01:24,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73700.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  97%|█████▊| 723/744 [46:22<01:20,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73996.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  97%|█████▊| 724/744 [46:25<01:16,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84377.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  97%|█████▊| 725/744 [46:29<01:13,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66675.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  98%|█████▊| 726/744 [46:33<01:09,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81166.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  98%|█████▊| 727/744 [46:37<01:05,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70891.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  98%|█████▊| 728/744 [46:40<01:01,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71380.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  98%|█████▉| 729/744 [46:44<00:57,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77524., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  98%|█████▉| 730/744 [46:48<00:53,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74641.1641, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  98%|█████▉| 731/744 [46:51<00:50,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76350.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  98%|█████▉| 732/744 [46:55<00:46,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81441.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  99%|█████▉| 733/744 [46:59<00:42,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72596.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  99%|█████▉| 734/744 [47:03<00:38,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80720.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  99%|█████▉| 735/744 [47:07<00:34,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76446.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  99%|█████▉| 736/744 [47:11<00:30,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73733.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  99%|█████▉| 737/744 [47:14<00:26,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84471.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  99%|█████▉| 738/744 [47:18<00:23,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83174.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  99%|█████▉| 739/744 [47:22<00:19,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73968.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11:  99%|█████▉| 740/744 [47:26<00:15,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76329.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11: 100%|█████▉| 741/744 [47:29<00:11,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65418.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11: 100%|█████▉| 742/744 [47:33<00:07,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75434.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11: 100%|█████▉| 743/744 [47:36<00:03,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72413.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   0%|                | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(74846.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   0%|      | 1/744 [00:05<1:03:48,  5.15s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80302.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   0%|        | 2/744 [00:09<56:21,  4.56s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76609.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   0%|        | 3/744 [00:13<54:10,  4.39s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65712.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   1%|        | 4/744 [00:17<52:25,  4.25s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74320.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   1%|        | 5/744 [00:20<51:15,  4.16s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76430.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   1%|        | 6/744 [00:24<50:21,  4.09s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73220.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   1%|        | 7/744 [00:28<49:30,  4.03s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65523.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   1%|        | 8/744 [00:31<48:49,  3.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75511.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   1%|        | 9/744 [00:35<48:26,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81018.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   1%|       | 10/744 [00:39<48:01,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68583.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   1%|       | 11/744 [00:42<47:35,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82751.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   2%|       | 12/744 [00:46<47:22,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77685.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   2%|       | 13/744 [00:50<47:10,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84516.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   2%|▏      | 14/744 [00:54<46:56,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83924.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   2%|▏      | 15/744 [00:57<46:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71239.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   2%|▏      | 16/744 [01:01<46:23,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85076.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   2%|▏      | 17/744 [01:05<46:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70365.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   2%|▏      | 18/744 [01:08<46:13,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73193.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   3%|▏      | 19/744 [01:12<45:59,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77620.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   3%|▏      | 20/744 [01:16<45:51,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73726.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   3%|▏      | 21/744 [01:19<45:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82636.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   3%|▏      | 22/744 [01:23<45:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75158.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   3%|▏      | 23/744 [01:27<45:43,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80199.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   3%|▏      | 24/744 [01:31<45:36,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82741.4219, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   3%|▏      | 25/744 [01:34<45:30,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76412.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9148, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   3%|▏      | 26/744 [01:38<45:30,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77441.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   4%|▎      | 27/744 [01:42<45:30,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84315.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   4%|▎      | 28/744 [01:46<45:22,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75991.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   4%|▎      | 29/744 [01:50<45:20,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78738.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   4%|▎      | 30/744 [01:54<45:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75469.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   4%|▎      | 31/744 [01:57<45:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72447.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   4%|▎      | 32/744 [02:01<45:08,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71051.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   4%|▎      | 33/744 [02:05<45:01,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83903.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8601, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   5%|▎      | 34/744 [02:09<44:55,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69139.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   5%|▎      | 35/744 [02:12<44:48,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69730.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   5%|▎      | 36/744 [02:16<44:46,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78098.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   5%|▎      | 37/744 [02:20<44:42,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72965., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   5%|▎      | 38/744 [02:24<44:36,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73213.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   5%|▎      | 39/744 [02:27<44:34,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77557.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   5%|▍      | 40/744 [02:32<44:41,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80759.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   6%|▍      | 41/744 [02:36<44:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70474.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   6%|▍      | 42/744 [02:40<44:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74408.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   6%|▍      | 43/744 [02:43<44:29,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76562.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   6%|▍      | 44/744 [02:47<44:26,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74446.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   6%|▍      | 45/744 [02:51<44:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76398.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   6%|▍      | 46/744 [02:55<44:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79410.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   6%|▍      | 47/744 [02:58<44:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86217.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   6%|▍      | 48/744 [03:02<44:07,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75552.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   7%|▍      | 49/744 [03:06<44:04,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71670.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   7%|▍      | 50/744 [03:10<44:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74392.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   7%|▍      | 51/744 [03:14<44:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79451.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   7%|▍      | 52/744 [03:18<43:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82037.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   7%|▍      | 53/744 [03:22<43:55,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81917.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   7%|▌      | 54/744 [03:25<43:51,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85154.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   7%|▌      | 55/744 [03:29<43:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81701.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   8%|▌      | 56/744 [03:33<43:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81360.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   8%|▌      | 57/744 [03:37<43:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71162.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   8%|▌      | 58/744 [03:41<43:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73500.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   8%|▌      | 59/744 [03:44<43:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78908.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   8%|▌      | 60/744 [03:48<43:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80317.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   8%|▌      | 61/744 [03:52<43:22,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81898.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   8%|▌      | 62/744 [03:56<43:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81831.5469, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(1.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   8%|▌      | 63/744 [04:00<43:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70769.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   9%|▌      | 64/744 [04:03<43:10,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85646.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   9%|▌      | 65/744 [04:07<43:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81273.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   9%|▌      | 66/744 [04:11<43:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74543.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   9%|▋      | 67/744 [04:15<42:59,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81585.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   9%|▋      | 68/744 [04:19<42:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87345.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   9%|▋      | 69/744 [04:22<42:51,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75318.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:   9%|▋      | 70/744 [04:26<42:46,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77587.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  10%|▋      | 71/744 [04:30<42:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78763.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  10%|▋      | 72/744 [04:34<42:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75760.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  10%|▋      | 73/744 [04:37<42:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71830.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  10%|▋      | 74/744 [04:41<42:29,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76280.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  10%|▋      | 75/744 [04:45<42:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75124.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  10%|▋      | 76/744 [04:49<42:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71979.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  10%|▋      | 77/744 [04:53<42:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79003.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  10%|▋      | 78/744 [04:56<42:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73512.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  11%|▋      | 79/744 [05:00<42:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72618.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  11%|▊      | 80/744 [05:04<42:11,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74434.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  11%|▊      | 81/744 [05:08<42:07,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81257.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  11%|▊      | 82/744 [05:12<42:02,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70674.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  11%|▊      | 83/744 [05:16<41:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79983.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  11%|▊      | 84/744 [05:19<41:51,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81066.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  11%|▊      | 85/744 [05:23<41:48,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81305.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  12%|▊      | 86/744 [05:27<41:43,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79005.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  12%|▊      | 87/744 [05:31<41:41,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64824.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  12%|▊      | 88/744 [05:35<41:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73813.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  12%|▊      | 89/744 [05:38<41:32,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69549.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  12%|▊      | 90/744 [05:42<41:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74046.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  12%|▊      | 91/744 [05:46<41:24,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79057.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  12%|▊      | 92/744 [05:50<41:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75477.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  12%|▉      | 93/744 [05:54<41:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79789.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  13%|▉      | 94/744 [05:57<41:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80240.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  13%|▉      | 95/744 [06:02<41:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83421.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  13%|▉      | 96/744 [06:06<41:10,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75041.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9769, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  13%|▉      | 97/744 [06:09<41:07,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82151.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  13%|▉      | 98/744 [06:13<41:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77697.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  13%|▉      | 99/744 [06:17<40:59,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75665.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  13%|▊     | 100/744 [06:21<40:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82878.8125, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  14%|▊     | 101/744 [06:24<40:49,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80830.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  14%|▊     | 102/744 [06:28<40:46,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77306.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  14%|▊     | 103/744 [06:32<40:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77594.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  14%|▊     | 104/744 [06:36<40:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75272.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  14%|▊     | 105/744 [06:40<40:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77830.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  14%|▊     | 106/744 [06:43<40:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74644.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  14%|▊     | 107/744 [06:47<40:26,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77115.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  15%|▊     | 108/744 [06:51<40:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76545.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  15%|▉     | 109/744 [06:55<40:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80496.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  15%|▉     | 110/744 [06:59<40:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78457.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  15%|▉     | 111/744 [07:03<40:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71870.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  15%|▉     | 112/744 [07:06<40:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76619.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  15%|▉     | 113/744 [07:10<40:06,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75067.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  15%|▉     | 114/744 [07:14<40:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78257.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  15%|▉     | 115/744 [07:18<40:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81653.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  16%|▉     | 116/744 [07:23<39:58,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76960.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  16%|▉     | 117/744 [07:26<39:54,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73626.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  16%|▉     | 118/744 [07:30<39:51,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78689.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0807, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  16%|▉     | 119/744 [07:34<39:47,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80155.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  16%|▉     | 120/744 [07:38<39:43,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78086.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  16%|▉     | 121/744 [07:42<39:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73243.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  16%|▉     | 122/744 [07:46<39:36,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80889.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  17%|▉     | 123/744 [07:50<39:33,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74288.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  17%|█     | 124/744 [07:54<39:30,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72724.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  17%|█     | 125/744 [07:58<39:27,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75959.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  17%|█     | 126/744 [08:01<39:23,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78309.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  17%|█     | 127/744 [08:05<39:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76593.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  17%|█     | 128/744 [08:09<39:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75977.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  17%|█     | 129/744 [08:13<39:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84128.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  17%|█     | 130/744 [08:17<39:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76345., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  18%|█     | 131/744 [08:21<39:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86640.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  18%|█     | 132/744 [08:25<39:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84640.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  18%|█     | 133/744 [08:29<38:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70400., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  18%|█     | 134/744 [08:32<38:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80766., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  18%|█     | 135/744 [08:36<38:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78655.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  18%|█     | 136/744 [08:40<38:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75217.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  18%|█     | 137/744 [08:44<38:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77363.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  19%|█     | 138/744 [08:48<38:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80631.4688, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  19%|█     | 139/744 [08:51<38:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83797.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  19%|█▏    | 140/744 [08:55<38:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82918.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  19%|█▏    | 141/744 [08:59<38:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79613.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  19%|█▏    | 142/744 [09:03<38:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73887.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  19%|█▏    | 143/744 [09:07<38:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79455.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  19%|█▏    | 144/744 [09:10<38:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72513.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  19%|█▏    | 145/744 [09:14<38:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70871.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  20%|█▏    | 146/744 [09:18<38:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87064.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  20%|█▏    | 147/744 [09:22<38:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73357.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  20%|█▏    | 148/744 [09:25<37:59,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76415.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  20%|█▏    | 149/744 [09:30<37:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75496.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  20%|█▏    | 150/744 [09:33<37:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66496.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  20%|█▏    | 151/744 [09:37<37:48,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80443.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  20%|█▏    | 152/744 [09:41<37:43,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84464.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8999, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  21%|█▏    | 153/744 [09:44<37:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75151.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  21%|█▏    | 154/744 [09:48<37:36,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73903.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  21%|█▎    | 155/744 [09:52<37:32,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86078.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  21%|█▎    | 156/744 [09:56<37:28,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77679.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  21%|█▎    | 157/744 [10:00<37:24,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75024.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  21%|█▎    | 158/744 [10:04<37:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70852.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  21%|█▎    | 159/744 [10:08<37:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73948.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  22%|█▎    | 160/744 [10:12<37:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67060.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  22%|█▎    | 161/744 [10:16<37:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75812.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  22%|█▎    | 162/744 [10:20<37:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71372.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  22%|█▎    | 163/744 [10:24<37:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70864.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  22%|█▎    | 164/744 [10:28<37:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70398.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  22%|█▎    | 165/744 [10:31<36:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58458.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  22%|█▎    | 166/744 [10:35<36:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77793.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  22%|█▎    | 167/744 [10:39<36:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84155.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  23%|█▎    | 168/744 [10:43<36:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81167.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  23%|█▎    | 169/744 [10:47<36:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71594.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  23%|█▎    | 170/744 [10:51<36:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77497.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  23%|█▍    | 171/744 [10:54<36:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76751.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  23%|█▍    | 172/744 [10:58<36:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82168.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  23%|█▍    | 173/744 [11:02<36:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82513.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  23%|█▍    | 174/744 [11:06<36:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77732.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9756, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  24%|█▍    | 175/744 [11:10<36:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71372.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  24%|█▍    | 176/744 [11:14<36:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74955.2344, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(1.0378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  24%|█▍    | 177/744 [11:18<36:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75703.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  24%|█▍    | 178/744 [11:22<36:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85851.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  24%|█▍    | 179/744 [11:26<36:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79377.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  24%|█▍    | 180/744 [11:30<36:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84892.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  24%|█▍    | 181/744 [11:33<35:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71229.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  24%|█▍    | 182/744 [11:37<35:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80729.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  25%|█▍    | 183/744 [11:41<35:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72178.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  25%|█▍    | 184/744 [11:45<35:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83211.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  25%|█▍    | 185/744 [11:49<35:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80225.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  25%|█▌    | 186/744 [11:52<35:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77302.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  25%|█▌    | 187/744 [11:56<35:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76828.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9715, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  25%|█▌    | 188/744 [12:00<35:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88104.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  25%|█▌    | 189/744 [12:04<35:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82941.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  26%|█▌    | 190/744 [12:08<35:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77874.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  26%|█▌    | 191/744 [12:12<35:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72619.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  26%|█▌    | 192/744 [12:15<35:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80220.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  26%|█▌    | 193/744 [12:19<35:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74331.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  26%|█▌    | 194/744 [12:23<35:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87418.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  26%|█▌    | 195/744 [12:27<35:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87698.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  26%|█▌    | 196/744 [12:31<35:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78594.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  26%|█▌    | 197/744 [12:35<34:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75300.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7958, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  27%|█▌    | 198/744 [12:38<34:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83861.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  27%|█▌    | 199/744 [12:42<34:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69732.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  27%|█▌    | 200/744 [12:46<34:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75994.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  27%|█▌    | 201/744 [12:50<34:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76016.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  27%|█▋    | 202/744 [12:54<34:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84439.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  27%|█▋    | 203/744 [12:58<34:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73536.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  27%|█▋    | 204/744 [13:02<34:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69848.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  28%|█▋    | 205/744 [13:05<34:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83044.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  28%|█▋    | 206/744 [13:09<34:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71412.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  28%|█▋    | 207/744 [13:13<34:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82480.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  28%|█▋    | 208/744 [13:17<34:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77849.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  28%|█▋    | 209/744 [13:21<34:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80831.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  28%|█▋    | 210/744 [13:25<34:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73847.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  28%|█▋    | 211/744 [13:28<34:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86314.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  28%|█▋    | 212/744 [13:32<33:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79517.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  29%|█▋    | 213/744 [13:36<33:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75940.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  29%|█▋    | 214/744 [13:40<33:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68903.7109, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  29%|█▋    | 215/744 [13:44<33:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77778.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  29%|█▋    | 216/744 [13:48<33:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78003.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  29%|█▊    | 217/744 [13:52<33:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(62035.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  29%|█▊    | 218/744 [13:56<33:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81429.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  29%|█▊    | 219/744 [14:00<33:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78316.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  30%|█▊    | 220/744 [14:04<33:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84453.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  30%|█▊    | 221/744 [14:07<33:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78832.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  30%|█▊    | 222/744 [14:12<33:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82632.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  30%|█▊    | 223/744 [14:16<33:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76981.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  30%|█▊    | 224/744 [14:19<33:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78833.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  30%|█▊    | 225/744 [14:23<33:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76038.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  30%|█▊    | 226/744 [14:27<33:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79555.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  31%|█▊    | 227/744 [14:31<33:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81716.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  31%|█▊    | 228/744 [14:35<33:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77314.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8756, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  31%|█▊    | 229/744 [14:39<32:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70148.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  31%|█▊    | 230/744 [14:43<32:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74867.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  31%|█▊    | 231/744 [14:47<32:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78791.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  31%|█▊    | 232/744 [14:51<32:46,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81695.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  31%|█▉    | 233/744 [14:54<32:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85443.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  31%|█▉    | 234/744 [14:58<32:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78635.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  32%|█▉    | 235/744 [15:02<32:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74316.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  32%|█▉    | 236/744 [15:06<32:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83017.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  32%|█▉    | 237/744 [15:10<32:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80316.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  32%|█▉    | 238/744 [15:14<32:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78792.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  32%|█▉    | 239/744 [15:17<32:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71806.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  32%|█▉    | 240/744 [15:21<32:16,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82376.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  32%|█▉    | 241/744 [15:25<32:12,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74957.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  33%|█▉    | 242/744 [15:29<32:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73311.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  33%|█▉    | 243/744 [15:33<32:04,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79242.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  33%|█▉    | 244/744 [15:37<32:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93679.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  33%|█▉    | 245/744 [15:41<31:57,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84350.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  33%|█▉    | 246/744 [15:45<31:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78053.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  33%|█▉    | 247/744 [15:49<31:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80392.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  33%|██    | 248/744 [15:52<31:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74244.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  33%|██    | 249/744 [15:56<31:41,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77181.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  34%|██    | 250/744 [16:00<31:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(65451.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  34%|██    | 251/744 [16:04<31:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86427.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  34%|██    | 252/744 [16:08<31:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82010.5000, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  34%|██    | 253/744 [16:12<31:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80731.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  34%|██    | 254/744 [16:16<31:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72340.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  34%|██    | 255/744 [16:20<31:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70853.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  34%|██    | 256/744 [16:23<31:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77606.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  35%|██    | 257/744 [16:27<31:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76260.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  35%|██    | 258/744 [16:31<31:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76006.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  35%|██    | 259/744 [16:35<31:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76380.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  35%|██    | 260/744 [16:38<30:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82112.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  35%|██    | 261/744 [16:42<30:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79804.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  35%|██    | 262/744 [16:46<30:51,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85988.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  35%|██    | 263/744 [16:50<30:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82688.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  35%|██▏   | 264/744 [16:54<30:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70578.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  36%|██▏   | 265/744 [16:58<30:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71413.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  36%|██▏   | 266/744 [17:02<30:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78659.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  36%|██▏   | 267/744 [17:05<30:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84576.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  36%|██▏   | 268/744 [17:09<30:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82021.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  36%|██▏   | 269/744 [17:13<30:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78350.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  36%|██▏   | 270/744 [17:17<30:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72314.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  36%|██▏   | 271/744 [17:21<30:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78252.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  37%|██▏   | 272/744 [17:25<30:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85502.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  37%|██▏   | 273/744 [17:29<30:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82032.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  37%|██▏   | 274/744 [17:32<30:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75650.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  37%|██▏   | 275/744 [17:36<30:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70890.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  37%|██▏   | 276/744 [17:40<29:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78586.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  37%|██▏   | 277/744 [17:44<29:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79614.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  37%|██▏   | 278/744 [17:47<29:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76662.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  38%|██▎   | 279/744 [17:51<29:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77266.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  38%|██▎   | 280/744 [17:55<29:41,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80380.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  38%|██▎   | 281/744 [17:59<29:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79078.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  38%|██▎   | 282/744 [18:03<29:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84520.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  38%|██▎   | 283/744 [18:07<29:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71073.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  38%|██▎   | 284/744 [18:10<29:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73953.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  38%|██▎   | 285/744 [18:14<29:22,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78793.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  38%|██▎   | 286/744 [18:18<29:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77440.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  39%|██▎   | 287/744 [18:22<29:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71806.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  39%|██▎   | 288/744 [18:26<29:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80265.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  39%|██▎   | 289/744 [18:30<29:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81549.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  39%|██▎   | 290/744 [18:33<29:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74560.6641, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  39%|██▎   | 291/744 [18:37<29:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71863.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  39%|██▎   | 292/744 [18:41<28:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82186.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  39%|██▎   | 293/744 [18:45<28:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78602.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  40%|██▎   | 294/744 [18:49<28:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89321.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  40%|██▍   | 295/744 [18:53<28:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78474.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  40%|██▍   | 296/744 [18:57<28:41,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(68717.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  40%|██▍   | 297/744 [19:01<28:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76891.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  40%|██▍   | 298/744 [19:05<28:33,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76329.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  40%|██▍   | 299/744 [19:09<28:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75549.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  40%|██▍   | 300/744 [19:12<28:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82926.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  40%|██▍   | 301/744 [19:16<28:22,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75411.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  41%|██▍   | 302/744 [19:20<28:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67284.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9213, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  41%|██▍   | 303/744 [19:24<28:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88313.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8694, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  41%|██▍   | 304/744 [19:28<28:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75253.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  41%|██▍   | 305/744 [19:32<28:06,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64656.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  41%|██▍   | 306/744 [19:35<28:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71803.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  41%|██▍   | 307/744 [19:39<27:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76833.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  41%|██▍   | 308/744 [19:43<27:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81442.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  42%|██▍   | 309/744 [19:47<27:51,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80326.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  42%|██▌   | 310/744 [19:51<27:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75983.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  42%|██▌   | 311/744 [19:54<27:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84775.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  42%|██▌   | 312/744 [19:59<27:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80783.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  42%|██▌   | 313/744 [20:03<27:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74638.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  42%|██▌   | 314/744 [20:06<27:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76476.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  42%|██▌   | 315/744 [20:10<27:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70983.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  42%|██▌   | 316/744 [20:14<27:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81078.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  43%|██▌   | 317/744 [20:18<27:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79963.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9203, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  43%|██▌   | 318/744 [20:22<27:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86296.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  43%|██▌   | 319/744 [20:26<27:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71474.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  43%|██▌   | 320/744 [20:30<27:10,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76926.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  43%|██▌   | 321/744 [20:34<27:06,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78236.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  43%|██▌   | 322/744 [20:38<27:02,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84742.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  43%|██▌   | 323/744 [20:42<26:59,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78591.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  44%|██▌   | 324/744 [20:46<26:55,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77956.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  44%|██▌   | 325/744 [20:49<26:51,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82200.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  44%|██▋   | 326/744 [20:53<26:47,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80791.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  44%|██▋   | 327/744 [20:57<26:43,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77115.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  44%|██▋   | 328/744 [21:01<26:39,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79627.6250, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  44%|██▋   | 329/744 [21:05<26:36,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86168.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  44%|██▋   | 330/744 [21:09<26:32,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84714.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  44%|██▋   | 331/744 [21:12<26:28,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73838.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  45%|██▋   | 332/744 [21:16<26:24,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80707.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  45%|██▋   | 333/744 [21:20<26:20,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87358.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  45%|██▋   | 334/744 [21:24<26:16,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82034.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  45%|██▋   | 335/744 [21:28<26:12,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74152.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  45%|██▋   | 336/744 [21:32<26:09,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(70200.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  45%|██▋   | 337/744 [21:36<26:05,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76848.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  45%|██▋   | 338/744 [21:40<26:01,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83700.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  46%|██▋   | 339/744 [21:43<25:57,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84891.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  46%|██▋   | 340/744 [21:47<25:53,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75238.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  46%|██▊   | 341/744 [21:51<25:49,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86076.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  46%|██▊   | 342/744 [21:55<25:45,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72821.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  46%|██▊   | 343/744 [21:59<25:42,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77700.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  46%|██▊   | 344/744 [22:02<25:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87192.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  46%|██▊   | 345/744 [22:06<25:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76593.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  47%|██▊   | 346/744 [22:10<25:30,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80898.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  47%|██▊   | 347/744 [22:14<25:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80928.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  47%|██▊   | 348/744 [22:18<25:22,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75497.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  47%|██▊   | 349/744 [22:21<25:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77685.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  47%|██▊   | 350/744 [22:25<25:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81933.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  47%|██▊   | 351/744 [22:29<25:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77887.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  47%|██▊   | 352/744 [22:33<25:06,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80123.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  47%|██▊   | 353/744 [22:36<25:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73476.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  48%|██▊   | 354/744 [22:40<24:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81126.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  48%|██▊   | 355/744 [22:44<24:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81828.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  48%|██▊   | 356/744 [22:48<24:51,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79570.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  48%|██▉   | 357/744 [22:52<24:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83713.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  48%|██▉   | 358/744 [22:55<24:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75612.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  48%|██▉   | 359/744 [23:00<24:39,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77973.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  48%|██▉   | 360/744 [23:03<24:35,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71635.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  49%|██▉   | 361/744 [23:07<24:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76152.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  49%|██▉   | 362/744 [23:11<24:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77669.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  49%|██▉   | 363/744 [23:15<24:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(58933.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  49%|██▉   | 364/744 [23:19<24:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78672.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  49%|██▉   | 365/744 [23:23<24:16,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79773.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  49%|██▉   | 366/744 [23:27<24:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74830.8125, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  49%|██▉   | 367/744 [23:31<24:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85645.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  49%|██▉   | 368/744 [23:34<24:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80829.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  50%|██▉   | 369/744 [23:38<24:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81078.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  50%|██▉   | 370/744 [23:42<23:57,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71922.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  50%|██▉   | 371/744 [23:46<23:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87581.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  50%|███   | 372/744 [23:50<23:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64066.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  50%|███   | 373/744 [23:54<23:46,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72918.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  50%|███   | 374/744 [23:57<23:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82771.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  50%|███   | 375/744 [24:01<23:38,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85560.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  51%|███   | 376/744 [24:05<23:35,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77330.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  51%|███   | 377/744 [24:09<23:31,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75883.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  51%|███   | 378/744 [24:13<23:27,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85339.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  51%|███   | 379/744 [24:17<23:23,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82742.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  51%|███   | 380/744 [24:21<23:19,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77896.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  51%|███   | 381/744 [24:25<23:16,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75508.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  51%|███   | 382/744 [24:29<23:12,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79146.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  51%|███   | 383/744 [24:32<23:08,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83081.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  52%|███   | 384/744 [24:36<23:04,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87373.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  52%|███   | 385/744 [24:40<23:00,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78888.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  52%|███   | 386/744 [24:44<22:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76477.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  52%|███   | 387/744 [24:47<22:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83490., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  52%|███▏  | 388/744 [24:51<22:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80364.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  52%|███▏  | 389/744 [24:55<22:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82419.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  52%|███▏  | 390/744 [24:59<22:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78850.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  53%|███▏  | 391/744 [25:02<22:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82847.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  53%|███▏  | 392/744 [25:06<22:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(66662.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  53%|███▏  | 393/744 [25:10<22:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84364.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  53%|███▏  | 394/744 [25:14<22:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82612.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  53%|███▏  | 395/744 [25:18<22:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83163.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  53%|███▏  | 396/744 [25:22<22:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81898.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  53%|███▏  | 397/744 [25:26<22:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90022.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  53%|███▏  | 398/744 [25:30<22:10,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80482.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  54%|███▏  | 399/744 [25:34<22:06,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77003.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  54%|███▏  | 400/744 [25:38<22:02,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82245.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  54%|███▏  | 401/744 [25:42<21:59,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74217.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  54%|███▏  | 402/744 [25:46<21:55,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71844.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  54%|███▎  | 403/744 [25:50<21:51,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82851.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  54%|███▎  | 404/744 [25:53<21:47,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77178.0391, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  54%|███▎  | 405/744 [25:57<21:43,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85785.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  55%|███▎  | 406/744 [26:01<21:40,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74586.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  55%|███▎  | 407/744 [26:05<21:35,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79037.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  55%|███▎  | 408/744 [26:08<21:32,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82648.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  55%|███▎  | 409/744 [26:12<21:28,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79050.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  55%|███▎  | 410/744 [26:16<21:24,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74562.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  55%|███▎  | 411/744 [26:20<21:20,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77291.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  55%|███▎  | 412/744 [26:24<21:16,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76062.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  56%|███▎  | 413/744 [26:28<21:12,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73368.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  56%|███▎  | 414/744 [26:32<21:09,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85032.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  56%|███▎  | 415/744 [26:35<21:05,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74390.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  56%|███▎  | 416/744 [26:39<21:01,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84559.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  56%|███▎  | 417/744 [26:43<20:57,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72471.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  56%|███▎  | 418/744 [26:47<20:53,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80021.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  56%|███▍  | 419/744 [26:51<20:49,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82753.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  56%|███▍  | 420/744 [26:55<20:45,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82829.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  57%|███▍  | 421/744 [26:59<20:42,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80867.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  57%|███▍  | 422/744 [27:03<20:38,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84199.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  57%|███▍  | 423/744 [27:06<20:34,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79061.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8238, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  57%|███▍  | 424/744 [27:10<20:30,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83076.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  57%|███▍  | 425/744 [27:14<20:27,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77892.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  57%|███▍  | 426/744 [27:18<20:23,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81104.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  57%|███▍  | 427/744 [27:22<20:19,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86335.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  58%|███▍  | 428/744 [27:26<20:15,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84488.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  58%|███▍  | 429/744 [27:30<20:12,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74757.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  58%|███▍  | 430/744 [27:34<20:08,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78919.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  58%|███▍  | 431/744 [27:38<20:04,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79374.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  58%|███▍  | 432/744 [27:41<20:00,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83036.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  58%|███▍  | 433/744 [27:45<19:56,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78375.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  58%|███▌  | 434/744 [27:49<19:52,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83621.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  58%|███▌  | 435/744 [27:53<19:48,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74446.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  59%|███▌  | 436/744 [27:57<19:44,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80239.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  59%|███▌  | 437/744 [28:00<19:40,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80790.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  59%|███▌  | 438/744 [28:04<19:36,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82768.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  59%|███▌  | 439/744 [28:08<19:33,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72058.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  59%|███▌  | 440/744 [28:12<19:29,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76305.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  59%|███▌  | 441/744 [28:15<19:25,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89406.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  59%|███▌  | 442/744 [28:19<19:21,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86097.1484, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  60%|███▌  | 443/744 [28:23<19:17,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75333.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  60%|███▌  | 444/744 [28:27<19:13,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81791.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  60%|███▌  | 445/744 [28:31<19:09,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85034.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  60%|███▌  | 446/744 [28:35<19:06,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74914.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  60%|███▌  | 447/744 [28:39<19:02,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80547.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  60%|███▌  | 448/744 [28:43<18:58,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73922.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  60%|███▌  | 449/744 [28:47<18:54,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80020.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  60%|███▋  | 450/744 [28:50<18:50,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(64289.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  61%|███▋  | 451/744 [28:54<18:46,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79719.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  61%|███▋  | 452/744 [28:57<18:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79556.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  61%|███▋  | 453/744 [29:01<18:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80685.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  61%|███▋  | 454/744 [29:05<18:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73491.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  61%|███▋  | 455/744 [29:09<18:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80973.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  61%|███▋  | 456/744 [29:12<18:27,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82748.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  61%|███▋  | 457/744 [29:16<18:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76104.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  62%|███▋  | 458/744 [29:20<18:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77985.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  62%|███▋  | 459/744 [29:24<18:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74601.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  62%|███▋  | 460/744 [29:28<18:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84566.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  62%|███▋  | 461/744 [29:31<18:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79617.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7807, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  62%|███▋  | 462/744 [29:35<18:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87413.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  62%|███▋  | 463/744 [29:39<17:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79673.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  62%|███▋  | 464/744 [29:43<17:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76308.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  62%|███▊  | 465/744 [29:46<17:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85549.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  63%|███▊  | 466/744 [29:50<17:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81618.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  63%|███▊  | 467/744 [29:54<17:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81527.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  63%|███▊  | 468/744 [29:58<17:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67941.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  63%|███▊  | 469/744 [30:01<17:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85116.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  63%|███▊  | 470/744 [30:05<17:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79944.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  63%|███▊  | 471/744 [30:09<17:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77209.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  63%|███▊  | 472/744 [30:13<17:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76104.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  64%|███▊  | 473/744 [30:17<17:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77162.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  64%|███▊  | 474/744 [30:21<17:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74525.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  64%|███▊  | 475/744 [30:24<17:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80879.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  64%|███▊  | 476/744 [30:28<17:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82627.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  64%|███▊  | 477/744 [30:33<17:06,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81917.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  64%|███▊  | 478/744 [30:36<17:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81954.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  64%|███▊  | 479/744 [30:40<16:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85129.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  65%|███▊  | 480/744 [30:44<16:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86669.0469, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(1.0282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  65%|███▉  | 481/744 [30:48<16:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86206.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  65%|███▉  | 482/744 [30:52<16:46,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84088.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  65%|███▉  | 483/744 [30:56<16:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87287.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  65%|███▉  | 484/744 [30:59<16:39,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82862.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  65%|███▉  | 485/744 [31:03<16:35,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75144.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  65%|███▉  | 486/744 [31:07<16:31,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83907.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9774, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  65%|███▉  | 487/744 [31:11<16:27,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84383.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  66%|███▉  | 488/744 [31:14<16:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84423.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  66%|███▉  | 489/744 [31:18<16:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76861.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  66%|███▉  | 490/744 [31:22<16:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85020.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  66%|███▉  | 491/744 [31:26<16:12,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82887.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  66%|███▉  | 492/744 [31:30<16:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83664.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  66%|███▉  | 493/744 [31:34<16:04,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74680.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  66%|███▉  | 494/744 [31:37<16:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77514.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  67%|███▉  | 495/744 [31:41<15:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75295.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  67%|████  | 496/744 [31:45<15:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79882.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  67%|████  | 497/744 [31:49<15:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83966.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  67%|████  | 498/744 [31:53<15:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77196.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  67%|████  | 499/744 [31:57<15:41,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78763.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  67%|████  | 500/744 [32:01<15:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80740.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  67%|████  | 501/744 [32:05<15:33,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81427.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  67%|████  | 502/744 [32:09<15:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93659.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  68%|████  | 503/744 [32:13<15:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75371.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  68%|████  | 504/744 [32:16<15:22,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82253.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  68%|████  | 505/744 [32:20<15:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89046.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  68%|████  | 506/744 [32:24<15:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88813.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  68%|████  | 507/744 [32:28<15:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81916.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  68%|████  | 508/744 [32:31<15:06,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82926.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  68%|████  | 509/744 [32:35<15:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75765.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  69%|████  | 510/744 [32:39<14:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77775.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  69%|████  | 511/744 [32:43<14:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83452.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  69%|████▏ | 512/744 [32:47<14:51,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78798.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  69%|████▏ | 513/744 [32:51<14:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82925.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  69%|████▏ | 514/744 [32:55<14:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85825.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  69%|████▏ | 515/744 [32:59<14:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88055.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  69%|████▏ | 516/744 [33:03<14:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89421.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  69%|████▏ | 517/744 [33:06<14:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74374.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  70%|████▏ | 518/744 [33:10<14:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83210.8984, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  70%|████▏ | 519/744 [33:14<14:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83231.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  70%|████▏ | 520/744 [33:18<14:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73773.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  70%|████▏ | 521/744 [33:22<14:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83845.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  70%|████▏ | 522/744 [33:26<14:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81019.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  70%|████▏ | 523/744 [33:30<14:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81550.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  70%|████▏ | 524/744 [33:34<14:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79481.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  71%|████▏ | 525/744 [33:37<14:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88141.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  71%|████▏ | 526/744 [33:41<13:57,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(67956.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  71%|████▎ | 527/744 [33:45<13:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84350.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  71%|████▎ | 528/744 [33:49<13:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71836.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9601, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  71%|████▎ | 529/744 [33:52<13:46,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79444.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  71%|████▎ | 530/744 [33:56<13:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73055.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  71%|████▎ | 531/744 [34:00<13:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85529.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  72%|████▎ | 532/744 [34:04<13:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88931.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  72%|████▎ | 533/744 [34:08<13:31,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82047.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  72%|████▎ | 534/744 [34:12<13:27,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77559.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  72%|████▎ | 535/744 [34:16<13:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84356.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  72%|████▎ | 536/744 [34:19<13:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79349.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  72%|████▎ | 537/744 [34:23<13:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77292.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  72%|████▎ | 538/744 [34:27<13:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83304.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  72%|████▎ | 539/744 [34:31<13:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75939.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7893, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  73%|████▎ | 540/744 [34:35<13:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74744.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  73%|████▎ | 541/744 [34:38<13:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81657.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  73%|████▎ | 542/744 [34:42<12:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74541.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  73%|████▍ | 543/744 [34:46<12:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92711.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  73%|████▍ | 544/744 [34:49<12:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77986.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  73%|████▍ | 545/744 [34:53<12:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80769.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  73%|████▍ | 546/744 [34:57<12:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80491.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  74%|████▍ | 547/744 [35:01<12:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86732.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  74%|████▍ | 548/744 [35:05<12:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91732.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  74%|████▍ | 549/744 [35:08<12:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76278.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  74%|████▍ | 550/744 [35:12<12:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87555.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  74%|████▍ | 551/744 [35:16<12:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80897.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  74%|████▍ | 552/744 [35:19<12:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90652.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  74%|████▍ | 553/744 [35:23<12:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81867.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  74%|████▍ | 554/744 [35:27<12:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84671.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  75%|████▍ | 555/744 [35:31<12:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82925.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  75%|████▍ | 556/744 [35:34<12:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81959.2578, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  75%|████▍ | 557/744 [35:38<11:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85031.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  75%|████▌ | 558/744 [35:42<11:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84710.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  75%|████▌ | 559/744 [35:46<11:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77442.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  75%|████▌ | 560/744 [35:50<11:46,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75358.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  75%|████▌ | 561/744 [35:53<11:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85677.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  76%|████▌ | 562/744 [35:57<11:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79516.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  76%|████▌ | 563/744 [36:01<11:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79060.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  76%|████▌ | 564/744 [36:05<11:31,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83727.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  76%|████▌ | 565/744 [36:09<11:27,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76155.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  76%|████▌ | 566/744 [36:13<11:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83446.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  76%|████▌ | 567/744 [36:16<11:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81815.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  76%|████▌ | 568/744 [36:20<11:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88511.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  76%|████▌ | 569/744 [36:24<11:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78878.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  77%|████▌ | 570/744 [36:28<11:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82504.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  77%|████▌ | 571/744 [36:32<11:04,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87439.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  77%|████▌ | 572/744 [36:36<11:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79675.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  77%|████▌ | 573/744 [36:40<10:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85855.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  77%|████▋ | 574/744 [36:43<10:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79612.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  77%|████▋ | 575/744 [36:47<10:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78357.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  77%|████▋ | 576/744 [36:51<10:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79772.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  78%|████▋ | 577/744 [36:54<10:41,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75940.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  78%|████▋ | 578/744 [36:58<10:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86901.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  78%|████▋ | 579/744 [37:02<10:33,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88376.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  78%|████▋ | 580/744 [37:06<10:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79530.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  78%|████▋ | 581/744 [37:10<10:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84697.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  78%|████▋ | 582/744 [37:14<10:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71056.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  78%|████▋ | 583/744 [37:17<10:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76726.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  78%|████▋ | 584/744 [37:21<10:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71836.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  79%|████▋ | 585/744 [37:25<10:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79149.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  79%|████▋ | 586/744 [37:28<10:06,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77221.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  79%|████▋ | 587/744 [37:32<10:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80967.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  79%|████▋ | 588/744 [37:36<09:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79769.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  79%|████▊ | 589/744 [37:40<09:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83048.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  79%|████▊ | 590/744 [37:43<09:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88598.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  79%|████▊ | 591/744 [37:47<09:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89505.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  80%|████▊ | 592/744 [37:51<09:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83207.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  80%|████▊ | 593/744 [37:55<09:39,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83466.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  80%|████▊ | 594/744 [37:58<09:35,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84858.1562, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  80%|████▊ | 595/744 [38:02<09:31,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81360.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  80%|████▊ | 596/744 [38:06<09:27,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86148.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  80%|████▊ | 597/744 [38:10<09:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79560.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  80%|████▊ | 598/744 [38:13<09:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74940.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  81%|████▊ | 599/744 [38:17<09:16,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78873.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  81%|████▊ | 600/744 [38:21<09:12,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79904.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  81%|████▊ | 601/744 [38:25<09:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81780.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  81%|████▊ | 602/744 [38:29<09:04,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88120.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  81%|████▊ | 603/744 [38:32<09:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76592.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  81%|████▊ | 604/744 [38:36<08:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77721.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  81%|████▉ | 605/744 [38:40<08:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85487.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  81%|████▉ | 606/744 [38:44<08:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69945.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  82%|████▉ | 607/744 [38:47<08:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80027.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  82%|████▉ | 608/744 [38:52<08:41,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78585.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9769, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  82%|████▉ | 609/744 [38:55<08:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79802.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  82%|████▉ | 610/744 [39:00<08:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82668.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  82%|████▉ | 611/744 [39:03<08:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82212.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  82%|████▉ | 612/744 [39:07<08:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88818.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  82%|████▉ | 613/744 [39:10<08:22,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77068.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  83%|████▉ | 614/744 [39:14<08:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81092.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  83%|████▉ | 615/744 [39:18<08:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84628.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  83%|████▉ | 616/744 [39:22<08:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(69107.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  83%|████▉ | 617/744 [39:26<08:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83562.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  83%|████▉ | 618/744 [39:29<08:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72851.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  83%|████▉ | 619/744 [39:33<07:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86577.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  83%|█████ | 620/744 [39:37<07:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81652.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  83%|█████ | 621/744 [39:41<07:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74377.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  84%|█████ | 622/744 [39:44<07:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78497.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  84%|█████ | 623/744 [39:48<07:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86536.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  84%|█████ | 624/744 [39:52<07:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86944.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  84%|█████ | 625/744 [39:56<07:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88116.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  84%|█████ | 626/744 [40:00<07:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77590.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  84%|█████ | 627/744 [40:04<07:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76509.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  84%|█████ | 628/744 [40:08<07:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74733.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  85%|█████ | 629/744 [40:11<07:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85315.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  85%|█████ | 630/744 [40:15<07:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73153.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  85%|█████ | 631/744 [40:19<07:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78866.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  85%|█████ | 632/744 [40:22<07:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86447.8750, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  85%|█████ | 633/744 [40:26<07:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82023.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  85%|█████ | 634/744 [40:30<07:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76540.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  85%|█████ | 635/744 [40:33<06:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80982.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  85%|█████▏| 636/744 [40:37<06:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89160.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9632, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  86%|█████▏| 637/744 [40:41<06:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82513.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  86%|█████▏| 638/744 [40:45<06:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84274.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  86%|█████▏| 639/744 [40:49<06:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80674.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  86%|█████▏| 640/744 [40:53<06:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73321.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  86%|█████▏| 641/744 [40:57<06:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83677.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  86%|█████▏| 642/744 [41:00<06:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85161.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  86%|█████▏| 643/744 [41:04<06:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79392.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  87%|█████▏| 644/744 [41:08<06:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80709.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  87%|█████▏| 645/744 [41:12<06:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78058.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  87%|█████▏| 646/744 [41:15<06:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80057.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  87%|█████▏| 647/744 [41:19<06:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87337.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  87%|█████▏| 648/744 [41:23<06:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76503., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  87%|█████▏| 649/744 [41:27<06:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80356.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  87%|█████▏| 650/744 [41:31<06:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80723.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  88%|█████▎| 651/744 [41:35<05:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84779.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  88%|█████▎| 652/744 [41:38<05:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83229.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  88%|█████▎| 653/744 [41:42<05:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83989.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  88%|█████▎| 654/744 [41:46<05:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89171.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  88%|█████▎| 655/744 [41:50<05:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82580.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  88%|█████▎| 656/744 [41:54<05:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76231.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  88%|█████▎| 657/744 [41:57<05:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86371.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  88%|█████▎| 658/744 [42:01<05:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77410.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  89%|█████▎| 659/744 [42:05<05:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89582.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  89%|█████▎| 660/744 [42:08<05:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87672.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  89%|█████▎| 661/744 [42:12<05:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75505.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  89%|█████▎| 662/744 [42:16<05:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76641.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  89%|█████▎| 663/744 [42:20<05:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84073.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  89%|█████▎| 664/744 [42:23<05:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88106.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  89%|█████▎| 665/744 [42:27<05:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77526.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  90%|█████▎| 666/744 [42:31<04:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83790.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  90%|█████▍| 667/744 [42:35<04:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82121.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  90%|█████▍| 668/744 [42:38<04:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86926.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  90%|█████▍| 669/744 [42:42<04:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85957.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  90%|█████▍| 670/744 [42:46<04:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77935.6016, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  90%|█████▍| 671/744 [42:50<04:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74397.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  90%|█████▍| 672/744 [42:54<04:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86915.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  90%|█████▍| 673/744 [42:57<04:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81971.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  91%|█████▍| 674/744 [43:01<04:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83698.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  91%|█████▍| 675/744 [43:05<04:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81615.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  91%|█████▍| 676/744 [43:09<04:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89165.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  91%|█████▍| 677/744 [43:13<04:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81800.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  91%|█████▍| 678/744 [43:17<04:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81707.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  91%|█████▍| 679/744 [43:21<04:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84281.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  91%|█████▍| 680/744 [43:25<04:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79496.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  92%|█████▍| 681/744 [43:28<04:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91574.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  92%|█████▌| 682/744 [43:32<03:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89804.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  92%|█████▌| 683/744 [43:36<03:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82806.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  92%|█████▌| 684/744 [43:40<03:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83775.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  92%|█████▌| 685/744 [43:44<03:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88977.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  92%|█████▌| 686/744 [43:47<03:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83376.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  92%|█████▌| 687/744 [43:51<03:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80302.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  92%|█████▌| 688/744 [43:55<03:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80140.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  93%|█████▌| 689/744 [43:59<03:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87489.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  93%|█████▌| 690/744 [44:03<03:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78144.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  93%|█████▌| 691/744 [44:07<03:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86360.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  93%|█████▌| 692/744 [44:11<03:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84508.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  93%|█████▌| 693/744 [44:14<03:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89555.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  93%|█████▌| 694/744 [44:18<03:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86548.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  93%|█████▌| 695/744 [44:22<03:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84562.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  94%|█████▌| 696/744 [44:25<03:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72067.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  94%|█████▌| 697/744 [44:29<03:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78032.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8715, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  94%|█████▋| 698/744 [44:33<02:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76445.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  94%|█████▋| 699/744 [44:37<02:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82577.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  94%|█████▋| 700/744 [44:41<02:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86315.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  94%|█████▋| 701/744 [44:44<02:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81659.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  94%|█████▋| 702/744 [44:48<02:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83176.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  94%|█████▋| 703/744 [44:52<02:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79712.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  95%|█████▋| 704/744 [44:56<02:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83815.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  95%|█████▋| 705/744 [44:59<02:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79479.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  95%|█████▋| 706/744 [45:03<02:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80111.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  95%|█████▋| 707/744 [45:07<02:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80140.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  95%|█████▋| 708/744 [45:11<02:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81942.9375, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  95%|█████▋| 709/744 [45:14<02:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74577.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  95%|█████▋| 710/744 [45:18<02:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79870.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  96%|█████▋| 711/744 [45:22<02:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83149.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  96%|█████▋| 712/744 [45:26<02:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(75973.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  96%|█████▊| 713/744 [45:30<01:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(74007.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  96%|█████▊| 714/744 [45:34<01:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79392.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  96%|█████▊| 715/744 [45:37<01:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(73330.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  96%|█████▊| 716/744 [45:41<01:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78850.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  96%|█████▊| 717/744 [45:45<01:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78093.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  97%|█████▊| 718/744 [45:49<01:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86540.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  97%|█████▊| 719/744 [45:53<01:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80552.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  97%|█████▊| 720/744 [45:57<01:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77941.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  97%|█████▊| 721/744 [46:01<01:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92483.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  97%|█████▊| 722/744 [46:05<01:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85614.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  97%|█████▊| 723/744 [46:09<01:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79928.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  97%|█████▊| 724/744 [46:13<01:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81549.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  97%|█████▊| 725/744 [46:17<01:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84642.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12:  98%|█████▊| 726/744 [46:20<01:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88792.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9161, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8673, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  59%|███▌  | 440/744 [28:07<19:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92914.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  59%|███▌  | 441/744 [28:10<19:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87995.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  59%|███▌  | 442/744 [28:14<19:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85686.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  60%|███▌  | 443/744 [28:18<19:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86841.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  60%|███▌  | 444/744 [28:22<19:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85949.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  60%|███▌  | 445/744 [28:26<19:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91199.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  60%|███▌  | 446/744 [28:30<19:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94854.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  60%|███▌  | 447/744 [28:33<18:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98099.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  60%|███▌  | 448/744 [28:37<18:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104076.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  60%|███▌  | 449/744 [28:41<18:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95966.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  60%|███▋  | 450/744 [28:45<18:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78649.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  61%|███▋  | 451/744 [28:48<18:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97923.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  61%|███▋  | 452/744 [28:52<18:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98543.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8863, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  61%|███▋  | 453/744 [28:56<18:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92178.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  61%|███▋  | 454/744 [29:00<18:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92704.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  61%|███▋  | 455/744 [29:04<18:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83817.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  61%|███▋  | 456/744 [29:08<18:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88444.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  61%|███▋  | 457/744 [29:12<18:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90604.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  62%|███▋  | 458/744 [29:16<18:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87223.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  62%|███▋  | 459/744 [29:19<18:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97530.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  62%|███▋  | 460/744 [29:23<18:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95238.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  62%|███▋  | 461/744 [29:27<18:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85853.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7984, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  62%|███▋  | 462/744 [29:31<18:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87878.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  62%|███▋  | 463/744 [29:35<17:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92285.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  62%|███▋  | 464/744 [29:39<17:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101272.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  62%|███▊  | 465/744 [29:42<17:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94944.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  63%|███▊  | 466/744 [29:46<17:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100439.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  63%|███▊  | 467/744 [29:50<17:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95130.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  63%|███▊  | 468/744 [29:54<17:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82274.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  63%|███▊  | 469/744 [29:57<17:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96717.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  63%|███▊  | 470/744 [30:01<17:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92228.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  63%|███▊  | 471/744 [30:05<17:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95903., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  63%|███▊  | 472/744 [30:08<17:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89110.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  64%|███▊  | 473/744 [30:12<17:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96357.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  64%|███▊  | 474/744 [30:16<17:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94660.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  64%|███▊  | 475/744 [30:19<17:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87712.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  64%|███▊  | 476/744 [30:23<17:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90427.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  64%|███▊  | 477/744 [30:27<17:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104055.7812, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  64%|███▊  | 478/744 [30:31<16:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95220.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  64%|███▊  | 479/744 [30:35<16:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89184.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  65%|███▊  | 480/744 [30:39<16:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95114.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8572, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  65%|███▉  | 481/744 [30:43<16:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89161.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  65%|███▉  | 482/744 [30:47<16:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91274.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  65%|███▉  | 483/744 [30:51<16:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92436.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  65%|███▉  | 484/744 [30:54<16:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81383.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  65%|███▉  | 485/744 [30:58<16:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97546.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  65%|███▉  | 486/744 [31:02<16:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85324.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  65%|███▉  | 487/744 [31:06<16:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92464.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  66%|███▉  | 488/744 [31:09<16:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89923.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  66%|███▉  | 489/744 [31:13<16:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98467.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  66%|███▉  | 490/744 [31:17<16:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92944.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  66%|███▉  | 491/744 [31:20<16:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92914.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  66%|███▉  | 492/744 [31:24<16:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96242.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  66%|███▉  | 493/744 [31:28<16:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97377., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  66%|███▉  | 494/744 [31:32<15:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88929.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  67%|███▉  | 495/744 [31:36<15:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86391.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  67%|████  | 496/744 [31:40<15:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88835.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  67%|████  | 497/744 [31:43<15:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88733.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  67%|████  | 498/744 [31:47<15:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96759.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  67%|████  | 499/744 [31:51<15:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78237.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  67%|████  | 500/744 [31:55<15:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96007.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  67%|████  | 501/744 [31:59<15:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88834.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  67%|████  | 502/744 [32:02<15:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96829.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  68%|████  | 503/744 [32:06<15:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92578.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  68%|████  | 504/744 [32:10<15:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88642.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  68%|████  | 505/744 [32:14<15:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90422.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  68%|████  | 506/744 [32:18<15:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98577.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  68%|████  | 507/744 [32:22<15:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90473.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  68%|████  | 508/744 [32:26<15:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94322.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  68%|████  | 509/744 [32:29<15:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99662.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  69%|████  | 510/744 [32:33<14:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81775.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  69%|████  | 511/744 [32:37<14:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95259.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  69%|████▏ | 512/744 [32:41<14:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93946.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  69%|████▏ | 513/744 [32:45<14:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97673.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  69%|████▏ | 514/744 [32:48<14:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100869.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  69%|████▏ | 515/744 [32:52<14:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91418.3906, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  69%|████▏ | 516/744 [32:56<14:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86837.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  69%|████▏ | 517/744 [33:00<14:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83980.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  70%|████▏ | 518/744 [33:04<14:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81394.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  70%|████▏ | 519/744 [33:08<14:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93506.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  70%|████▏ | 520/744 [33:11<14:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95544.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  70%|████▏ | 521/744 [33:15<14:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94946.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  70%|████▏ | 522/744 [33:19<14:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85337.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  70%|████▏ | 523/744 [33:23<14:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99258.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  70%|████▏ | 524/744 [33:27<14:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95291.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  71%|████▏ | 525/744 [33:30<13:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84307.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  71%|████▏ | 526/744 [33:34<13:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97026.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  71%|████▎ | 527/744 [33:38<13:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91175.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  71%|████▎ | 528/744 [33:42<13:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95430.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8791, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  71%|████▎ | 529/744 [33:46<13:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93367.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  71%|████▎ | 530/744 [33:50<13:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101968.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  71%|████▎ | 531/744 [33:53<13:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102510.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  72%|████▎ | 532/744 [33:57<13:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99704.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  72%|████▎ | 533/744 [34:01<13:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89206.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  72%|████▎ | 534/744 [34:05<13:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87571.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  72%|████▎ | 535/744 [34:09<13:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85223.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  72%|████▎ | 536/744 [34:12<13:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87138.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  72%|████▎ | 537/744 [34:16<13:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91947.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  72%|████▎ | 538/744 [34:20<13:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91331.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8791, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  72%|████▎ | 539/744 [34:24<13:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89756.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  73%|████▎ | 540/744 [34:28<13:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94417.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  73%|████▎ | 541/744 [34:31<12:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91481.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  73%|████▎ | 542/744 [34:35<12:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91923.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  73%|████▍ | 543/744 [34:39<12:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86945.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  73%|████▍ | 544/744 [34:43<12:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89964.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  73%|████▍ | 545/744 [34:47<12:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97191.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  73%|████▍ | 546/744 [34:51<12:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92460.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  74%|████▍ | 547/744 [34:54<12:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89283.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  74%|████▍ | 548/744 [34:58<12:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100116.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  74%|████▍ | 549/744 [35:02<12:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95498.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  74%|████▍ | 550/744 [35:06<12:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102174.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  74%|████▍ | 551/744 [35:09<12:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87298.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  74%|████▍ | 552/744 [35:13<12:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99417.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  74%|████▍ | 553/744 [35:17<12:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96797.2656, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  74%|████▍ | 554/744 [35:21<12:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94165.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  75%|████▍ | 555/744 [35:25<12:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97438.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  75%|████▍ | 556/744 [35:29<11:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92531.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  75%|████▍ | 557/744 [35:33<11:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94599.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  75%|████▌ | 558/744 [35:36<11:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94189.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  75%|████▌ | 559/744 [35:40<11:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83008.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  75%|████▌ | 560/744 [35:44<11:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95534.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  75%|████▌ | 561/744 [35:48<11:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87188.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  76%|████▌ | 562/744 [35:52<11:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80316.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  76%|████▌ | 563/744 [35:56<11:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84329.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  76%|████▌ | 564/744 [36:00<11:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92202.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  76%|████▌ | 565/744 [36:03<11:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83727.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  76%|████▌ | 566/744 [36:07<11:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91057.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  76%|████▌ | 567/744 [36:11<11:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95069.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  76%|████▌ | 568/744 [36:15<11:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88778.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  76%|████▌ | 569/744 [36:19<11:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88266.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  77%|████▌ | 570/744 [36:23<11:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92054.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  77%|████▌ | 571/744 [36:27<11:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87612.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  77%|████▌ | 572/744 [36:31<10:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100911.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  77%|████▌ | 573/744 [36:34<10:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89747.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  77%|████▋ | 574/744 [36:38<10:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82143.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  77%|████▋ | 575/744 [36:42<10:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93452.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  77%|████▋ | 576/744 [36:46<10:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89027.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  78%|████▋ | 577/744 [36:50<10:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96505.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  78%|████▋ | 578/744 [36:53<10:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93378.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  78%|████▋ | 579/744 [36:57<10:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92719.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  78%|████▋ | 580/744 [37:01<10:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92680.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  78%|████▋ | 581/744 [37:05<10:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93958.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  78%|████▋ | 582/744 [37:09<10:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102277.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  78%|████▋ | 583/744 [37:12<10:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98370.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  78%|████▋ | 584/744 [37:16<10:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95540., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  79%|████▋ | 585/744 [37:20<10:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90311.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  79%|████▋ | 586/744 [37:24<10:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92707.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  79%|████▋ | 587/744 [37:28<10:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97435.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  79%|████▋ | 588/744 [37:32<09:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92509.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  79%|████▊ | 589/744 [37:36<09:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93405.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  79%|████▊ | 590/744 [37:40<09:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91589.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  79%|████▊ | 591/744 [37:44<09:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96958.9297, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  80%|████▊ | 592/744 [37:48<09:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97914.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  80%|████▊ | 593/744 [37:52<09:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94205.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  80%|████▊ | 594/744 [37:56<09:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101299.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  80%|████▊ | 595/744 [38:00<09:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87026.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  80%|████▊ | 596/744 [38:04<09:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83462.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  80%|████▊ | 597/744 [38:08<09:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91902.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  80%|████▊ | 598/744 [38:12<09:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97217.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  81%|████▊ | 599/744 [38:15<09:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99785.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  81%|████▊ | 600/744 [38:19<09:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93780.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  81%|████▊ | 601/744 [38:23<09:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96287.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  81%|████▊ | 602/744 [38:27<09:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95242.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  81%|████▊ | 603/744 [38:30<09:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(77777.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  81%|████▊ | 604/744 [38:34<08:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94491.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  81%|████▉ | 605/744 [38:38<08:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(76787.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  81%|████▉ | 606/744 [38:42<08:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101091.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  82%|████▉ | 607/744 [38:46<08:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84841.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  82%|████▉ | 608/744 [38:50<08:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107598.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  82%|████▉ | 609/744 [38:55<08:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94814.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  82%|████▉ | 610/744 [38:59<08:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96685.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  82%|████▉ | 611/744 [39:02<08:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84196.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  82%|████▉ | 612/744 [39:06<08:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89122.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  82%|████▉ | 613/744 [39:10<08:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98197.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8316, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  83%|████▉ | 614/744 [39:14<08:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94954.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  83%|████▉ | 615/744 [39:18<08:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84862.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  83%|████▉ | 616/744 [39:21<08:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92558.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  83%|████▉ | 617/744 [39:25<08:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101378.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  83%|████▉ | 618/744 [39:29<08:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105210.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  83%|████▉ | 619/744 [39:33<07:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86967.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  83%|█████ | 620/744 [39:36<07:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102360.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  83%|█████ | 621/744 [39:40<07:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90993.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  84%|█████ | 622/744 [39:44<07:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87566.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  84%|█████ | 623/744 [39:48<07:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94289.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  84%|█████ | 624/744 [39:51<07:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83414.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  84%|█████ | 625/744 [39:55<07:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93551., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  84%|█████ | 626/744 [39:59<07:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102914.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  84%|█████ | 627/744 [40:03<07:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86353.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  84%|█████ | 628/744 [40:06<07:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84163.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  85%|█████ | 629/744 [40:10<07:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98697.2188, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  85%|█████ | 630/744 [40:14<07:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94951.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  85%|█████ | 631/744 [40:18<07:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93800.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  85%|█████ | 632/744 [40:22<07:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94450.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  85%|█████ | 633/744 [40:25<07:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88909.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  85%|█████ | 634/744 [40:29<07:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89026.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  85%|█████ | 635/744 [40:33<06:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99442.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  85%|█████▏| 636/744 [40:37<06:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98048.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  86%|█████▏| 637/744 [40:41<06:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102259.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  86%|█████▏| 638/744 [40:45<06:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98093.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  86%|█████▏| 639/744 [40:48<06:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94152.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  86%|█████▏| 640/744 [40:52<06:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99835.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  86%|█████▏| 641/744 [40:56<06:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84681.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  86%|█████▏| 642/744 [41:00<06:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96495.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  86%|█████▏| 643/744 [41:04<06:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91647.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  87%|█████▏| 644/744 [41:08<06:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96543.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  87%|█████▏| 645/744 [41:12<06:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92008.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  87%|█████▏| 646/744 [41:15<06:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96741.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  87%|█████▏| 647/744 [41:20<06:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100400.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  87%|█████▏| 648/744 [41:24<06:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94623.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  87%|█████▏| 649/744 [41:28<06:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88705.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  87%|█████▏| 650/744 [41:32<06:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88996.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  88%|█████▎| 651/744 [41:35<05:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98862.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  88%|█████▎| 652/744 [41:39<05:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94416.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  88%|█████▎| 653/744 [41:43<05:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87156.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  88%|█████▎| 654/744 [41:46<05:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87648.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  88%|█████▎| 655/744 [41:50<05:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98774.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  88%|█████▎| 656/744 [41:54<05:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95249.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  88%|█████▎| 657/744 [41:58<05:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97149.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  88%|█████▎| 658/744 [42:02<05:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95883.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  89%|█████▎| 659/744 [42:05<05:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103467.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  89%|█████▎| 660/744 [42:09<05:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92991.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  89%|█████▎| 661/744 [42:13<05:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91383.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  89%|█████▎| 662/744 [42:17<05:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100306.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  89%|█████▎| 663/744 [42:21<05:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94335., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  89%|█████▎| 664/744 [42:24<05:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91577.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  89%|█████▎| 665/744 [42:28<05:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97381.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  90%|█████▎| 666/744 [42:32<04:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95080.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  90%|█████▍| 667/744 [42:36<04:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93356.0625, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  90%|█████▍| 668/744 [42:39<04:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(81742.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  90%|█████▍| 669/744 [42:43<04:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94882.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  90%|█████▍| 670/744 [42:47<04:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98573.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  90%|█████▍| 671/744 [42:51<04:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96184.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  90%|█████▍| 672/744 [42:54<04:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99525.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  90%|█████▍| 673/744 [42:58<04:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103048.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  91%|█████▍| 674/744 [43:02<04:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104680.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  91%|█████▍| 675/744 [43:06<04:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90204.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  91%|█████▍| 676/744 [43:10<04:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93767.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  91%|█████▍| 677/744 [43:13<04:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88778.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  91%|█████▍| 678/744 [43:17<04:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98819.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  91%|█████▍| 679/744 [43:21<04:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90303.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  91%|█████▍| 680/744 [43:24<04:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88661.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  92%|█████▍| 681/744 [43:28<04:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94722.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  92%|█████▌| 682/744 [43:32<03:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90570.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  92%|█████▌| 683/744 [43:36<03:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94447.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  92%|█████▌| 684/744 [43:40<03:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100791.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  92%|█████▌| 685/744 [43:43<03:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96163.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  92%|█████▌| 686/744 [43:47<03:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105985.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  92%|█████▌| 687/744 [43:51<03:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102676.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  92%|█████▌| 688/744 [43:55<03:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95204.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  93%|█████▌| 689/744 [43:59<03:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89523.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  93%|█████▌| 690/744 [44:02<03:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96502.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  93%|█████▌| 691/744 [44:06<03:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97797.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  93%|█████▌| 692/744 [44:10<03:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85054.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  93%|█████▌| 693/744 [44:14<03:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102928.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  93%|█████▌| 694/744 [44:18<03:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85223.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  93%|█████▌| 695/744 [44:21<03:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97913.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  94%|█████▌| 696/744 [44:25<03:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97013.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  94%|█████▌| 697/744 [44:29<03:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103376.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  94%|█████▋| 698/744 [44:33<02:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95397.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  94%|█████▋| 699/744 [44:37<02:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97639.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  94%|█████▋| 700/744 [44:41<02:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78939.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  94%|█████▋| 701/744 [44:45<02:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93443.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  94%|█████▋| 702/744 [44:49<02:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94147.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  94%|█████▋| 703/744 [44:53<02:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94076.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  95%|█████▋| 704/744 [44:56<02:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89272.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  95%|█████▋| 705/744 [45:00<02:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87969.6094, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  95%|█████▋| 706/744 [45:04<02:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97899.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  95%|█████▋| 707/744 [45:08<02:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87121.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  95%|█████▋| 708/744 [45:12<02:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84727.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  95%|█████▋| 709/744 [45:15<02:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85197.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  95%|█████▋| 710/744 [45:19<02:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98206.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  96%|█████▋| 711/744 [45:23<02:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95041., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  96%|█████▋| 712/744 [45:27<02:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84385.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  96%|█████▊| 713/744 [45:31<01:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100735.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  96%|█████▊| 714/744 [45:35<01:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92163.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  96%|█████▊| 715/744 [45:39<01:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95165.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  96%|█████▊| 716/744 [45:42<01:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99570.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  96%|█████▊| 717/744 [45:46<01:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92518.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  97%|█████▊| 718/744 [45:50<01:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95482.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  97%|█████▊| 719/744 [45:54<01:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94468.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  97%|█████▊| 720/744 [45:58<01:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94488.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  97%|█████▊| 721/744 [46:02<01:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85872.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  97%|█████▊| 722/744 [46:06<01:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95108.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  97%|█████▊| 723/744 [46:10<01:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92629.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  97%|█████▊| 724/744 [46:14<01:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93273.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  97%|█████▊| 725/744 [46:18<01:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93946.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  98%|█████▊| 726/744 [46:22<01:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84620.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  98%|█████▊| 727/744 [46:26<01:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92630.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  98%|█████▊| 728/744 [46:30<01:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96734.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  98%|█████▉| 729/744 [46:33<00:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88047.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  98%|█████▉| 730/744 [46:37<00:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89200.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  98%|█████▉| 731/744 [46:41<00:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90858.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  98%|█████▉| 732/744 [46:45<00:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99664.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  99%|█████▉| 733/744 [46:49<00:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83411.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  99%|█████▉| 734/744 [46:52<00:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101720.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  99%|█████▉| 735/744 [46:56<00:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95279.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  99%|█████▉| 736/744 [47:00<00:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87121.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  99%|█████▉| 737/744 [47:04<00:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89623.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  99%|█████▉| 738/744 [47:08<00:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94858.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  99%|█████▉| 739/744 [47:11<00:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97201.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14:  99%|█████▉| 740/744 [47:15<00:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98500.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14: 100%|█████▉| 741/744 [47:19<00:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91259.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14: 100%|█████▉| 742/744 [47:23<00:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101028.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14: 100%|█████▉| 743/744 [47:27<00:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95106.2031, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   0%|                | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(97027.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   0%|      | 1/744 [00:05<1:05:48,  5.31s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88844.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   0%|        | 2/744 [00:09<57:32,  4.65s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98560.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   0%|        | 3/744 [00:13<53:49,  4.36s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93897.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   1%|        | 4/744 [00:17<52:27,  4.25s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98105.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   1%|        | 5/744 [00:20<51:23,  4.17s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91896.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   1%|        | 6/744 [00:24<50:10,  4.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88235.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   1%|        | 7/744 [00:28<49:41,  4.05s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100991.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   1%|        | 8/744 [00:32<49:07,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93726.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   1%|        | 9/744 [00:35<48:25,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91180.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   1%|       | 10/744 [00:39<48:05,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97810.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   1%|       | 11/744 [00:43<47:59,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90448.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   2%|       | 12/744 [00:46<47:40,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95546.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   2%|       | 13/744 [00:50<47:27,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94271.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   2%|▏      | 14/744 [00:54<47:24,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87909.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   2%|▏      | 15/744 [00:58<47:11,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101923.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   2%|▏      | 16/744 [01:01<46:52,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98080.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   2%|▏      | 17/744 [01:05<46:56,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97930.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9213, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   2%|▏      | 18/744 [01:09<46:51,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102856.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   3%|▏      | 19/744 [01:13<46:44,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101531.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   3%|▏      | 20/744 [01:17<46:44,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102140.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   3%|▏      | 21/744 [01:21<46:36,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103227.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   3%|▏      | 22/744 [01:25<46:29,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97118.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   3%|▏      | 23/744 [01:29<46:29,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95424.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   3%|▏      | 24/744 [01:32<46:25,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94077.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   3%|▏      | 25/744 [01:36<46:21,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93194.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   3%|▏      | 26/744 [01:40<46:15,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96133.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   4%|▎      | 27/744 [01:44<46:08,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85497.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   4%|▎      | 28/744 [01:48<46:06,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89099.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   4%|▎      | 29/744 [01:51<46:00,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97198.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   4%|▎      | 30/744 [01:55<45:55,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88870.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   4%|▎      | 31/744 [01:59<45:52,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(72607.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   4%|▎      | 32/744 [02:03<45:44,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93460.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   4%|▎      | 33/744 [02:07<45:38,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90860.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   5%|▎      | 34/744 [02:10<45:32,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95863.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   5%|▎      | 35/744 [02:14<45:33,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92014.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   5%|▎      | 36/744 [02:18<45:26,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88475.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   5%|▎      | 37/744 [02:22<45:20,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99171.7266, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.7995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   5%|▎      | 38/744 [02:26<45:18,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101090.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   5%|▎      | 39/744 [02:29<45:11,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88621.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   5%|▍      | 40/744 [02:34<45:11,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104715.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   6%|▍      | 41/744 [02:38<45:10,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99839.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   6%|▍      | 42/744 [02:41<45:06,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102319.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   6%|▍      | 43/744 [02:45<45:01,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99400.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   6%|▍      | 44/744 [02:49<44:56,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91067.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   6%|▍      | 45/744 [02:53<44:53,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(71249.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   6%|▍      | 46/744 [02:57<44:46,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93264.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   6%|▍      | 47/744 [03:00<44:40,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91802.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   6%|▍      | 48/744 [03:04<44:35,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98005.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   7%|▍      | 49/744 [03:08<44:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95816.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   7%|▍      | 50/744 [03:11<44:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98960.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   7%|▍      | 51/744 [03:15<44:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100443.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   7%|▍      | 52/744 [03:19<44:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93511.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   7%|▍      | 53/744 [03:23<44:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97228.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   7%|▌      | 54/744 [03:26<44:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97309.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   7%|▌      | 55/744 [03:30<43:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94529.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   8%|▌      | 56/744 [03:34<43:51,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86089.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   8%|▌      | 57/744 [03:37<43:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84505.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   8%|▌      | 58/744 [03:41<43:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91174.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   8%|▌      | 59/744 [03:45<43:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82225.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   8%|▌      | 60/744 [03:49<43:33,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99068.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   8%|▌      | 61/744 [03:53<43:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86311.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8601, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   8%|▌      | 62/744 [03:57<43:28,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92768.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   8%|▌      | 63/744 [04:00<43:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100676.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   9%|▌      | 64/744 [04:04<43:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86084.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   9%|▌      | 65/744 [04:08<43:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99247.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   9%|▌      | 66/744 [04:12<43:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85448.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   9%|▋      | 67/744 [04:16<43:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97870.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   9%|▋      | 68/744 [04:20<43:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90171.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   9%|▋      | 69/744 [04:23<43:01,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91292.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:   9%|▋      | 70/744 [04:27<42:54,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82656.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  10%|▋      | 71/744 [04:31<42:50,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87506.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  10%|▋      | 72/744 [04:34<42:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98810.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  10%|▋      | 73/744 [04:38<42:41,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95389.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  10%|▋      | 74/744 [04:42<42:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98076.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  10%|▋      | 75/744 [04:46<42:33,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90064.6875, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  10%|▋      | 76/744 [04:50<42:30,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100683.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  10%|▋      | 77/744 [04:54<42:27,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88512.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  10%|▋      | 78/744 [04:57<42:24,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98367.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9999, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  11%|▋      | 79/744 [05:01<42:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105882.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  11%|▊      | 80/744 [05:05<42:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88432.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  11%|▊      | 81/744 [05:10<42:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92584.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  11%|▊      | 82/744 [05:13<42:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93230.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  11%|▊      | 83/744 [05:18<42:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89609.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  11%|▊      | 84/744 [05:22<42:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94141.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  11%|▊      | 85/744 [05:26<42:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101994.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  12%|▊      | 86/744 [05:29<42:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105383.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  12%|▊      | 87/744 [05:34<42:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88350.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  12%|▊      | 88/744 [05:38<42:03,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101098.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  12%|▊      | 89/744 [05:42<41:58,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92347.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  12%|▊      | 90/744 [05:45<41:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97664.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  12%|▊      | 91/744 [05:49<41:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99053.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  12%|▊      | 92/744 [05:53<41:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103857.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  12%|▉      | 93/744 [05:57<41:39,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86279.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  13%|▉      | 94/744 [06:00<41:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97479.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  13%|▉      | 95/744 [06:04<41:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95069.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  13%|▉      | 96/744 [06:08<41:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99820.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  13%|▉      | 97/744 [06:12<41:22,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91434.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  13%|▉      | 98/744 [06:16<41:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97651.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  13%|▉      | 99/744 [06:20<41:16,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96083.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  13%|▊     | 100/744 [06:24<41:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97609.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  14%|▊     | 101/744 [06:27<41:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87045.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  14%|▊     | 102/744 [06:31<41:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99053.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  14%|▊     | 103/744 [06:35<40:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93265.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  14%|▊     | 104/744 [06:39<40:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98896.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  14%|▊     | 105/744 [06:43<40:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105841.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  14%|▊     | 106/744 [06:47<40:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84238.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  14%|▊     | 107/744 [06:50<40:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83777.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  15%|▊     | 108/744 [06:54<40:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98935.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  15%|▉     | 109/744 [06:58<40:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93750.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  15%|▉     | 110/744 [07:01<40:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102839.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  15%|▉     | 111/744 [07:05<40:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92473.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  15%|▉     | 112/744 [07:09<40:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97312.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  15%|▉     | 113/744 [07:13<40:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94563.2812, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  15%|▉     | 114/744 [07:17<40:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96924.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  15%|▉     | 115/744 [07:21<40:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101731., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  16%|▉     | 116/744 [07:25<40:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95804.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  16%|▉     | 117/744 [07:28<40:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95911.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  16%|▉     | 118/744 [07:32<40:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90576.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  16%|▉     | 119/744 [07:36<39:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96606.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  16%|▉     | 120/744 [07:40<39:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105085.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  16%|▉     | 121/744 [07:44<39:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86266.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  16%|▉     | 122/744 [07:48<39:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83894.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  17%|▉     | 123/744 [07:52<39:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98771.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  17%|█     | 124/744 [07:56<39:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102959.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  17%|█     | 125/744 [07:59<39:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101604.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  17%|█     | 126/744 [08:03<39:31,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92962.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  17%|█     | 127/744 [08:07<39:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96468.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  17%|█     | 128/744 [08:11<39:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107482.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  17%|█     | 129/744 [08:15<39:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90196.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  17%|█     | 130/744 [08:19<39:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96673.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  18%|█     | 131/744 [08:23<39:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101107.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  18%|█     | 132/744 [08:27<39:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87514.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  18%|█     | 133/744 [08:31<39:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90938.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  18%|█     | 134/744 [08:34<39:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105348.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  18%|█     | 135/744 [08:38<38:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95133.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  18%|█     | 136/744 [08:42<38:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91281.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  18%|█     | 137/744 [08:46<38:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85253.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  19%|█     | 138/744 [08:50<38:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100157.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  19%|█     | 139/744 [08:54<38:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100323.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  19%|█▏    | 140/744 [08:58<38:41,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85214.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  19%|█▏    | 141/744 [09:01<38:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96181.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  19%|█▏    | 142/744 [09:05<38:34,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86913., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  19%|█▏    | 143/744 [09:09<38:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91878.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  19%|█▏    | 144/744 [09:13<38:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97430.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  19%|█▏    | 145/744 [09:17<38:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101031.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  20%|█▏    | 146/744 [09:21<38:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99673.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  20%|█▏    | 147/744 [09:25<38:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95864.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  20%|█▏    | 148/744 [09:28<38:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93385.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  20%|█▏    | 149/744 [09:32<38:06,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102375.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  20%|█▏    | 150/744 [09:36<38:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100456.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  20%|█▏    | 151/744 [09:40<37:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95041.9375, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  20%|█▏    | 152/744 [09:44<37:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98876.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  21%|█▏    | 153/744 [09:48<37:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98603.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8822, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  21%|█▏    | 154/744 [09:51<37:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104260.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  21%|█▎    | 155/744 [09:55<37:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98571.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  21%|█▎    | 156/744 [09:59<37:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94380.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  21%|█▎    | 157/744 [10:03<37:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93831.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  21%|█▎    | 158/744 [10:07<37:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102805.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  21%|█▎    | 159/744 [10:10<37:27,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86216.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  22%|█▎    | 160/744 [10:14<37:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98571.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  22%|█▎    | 161/744 [10:19<37:22,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95227.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  22%|█▎    | 162/744 [10:23<37:18,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92510.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  22%|█▎    | 163/744 [10:26<37:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102775.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  22%|█▎    | 164/744 [10:30<37:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101815.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  22%|█▎    | 165/744 [10:34<37:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93373.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  22%|█▎    | 166/744 [10:38<37:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101497.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  22%|█▎    | 167/744 [10:41<36:57,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95196.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  23%|█▎    | 168/744 [10:45<36:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100443.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  23%|█▎    | 169/744 [10:49<36:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88648.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  23%|█▎    | 170/744 [10:53<36:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91736.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  23%|█▍    | 171/744 [10:57<36:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99322.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  23%|█▍    | 172/744 [11:00<36:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104184.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  23%|█▍    | 173/744 [11:04<36:33,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97588.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  23%|█▍    | 174/744 [11:08<36:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100313.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  24%|█▍    | 175/744 [11:12<36:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94428.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  24%|█▍    | 176/744 [11:16<36:22,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91913.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  24%|█▍    | 177/744 [11:20<36:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91806.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  24%|█▍    | 178/744 [11:24<36:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87700.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  24%|█▍    | 179/744 [11:27<36:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99993.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  24%|█▍    | 180/744 [11:31<36:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92665.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  24%|█▍    | 181/744 [11:35<36:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105095.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  24%|█▍    | 182/744 [11:39<36:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88705.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  25%|█▍    | 183/744 [11:43<35:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101126.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  25%|█▍    | 184/744 [11:47<35:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87946.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  25%|█▍    | 185/744 [11:51<35:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95386.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  25%|█▌    | 186/744 [11:55<35:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99138.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  25%|█▌    | 187/744 [11:59<35:42,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104494.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  25%|█▌    | 188/744 [12:02<35:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84282.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  25%|█▌    | 189/744 [12:06<35:33,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97601.4141, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  26%|█▌    | 190/744 [12:10<35:31,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100033.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  26%|█▌    | 191/744 [12:14<35:26,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95952.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  26%|█▌    | 192/744 [12:18<35:22,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91831.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  26%|█▌    | 193/744 [12:22<35:19,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100212.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  26%|█▌    | 194/744 [12:26<35:15,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101687.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  26%|█▌    | 195/744 [12:30<35:12,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93719.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  26%|█▌    | 196/744 [12:34<35:08,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102150.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  26%|█▌    | 197/744 [12:37<35:04,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100238.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  27%|█▌    | 198/744 [12:41<34:59,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98511.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  27%|█▌    | 199/744 [12:45<34:56,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98265.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  27%|█▌    | 200/744 [12:49<34:52,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110620.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  27%|█▌    | 201/744 [12:52<34:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104633.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  27%|█▋    | 202/744 [12:56<34:44,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92324.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  27%|█▋    | 203/744 [13:00<34:40,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94304.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  27%|█▋    | 204/744 [13:04<34:36,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96585.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  28%|█▋    | 205/744 [13:08<34:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98560.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  28%|█▋    | 206/744 [13:11<34:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94850.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  28%|█▋    | 207/744 [13:15<34:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90100.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  28%|█▋    | 208/744 [13:19<34:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99288.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  28%|█▋    | 209/744 [13:23<34:16,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105015.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  28%|█▋    | 210/744 [13:27<34:12,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100342.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  28%|█▋    | 211/744 [13:31<34:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98790.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  28%|█▋    | 212/744 [13:34<34:04,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92674.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  29%|█▋    | 213/744 [13:38<34:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98072.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  29%|█▋    | 214/744 [13:41<33:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98473.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  29%|█▋    | 215/744 [13:45<33:51,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103930.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  29%|█▋    | 216/744 [13:49<33:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94990.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  29%|█▊    | 217/744 [13:53<33:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90965.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  29%|█▊    | 218/744 [13:57<33:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99922.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  29%|█▊    | 219/744 [14:01<33:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100249.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  30%|█▊    | 220/744 [14:04<33:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96960.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  30%|█▊    | 221/744 [14:08<33:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100516.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  30%|█▊    | 222/744 [14:12<33:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97299.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  30%|█▊    | 223/744 [14:16<33:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94291.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  30%|█▊    | 224/744 [14:20<33:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99017.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  30%|█▊    | 225/744 [14:23<33:12,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87944.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  30%|█▊    | 226/744 [14:27<33:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86753.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  31%|█▊    | 227/744 [14:31<33:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96367.7578, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8316, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  31%|█▊    | 228/744 [14:35<33:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96446.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9609, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  31%|█▊    | 229/744 [14:39<32:57,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95193.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  31%|█▊    | 230/744 [14:43<32:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103639.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  31%|█▊    | 231/744 [14:47<32:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91400.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  31%|█▊    | 232/744 [14:50<32:45,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94728.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  31%|█▉    | 233/744 [14:54<32:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94181.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  31%|█▉    | 234/744 [14:58<32:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93030.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  32%|█▉    | 235/744 [15:02<32:33,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89096.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  32%|█▉    | 236/744 [15:05<32:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97838.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  32%|█▉    | 237/744 [15:09<32:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108168.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  32%|█▉    | 238/744 [15:13<32:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95853.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  32%|█▉    | 239/744 [15:17<32:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92640.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  32%|█▉    | 240/744 [15:21<32:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94684.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  32%|█▉    | 241/744 [15:25<32:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96029.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  33%|█▉    | 242/744 [15:29<32:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94919.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  33%|█▉    | 243/744 [15:33<32:04,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93968.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  33%|█▉    | 244/744 [15:37<32:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97791.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  33%|█▉    | 245/744 [15:40<31:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92746.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  33%|█▉    | 246/744 [15:44<31:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99185.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  33%|█▉    | 247/744 [15:48<31:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91967.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  33%|██    | 248/744 [15:51<31:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95651.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  33%|██    | 249/744 [15:55<31:39,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101371.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  34%|██    | 250/744 [15:59<31:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82324.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  34%|██    | 251/744 [16:03<31:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95227.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  34%|██    | 252/744 [16:07<31:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97029.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  34%|██    | 253/744 [16:10<31:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108837.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  34%|██    | 254/744 [16:15<31:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90433., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  34%|██    | 255/744 [16:19<31:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111508.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  34%|██    | 256/744 [16:22<31:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101973.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  35%|██    | 257/744 [16:26<31:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94742.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  35%|██    | 258/744 [16:30<31:06,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99670.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  35%|██    | 259/744 [16:34<31:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93421.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  35%|██    | 260/744 [16:38<30:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98352.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  35%|██    | 261/744 [16:42<30:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99514., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  35%|██    | 262/744 [16:45<30:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82877.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  35%|██    | 263/744 [16:49<30:46,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95536.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  35%|██▏   | 264/744 [16:53<30:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104004.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  36%|██▏   | 265/744 [16:57<30:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93548.4922, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.7942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  36%|██▏   | 266/744 [17:00<30:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84688.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  36%|██▏   | 267/744 [17:04<30:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98614.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  36%|██▏   | 268/744 [17:08<30:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107519.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  36%|██▏   | 269/744 [17:11<30:22,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93933.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  36%|██▏   | 270/744 [17:15<30:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112366.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  36%|██▏   | 271/744 [17:19<30:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88897.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  37%|██▏   | 272/744 [17:23<30:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99847.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  37%|██▏   | 273/744 [17:27<30:06,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90128.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9643, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  37%|██▏   | 274/744 [17:31<30:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91064.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  37%|██▏   | 275/744 [17:34<29:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98355.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  37%|██▏   | 276/744 [17:38<29:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92963.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  37%|██▏   | 277/744 [17:42<29:51,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102344.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  37%|██▏   | 278/744 [17:46<29:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96965.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  38%|██▎   | 279/744 [17:50<29:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100093.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  38%|██▎   | 280/744 [17:54<29:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93579.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  38%|██▎   | 281/744 [17:58<29:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97365.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  38%|██▎   | 282/744 [18:02<29:33,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105904.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  38%|██▎   | 283/744 [18:06<29:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90806.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  38%|██▎   | 284/744 [18:10<29:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94582.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  38%|██▎   | 285/744 [18:13<29:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91579.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  38%|██▎   | 286/744 [18:17<29:17,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93705.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  39%|██▎   | 287/744 [18:21<29:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89583.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  39%|██▎   | 288/744 [18:25<29:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93315.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  39%|██▎   | 289/744 [18:29<29:06,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99084.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  39%|██▎   | 290/744 [18:33<29:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92564.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  39%|██▎   | 291/744 [18:36<28:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102102.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  39%|██▎   | 292/744 [18:40<28:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86964.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  39%|██▎   | 293/744 [18:44<28:51,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105366.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  40%|██▎   | 294/744 [18:48<28:46,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88650.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  40%|██▍   | 295/744 [18:51<28:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99055., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  40%|██▍   | 296/744 [18:55<28:39,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97292.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  40%|██▍   | 297/744 [18:59<28:35,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96786.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  40%|██▍   | 298/744 [19:03<28:31,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100355.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  40%|██▍   | 299/744 [19:07<28:27,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97437.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  40%|██▍   | 300/744 [19:11<28:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92394.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  40%|██▍   | 301/744 [19:14<28:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105463.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  41%|██▍   | 302/744 [19:18<28:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97358.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  41%|██▍   | 303/744 [19:22<28:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98899.5312, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  41%|██▍   | 304/744 [19:25<28:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101757.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  41%|██▍   | 305/744 [19:29<28:03,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99633.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  41%|██▍   | 306/744 [19:33<28:00,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95112.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  41%|██▍   | 307/744 [19:37<27:56,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90332.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  41%|██▍   | 308/744 [19:41<27:52,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93452.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  42%|██▍   | 309/744 [19:45<27:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103849.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  42%|██▌   | 310/744 [19:48<27:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97933.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  42%|██▌   | 311/744 [19:52<27:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102226.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  42%|██▌   | 312/744 [19:56<27:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102798.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  42%|██▌   | 313/744 [20:00<27:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102292.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  42%|██▌   | 314/744 [20:04<27:29,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95176.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  42%|██▌   | 315/744 [20:08<27:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98942.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  42%|██▌   | 316/744 [20:11<27:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97905.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  43%|██▌   | 317/744 [20:15<27:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90602.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  43%|██▌   | 318/744 [20:19<27:13,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98266.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  43%|██▌   | 319/744 [20:23<27:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94097.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  43%|██▌   | 320/744 [20:27<27:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98264.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  43%|██▌   | 321/744 [20:31<27:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101920.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  43%|██▌   | 322/744 [20:35<26:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96370.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  43%|██▌   | 323/744 [20:39<26:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106175.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  44%|██▌   | 324/744 [20:42<26:51,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99411.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  44%|██▌   | 325/744 [20:46<26:47,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102611.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  44%|██▋   | 326/744 [20:50<26:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96365.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  44%|██▋   | 327/744 [20:54<26:39,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88276.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  44%|██▋   | 328/744 [20:58<26:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101018.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  44%|██▋   | 329/744 [21:02<26:32,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99374.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  44%|██▋   | 330/744 [21:06<26:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101928.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  44%|██▋   | 331/744 [21:10<26:24,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105954.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  45%|██▋   | 332/744 [21:13<26:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95283.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  45%|██▋   | 333/744 [21:17<26:16,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100662.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  45%|██▋   | 334/744 [21:21<26:12,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100544.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  45%|██▋   | 335/744 [21:24<26:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91702.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  45%|██▋   | 336/744 [21:28<26:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102696.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  45%|██▋   | 337/744 [21:32<26:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94464.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  45%|██▋   | 338/744 [21:36<25:57,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100866.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  46%|██▋   | 339/744 [21:40<25:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93379.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  46%|██▋   | 340/744 [21:43<25:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98957.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  46%|██▊   | 341/744 [21:47<25:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96281.7188, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  46%|██▊   | 342/744 [21:51<25:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101173.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  46%|██▊   | 343/744 [21:54<25:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87585.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  46%|██▊   | 344/744 [21:58<25:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96974.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  46%|██▊   | 345/744 [22:02<25:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88862.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  47%|██▊   | 346/744 [22:06<25:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98986.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  47%|██▊   | 347/744 [22:09<25:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93358.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  47%|██▊   | 348/744 [22:13<25:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93857.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  47%|██▊   | 349/744 [22:17<25:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104658.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  47%|██▊   | 350/744 [22:21<25:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103569.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  47%|██▊   | 351/744 [22:25<25:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96165.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  47%|██▊   | 352/744 [22:28<25:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94333.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  47%|██▊   | 353/744 [22:32<24:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104446.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  48%|██▊   | 354/744 [22:36<24:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103586.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  48%|██▊   | 355/744 [22:40<24:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94885.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  48%|██▊   | 356/744 [22:44<24:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96633.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  48%|██▉   | 357/744 [22:47<24:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85555.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  48%|██▉   | 358/744 [22:51<24:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102359.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  48%|██▉   | 359/744 [22:55<24:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91847.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  48%|██▉   | 360/744 [22:59<24:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100974.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  49%|██▉   | 361/744 [23:03<24:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100047.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  49%|██▉   | 362/744 [23:07<24:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92832.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8843, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  49%|██▉   | 363/744 [23:11<24:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116065.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  49%|██▉   | 364/744 [23:14<24:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103657.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  49%|██▉   | 365/744 [23:18<24:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100352.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  49%|██▉   | 366/744 [23:22<24:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95930.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  49%|██▉   | 367/744 [23:26<24:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97021.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  49%|██▉   | 368/744 [23:29<24:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104018.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  50%|██▉   | 369/744 [23:33<23:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94534.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  50%|██▉   | 370/744 [23:37<23:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96448.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  50%|██▉   | 371/744 [23:41<23:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96786.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  50%|███   | 372/744 [23:45<23:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94837.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  50%|███   | 373/744 [23:48<23:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97779.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  50%|███   | 374/744 [23:52<23:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90093.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  50%|███   | 375/744 [23:56<23:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94609.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  51%|███   | 376/744 [24:00<23:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102642.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7791, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  51%|███   | 377/744 [24:04<23:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93593.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  51%|███   | 378/744 [24:08<23:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95901.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  51%|███   | 379/744 [24:11<23:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102854.9609, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  51%|███   | 380/744 [24:15<23:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95877.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  51%|███   | 381/744 [24:19<23:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95077.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  51%|███   | 382/744 [24:23<23:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100748.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  51%|███   | 383/744 [24:27<23:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92994.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  52%|███   | 384/744 [24:31<22:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98710.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  52%|███   | 385/744 [24:35<22:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101370.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  52%|███   | 386/744 [24:38<22:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102888.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  52%|███   | 387/744 [24:42<22:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96098.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  52%|███▏  | 388/744 [24:46<22:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97209.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  52%|███▏  | 389/744 [24:49<22:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89057.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  52%|███▏  | 390/744 [24:53<22:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89257.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  53%|███▏  | 391/744 [24:57<22:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95574.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  53%|███▏  | 392/744 [25:01<22:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95838.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  53%|███▏  | 393/744 [25:04<22:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99478.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  53%|███▏  | 394/744 [25:08<22:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97432.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  53%|███▏  | 395/744 [25:12<22:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95298.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  53%|███▏  | 396/744 [25:16<22:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96322.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  53%|███▏  | 397/744 [25:19<22:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98557.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  53%|███▏  | 398/744 [25:23<22:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114263.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  54%|███▏  | 399/744 [25:27<22:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109985.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  54%|███▏  | 400/744 [25:31<21:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103907.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  54%|███▏  | 401/744 [25:35<21:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96566.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  54%|███▏  | 402/744 [25:39<21:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94188.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  54%|███▎  | 403/744 [25:43<21:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101275.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  54%|███▎  | 404/744 [25:47<21:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83699.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  54%|███▎  | 405/744 [25:51<21:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91687.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  55%|███▎  | 406/744 [25:54<21:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90549.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  55%|███▎  | 407/744 [25:58<21:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98539.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  55%|███▎  | 408/744 [26:02<21:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94374.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  55%|███▎  | 409/744 [26:06<21:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100360.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  55%|███▎  | 410/744 [26:10<21:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99271.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  55%|███▎  | 411/744 [26:14<21:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96938.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  55%|███▎  | 412/744 [26:17<21:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99436.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  56%|███▎  | 413/744 [26:21<21:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104200.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  56%|███▎  | 414/744 [26:25<21:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105159.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  56%|███▎  | 415/744 [26:29<21:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86202.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  56%|███▎  | 416/744 [26:33<20:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101239.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  56%|███▎  | 417/744 [26:36<20:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91223.1250, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  56%|███▎  | 418/744 [26:40<20:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98520.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  56%|███▍  | 419/744 [26:44<20:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100292.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  56%|███▍  | 420/744 [26:48<20:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84505.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  57%|███▍  | 421/744 [26:52<20:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102743.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  57%|███▍  | 422/744 [26:56<20:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95096.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  57%|███▍  | 423/744 [26:59<20:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90886.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  57%|███▍  | 424/744 [27:03<20:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100316.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  57%|███▍  | 425/744 [27:07<20:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86522.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  57%|███▍  | 426/744 [27:10<20:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104716.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  57%|███▍  | 427/744 [27:14<20:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108841.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  58%|███▍  | 428/744 [27:18<20:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103515.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  58%|███▍  | 429/744 [27:21<20:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86796.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  58%|███▍  | 430/744 [27:25<20:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98320.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  58%|███▍  | 431/744 [27:29<19:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100487.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  58%|███▍  | 432/744 [27:33<19:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98227.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  58%|███▍  | 433/744 [27:37<19:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107382.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  58%|███▌  | 434/744 [27:41<19:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98455.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  58%|███▌  | 435/744 [27:44<19:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90904.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  59%|███▌  | 436/744 [27:48<19:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88328.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  59%|███▌  | 437/744 [27:52<19:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103342.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  59%|███▌  | 438/744 [27:56<19:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103061.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  59%|███▌  | 439/744 [27:59<19:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90560.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  59%|███▌  | 440/744 [28:03<19:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91399.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  59%|███▌  | 441/744 [28:07<19:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99777.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  59%|███▌  | 442/744 [28:11<19:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89738.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  60%|███▌  | 443/744 [28:15<19:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95276.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  60%|███▌  | 444/744 [28:19<19:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103601.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  60%|███▌  | 445/744 [28:23<19:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102347.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  60%|███▌  | 446/744 [28:27<19:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107739.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  60%|███▌  | 447/744 [28:31<18:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99152.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  60%|███▌  | 448/744 [28:34<18:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80071.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  60%|███▌  | 449/744 [28:38<18:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93473., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  60%|███▋  | 450/744 [28:42<18:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98833.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  61%|███▋  | 451/744 [28:46<18:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102875.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  61%|███▋  | 452/744 [28:49<18:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99202.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  61%|███▋  | 453/744 [28:53<18:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88565.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  61%|███▋  | 454/744 [28:57<18:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95529.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  61%|███▋  | 455/744 [29:01<18:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96285.0859, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  61%|███▋  | 456/744 [29:05<18:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99172.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  61%|███▋  | 457/744 [29:09<18:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105201.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  62%|███▋  | 458/744 [29:12<18:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100742.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  62%|███▋  | 459/744 [29:16<18:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92758.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  62%|███▋  | 460/744 [29:20<18:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100280.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  62%|███▋  | 461/744 [29:24<18:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111273.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  62%|███▋  | 462/744 [29:28<17:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99469.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  62%|███▋  | 463/744 [29:32<17:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92759.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  62%|███▋  | 464/744 [29:35<17:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98192.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  62%|███▊  | 465/744 [29:39<17:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88344.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  63%|███▊  | 466/744 [29:43<17:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96976.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  63%|███▊  | 467/744 [29:47<17:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99386.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  63%|███▊  | 468/744 [29:50<17:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103909.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  63%|███▊  | 469/744 [29:54<17:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87309.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  63%|███▊  | 470/744 [29:58<17:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104201.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  63%|███▊  | 471/744 [30:02<17:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88827.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  63%|███▊  | 472/744 [30:05<17:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99381.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  64%|███▊  | 473/744 [30:10<17:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96188.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  64%|███▊  | 474/744 [30:13<17:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89451.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  64%|███▊  | 475/744 [30:17<17:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101993.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  64%|███▊  | 476/744 [30:21<17:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96891.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  64%|███▊  | 477/744 [30:24<17:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90004.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  64%|███▊  | 478/744 [30:28<16:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104949.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  64%|███▊  | 479/744 [30:32<16:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105619.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  65%|███▊  | 480/744 [30:36<16:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87639.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  65%|███▉  | 481/744 [30:39<16:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92275.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8909, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  65%|███▉  | 482/744 [30:43<16:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103936.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  65%|███▉  | 483/744 [30:47<16:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92917.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  65%|███▉  | 484/744 [30:51<16:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98474.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  65%|███▉  | 485/744 [30:55<16:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100864.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  65%|███▉  | 486/744 [30:59<16:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93390.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  65%|███▉  | 487/744 [31:03<16:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91004.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  66%|███▉  | 488/744 [31:07<16:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106674.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  66%|███▉  | 489/744 [31:11<16:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94333.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  66%|███▉  | 490/744 [31:15<16:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111618.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  66%|███▉  | 491/744 [31:19<16:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103074.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  66%|███▉  | 492/744 [31:23<16:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99058.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  66%|███▉  | 493/744 [31:26<16:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102232.8125, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(1.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  66%|███▉  | 494/744 [31:30<15:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108503.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  67%|███▉  | 495/744 [31:34<15:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107668.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  67%|████  | 496/744 [31:38<15:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95936.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  67%|████  | 497/744 [31:42<15:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82090.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  67%|████  | 498/744 [31:45<15:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99329.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  67%|████  | 499/744 [31:49<15:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106254.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  67%|████  | 500/744 [31:53<15:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92095.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  67%|████  | 501/744 [31:57<15:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112379.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  67%|████  | 502/744 [32:01<15:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97219.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  68%|████  | 503/744 [32:04<15:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100586.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  68%|████  | 504/744 [32:08<15:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95936.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  68%|████  | 505/744 [32:13<15:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95493.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  68%|████  | 506/744 [32:16<15:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97571.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  68%|████  | 507/744 [32:20<15:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112133.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  68%|████  | 508/744 [32:24<15:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98127.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  68%|████  | 509/744 [32:28<14:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99667.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  69%|████  | 510/744 [32:32<14:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102444.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  69%|████  | 511/744 [32:36<14:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101375.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  69%|████▏ | 512/744 [32:40<14:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101986.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  69%|████▏ | 513/744 [32:44<14:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99412.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  69%|████▏ | 514/744 [32:48<14:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95356.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  69%|████▏ | 515/744 [32:51<14:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93836.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  69%|████▏ | 516/744 [32:56<14:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(79106.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  69%|████▏ | 517/744 [32:59<14:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98962.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  70%|████▏ | 518/744 [33:03<14:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111015.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  70%|████▏ | 519/744 [33:07<14:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91447.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  70%|████▏ | 520/744 [33:11<14:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100101.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  70%|████▏ | 521/744 [33:14<14:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100391.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  70%|████▏ | 522/744 [33:18<14:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85395.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  70%|████▏ | 523/744 [33:22<14:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102539.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  70%|████▏ | 524/744 [33:26<14:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102606.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  71%|████▏ | 525/744 [33:29<13:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96066.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  71%|████▏ | 526/744 [33:33<13:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82942.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  71%|████▎ | 527/744 [33:37<13:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99927.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  71%|████▎ | 528/744 [33:41<13:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95350.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  71%|████▎ | 529/744 [33:45<13:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106516.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  71%|████▎ | 530/744 [33:49<13:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107670.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  71%|████▎ | 531/744 [33:53<13:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97791.6953, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(1.0690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  72%|████▎ | 532/744 [33:57<13:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88607.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  72%|████▎ | 533/744 [34:01<13:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91582.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  72%|████▎ | 534/744 [34:04<13:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107431.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  72%|████▎ | 535/744 [34:08<13:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103470.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  72%|████▎ | 536/744 [34:12<13:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93469.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  72%|████▎ | 537/744 [34:16<13:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100148.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  72%|████▎ | 538/744 [34:20<13:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89422.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  72%|████▎ | 539/744 [34:24<13:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109858.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  73%|████▎ | 540/744 [34:28<13:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93351.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  73%|████▎ | 541/744 [34:31<12:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99676.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  73%|████▎ | 542/744 [34:35<12:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96814.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  73%|████▍ | 543/744 [34:39<12:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96693.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  73%|████▍ | 544/744 [34:42<12:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100218.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  73%|████▍ | 545/744 [34:46<12:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102439.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  73%|████▍ | 546/744 [34:50<12:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97267.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  74%|████▍ | 547/744 [34:54<12:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97385.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  74%|████▍ | 548/744 [34:58<12:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89399.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  74%|████▍ | 549/744 [35:01<12:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78624.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  74%|████▍ | 550/744 [35:05<12:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101514.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  74%|████▍ | 551/744 [35:09<12:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105117.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  74%|████▍ | 552/744 [35:13<12:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106137.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  74%|████▍ | 553/744 [35:17<12:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97040.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  74%|████▍ | 554/744 [35:20<12:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108740.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  75%|████▍ | 555/744 [35:24<12:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95400.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  75%|████▍ | 556/744 [35:28<11:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101028.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  75%|████▍ | 557/744 [35:32<11:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102264.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0070, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  75%|████▌ | 558/744 [35:36<11:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96847.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8739, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  75%|████▌ | 559/744 [35:40<11:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88655.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  75%|████▌ | 560/744 [35:43<11:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99186.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  75%|████▌ | 561/744 [35:47<11:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96181.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  76%|████▌ | 562/744 [35:52<11:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95457.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  76%|████▌ | 563/744 [35:55<11:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91626.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  76%|████▌ | 564/744 [35:59<11:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101426.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  76%|████▌ | 565/744 [36:03<11:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89885.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  76%|████▌ | 566/744 [36:07<11:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106578.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  76%|████▌ | 567/744 [36:11<11:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95644.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  76%|████▌ | 568/744 [36:14<11:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101637.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  76%|████▌ | 569/744 [36:18<11:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99776.1328, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  77%|████▌ | 570/744 [36:22<11:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94215.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  77%|████▌ | 571/744 [36:25<11:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102598.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  77%|████▌ | 572/744 [36:29<10:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100991.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  77%|████▌ | 573/744 [36:33<10:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82974.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  77%|████▋ | 574/744 [36:36<10:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111762.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  77%|████▋ | 575/744 [36:40<10:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94721.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  77%|████▋ | 576/744 [36:44<10:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91556.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  78%|████▋ | 577/744 [36:47<10:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99507.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  78%|████▋ | 578/744 [36:52<10:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100191.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  78%|████▋ | 579/744 [36:55<10:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109992.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  78%|████▋ | 580/744 [36:59<10:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90189.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  78%|████▋ | 581/744 [37:03<10:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97121.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  78%|████▋ | 582/744 [37:07<10:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97858.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  78%|████▋ | 583/744 [37:11<10:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112185.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  78%|████▋ | 584/744 [37:15<10:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105097.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  79%|████▋ | 585/744 [37:19<10:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103062.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  79%|████▋ | 586/744 [37:23<10:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98576.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  79%|████▋ | 587/744 [37:26<10:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88990.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  79%|████▋ | 588/744 [37:30<09:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96488.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  79%|████▊ | 589/744 [37:34<09:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101418.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  79%|████▊ | 590/744 [37:37<09:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105135.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  79%|████▊ | 591/744 [37:41<09:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110512.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  80%|████▊ | 592/744 [37:45<09:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113527.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  80%|████▊ | 593/744 [37:49<09:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96976.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  80%|████▊ | 594/744 [37:52<09:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101217.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  80%|████▊ | 595/744 [37:56<09:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101709.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  80%|████▊ | 596/744 [38:00<09:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107677.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  80%|████▊ | 597/744 [38:04<09:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93299.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  80%|████▊ | 598/744 [38:08<09:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92751.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  81%|████▊ | 599/744 [38:12<09:14,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103983.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  81%|████▊ | 600/744 [38:16<09:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95231.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  81%|████▊ | 601/744 [38:20<09:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96584.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  81%|████▊ | 602/744 [38:23<09:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98083.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  81%|████▊ | 603/744 [38:27<08:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97461.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  81%|████▊ | 604/744 [38:31<08:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99081.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  81%|████▉ | 605/744 [38:34<08:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107567.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  81%|████▉ | 606/744 [38:38<08:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107856.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  82%|████▉ | 607/744 [38:42<08:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97132.9141, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  82%|████▉ | 608/744 [38:46<08:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96697.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  82%|████▉ | 609/744 [38:49<08:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95557.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  82%|████▉ | 610/744 [38:53<08:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95843.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  82%|████▉ | 611/744 [38:57<08:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101760.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  82%|████▉ | 612/744 [39:01<08:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95254.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  82%|████▉ | 613/744 [39:04<08:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96396.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  83%|████▉ | 614/744 [39:08<08:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98781.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  83%|████▉ | 615/744 [39:12<08:13,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102814.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  83%|████▉ | 616/744 [39:15<08:09,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93510.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  83%|████▉ | 617/744 [39:19<08:05,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110788.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  83%|████▉ | 618/744 [39:23<08:01,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96898.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  83%|████▉ | 619/744 [39:27<07:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85871.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  83%|█████ | 620/744 [39:31<07:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87442.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  83%|█████ | 621/744 [39:35<07:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92457.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  84%|█████ | 622/744 [39:39<07:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92351.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  84%|█████ | 623/744 [39:42<07:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94266.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  84%|█████ | 624/744 [39:46<07:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91785.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  84%|█████ | 625/744 [39:50<07:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91551.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  84%|█████ | 626/744 [39:54<07:31,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90169.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  84%|█████ | 627/744 [39:57<07:27,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84586.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  84%|█████ | 628/744 [40:01<07:23,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96243.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  85%|█████ | 629/744 [40:05<07:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98566.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  85%|█████ | 630/744 [40:08<07:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117500.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  85%|█████ | 631/744 [40:12<07:12,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102845.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  85%|█████ | 632/744 [40:16<07:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98094.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  85%|█████ | 633/744 [40:20<07:04,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93726.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  85%|█████ | 634/744 [40:24<07:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104686.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  85%|█████ | 635/744 [40:27<06:56,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96130.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  85%|█████▏| 636/744 [40:31<06:52,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101269.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  86%|█████▏| 637/744 [40:35<06:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101305.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  86%|█████▏| 638/744 [40:39<06:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104132.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  86%|█████▏| 639/744 [40:43<06:41,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90450.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  86%|█████▏| 640/744 [40:46<06:37,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104969.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  86%|█████▏| 641/744 [40:50<06:33,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95447.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  86%|█████▏| 642/744 [40:54<06:29,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103326.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  86%|█████▏| 643/744 [40:58<06:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99303.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  87%|█████▏| 644/744 [41:01<06:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106256.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  87%|█████▏| 645/744 [41:05<06:18,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101892.2031, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  87%|█████▏| 646/744 [41:09<06:14,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97697.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  87%|█████▏| 647/744 [41:13<06:10,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90946.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  87%|█████▏| 648/744 [41:17<06:06,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104928.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  87%|█████▏| 649/744 [41:20<06:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96991.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  87%|█████▏| 650/744 [41:24<05:59,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96692.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  88%|█████▎| 651/744 [41:28<05:55,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107718.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  88%|█████▎| 652/744 [41:32<05:51,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105863.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  88%|█████▎| 653/744 [41:36<05:47,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88552.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  88%|█████▎| 654/744 [41:40<05:44,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91256.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  88%|█████▎| 655/744 [41:43<05:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100336.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  88%|█████▎| 656/744 [41:47<05:36,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105147.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  88%|█████▎| 657/744 [41:51<05:32,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90429.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  88%|█████▎| 658/744 [41:55<05:28,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94494.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  89%|█████▎| 659/744 [41:59<05:24,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98023.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  89%|█████▎| 660/744 [42:03<05:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93885.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  89%|█████▎| 661/744 [42:06<05:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94805.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  89%|█████▎| 662/744 [42:10<05:13,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99939.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  89%|█████▎| 663/744 [42:14<05:09,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101902.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  89%|█████▎| 664/744 [42:18<05:05,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109996.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  89%|█████▎| 665/744 [42:22<05:02,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94689.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  90%|█████▎| 666/744 [42:25<04:58,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113902.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  90%|█████▍| 667/744 [42:29<04:54,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95368.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  90%|█████▍| 668/744 [42:33<04:50,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101544.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  90%|█████▍| 669/744 [42:37<04:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98232.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  90%|█████▍| 670/744 [42:40<04:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111471.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  90%|█████▍| 671/744 [42:44<04:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99592.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  90%|█████▍| 672/744 [42:48<04:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97216.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  90%|█████▍| 673/744 [42:52<04:31,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103357.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  91%|█████▍| 674/744 [42:56<04:27,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100232.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  91%|█████▍| 675/744 [43:00<04:23,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105170.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  91%|█████▍| 676/744 [43:04<04:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103325.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  91%|█████▍| 677/744 [43:08<04:16,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96334.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  91%|█████▍| 678/744 [43:11<04:12,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110221.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  91%|█████▍| 679/744 [43:15<04:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96866.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  91%|█████▍| 680/744 [43:19<04:04,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100332.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  92%|█████▍| 681/744 [43:23<04:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105616.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  92%|█████▌| 682/744 [43:27<03:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109509.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  92%|█████▌| 683/744 [43:31<03:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97182.3438, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  92%|█████▌| 684/744 [43:35<03:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113631.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  92%|█████▌| 685/744 [43:38<03:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102810.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  92%|█████▌| 686/744 [43:42<03:41,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105408.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  92%|█████▌| 687/744 [43:46<03:37,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109802.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  92%|█████▌| 688/744 [43:50<03:34,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103288.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  93%|█████▌| 689/744 [43:54<03:30,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102170.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  93%|█████▌| 690/744 [43:58<03:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102854.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  93%|█████▌| 691/744 [44:02<03:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91704.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  93%|█████▌| 692/744 [44:06<03:18,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103323.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  93%|█████▌| 693/744 [44:09<03:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107006.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  93%|█████▌| 694/744 [44:13<03:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91911.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  93%|█████▌| 695/744 [44:17<03:07,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106518.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  94%|█████▌| 696/744 [44:21<03:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92697.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  94%|█████▌| 697/744 [44:25<02:59,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98028.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  94%|█████▋| 698/744 [44:29<02:55,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102826.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  94%|█████▋| 699/744 [44:32<02:52,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96528.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  94%|█████▋| 700/744 [44:36<02:48,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109693.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  94%|█████▋| 701/744 [44:40<02:44,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93604.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  94%|█████▋| 702/744 [44:44<02:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105968.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  94%|█████▋| 703/744 [44:48<02:36,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105416.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  95%|█████▋| 704/744 [44:51<02:32,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103560.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  95%|█████▋| 705/744 [44:55<02:29,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97045.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  95%|█████▋| 706/744 [44:59<02:25,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98013.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  95%|█████▋| 707/744 [45:03<02:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98788.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  95%|█████▋| 708/744 [45:07<02:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102028.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  95%|█████▋| 709/744 [45:11<02:13,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102082.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  95%|█████▋| 710/744 [45:14<02:10,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92636.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  96%|█████▋| 711/744 [45:18<02:06,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93427.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  96%|█████▋| 712/744 [45:22<02:02,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92109.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  96%|█████▊| 713/744 [45:26<01:58,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94407.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  96%|█████▊| 714/744 [45:30<01:54,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100888.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  96%|█████▊| 715/744 [45:34<01:50,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95540.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  96%|█████▊| 716/744 [45:38<01:47,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102511.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  96%|█████▊| 717/744 [45:41<01:43,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106463.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  97%|█████▊| 718/744 [45:45<01:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111182.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  97%|█████▊| 719/744 [45:49<01:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91047.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  97%|█████▊| 720/744 [45:52<01:31,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101765.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  97%|█████▊| 721/744 [45:56<01:27,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95064.2734, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  97%|█████▊| 722/744 [46:00<01:24,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99649.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  97%|█████▊| 723/744 [46:04<01:20,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98425.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  97%|█████▊| 724/744 [46:07<01:16,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100562.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  97%|█████▊| 725/744 [46:11<01:12,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103026.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  98%|█████▊| 726/744 [46:15<01:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97980.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  98%|█████▊| 727/744 [46:19<01:04,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106330.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  98%|█████▊| 728/744 [46:23<01:01,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92365.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  98%|█████▉| 729/744 [46:26<00:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80769.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  98%|█████▉| 730/744 [46:30<00:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90229.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  98%|█████▉| 731/744 [46:34<00:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113834.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  98%|█████▉| 732/744 [46:37<00:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92706.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  99%|█████▉| 733/744 [46:41<00:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100702.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  99%|█████▉| 734/744 [46:45<00:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92560.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  99%|█████▉| 735/744 [46:49<00:34,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105153.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  99%|█████▉| 736/744 [46:53<00:30,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99744.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  99%|█████▉| 737/744 [46:57<00:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103104.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  99%|█████▉| 738/744 [47:01<00:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104805.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  99%|█████▉| 739/744 [47:04<00:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105177.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15:  99%|█████▉| 740/744 [47:08<00:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98771.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15: 100%|█████▉| 741/744 [47:12<00:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98219.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15: 100%|█████▉| 742/744 [47:16<00:07,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108324.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15: 100%|█████▉| 743/744 [47:20<00:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107806.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   0%|                | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(107886.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   0%|      | 1/744 [00:05<1:06:28,  5.37s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99177.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   0%|        | 2/744 [00:09<55:40,  4.50s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101315.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   0%|        | 3/744 [00:12<52:17,  4.23s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99737.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   1%|        | 4/744 [00:16<49:59,  4.05s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89038.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   1%|        | 5/744 [00:20<49:23,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89231.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8652, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   1%|        | 6/744 [00:23<48:20,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100831.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   1%|        | 7/744 [00:27<47:34,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100632.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   1%|        | 8/744 [00:30<47:18,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94367.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   1%|        | 9/744 [00:34<47:06,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102005.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   1%|       | 10/744 [00:38<47:29,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95244.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   1%|       | 11/744 [00:42<47:26,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106233.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   2%|       | 12/744 [00:46<47:03,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104965.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   2%|       | 13/744 [00:49<46:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104046.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   2%|▏      | 14/744 [00:53<46:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102554.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   2%|▏      | 15/744 [00:57<46:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112265.4375, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   2%|▏      | 16/744 [01:01<46:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109923.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   2%|▏      | 17/744 [01:05<46:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93106.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   2%|▏      | 18/744 [01:08<46:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104279.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   3%|▏      | 19/744 [01:12<46:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108090.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   3%|▏      | 20/744 [01:16<46:05,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99748.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   3%|▏      | 21/744 [01:20<46:02,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106453.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   3%|▏      | 22/744 [01:24<46:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113160.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   3%|▏      | 23/744 [01:28<46:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94858.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   3%|▏      | 24/744 [01:31<45:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92467.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8070, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   3%|▏      | 25/744 [01:35<45:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103477.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   3%|▏      | 26/744 [01:39<45:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87048.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   4%|▎      | 27/744 [01:43<45:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(87728.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   4%|▎      | 28/744 [01:47<45:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92291.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   4%|▎      | 29/744 [01:50<45:32,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104477.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9103, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   4%|▎      | 30/744 [01:54<45:24,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95311.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   4%|▎      | 31/744 [01:58<45:20,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98453.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   4%|▎      | 32/744 [02:02<45:16,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108973.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   4%|▎      | 33/744 [02:05<45:14,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98566.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   5%|▎      | 34/744 [02:09<45:12,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103103.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   5%|▎      | 35/744 [02:13<45:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92493.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   5%|▎      | 36/744 [02:17<45:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111955.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8080, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   5%|▎      | 37/744 [02:21<45:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107761.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   5%|▎      | 38/744 [02:25<44:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106298.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   5%|▎      | 39/744 [02:28<44:52,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102653.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   5%|▍      | 40/744 [02:32<44:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99409.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   6%|▍      | 41/744 [02:36<44:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104058., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   6%|▍      | 42/744 [02:40<44:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103573.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   6%|▍      | 43/744 [02:44<44:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109320.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   6%|▍      | 44/744 [02:47<44:26,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96607.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   6%|▍      | 45/744 [02:51<44:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102104.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   6%|▍      | 46/744 [02:55<44:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92486.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   6%|▍      | 47/744 [02:59<44:16,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102453.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   6%|▍      | 48/744 [03:02<44:11,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95192.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   7%|▍      | 49/744 [03:06<44:07,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99898.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   7%|▍      | 50/744 [03:10<44:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97248.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   7%|▍      | 51/744 [03:14<43:56,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107247.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   7%|▍      | 52/744 [03:17<43:52,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100914.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   7%|▍      | 53/744 [03:21<43:48,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102587.2109, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   7%|▌      | 54/744 [03:25<43:48,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115301.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   7%|▌      | 55/744 [03:29<43:44,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99914.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   8%|▌      | 56/744 [03:33<43:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97943.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   8%|▌      | 57/744 [03:36<43:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101157.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   8%|▌      | 58/744 [03:40<43:30,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103035.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   8%|▌      | 59/744 [03:44<43:25,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94741.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   8%|▌      | 60/744 [03:48<43:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103223.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   8%|▌      | 61/744 [03:52<43:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94166.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   8%|▌      | 62/744 [03:55<43:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101035.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   8%|▌      | 63/744 [03:59<43:10,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103594.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   9%|▌      | 64/744 [04:03<43:06,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105268.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   9%|▌      | 65/744 [04:07<43:03,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102957.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   9%|▌      | 66/744 [04:11<42:58,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105280.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   9%|▋      | 67/744 [04:14<42:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102211.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   9%|▋      | 68/744 [04:18<42:53,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107401.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   9%|▋      | 69/744 [04:22<42:49,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95308.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:   9%|▋      | 70/744 [04:26<42:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98850.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  10%|▋      | 71/744 [04:30<42:40,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98140.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  10%|▋      | 72/744 [04:33<42:34,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107987.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  10%|▋      | 73/744 [04:37<42:31,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90869.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8998, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  10%|▋      | 74/744 [04:41<42:24,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102677.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  10%|▋      | 75/744 [04:45<42:24,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105285.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  10%|▋      | 76/744 [04:49<42:22,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97332.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  10%|▋      | 77/744 [04:53<42:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99610.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  10%|▋      | 78/744 [04:56<42:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93193.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  11%|▋      | 79/744 [05:00<42:09,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96084.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  11%|▊      | 80/744 [05:04<42:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98860.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  11%|▊      | 81/744 [05:08<42:04,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109981.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9277, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  11%|▊      | 82/744 [05:12<42:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93144.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  11%|▊      | 83/744 [05:16<41:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108123.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  11%|▊      | 84/744 [05:19<41:53,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100512.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  11%|▊      | 85/744 [05:23<41:48,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112229.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  12%|▊      | 86/744 [05:27<41:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109372.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  12%|▊      | 87/744 [05:31<41:41,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111264.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  12%|▊      | 88/744 [05:34<41:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107221.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  12%|▊      | 89/744 [05:39<41:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105968.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  12%|▊      | 90/744 [05:43<41:33,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110047.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  12%|▊      | 91/744 [05:46<41:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110440.1562, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  12%|▊      | 92/744 [05:50<41:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102490.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  12%|▉      | 93/744 [05:54<41:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94761.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  13%|▉      | 94/744 [05:57<41:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97975.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  13%|▉      | 95/744 [06:01<41:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103472.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  13%|▉      | 96/744 [06:05<41:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97227.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  13%|▉      | 97/744 [06:09<41:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95427.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  13%|▉      | 98/744 [06:13<40:59,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107294.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  13%|▉      | 99/744 [06:17<40:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95411.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  13%|▊     | 100/744 [06:20<40:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103962.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  14%|▊     | 101/744 [06:24<40:47,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101220.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  14%|▊     | 102/744 [06:28<40:44,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89706., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  14%|▊     | 103/744 [06:32<40:41,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102552.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  14%|▊     | 104/744 [06:36<40:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100112.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  14%|▊     | 105/744 [06:39<40:33,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114170.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  14%|▊     | 106/744 [06:43<40:30,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107593.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  14%|▊     | 107/744 [06:47<40:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101393.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  15%|▊     | 108/744 [06:51<40:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105596.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  15%|▉     | 109/744 [06:55<40:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97955.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  15%|▉     | 110/744 [06:59<40:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113368.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  15%|▉     | 111/744 [07:03<40:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108621.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  15%|▉     | 112/744 [07:07<40:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97485.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  15%|▉     | 113/744 [07:11<40:07,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104578.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  15%|▉     | 114/744 [07:14<40:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101372.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  15%|▉     | 115/744 [07:18<40:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98437.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  16%|▉     | 116/744 [07:22<39:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99858.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  16%|▉     | 117/744 [07:26<39:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102465.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  16%|▉     | 118/744 [07:30<39:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104655.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  16%|▉     | 119/744 [07:34<39:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106015.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  16%|▉     | 120/744 [07:38<39:43,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98764.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  16%|▉     | 121/744 [07:42<39:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101652.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  16%|▉     | 122/744 [07:46<39:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104543.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  17%|▉     | 123/744 [07:51<39:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101475.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  17%|█     | 124/744 [07:54<39:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102350.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  17%|█     | 125/744 [07:58<39:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104179.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  17%|█     | 126/744 [08:02<39:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103580.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  17%|█     | 127/744 [08:06<39:22,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98667., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  17%|█     | 128/744 [08:10<39:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101089.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  17%|█     | 129/744 [08:13<39:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104489.7500, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  17%|█     | 130/744 [08:17<39:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99136.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  18%|█     | 131/744 [08:21<39:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96348.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8863, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  18%|█     | 132/744 [08:25<39:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96430.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  18%|█     | 133/744 [08:29<39:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97620.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  18%|█     | 134/744 [08:33<38:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113763.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  18%|█     | 135/744 [08:37<38:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94007.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  18%|█     | 136/744 [08:41<38:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94586.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  18%|█     | 137/744 [08:44<38:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100963.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  19%|█     | 138/744 [08:48<38:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105163.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  19%|█     | 139/744 [08:52<38:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100503.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  19%|█▏    | 140/744 [08:56<38:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109383.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  19%|█▏    | 141/744 [08:59<38:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109569.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  19%|█▏    | 142/744 [09:03<38:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93073.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  19%|█▏    | 143/744 [09:07<38:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98137.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  19%|█▏    | 144/744 [09:11<38:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101283.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  19%|█▏    | 145/744 [09:14<38:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93387.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  20%|█▏    | 146/744 [09:18<38:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96774.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  20%|█▏    | 147/744 [09:22<38:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98934.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  20%|█▏    | 148/744 [09:26<38:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105354.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  20%|█▏    | 149/744 [09:30<37:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98415.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  20%|█▏    | 150/744 [09:34<37:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109809.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  20%|█▏    | 151/744 [09:38<37:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105054.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8999, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  20%|█▏    | 152/744 [09:41<37:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104736.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  21%|█▏    | 153/744 [09:45<37:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105468.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  21%|█▏    | 154/744 [09:49<37:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100062.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  21%|█▎    | 155/744 [09:53<37:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107792.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  21%|█▎    | 156/744 [09:57<37:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100786.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  21%|█▎    | 157/744 [10:01<37:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106345.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  21%|█▎    | 158/744 [10:05<37:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104535.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  21%|█▎    | 159/744 [10:09<37:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98668.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  22%|█▎    | 160/744 [10:13<37:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97683.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  22%|█▎    | 161/744 [10:17<37:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111869.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  22%|█▎    | 162/744 [10:21<37:12,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84087.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  22%|█▎    | 163/744 [10:25<37:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93637.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  22%|█▎    | 164/744 [10:29<37:05,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103606.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  22%|█▎    | 165/744 [10:33<37:01,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91087., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  22%|█▎    | 166/744 [10:37<36:58,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110437.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  22%|█▎    | 167/744 [10:40<36:54,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107318.3672, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  23%|█▎    | 168/744 [10:44<36:50,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106216.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  23%|█▎    | 169/744 [10:48<36:46,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99863.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  23%|█▎    | 170/744 [10:52<36:42,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97768.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  23%|█▍    | 171/744 [10:56<36:38,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95535.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  23%|█▍    | 172/744 [10:59<36:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110505.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  23%|█▍    | 173/744 [11:03<36:30,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111519.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  23%|█▍    | 174/744 [11:07<36:27,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111486.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  24%|█▍    | 175/744 [11:11<36:23,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111105.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  24%|█▍    | 176/744 [11:15<36:19,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101155.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  24%|█▍    | 177/744 [11:19<36:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104251.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  24%|█▍    | 178/744 [11:22<36:11,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98971.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  24%|█▍    | 179/744 [11:26<36:07,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99190.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  24%|█▍    | 180/744 [11:30<36:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103008.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  24%|█▍    | 181/744 [11:34<35:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109475.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  24%|█▍    | 182/744 [11:38<35:55,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107648.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  25%|█▍    | 183/744 [11:41<35:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99080.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  25%|█▍    | 184/744 [11:45<35:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105461.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  25%|█▍    | 185/744 [11:49<35:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108100.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  25%|█▌    | 186/744 [11:53<35:40,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105767.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  25%|█▌    | 187/744 [11:57<35:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103623.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  25%|█▌    | 188/744 [12:00<35:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94807.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  25%|█▌    | 189/744 [12:04<35:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110806.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  26%|█▌    | 190/744 [12:08<35:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107548.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  26%|█▌    | 191/744 [12:11<35:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100539.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9125, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  26%|█▌    | 192/744 [12:15<35:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102262.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  26%|█▌    | 193/744 [12:19<35:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115180.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  26%|█▌    | 194/744 [12:23<35:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95210.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  26%|█▌    | 195/744 [12:27<35:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105664.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  26%|█▌    | 196/744 [12:30<34:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94702.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  26%|█▌    | 197/744 [12:34<34:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106945.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  27%|█▌    | 198/744 [12:38<34:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108828.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  27%|█▌    | 199/744 [12:41<34:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100315.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  27%|█▌    | 200/744 [12:45<34:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104898.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  27%|█▌    | 201/744 [12:49<34:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107307.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  27%|█▋    | 202/744 [12:53<34:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94019.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  27%|█▋    | 203/744 [12:57<34:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105824.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  27%|█▋    | 204/744 [13:01<34:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108207.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  28%|█▋    | 205/744 [13:05<34:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88266.7031, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  28%|█▋    | 206/744 [13:08<34:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99389.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  28%|█▋    | 207/744 [13:12<34:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101522.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  28%|█▋    | 208/744 [13:16<34:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98532.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  28%|█▋    | 209/744 [13:20<34:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106414.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  28%|█▋    | 210/744 [13:23<34:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93059.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  28%|█▋    | 211/744 [13:27<33:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94203.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  28%|█▋    | 212/744 [13:31<33:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90476.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  29%|█▋    | 213/744 [13:34<33:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98772.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  29%|█▋    | 214/744 [13:38<33:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98443.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  29%|█▋    | 215/744 [13:42<33:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95918.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  29%|█▋    | 216/744 [13:46<33:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107346.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  29%|█▊    | 217/744 [13:50<33:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103293.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  29%|█▊    | 218/744 [13:54<33:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102549.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  29%|█▊    | 219/744 [13:58<33:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114664.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  30%|█▊    | 220/744 [14:01<33:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103289.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  30%|█▊    | 221/744 [14:05<33:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110978.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  30%|█▊    | 222/744 [14:09<33:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114211.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  30%|█▊    | 223/744 [14:13<33:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105086.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  30%|█▊    | 224/744 [14:16<33:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106586.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  30%|█▊    | 225/744 [14:20<33:05,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99835.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  30%|█▊    | 226/744 [14:24<33:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104631.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  31%|█▊    | 227/744 [14:28<32:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109761.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  31%|█▊    | 228/744 [14:32<32:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93671.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  31%|█▊    | 229/744 [14:36<32:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95197.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  31%|█▊    | 230/744 [14:39<32:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102923.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  31%|█▊    | 231/744 [14:43<32:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105193.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  31%|█▊    | 232/744 [14:47<32:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96545.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  31%|█▉    | 233/744 [14:51<32:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(84562.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  31%|█▉    | 234/744 [14:55<32:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105163.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  32%|█▉    | 235/744 [14:59<32:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105121.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  32%|█▉    | 236/744 [15:02<32:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99155.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  32%|█▉    | 237/744 [15:06<32:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103782.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  32%|█▉    | 238/744 [15:10<32:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103538.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  32%|█▉    | 239/744 [15:14<32:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116553.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  32%|█▉    | 240/744 [15:18<32:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98778.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  32%|█▉    | 241/744 [15:22<32:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102632.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  33%|█▉    | 242/744 [15:26<32:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112793.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  33%|█▉    | 243/744 [15:30<31:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91368.1094, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  33%|█▉    | 244/744 [15:33<31:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103180.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  33%|█▉    | 245/744 [15:37<31:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111193.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  33%|█▉    | 246/744 [15:41<31:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106072.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  33%|█▉    | 247/744 [15:45<31:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98639.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  33%|██    | 248/744 [15:49<31:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113787.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  33%|██    | 249/744 [15:53<31:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103208.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  34%|██    | 250/744 [15:56<31:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113069.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  34%|██    | 251/744 [16:00<31:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102366.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  34%|██    | 252/744 [16:04<31:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97748.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  34%|██    | 253/744 [16:08<31:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103360.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  34%|██    | 254/744 [16:12<31:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90584.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  34%|██    | 255/744 [16:15<31:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105569.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  34%|██    | 256/744 [16:19<31:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105282.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  35%|██    | 257/744 [16:23<31:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98312.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  35%|██    | 258/744 [16:27<31:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103099.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  35%|██    | 259/744 [16:31<30:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107453.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  35%|██    | 260/744 [16:35<30:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99026.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  35%|██    | 261/744 [16:39<30:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102133.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  35%|██    | 262/744 [16:42<30:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102369.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  35%|██    | 263/744 [16:46<30:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101785.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  35%|██▏   | 264/744 [16:50<30:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104248.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  36%|██▏   | 265/744 [16:54<30:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107118.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  36%|██▏   | 266/744 [16:58<30:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96759.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  36%|██▏   | 267/744 [17:01<30:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104182.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9673, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  36%|██▏   | 268/744 [17:05<30:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105206.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  36%|██▏   | 269/744 [17:09<30:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108249.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  36%|██▏   | 270/744 [17:13<30:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107744.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  36%|██▏   | 271/744 [17:17<30:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92120.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  37%|██▏   | 272/744 [17:20<30:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90026.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  37%|██▏   | 273/744 [17:24<30:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107157.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  37%|██▏   | 274/744 [17:28<29:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91821.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  37%|██▏   | 275/744 [17:32<29:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97453.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  37%|██▏   | 276/744 [17:35<29:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98227.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  37%|██▏   | 277/744 [17:39<29:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105236.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  37%|██▏   | 278/744 [17:43<29:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106355.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  38%|██▎   | 279/744 [17:47<29:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99844.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  38%|██▎   | 280/744 [17:51<29:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99856.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  38%|██▎   | 281/744 [17:55<29:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94505.2031, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  38%|██▎   | 282/744 [17:59<29:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96859.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  38%|██▎   | 283/744 [18:02<29:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107432.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  38%|██▎   | 284/744 [18:06<29:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104012.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  38%|██▎   | 285/744 [18:10<29:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101908.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  38%|██▎   | 286/744 [18:14<29:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112479.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  39%|██▎   | 287/744 [18:18<29:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93005.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  39%|██▎   | 288/744 [18:21<29:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105643.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  39%|██▎   | 289/744 [18:25<29:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102686.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8632, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  39%|██▎   | 290/744 [18:29<28:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108851.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  39%|██▎   | 291/744 [18:33<28:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89114.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  39%|██▎   | 292/744 [18:37<28:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104893.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  39%|██▎   | 293/744 [18:40<28:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98939.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  40%|██▎   | 294/744 [18:44<28:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91091.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  40%|██▍   | 295/744 [18:48<28:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112665.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  40%|██▍   | 296/744 [18:52<28:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94865.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  40%|██▍   | 297/744 [18:56<28:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102787.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  40%|██▍   | 298/744 [18:59<28:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105995.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  40%|██▍   | 299/744 [19:03<28:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111379.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  40%|██▍   | 300/744 [19:07<28:18,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104239.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  40%|██▍   | 301/744 [19:11<28:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98106.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  41%|██▍   | 302/744 [19:15<28:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109990.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  41%|██▍   | 303/744 [19:19<28:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98427.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  41%|██▍   | 304/744 [19:23<28:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97371.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  41%|██▍   | 305/744 [19:26<27:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106976.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  41%|██▍   | 306/744 [19:30<27:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107718.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8739, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  41%|██▍   | 307/744 [19:34<27:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107748.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  41%|██▍   | 308/744 [19:38<27:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99627.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  42%|██▍   | 309/744 [19:42<27:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99826.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  42%|██▌   | 310/744 [19:46<27:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105093.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  42%|██▌   | 311/744 [19:50<27:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101568.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  42%|██▌   | 312/744 [19:53<27:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97787.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  42%|██▌   | 313/744 [19:57<27:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94125.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  42%|██▌   | 314/744 [20:01<27:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111058.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  42%|██▌   | 315/744 [20:05<27:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80993.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  42%|██▌   | 316/744 [20:09<27:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112913., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  43%|██▌   | 317/744 [20:12<27:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86152.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  43%|██▌   | 318/744 [20:16<27:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105392.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  43%|██▌   | 319/744 [20:20<27:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100280.3828, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  43%|██▌   | 320/744 [20:24<27:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99116.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  43%|██▌   | 321/744 [20:27<26:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96943.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  43%|██▌   | 322/744 [20:31<26:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100819.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  43%|██▌   | 323/744 [20:35<26:50,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105525.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  44%|██▌   | 324/744 [20:39<26:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106323.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  44%|██▌   | 325/744 [20:42<26:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106645.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  44%|██▋   | 326/744 [20:46<26:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97158.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  44%|██▋   | 327/744 [20:50<26:34,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99574.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  44%|██▋   | 328/744 [20:54<26:30,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111075.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  44%|██▋   | 329/744 [20:58<26:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111455.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  44%|██▋   | 330/744 [21:01<26:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111256.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  44%|██▋   | 331/744 [21:05<26:18,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104454.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  45%|██▋   | 332/744 [21:09<26:14,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103635.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  45%|██▋   | 333/744 [21:13<26:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106372.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  45%|██▋   | 334/744 [21:16<26:07,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94588.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  45%|██▋   | 335/744 [21:20<26:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107867.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  45%|██▋   | 336/744 [21:24<25:59,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106252.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  45%|██▋   | 337/744 [21:28<25:56,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109973.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  45%|██▋   | 338/744 [21:32<25:52,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108461.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  46%|██▋   | 339/744 [21:36<25:48,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104954.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  46%|██▋   | 340/744 [21:39<25:44,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104051.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  46%|██▊   | 341/744 [21:43<25:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102817.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  46%|██▊   | 342/744 [21:47<25:36,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91335., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  46%|██▊   | 343/744 [21:51<25:33,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107299.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  46%|██▊   | 344/744 [21:55<25:29,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102077.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  46%|██▊   | 345/744 [21:58<25:25,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98198.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  47%|██▊   | 346/744 [22:02<25:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107491.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  47%|██▊   | 347/744 [22:06<25:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99734.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  47%|██▊   | 348/744 [22:10<25:13,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119842.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  47%|██▊   | 349/744 [22:14<25:10,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113320.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  47%|██▊   | 350/744 [22:18<25:06,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98105.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  47%|██▊   | 351/744 [22:22<25:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98815.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  47%|██▊   | 352/744 [22:26<24:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114053.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  47%|██▊   | 353/744 [22:29<24:55,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92378.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  48%|██▊   | 354/744 [22:33<24:51,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106579.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  48%|██▊   | 355/744 [22:37<24:47,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105153.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  48%|██▊   | 356/744 [22:40<24:43,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99753.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  48%|██▉   | 357/744 [22:45<24:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92011.4766, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  48%|██▉   | 358/744 [22:49<24:36,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99504.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  48%|██▉   | 359/744 [22:52<24:32,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99230.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  48%|██▉   | 360/744 [22:56<24:28,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107625.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9909, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  49%|██▉   | 361/744 [23:00<24:24,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107513.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  49%|██▉   | 362/744 [23:04<24:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100719.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  49%|██▉   | 363/744 [23:08<24:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86127.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  49%|██▉   | 364/744 [23:12<24:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106653.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  49%|██▉   | 365/744 [23:16<24:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102339.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  49%|██▉   | 366/744 [23:19<24:05,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94129.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  49%|██▉   | 367/744 [23:23<24:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107480.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  49%|██▉   | 368/744 [23:27<23:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109502.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  50%|██▉   | 369/744 [23:31<23:54,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107951.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  50%|██▉   | 370/744 [23:35<23:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105236.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  50%|██▉   | 371/744 [23:39<23:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100845.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  50%|███   | 372/744 [23:43<23:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94761.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  50%|███   | 373/744 [23:46<23:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105676.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  50%|███   | 374/744 [23:50<23:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93387.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  50%|███   | 375/744 [23:54<23:31,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120191.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  51%|███   | 376/744 [23:58<23:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112592.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  51%|███   | 377/744 [24:01<23:23,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105559.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  51%|███   | 378/744 [24:06<23:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105184.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  51%|███   | 379/744 [24:10<23:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107929.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  51%|███   | 380/744 [24:14<23:12,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103354.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  51%|███   | 381/744 [24:17<23:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92420.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  51%|███   | 382/744 [24:21<23:05,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108478.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  51%|███   | 383/744 [24:25<23:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103942.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  52%|███   | 384/744 [24:29<22:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102085.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  52%|███   | 385/744 [24:33<22:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104748.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  52%|███   | 386/744 [24:37<22:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111087.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  52%|███   | 387/744 [24:41<22:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107180.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  52%|███▏  | 388/744 [24:44<22:42,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114533.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  52%|███▏  | 389/744 [24:48<22:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91065.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  52%|███▏  | 390/744 [24:52<22:34,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105340.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  53%|███▏  | 391/744 [24:56<22:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93376.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  53%|███▏  | 392/744 [25:00<22:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106653.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  53%|███▏  | 393/744 [25:03<22:23,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106518.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  53%|███▏  | 394/744 [25:07<22:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107031.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  53%|███▏  | 395/744 [25:11<22:15,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85809.7734, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  53%|███▏  | 396/744 [25:15<22:11,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104835.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  53%|███▏  | 397/744 [25:18<22:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114352.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  53%|███▏  | 398/744 [25:22<22:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108588.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  54%|███▏  | 399/744 [25:26<22:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100399.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  54%|███▏  | 400/744 [25:30<21:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103289.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  54%|███▏  | 401/744 [25:34<21:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115454.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  54%|███▏  | 402/744 [25:38<21:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100910.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  54%|███▎  | 403/744 [25:42<21:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107851.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  54%|███▎  | 404/744 [25:45<21:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96227.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  54%|███▎  | 405/744 [25:49<21:36,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106588.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  55%|███▎  | 406/744 [25:53<21:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97172.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  55%|███▎  | 407/744 [25:57<21:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101101.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  55%|███▎  | 408/744 [26:01<21:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102992.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  55%|███▎  | 409/744 [26:04<21:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100463.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  55%|███▎  | 410/744 [26:08<21:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100593.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  55%|███▎  | 411/744 [26:12<21:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113506.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  55%|███▎  | 412/744 [26:16<21:10,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95550.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8853, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  56%|███▎  | 413/744 [26:20<21:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100511.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  56%|███▎  | 414/744 [26:24<21:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106707.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  56%|███▎  | 415/744 [26:27<20:58,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101092.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  56%|███▎  | 416/744 [26:31<20:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103771.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  56%|███▎  | 417/744 [26:35<20:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105100.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  56%|███▎  | 418/744 [26:39<20:47,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99759.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  56%|███▍  | 419/744 [26:42<20:43,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102145.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  56%|███▍  | 420/744 [26:46<20:39,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106406.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  57%|███▍  | 421/744 [26:50<20:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95655.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7853, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  57%|███▍  | 422/744 [26:54<20:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97326.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  57%|███▍  | 423/744 [26:58<20:27,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106854.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  57%|███▍  | 424/744 [27:01<20:24,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100144.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  57%|███▍  | 425/744 [27:05<20:20,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108469.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  57%|███▍  | 426/744 [27:09<20:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110565.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  57%|███▍  | 427/744 [27:13<20:12,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115285.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  58%|███▍  | 428/744 [27:17<20:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107607.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  58%|███▍  | 429/744 [27:20<20:04,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91584.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  58%|███▍  | 430/744 [27:24<20:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104307.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  58%|███▍  | 431/744 [27:28<19:56,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85294.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  58%|███▍  | 432/744 [27:31<19:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112558.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  58%|███▍  | 433/744 [27:35<19:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95407.4766, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.7818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  58%|███▌  | 434/744 [27:39<19:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100978.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  58%|███▌  | 435/744 [27:43<19:41,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102222.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  59%|███▌  | 436/744 [27:47<19:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94886.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  59%|███▌  | 437/744 [27:51<19:34,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105476.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  59%|███▌  | 438/744 [27:55<19:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103511.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  59%|███▌  | 439/744 [27:59<19:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96161.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8853, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  59%|███▌  | 440/744 [28:02<19:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105193.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  59%|███▌  | 441/744 [28:06<19:18,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109845.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  59%|███▌  | 442/744 [28:10<19:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112581.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  60%|███▌  | 443/744 [28:14<19:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88513.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  60%|███▌  | 444/744 [28:18<19:07,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103846.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  60%|███▌  | 445/744 [28:22<19:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106104.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  60%|███▌  | 446/744 [28:26<19:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93928.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  60%|███▌  | 447/744 [28:30<18:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96184.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  60%|███▌  | 448/744 [28:33<18:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105762.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  60%|███▌  | 449/744 [28:37<18:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104042.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  60%|███▋  | 450/744 [28:41<18:44,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103307.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  61%|███▋  | 451/744 [28:45<18:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100942.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  61%|███▋  | 452/744 [28:49<18:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93085.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  61%|███▋  | 453/744 [28:53<18:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92694.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  61%|███▋  | 454/744 [28:56<18:29,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104157.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  61%|███▋  | 455/744 [29:00<18:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109409.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  61%|███▋  | 456/744 [29:04<18:21,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107462.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  61%|███▋  | 457/744 [29:07<18:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112978.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  62%|███▋  | 458/744 [29:11<18:13,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104505.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  62%|███▋  | 459/744 [29:15<18:09,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107800.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  62%|███▋  | 460/744 [29:19<18:06,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105433.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  62%|███▋  | 461/744 [29:22<18:02,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111725.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8108, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  62%|███▋  | 462/744 [29:26<17:58,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107052.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  62%|███▋  | 463/744 [29:30<17:54,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101778.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  62%|███▋  | 464/744 [29:34<17:50,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102967.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  62%|███▊  | 465/744 [29:37<17:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96782.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  63%|███▊  | 466/744 [29:41<17:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108427.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  63%|███▊  | 467/744 [29:45<17:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106932.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  63%|███▊  | 468/744 [29:49<17:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98789.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  63%|███▊  | 469/744 [29:53<17:31,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92619.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  63%|███▊  | 470/744 [29:57<17:27,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108643.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  63%|███▊  | 471/744 [30:00<17:23,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114738.9141, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.7979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  63%|███▊  | 472/744 [30:04<17:20,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112802.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  64%|███▊  | 473/744 [30:08<17:16,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116243.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  64%|███▊  | 474/744 [30:12<17:12,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112464.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  64%|███▊  | 475/744 [30:16<17:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100491.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  64%|███▊  | 476/744 [30:19<17:04,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102408.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  64%|███▊  | 477/744 [30:23<17:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97486.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  64%|███▊  | 478/744 [30:27<16:56,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99065., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  64%|███▊  | 479/744 [30:31<16:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102458.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8601, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  65%|███▊  | 480/744 [30:35<16:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104694.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  65%|███▉  | 481/744 [30:39<16:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110829.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  65%|███▉  | 482/744 [30:43<16:41,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103876.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  65%|███▉  | 483/744 [30:46<16:37,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118217.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  65%|███▉  | 484/744 [30:50<16:34,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116577.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  65%|███▉  | 485/744 [30:54<16:30,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114399.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  65%|███▉  | 486/744 [30:58<16:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91663.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  65%|███▉  | 487/744 [31:02<16:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94088.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  66%|███▉  | 488/744 [31:06<16:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(82819.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  66%|███▉  | 489/744 [31:10<16:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113215.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  66%|███▉  | 490/744 [31:14<16:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113452.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  66%|███▉  | 491/744 [31:17<16:07,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105684.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  66%|███▉  | 492/744 [31:21<16:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116790.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  66%|███▉  | 493/744 [31:25<16:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108993.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  66%|███▉  | 494/744 [31:29<15:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120882.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  67%|███▉  | 495/744 [31:33<15:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94977.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  67%|████  | 496/744 [31:37<15:48,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116120.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  67%|████  | 497/744 [31:40<15:44,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110099.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  67%|████  | 498/744 [31:44<15:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101689.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  67%|████  | 499/744 [31:48<15:36,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108987.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  67%|████  | 500/744 [31:52<15:33,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104165.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  67%|████  | 501/744 [31:56<15:29,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111707.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  67%|████  | 502/744 [31:59<15:25,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115608.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  68%|████  | 503/744 [32:03<15:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111864.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  68%|████  | 504/744 [32:07<15:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94825.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  68%|████  | 505/744 [32:11<15:13,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106861.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  68%|████  | 506/744 [32:14<15:10,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93948., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  68%|████  | 507/744 [32:18<15:06,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101661.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  68%|████  | 508/744 [32:22<15:02,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101740.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  68%|████  | 509/744 [32:26<14:58,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104430.5703, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  69%|████  | 510/744 [32:30<14:54,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106315.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  69%|████  | 511/744 [32:33<14:50,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97181.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  69%|████▏ | 512/744 [32:37<14:47,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106285.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  69%|████▏ | 513/744 [32:41<14:43,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103128.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  69%|████▏ | 514/744 [32:45<14:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103790.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  69%|████▏ | 515/744 [32:49<14:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94935.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  69%|████▏ | 516/744 [32:52<14:31,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104490.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  69%|████▏ | 517/744 [32:56<14:27,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108467.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  70%|████▏ | 518/744 [33:00<14:24,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100481.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  70%|████▏ | 519/744 [33:04<14:20,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99656.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  70%|████▏ | 520/744 [33:07<14:16,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98017.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  70%|████▏ | 521/744 [33:11<14:12,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109666.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  70%|████▏ | 522/744 [33:15<14:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112327.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  70%|████▏ | 523/744 [33:19<14:04,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98495.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  70%|████▏ | 524/744 [33:23<14:01,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111997.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  71%|████▏ | 525/744 [33:27<13:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114366.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  71%|████▏ | 526/744 [33:30<13:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104877.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  71%|████▎ | 527/744 [33:34<13:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108267.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  71%|████▎ | 528/744 [33:38<13:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96259.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  71%|████▎ | 529/744 [33:42<13:41,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106969.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  71%|████▎ | 530/744 [33:46<13:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99532.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  71%|████▎ | 531/744 [33:50<13:34,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112047.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  72%|████▎ | 532/744 [33:53<13:30,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98405.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  72%|████▎ | 533/744 [33:57<13:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97473.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  72%|████▎ | 534/744 [34:01<13:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107973.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  72%|████▎ | 535/744 [34:05<13:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98827.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  72%|████▎ | 536/744 [34:09<13:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101457.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.1203, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  72%|████▎ | 537/744 [34:12<13:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105192.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  72%|████▎ | 538/744 [34:16<13:07,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98483.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  72%|████▎ | 539/744 [34:20<13:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109824.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  73%|████▎ | 540/744 [34:23<12:59,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110142.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  73%|████▎ | 541/744 [34:27<12:55,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100787.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  73%|████▎ | 542/744 [34:31<12:52,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106903.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  73%|████▍ | 543/744 [34:35<12:48,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97396.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  73%|████▍ | 544/744 [34:39<12:44,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95353.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  73%|████▍ | 545/744 [34:42<12:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105804.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  73%|████▍ | 546/744 [34:46<12:36,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(80586.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  74%|████▍ | 547/744 [34:50<12:32,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107247.6328, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  74%|████▍ | 548/744 [34:53<12:28,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100321.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  74%|████▍ | 549/744 [34:57<12:25,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98205.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  74%|████▍ | 550/744 [35:01<12:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115384.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  74%|████▍ | 551/744 [35:05<12:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112445.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  74%|████▍ | 552/744 [35:09<12:13,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98732.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  74%|████▍ | 553/744 [35:13<12:09,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106444.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  74%|████▍ | 554/744 [35:16<12:06,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103215.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  75%|████▍ | 555/744 [35:21<12:02,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98846.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  75%|████▍ | 556/744 [35:24<11:58,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(89935.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  75%|████▍ | 557/744 [35:28<11:54,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101390.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  75%|████▌ | 558/744 [35:32<11:50,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104239.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  75%|████▌ | 559/744 [35:35<11:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99794.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  75%|████▌ | 560/744 [35:39<11:43,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114345.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  75%|████▌ | 561/744 [35:43<11:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105667.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  76%|████▌ | 562/744 [35:47<11:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91603.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  76%|████▌ | 563/744 [35:51<11:31,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91267.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  76%|████▌ | 564/744 [35:54<11:27,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115567.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  76%|████▌ | 565/744 [35:58<11:23,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112143.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  76%|████▌ | 566/744 [36:02<11:20,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105268.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  76%|████▌ | 567/744 [36:06<11:16,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98948.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  76%|████▌ | 568/744 [36:10<11:12,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112452.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  76%|████▌ | 569/744 [36:14<11:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104576.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  77%|████▌ | 570/744 [36:17<11:04,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106060.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  77%|████▌ | 571/744 [36:21<11:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103971.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  77%|████▌ | 572/744 [36:25<10:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111838.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  77%|████▌ | 573/744 [36:29<10:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101943.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  77%|████▋ | 574/744 [36:33<10:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85289.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  77%|████▋ | 575/744 [36:37<10:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111361.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  77%|████▋ | 576/744 [36:41<10:41,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108472.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  78%|████▋ | 577/744 [36:44<10:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113800.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  78%|████▋ | 578/744 [36:48<10:34,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99185.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  78%|████▋ | 579/744 [36:52<10:30,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93705.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  78%|████▋ | 580/744 [36:56<10:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104827.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  78%|████▋ | 581/744 [37:00<10:23,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103883.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  78%|████▋ | 582/744 [37:04<10:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110892.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  78%|████▋ | 583/744 [37:08<10:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97605.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  78%|████▋ | 584/744 [37:12<10:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92649.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  79%|████▋ | 585/744 [37:15<10:07,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106618.3594, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  79%|████▋ | 586/744 [37:19<10:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106795.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  79%|████▋ | 587/744 [37:23<10:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115079.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  79%|████▋ | 588/744 [37:27<09:56,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105630.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  79%|████▊ | 589/744 [37:31<09:52,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106538.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8277, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  79%|████▊ | 590/744 [37:34<09:48,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113974.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  79%|████▊ | 591/744 [37:38<09:44,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104444.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  80%|████▊ | 592/744 [37:42<09:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98662.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  80%|████▊ | 593/744 [37:46<09:37,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(90711.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  80%|████▊ | 594/744 [37:49<09:33,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105678.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  80%|████▊ | 595/744 [37:53<09:29,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115732.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  80%|████▊ | 596/744 [37:57<09:25,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103337.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  80%|████▊ | 597/744 [38:01<09:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102007.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  80%|████▊ | 598/744 [38:05<09:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107028.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  81%|████▊ | 599/744 [38:08<09:14,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100175.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  81%|████▊ | 600/744 [38:12<09:10,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102727.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  81%|████▊ | 601/744 [38:16<09:06,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115022.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  81%|████▊ | 602/744 [38:20<09:02,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110571.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  81%|████▊ | 603/744 [38:24<08:58,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105354.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  81%|████▊ | 604/744 [38:28<08:55,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105643.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  81%|████▉ | 605/744 [38:32<08:51,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112867.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  81%|████▉ | 606/744 [38:36<08:47,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96304.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  82%|████▉ | 607/744 [38:39<08:43,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94200.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  82%|████▉ | 608/744 [38:43<08:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96408.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  82%|████▉ | 609/744 [38:47<08:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103808.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  82%|████▉ | 610/744 [38:51<08:32,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103294.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  82%|████▉ | 611/744 [38:54<08:28,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93637.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  82%|████▉ | 612/744 [38:58<08:24,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112208.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  82%|████▉ | 613/744 [39:02<08:20,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113492.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  83%|████▉ | 614/744 [39:05<08:16,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103019.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  83%|████▉ | 615/744 [39:09<08:12,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111470.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  83%|████▉ | 616/744 [39:13<08:09,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100835.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  83%|████▉ | 617/744 [39:17<08:05,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110776.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  83%|████▉ | 618/744 [39:20<08:01,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102385.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  83%|████▉ | 619/744 [39:24<07:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103745.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  83%|█████ | 620/744 [39:28<07:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108221., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  83%|█████ | 621/744 [39:32<07:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112957.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  84%|█████ | 622/744 [39:35<07:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104562.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  84%|█████ | 623/744 [39:39<07:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111356.5469, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  84%|█████ | 624/744 [39:43<07:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106950.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  84%|█████ | 625/744 [39:47<07:34,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107927.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  84%|█████ | 626/744 [39:51<07:30,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106523.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  84%|█████ | 627/744 [39:55<07:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99385.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  84%|█████ | 628/744 [39:58<07:23,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104698.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  85%|█████ | 629/744 [40:02<07:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101551.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  85%|█████ | 630/744 [40:06<07:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98037.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9643, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  85%|█████ | 631/744 [40:09<07:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114326.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  85%|█████ | 632/744 [40:13<07:07,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110038.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  85%|█████ | 633/744 [40:17<07:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112525.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  85%|█████ | 634/744 [40:21<07:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102890.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  85%|█████ | 635/744 [40:24<06:56,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110801.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  85%|█████▏| 636/744 [40:28<06:52,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112832.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  86%|█████▏| 637/744 [40:32<06:48,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110190.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  86%|█████▏| 638/744 [40:36<06:44,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107215.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9863, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  86%|█████▏| 639/744 [40:40<06:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97597.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  86%|█████▏| 640/744 [40:44<06:37,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111152.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  86%|█████▏| 641/744 [40:48<06:33,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106300.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  86%|█████▏| 642/744 [40:51<06:29,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104557.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  86%|█████▏| 643/744 [40:55<06:25,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109124.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  87%|█████▏| 644/744 [40:59<06:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97766.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  87%|█████▏| 645/744 [41:03<06:18,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104384.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  87%|█████▏| 646/744 [41:07<06:14,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(88187.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  87%|█████▏| 647/744 [41:11<06:10,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114162.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  87%|█████▏| 648/744 [41:15<06:06,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103115.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  87%|█████▏| 649/744 [41:19<06:02,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114682.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  87%|█████▏| 650/744 [41:22<05:59,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110488.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  88%|█████▎| 651/744 [41:26<05:55,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116016.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  88%|█████▎| 652/744 [41:30<05:51,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107547.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  88%|█████▎| 653/744 [41:34<05:47,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104674.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  88%|█████▎| 654/744 [41:37<05:43,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107401.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  88%|█████▎| 655/744 [41:41<05:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114355.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  88%|█████▎| 656/744 [41:45<05:36,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101433.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  88%|█████▎| 657/744 [41:49<05:32,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107492.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  88%|█████▎| 658/744 [41:52<05:28,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100172.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  89%|█████▎| 659/744 [41:56<05:24,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108418.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  89%|█████▎| 660/744 [42:00<05:20,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102105.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  89%|█████▎| 661/744 [42:04<05:16,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95822.4297, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  89%|█████▎| 662/744 [42:08<05:13,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104343.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  89%|█████▎| 663/744 [42:11<05:09,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113706.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  89%|█████▎| 664/744 [42:15<05:05,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108144.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  89%|█████▎| 665/744 [42:19<05:01,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110725.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  90%|█████▎| 666/744 [42:22<04:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99659.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  90%|█████▍| 667/744 [42:26<04:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98748.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  90%|█████▍| 668/744 [42:30<04:50,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109580.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  90%|█████▍| 669/744 [42:34<04:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92425.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  90%|█████▍| 670/744 [42:38<04:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110566.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  90%|█████▍| 671/744 [42:41<04:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113747.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  90%|█████▍| 672/744 [42:45<04:34,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111396.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  90%|█████▍| 673/744 [42:49<04:31,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103881., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  91%|█████▍| 674/744 [42:53<04:27,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104464.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  91%|█████▍| 675/744 [42:57<04:23,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105077.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  91%|█████▍| 676/744 [43:00<04:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107256.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  91%|█████▍| 677/744 [43:04<04:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105281.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  91%|█████▍| 678/744 [43:08<04:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102488.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  91%|█████▍| 679/744 [43:11<04:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108074.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  91%|█████▍| 680/744 [43:15<04:04,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103567.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  92%|█████▍| 681/744 [43:19<04:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111733.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  92%|█████▌| 682/744 [43:23<03:56,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108018.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  92%|█████▌| 683/744 [43:27<03:52,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117210.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  92%|█████▌| 684/744 [43:30<03:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93420.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  92%|█████▌| 685/744 [43:34<03:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110459.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  92%|█████▌| 686/744 [43:38<03:41,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109589.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  92%|█████▌| 687/744 [43:42<03:37,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100245.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  92%|█████▌| 688/744 [43:46<03:33,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116682.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  93%|█████▌| 689/744 [43:50<03:29,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109471.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  93%|█████▌| 690/744 [43:54<03:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95648.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  93%|█████▌| 691/744 [43:57<03:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103638.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  93%|█████▌| 692/744 [44:01<03:18,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103227.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  93%|█████▌| 693/744 [44:05<03:14,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110313.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  93%|█████▌| 694/744 [44:09<03:10,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105831.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  93%|█████▌| 695/744 [44:13<03:07,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104504.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  94%|█████▌| 696/744 [44:17<03:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117389.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  94%|█████▌| 697/744 [44:21<02:59,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103267.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  94%|█████▋| 698/744 [44:24<02:55,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108829.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  94%|█████▋| 699/744 [44:28<02:51,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94190.2344, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  94%|█████▋| 700/744 [44:32<02:47,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105369.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  94%|█████▋| 701/744 [44:36<02:44,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106688.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  94%|█████▋| 702/744 [44:40<02:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113827.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  94%|█████▋| 703/744 [44:44<02:36,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111131.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  95%|█████▋| 704/744 [44:48<02:32,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108337.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  95%|█████▋| 705/744 [44:52<02:28,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97657.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  95%|█████▋| 706/744 [44:56<02:25,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103165.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  95%|█████▋| 707/744 [45:00<02:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105764.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  95%|█████▋| 708/744 [45:04<02:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97838.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  95%|█████▋| 709/744 [45:08<02:13,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119301.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  95%|█████▋| 710/744 [45:12<02:09,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117020.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  96%|█████▋| 711/744 [45:15<02:06,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105854.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  96%|█████▋| 712/744 [45:19<02:02,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105838.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  96%|█████▊| 713/744 [45:23<01:58,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101713.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  96%|█████▊| 714/744 [45:27<01:54,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119237.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  96%|█████▊| 715/744 [45:31<01:50,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96008.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7863, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  96%|█████▊| 716/744 [45:34<01:46,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95586.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  96%|█████▊| 717/744 [45:38<01:43,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105749.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  97%|█████▊| 718/744 [45:42<01:39,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101603.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  97%|█████▊| 719/744 [45:46<01:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93955.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  97%|█████▊| 720/744 [45:50<01:31,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111887.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  97%|█████▊| 721/744 [45:54<01:27,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107844.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  97%|█████▊| 722/744 [45:57<01:24,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108668.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  97%|█████▊| 723/744 [46:01<01:20,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103315.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  97%|█████▊| 724/744 [46:05<01:16,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110193.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  97%|█████▊| 725/744 [46:09<01:12,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114976.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  98%|█████▊| 726/744 [46:12<01:08,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112800.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  98%|█████▊| 727/744 [46:16<01:04,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112042.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  98%|█████▊| 728/744 [46:20<01:01,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93457.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  98%|█████▉| 729/744 [46:24<00:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96590.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  98%|█████▉| 730/744 [46:28<00:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112045.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  98%|█████▉| 731/744 [46:32<00:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102634.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  98%|█████▉| 732/744 [46:36<00:45,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101213.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  99%|█████▉| 733/744 [46:40<00:42,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101598.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  99%|█████▉| 734/744 [46:43<00:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113890.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  99%|█████▉| 735/744 [46:47<00:34,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103136.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  99%|█████▉| 736/744 [46:51<00:30,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109562.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  99%|█████▉| 737/744 [46:55<00:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112277.9922, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  99%|█████▉| 738/744 [46:59<00:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111431.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  99%|█████▉| 739/744 [47:02<00:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83892.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16:  99%|█████▉| 740/744 [47:06<00:15,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103944.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16: 100%|█████▉| 741/744 [47:10<00:11,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98623.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16: 100%|█████▉| 742/744 [47:14<00:07,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109101.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16: 100%|█████▉| 743/744 [47:17<00:03,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110672.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   0%|                | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(110714.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   0%|      | 1/744 [00:05<1:05:49,  5.32s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110224., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   0%|        | 2/744 [00:09<55:59,  4.53s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99482.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   0%|        | 3/744 [00:13<53:46,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98417.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   1%|        | 4/744 [00:16<51:30,  4.18s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102597.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   1%|        | 5/744 [00:20<50:59,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105248.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   1%|        | 6/744 [00:24<49:48,  4.05s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112625.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   1%|        | 7/744 [00:28<49:15,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108133.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   1%|        | 8/744 [00:31<48:39,  3.97s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99438.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   1%|        | 9/744 [00:35<48:24,  3.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104425.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   1%|       | 10/744 [00:39<48:27,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104654.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   1%|       | 11/744 [00:43<48:23,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91013.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   2%|       | 12/744 [00:47<47:56,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93914.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   2%|       | 13/744 [00:50<47:36,  3.91s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96536.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   2%|▏      | 14/744 [00:54<47:23,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112362.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   2%|▏      | 15/744 [00:58<47:13,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104760.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   2%|▏      | 16/744 [01:01<46:59,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107694.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   2%|▏      | 17/744 [01:05<46:44,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109805.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   2%|▏      | 18/744 [01:09<46:39,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99996.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   3%|▏      | 19/744 [01:13<46:30,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106407.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   3%|▏      | 20/744 [01:16<46:21,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98397.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   3%|▏      | 21/744 [01:20<46:15,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106841.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   3%|▏      | 22/744 [01:24<46:10,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105079.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   3%|▏      | 23/744 [01:28<46:00,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(85414.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   3%|▏      | 24/744 [01:31<45:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114297.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   3%|▏      | 25/744 [01:35<45:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106645.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   3%|▏      | 26/744 [01:39<45:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106693.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   4%|▎      | 27/744 [01:43<45:38,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100346.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   4%|▎      | 28/744 [01:46<45:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106144.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   4%|▎      | 29/744 [01:50<45:29,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109081.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   4%|▎      | 30/744 [01:54<45:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106658.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   4%|▎      | 31/744 [01:58<45:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105895.6875, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   4%|▎      | 32/744 [02:01<45:08,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92495.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   4%|▎      | 33/744 [02:05<45:01,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110675., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   5%|▎      | 34/744 [02:08<44:53,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95926.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   5%|▎      | 35/744 [02:12<44:47,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102967.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   5%|▎      | 36/744 [02:16<44:42,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107564.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   5%|▎      | 37/744 [02:20<44:43,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116774.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   5%|▎      | 38/744 [02:24<44:37,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119483.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   5%|▎      | 39/744 [02:27<44:33,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119127.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   5%|▍      | 40/744 [02:31<44:28,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102692.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   6%|▍      | 41/744 [02:35<44:20,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111182.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   6%|▍      | 42/744 [02:39<44:17,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107759.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   6%|▍      | 43/744 [02:42<44:10,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112933.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   6%|▍      | 44/744 [02:46<44:04,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98208.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   6%|▍      | 45/744 [02:50<44:01,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98990.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   6%|▍      | 46/744 [02:53<43:59,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106372.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   6%|▍      | 47/744 [02:58<44:03,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114880.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   6%|▍      | 48/744 [03:02<44:01,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102222.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   7%|▍      | 49/744 [03:06<43:58,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107520.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   7%|▍      | 50/744 [03:09<43:51,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114300.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   7%|▍      | 51/744 [03:13<43:46,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112103.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   7%|▍      | 52/744 [03:16<43:41,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114950.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   7%|▍      | 53/744 [03:20<43:36,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112905.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   7%|▌      | 54/744 [03:24<43:31,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109731.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   7%|▌      | 55/744 [03:27<43:24,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106798.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   8%|▌      | 56/744 [03:31<43:21,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112045.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   8%|▌      | 57/744 [03:35<43:19,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105758.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   8%|▌      | 58/744 [03:39<43:15,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119054.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   8%|▌      | 59/744 [03:43<43:11,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105590.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   8%|▌      | 60/744 [03:46<43:07,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111550.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   8%|▌      | 61/744 [03:50<43:04,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122663.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   8%|▌      | 62/744 [03:54<43:00,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106681.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   8%|▌      | 63/744 [03:58<42:59,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113624.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   9%|▌      | 64/744 [04:02<42:57,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95678.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   9%|▌      | 65/744 [04:06<42:54,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106698.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   9%|▌      | 66/744 [04:10<42:49,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103768.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   9%|▋      | 67/744 [04:14<42:46,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98759.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   9%|▋      | 68/744 [04:17<42:44,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116129.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   9%|▋      | 69/744 [04:21<42:40,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106034.9609, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:   9%|▋      | 70/744 [04:25<42:38,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107163.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  10%|▋      | 71/744 [04:29<42:34,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102866.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  10%|▋      | 72/744 [04:33<42:31,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109621.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  10%|▋      | 73/744 [04:37<42:29,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111734.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8843, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  10%|▋      | 74/744 [04:41<42:26,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103586.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  10%|▋      | 75/744 [04:44<42:20,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100585.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  10%|▋      | 76/744 [04:48<42:14,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102812.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  10%|▋      | 77/744 [04:52<42:09,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110220.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  10%|▋      | 78/744 [04:55<42:04,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86978.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  11%|▋      | 79/744 [04:59<42:00,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115285.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  11%|▊      | 80/744 [05:03<41:57,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119424.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  11%|▊      | 81/744 [05:06<41:52,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99329.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  11%|▊      | 82/744 [05:11<41:50,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104991.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  11%|▊      | 83/744 [05:14<41:45,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96961.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  11%|▊      | 84/744 [05:18<41:42,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110370.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  11%|▊      | 85/744 [05:22<41:39,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114762.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  12%|▊      | 86/744 [05:26<41:36,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105568.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  12%|▊      | 87/744 [05:30<41:33,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99371.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  12%|▊      | 88/744 [05:33<41:28,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101967.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  12%|▊      | 89/744 [05:37<41:24,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115651.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  12%|▊      | 90/744 [05:41<41:20,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110308.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  12%|▊      | 91/744 [05:45<41:16,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98350.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  12%|▊      | 92/744 [05:48<41:12,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107158.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  12%|▉      | 93/744 [05:52<41:08,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105237.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  13%|▉      | 94/744 [05:56<41:05,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115116.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  13%|▉      | 95/744 [06:00<41:01,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93775.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  13%|▉      | 96/744 [06:04<40:57,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103726.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  13%|▉      | 97/744 [06:07<40:54,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112756.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  13%|▉      | 98/744 [06:11<40:51,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114538., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  13%|▉      | 99/744 [06:15<40:47,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108850.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  13%|▊     | 100/744 [06:19<40:44,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110538.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  14%|▊     | 101/744 [06:23<40:39,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111822.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  14%|▊     | 102/744 [06:26<40:35,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109358.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  14%|▊     | 103/744 [06:30<40:32,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106035.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  14%|▊     | 104/744 [06:34<40:29,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106262.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  14%|▊     | 105/744 [06:38<40:25,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105700.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  14%|▊     | 106/744 [06:42<40:21,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105871.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  14%|▊     | 107/744 [06:45<40:16,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111325.7422, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.7841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  15%|▊     | 108/744 [06:49<40:13,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107857.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  15%|▉     | 109/744 [06:53<40:08,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106609.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  15%|▉     | 110/744 [06:57<40:05,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107582.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  15%|▉     | 111/744 [07:00<40:00,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105679.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  15%|▉     | 112/744 [07:04<39:57,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108749.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  15%|▉     | 113/744 [07:08<39:52,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113161.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  15%|▉     | 114/744 [07:12<39:49,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107978.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  15%|▉     | 115/744 [07:16<39:45,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93029.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  16%|▉     | 116/744 [07:20<39:43,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112966.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  16%|▉     | 117/744 [07:23<39:39,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95052.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  16%|▉     | 118/744 [07:27<39:34,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107754.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  16%|▉     | 119/744 [07:31<39:30,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91618.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  16%|▉     | 120/744 [07:35<39:26,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108222.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  16%|▉     | 121/744 [07:39<39:25,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113910.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  16%|▉     | 122/744 [07:42<39:19,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107399.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  17%|▉     | 123/744 [07:46<39:15,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110060.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  17%|█     | 124/744 [07:50<39:12,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98532.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  17%|█     | 125/744 [07:54<39:08,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120462.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  17%|█     | 126/744 [07:58<39:05,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108489.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  17%|█     | 127/744 [08:02<39:02,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112416.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  17%|█     | 128/744 [08:05<38:58,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110617.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  17%|█     | 129/744 [08:09<38:54,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103049.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8652, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  17%|█     | 130/744 [08:13<38:50,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104390.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  18%|█     | 131/744 [08:17<38:48,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112132.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  18%|█     | 132/744 [08:21<38:45,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106882.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  18%|█     | 133/744 [08:25<38:41,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106659.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  18%|█     | 134/744 [08:29<38:38,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103744.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  18%|█     | 135/744 [08:32<38:33,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108072.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  18%|█     | 136/744 [08:36<38:29,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104642.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  18%|█     | 137/744 [08:40<38:25,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106191.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  19%|█     | 138/744 [08:44<38:23,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113007.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  19%|█     | 139/744 [08:48<38:19,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123335.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  19%|█▏    | 140/744 [08:52<38:17,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110176.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  19%|█▏    | 141/744 [08:56<38:13,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111433.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  19%|█▏    | 142/744 [09:00<38:09,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102023.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  19%|█▏    | 143/744 [09:03<38:05,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106478.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  19%|█▏    | 144/744 [09:07<38:01,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108533.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  19%|█▏    | 145/744 [09:11<37:59,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111644.1484, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  20%|█▏    | 146/744 [09:15<37:55,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100837.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  20%|█▏    | 147/744 [09:19<37:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112733.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  20%|█▏    | 148/744 [09:22<37:46,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114428.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  20%|█▏    | 149/744 [09:26<37:42,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98603.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  20%|█▏    | 150/744 [09:30<37:38,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104244.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  20%|█▏    | 151/744 [09:34<37:35,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104098.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  20%|█▏    | 152/744 [09:38<37:31,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111723.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  21%|█▏    | 153/744 [09:41<37:27,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120282.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  21%|█▏    | 154/744 [09:45<37:22,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100294.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  21%|█▎    | 155/744 [09:49<37:19,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96519.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  21%|█▎    | 156/744 [09:52<37:14,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113649.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  21%|█▎    | 157/744 [09:56<37:10,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99979.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  21%|█▎    | 158/744 [10:00<37:06,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102791.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  21%|█▎    | 159/744 [10:03<37:01,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110110.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  22%|█▎    | 160/744 [10:08<36:59,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110042.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  22%|█▎    | 161/744 [10:11<36:55,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111168.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  22%|█▎    | 162/744 [10:15<36:51,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108828.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  22%|█▎    | 163/744 [10:19<36:47,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100729.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  22%|█▎    | 164/744 [10:23<36:44,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114465.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  22%|█▎    | 165/744 [10:27<36:40,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101426.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  22%|█▎    | 166/744 [10:30<36:36,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111450.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  22%|█▎    | 167/744 [10:34<36:32,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107262.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  23%|█▎    | 168/744 [10:38<36:28,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109029., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  23%|█▎    | 169/744 [10:41<36:24,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93187.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  23%|█▎    | 170/744 [10:45<36:20,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109879.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  23%|█▍    | 171/744 [10:49<36:16,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94822.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  23%|█▍    | 172/744 [10:53<36:12,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115019.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  23%|█▍    | 173/744 [10:57<36:08,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101220.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  23%|█▍    | 174/744 [11:00<36:05,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101682.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  24%|█▍    | 175/744 [11:04<36:01,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112356.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  24%|█▍    | 176/744 [11:08<35:57,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104936.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  24%|█▍    | 177/744 [11:12<35:54,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100696.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  24%|█▍    | 178/744 [11:16<35:49,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103609.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  24%|█▍    | 179/744 [11:20<35:46,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111955.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  24%|█▍    | 180/744 [11:23<35:42,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99886.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  24%|█▍    | 181/744 [11:27<35:38,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106988.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8694, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  24%|█▍    | 182/744 [11:31<35:35,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106778.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  25%|█▍    | 183/744 [11:35<35:31,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105985.0391, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  25%|█▍    | 184/744 [11:39<35:28,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94986.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  25%|█▍    | 185/744 [11:43<35:24,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114745.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  25%|█▌    | 186/744 [11:47<35:21,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110559.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  25%|█▌    | 187/744 [11:50<35:17,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110990.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  25%|█▌    | 188/744 [11:54<35:13,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118814.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  25%|█▌    | 189/744 [11:58<35:10,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129845.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  26%|█▌    | 190/744 [12:02<35:06,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96632.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  26%|█▌    | 191/744 [12:06<35:03,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112747.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  26%|█▌    | 192/744 [12:10<34:59,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104111.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  26%|█▌    | 193/744 [12:14<34:56,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111928.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  26%|█▌    | 194/744 [12:17<34:52,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106207.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  26%|█▌    | 195/744 [12:21<34:48,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106608.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  26%|█▌    | 196/744 [12:25<34:43,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111165.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  26%|█▌    | 197/744 [12:29<34:40,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113681.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  27%|█▌    | 198/744 [12:33<34:36,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106315.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  27%|█▌    | 199/744 [12:36<34:33,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97358.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  27%|█▌    | 200/744 [12:40<34:29,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116276.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  27%|█▌    | 201/744 [12:44<34:25,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117921.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  27%|█▋    | 202/744 [12:48<34:21,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111041.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  27%|█▋    | 203/744 [12:52<34:18,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110225.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  27%|█▋    | 204/744 [12:55<34:13,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106931.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  28%|█▋    | 205/744 [12:59<34:10,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114789.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  28%|█▋    | 206/744 [13:03<34:06,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108517.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  28%|█▋    | 207/744 [13:07<34:03,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112365.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  28%|█▋    | 208/744 [13:11<33:58,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111940.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  28%|█▋    | 209/744 [13:14<33:54,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112569.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  28%|█▋    | 210/744 [13:18<33:51,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99286.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  28%|█▋    | 211/744 [13:22<33:47,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113950.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  28%|█▋    | 212/744 [13:26<33:44,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120071.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8958, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  29%|█▋    | 213/744 [13:30<33:39,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105751.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  29%|█▋    | 214/744 [13:33<33:35,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102200.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  29%|█▋    | 215/744 [13:37<33:31,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112203.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  29%|█▋    | 216/744 [13:41<33:27,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99090.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  29%|█▊    | 217/744 [13:44<33:23,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113142.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  29%|█▊    | 218/744 [13:48<33:19,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95031.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  29%|█▊    | 219/744 [13:52<33:15,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116578.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  30%|█▊    | 220/744 [13:56<33:11,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102986.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  30%|█▊    | 221/744 [13:59<33:07,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105375.9141, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  30%|█▊    | 222/744 [14:03<33:02,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122634.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  30%|█▊    | 223/744 [14:07<32:59,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104996.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  30%|█▊    | 224/744 [14:11<32:55,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108043.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  30%|█▊    | 225/744 [14:14<32:51,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109436.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  30%|█▊    | 226/744 [14:18<32:48,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117760.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  31%|█▊    | 227/744 [14:22<32:44,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104821.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  31%|█▊    | 228/744 [14:26<32:40,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93151.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  31%|█▊    | 229/744 [14:30<32:37,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119495.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  31%|█▊    | 230/744 [14:33<32:33,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118587.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  31%|█▊    | 231/744 [14:37<32:29,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109578.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  31%|█▊    | 232/744 [14:41<32:25,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108387.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  31%|█▉    | 233/744 [14:45<32:22,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106904.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  31%|█▉    | 234/744 [14:49<32:18,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109533.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  32%|█▉    | 235/744 [14:53<32:14,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114804.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  32%|█▉    | 236/744 [14:56<32:10,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114520.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  32%|█▉    | 237/744 [15:00<32:06,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112477.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  32%|█▉    | 238/744 [15:04<32:02,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109117.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  32%|█▉    | 239/744 [15:08<31:59,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120968.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  32%|█▉    | 240/744 [15:12<31:56,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116898.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  32%|█▉    | 241/744 [15:16<31:52,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106332.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  33%|█▉    | 242/744 [15:20<31:48,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106878.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  33%|█▉    | 243/744 [15:24<31:45,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112330.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  33%|█▉    | 244/744 [15:27<31:40,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112435.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  33%|█▉    | 245/744 [15:31<31:37,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107717.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  33%|█▉    | 246/744 [15:35<31:33,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107749.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  33%|█▉    | 247/744 [15:39<31:29,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106150.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  33%|██    | 248/744 [15:42<31:25,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109717.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  33%|██    | 249/744 [15:46<31:22,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100318.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  34%|██    | 250/744 [15:50<31:18,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100732.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  34%|██    | 251/744 [15:54<31:14,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101437.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  34%|██    | 252/744 [15:58<31:10,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108041.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  34%|██    | 253/744 [16:02<31:06,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111974.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  34%|██    | 254/744 [16:05<31:02,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117096.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  34%|██    | 255/744 [16:09<30:59,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118220.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  34%|██    | 256/744 [16:13<30:55,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98432.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  35%|██    | 257/744 [16:17<30:51,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114890.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  35%|██    | 258/744 [16:21<30:48,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110948.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  35%|██    | 259/744 [16:24<30:44,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113371.3672, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  35%|██    | 260/744 [16:28<30:40,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110538.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  35%|██    | 261/744 [16:32<30:36,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112428.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  35%|██    | 262/744 [16:36<30:32,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118719.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  35%|██    | 263/744 [16:39<30:28,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111397.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  35%|██▏   | 264/744 [16:43<30:24,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99269.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  36%|██▏   | 265/744 [16:47<30:20,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112002.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  36%|██▏   | 266/744 [16:51<30:17,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106029.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  36%|██▏   | 267/744 [16:54<30:13,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115178.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  36%|██▏   | 268/744 [16:58<30:09,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106201.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  36%|██▏   | 269/744 [17:03<30:06,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118315.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  36%|██▏   | 270/744 [17:07<30:03,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107249.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  36%|██▏   | 271/744 [17:10<29:59,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106808.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  37%|██▏   | 272/744 [17:14<29:55,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107814.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  37%|██▏   | 273/744 [17:18<29:51,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109031.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  37%|██▏   | 274/744 [17:22<29:47,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111711.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  37%|██▏   | 275/744 [17:25<29:43,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102777.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  37%|██▏   | 276/744 [17:29<29:39,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116514.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  37%|██▏   | 277/744 [17:33<29:35,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109410.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  37%|██▏   | 278/744 [17:36<29:31,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116932.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  38%|██▎   | 279/744 [17:41<29:28,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102906.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  38%|██▎   | 280/744 [17:44<29:24,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96304.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  38%|██▎   | 281/744 [17:48<29:21,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109974.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  38%|██▎   | 282/744 [17:52<29:17,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104046.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  38%|██▎   | 283/744 [17:56<29:14,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111527.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8807, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  38%|██▎   | 284/744 [18:00<29:10,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116945.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  38%|██▎   | 285/744 [18:04<29:06,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95860.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  38%|██▎   | 286/744 [18:08<29:02,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108966.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  39%|██▎   | 287/744 [18:12<28:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112818.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  39%|██▎   | 288/744 [18:15<28:55,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107786.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9819, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  39%|██▎   | 289/744 [18:19<28:51,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104580.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  39%|██▎   | 290/744 [18:23<28:47,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118825.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  39%|██▎   | 291/744 [18:27<28:43,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(91682.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  39%|██▎   | 292/744 [18:31<28:40,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107527.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  39%|██▎   | 293/744 [18:35<28:36,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96216.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  40%|██▎   | 294/744 [18:38<28:32,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116722.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  40%|██▍   | 295/744 [18:42<28:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109843.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  40%|██▍   | 296/744 [18:46<28:24,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105295.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  40%|██▍   | 297/744 [18:50<28:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108735.2109, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  40%|██▍   | 298/744 [18:54<28:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115187.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  40%|██▍   | 299/744 [18:57<28:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98790.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  40%|██▍   | 300/744 [19:01<28:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115362.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  40%|██▍   | 301/744 [19:05<28:05,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99323.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  41%|██▍   | 302/744 [19:08<28:01,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113456.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  41%|██▍   | 303/744 [19:12<27:57,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108899.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  41%|██▍   | 304/744 [19:16<27:54,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113150.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  41%|██▍   | 305/744 [19:20<27:50,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106095.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  41%|██▍   | 306/744 [19:24<27:46,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124602.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  41%|██▍   | 307/744 [19:28<27:42,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108364.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  41%|██▍   | 308/744 [19:32<27:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108884.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  42%|██▍   | 309/744 [19:36<27:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113767.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  42%|██▌   | 310/744 [19:39<27:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110803.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  42%|██▌   | 311/744 [19:43<27:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118885.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  42%|██▌   | 312/744 [19:47<27:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100148.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  42%|██▌   | 313/744 [19:51<27:20,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108271.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  42%|██▌   | 314/744 [19:55<27:16,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106518.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  42%|██▌   | 315/744 [19:59<27:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116819.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  42%|██▌   | 316/744 [20:02<27:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118732.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  43%|██▌   | 317/744 [20:06<27:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114538.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  43%|██▌   | 318/744 [20:10<27:02,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104657.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  43%|██▌   | 319/744 [20:14<26:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97920.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  43%|██▌   | 320/744 [20:18<26:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99359.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  43%|██▌   | 321/744 [20:22<26:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122265.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  43%|██▌   | 322/744 [20:26<26:47,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95298.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  43%|██▌   | 323/744 [20:30<26:43,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96697.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  44%|██▌   | 324/744 [20:34<26:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97120.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  44%|██▌   | 325/744 [20:37<26:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111442.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  44%|██▋   | 326/744 [20:41<26:32,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113179.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  44%|██▋   | 327/744 [20:45<26:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109489.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  44%|██▋   | 328/744 [20:49<26:24,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111555.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  44%|██▋   | 329/744 [20:53<26:20,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104319.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  44%|██▋   | 330/744 [20:57<26:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112682.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  44%|██▋   | 331/744 [21:01<26:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122725.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  45%|██▋   | 332/744 [21:05<26:10,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124657.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  45%|██▋   | 333/744 [21:08<26:06,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109378.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  45%|██▋   | 334/744 [21:12<26:02,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103649.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  45%|██▋   | 335/744 [21:16<25:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102207.2891, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  45%|██▋   | 336/744 [21:20<25:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117632.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  45%|██▋   | 337/744 [21:24<25:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122946.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  45%|██▋   | 338/744 [21:27<25:47,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106694.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  46%|██▋   | 339/744 [21:32<25:43,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101309.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  46%|██▋   | 340/744 [21:35<25:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124194.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  46%|██▊   | 341/744 [21:39<25:36,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109987.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  46%|██▊   | 342/744 [21:43<25:32,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112009.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  46%|██▊   | 343/744 [21:47<25:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109806.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  46%|██▊   | 344/744 [21:51<25:24,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110362.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  46%|██▊   | 345/744 [21:54<25:20,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120721.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  47%|██▊   | 346/744 [21:59<25:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106489.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  47%|██▊   | 347/744 [22:02<25:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112642.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  47%|██▊   | 348/744 [22:06<25:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97364.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  47%|██▊   | 349/744 [22:10<25:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105672.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  47%|██▊   | 350/744 [22:14<25:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109340.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  47%|██▊   | 351/744 [22:17<24:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114322.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  47%|██▊   | 352/744 [22:21<24:53,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101737.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  47%|██▊   | 353/744 [22:25<24:49,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108687.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  48%|██▊   | 354/744 [22:28<24:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100784.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  48%|██▊   | 355/744 [22:32<24:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108590.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9148, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  48%|██▊   | 356/744 [22:36<24:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117636.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  48%|██▉   | 357/744 [22:40<24:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123881.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  48%|██▉   | 358/744 [22:43<24:30,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114791.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  48%|██▉   | 359/744 [22:47<24:26,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114477.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  48%|██▉   | 360/744 [22:51<24:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101325.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  49%|██▉   | 361/744 [22:55<24:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112030.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  49%|██▉   | 362/744 [22:59<24:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111881.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  49%|██▉   | 363/744 [23:02<24:11,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102060.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  49%|██▉   | 364/744 [23:06<24:07,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103526.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  49%|██▉   | 365/744 [23:10<24:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96422.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  49%|██▉   | 366/744 [23:14<24:00,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119234.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  49%|██▉   | 367/744 [23:18<23:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99318.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  49%|██▉   | 368/744 [23:21<23:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111416.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  50%|██▉   | 369/744 [23:25<23:48,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109440.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  50%|██▉   | 370/744 [23:29<23:44,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105304.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  50%|██▉   | 371/744 [23:33<23:40,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98028.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  50%|███   | 372/744 [23:36<23:36,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120240.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  50%|███   | 373/744 [23:40<23:33,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99711.3047, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  50%|███   | 374/744 [23:44<23:29,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110976.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  50%|███   | 375/744 [23:48<23:25,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107345.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  51%|███   | 376/744 [23:52<23:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112545.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  51%|███   | 377/744 [23:56<23:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116596.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  51%|███   | 378/744 [23:59<23:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107819.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  51%|███   | 379/744 [24:03<23:10,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118154.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  51%|███   | 380/744 [24:07<23:06,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111737.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  51%|███   | 381/744 [24:11<23:02,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96274.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  51%|███   | 382/744 [24:14<22:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108786., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  51%|███   | 383/744 [24:18<22:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119193.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  52%|███   | 384/744 [24:22<22:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112393.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  52%|███   | 385/744 [24:26<22:47,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123527.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  52%|███   | 386/744 [24:30<22:43,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111861.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  52%|███   | 387/744 [24:33<22:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116001.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  52%|███▏  | 388/744 [24:37<22:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98541.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  52%|███▏  | 389/744 [24:41<22:32,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108653.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  52%|███▏  | 390/744 [24:45<22:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107961.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  53%|███▏  | 391/744 [24:48<22:24,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95977.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  53%|███▏  | 392/744 [24:53<22:20,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104024.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  53%|███▏  | 393/744 [24:57<22:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104611.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  53%|███▏  | 394/744 [25:00<22:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111297.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  53%|███▏  | 395/744 [25:04<22:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105025.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  53%|███▏  | 396/744 [25:08<22:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101440.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  53%|███▏  | 397/744 [25:12<22:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98408.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  53%|███▏  | 398/744 [25:15<21:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105836.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  54%|███▏  | 399/744 [25:20<21:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111440.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  54%|███▏  | 400/744 [25:23<21:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115181.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  54%|███▏  | 401/744 [25:27<21:46,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112180.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  54%|███▏  | 402/744 [25:31<21:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123421.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  54%|███▎  | 403/744 [25:35<21:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105707.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  54%|███▎  | 404/744 [25:38<21:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113024.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  54%|███▎  | 405/744 [25:42<21:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103925.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  55%|███▎  | 406/744 [25:46<21:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124024.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  55%|███▎  | 407/744 [25:50<21:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111026.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  55%|███▎  | 408/744 [25:54<21:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(83457.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  55%|███▎  | 409/744 [25:58<21:16,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117934.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  55%|███▎  | 410/744 [26:02<21:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105118.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  55%|███▎  | 411/744 [26:05<21:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106225.8125, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.7982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  55%|███▎  | 412/744 [26:09<21:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113123.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  56%|███▎  | 413/744 [26:13<21:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113418.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  56%|███▎  | 414/744 [26:17<20:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110057.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  56%|███▎  | 415/744 [26:21<20:53,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112782.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  56%|███▎  | 416/744 [26:25<20:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105554.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  56%|███▎  | 417/744 [26:29<20:46,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105463.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  56%|███▎  | 418/744 [26:33<20:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118029.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  56%|███▍  | 419/744 [26:37<20:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118696.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  56%|███▍  | 420/744 [26:41<20:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106827.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  57%|███▍  | 421/744 [26:44<20:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94188.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  57%|███▍  | 422/744 [26:48<20:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119336.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  57%|███▍  | 423/744 [26:52<20:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116777.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  57%|███▍  | 424/744 [26:56<20:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111386.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  57%|███▍  | 425/744 [27:00<20:16,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107414.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  57%|███▍  | 426/744 [27:04<20:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115958.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  57%|███▍  | 427/744 [27:07<20:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118387.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  58%|███▍  | 428/744 [27:12<20:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108428.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  58%|███▍  | 429/744 [27:15<20:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113959.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  58%|███▍  | 430/744 [27:19<19:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108493.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  58%|███▍  | 431/744 [27:23<19:53,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113919.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  58%|███▍  | 432/744 [27:26<19:49,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114053.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  58%|███▍  | 433/744 [27:30<19:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121480.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  58%|███▌  | 434/744 [27:34<19:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111286.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  58%|███▌  | 435/744 [27:38<19:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105844.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  59%|███▌  | 436/744 [27:42<19:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100338.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  59%|███▌  | 437/744 [27:46<19:30,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107625.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  59%|███▌  | 438/744 [27:50<19:26,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119023.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  59%|███▌  | 439/744 [27:53<19:22,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106343.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  59%|███▌  | 440/744 [27:57<19:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101421.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  59%|███▌  | 441/744 [28:01<19:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114629.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  59%|███▌  | 442/744 [28:05<19:11,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105704.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  60%|███▌  | 443/744 [28:08<19:07,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118153.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  60%|███▌  | 444/744 [28:12<19:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115691.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  60%|███▌  | 445/744 [28:16<18:59,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115530.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  60%|███▌  | 446/744 [28:20<18:55,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115187.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  60%|███▌  | 447/744 [28:23<18:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101939.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  60%|███▌  | 448/744 [28:27<18:48,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100866.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  60%|███▌  | 449/744 [28:31<18:44,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114496.5312, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  60%|███▋  | 450/744 [28:35<18:40,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105246.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8893, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  61%|███▋  | 451/744 [28:38<18:36,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128117.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  61%|███▋  | 452/744 [28:42<18:32,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113875.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  61%|███▋  | 453/744 [28:46<18:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118412.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  61%|███▋  | 454/744 [28:50<18:25,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117197.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  61%|███▋  | 455/744 [28:54<18:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120309.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  61%|███▋  | 456/744 [28:57<18:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113480.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8885, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  61%|███▋  | 457/744 [29:01<18:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101770.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  62%|███▋  | 458/744 [29:05<18:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110236.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  62%|███▋  | 459/744 [29:09<18:06,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109685.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  62%|███▋  | 460/744 [29:12<18:02,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102849.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  62%|███▋  | 461/744 [29:16<17:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95708.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  62%|███▋  | 462/744 [29:20<17:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109093.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  62%|███▋  | 463/744 [29:24<17:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117613.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  62%|███▋  | 464/744 [29:27<17:46,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102221.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  62%|███▊  | 465/744 [29:31<17:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112691.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  63%|███▊  | 466/744 [29:35<17:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107367.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  63%|███▊  | 467/744 [29:38<17:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113561.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7984, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  63%|███▊  | 468/744 [29:42<17:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113294.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  63%|███▊  | 469/744 [29:46<17:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116986.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  63%|███▊  | 470/744 [29:50<17:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114977.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  63%|███▊  | 471/744 [29:53<17:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120595.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  63%|███▊  | 472/744 [29:57<17:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108224.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  64%|███▊  | 473/744 [30:01<17:11,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116710.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  64%|███▊  | 474/744 [30:04<17:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111839.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  64%|███▊  | 475/744 [30:08<17:04,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96923.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  64%|███▊  | 476/744 [30:12<17:00,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101860.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  64%|███▊  | 477/744 [30:16<16:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110458.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  64%|███▊  | 478/744 [30:20<16:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112672.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  64%|███▊  | 479/744 [30:24<16:49,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97832.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  65%|███▊  | 480/744 [30:27<16:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117378.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  65%|███▉  | 481/744 [30:31<16:41,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100851.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  65%|███▉  | 482/744 [30:35<16:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111470.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  65%|███▉  | 483/744 [30:38<16:33,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113388.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  65%|███▉  | 484/744 [30:42<16:29,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93234.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  65%|███▉  | 485/744 [30:46<16:25,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104955.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  65%|███▉  | 486/744 [30:49<16:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114411.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  65%|███▉  | 487/744 [30:53<16:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106363.7812, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.7988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  66%|███▉  | 488/744 [30:57<16:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114568.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  66%|███▉  | 489/744 [31:01<16:10,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117312.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  66%|███▉  | 490/744 [31:04<16:06,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109776.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  66%|███▉  | 491/744 [31:08<16:02,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108485.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  66%|███▉  | 492/744 [31:12<15:59,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98058.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  66%|███▉  | 493/744 [31:16<15:55,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112588.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  66%|███▉  | 494/744 [31:20<15:51,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115978.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  67%|███▉  | 495/744 [31:24<15:47,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111328.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  67%|████  | 496/744 [31:28<15:44,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109481.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  67%|████  | 497/744 [31:31<15:40,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111888.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  67%|████  | 498/744 [31:35<15:36,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123859.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  67%|████  | 499/744 [31:39<15:32,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107906.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  67%|████  | 500/744 [31:43<15:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112704.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  67%|████  | 501/744 [31:47<15:25,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119859.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  67%|████  | 502/744 [31:50<15:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112864.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  68%|████  | 503/744 [31:54<15:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111654.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  68%|████  | 504/744 [31:58<15:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126328.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  68%|████  | 505/744 [32:01<15:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114324.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  68%|████  | 506/744 [32:05<15:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114623.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  68%|████  | 507/744 [32:09<15:02,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117844.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  68%|████  | 508/744 [32:13<14:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116824.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  68%|████  | 509/744 [32:17<14:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113582.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  69%|████  | 510/744 [32:20<14:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115998.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  69%|████  | 511/744 [32:24<14:46,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101621.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  69%|████▏ | 512/744 [32:28<14:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113842.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  69%|████▏ | 513/744 [32:32<14:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117277.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  69%|████▏ | 514/744 [32:36<14:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106391.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  69%|████▏ | 515/744 [32:39<14:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125003.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  69%|████▏ | 516/744 [32:43<14:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94290.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  69%|████▏ | 517/744 [32:47<14:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97666.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  70%|████▏ | 518/744 [32:51<14:20,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115232.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  70%|████▏ | 519/744 [32:55<14:16,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98489.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  70%|████▏ | 520/744 [32:59<14:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126772.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  70%|████▏ | 521/744 [33:02<14:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104146.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  70%|████▏ | 522/744 [33:06<14:04,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101541.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  70%|████▏ | 523/744 [33:10<14:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108293.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  70%|████▏ | 524/744 [33:14<13:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116710.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  71%|████▏ | 525/744 [33:17<13:53,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110368.7422, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  71%|████▏ | 526/744 [33:21<13:49,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100490.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  71%|████▎ | 527/744 [33:25<13:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110245.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  71%|████▎ | 528/744 [33:29<13:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111399.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  71%|████▎ | 529/744 [33:33<13:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119170.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  71%|████▎ | 530/744 [33:37<13:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120748.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  71%|████▎ | 531/744 [33:41<13:30,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110385.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  72%|████▎ | 532/744 [33:45<13:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115070.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  72%|████▎ | 533/744 [33:49<13:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101872.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  72%|████▎ | 534/744 [33:53<13:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114796.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  72%|████▎ | 535/744 [33:56<13:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107095.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  72%|████▎ | 536/744 [34:00<13:11,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114155.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  72%|████▎ | 537/744 [34:04<13:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112868.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  72%|████▎ | 538/744 [34:08<13:04,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119910.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  72%|████▎ | 539/744 [34:11<13:00,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110980.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  73%|████▎ | 540/744 [34:15<12:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114135.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  73%|████▎ | 541/744 [34:19<12:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105297.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  73%|████▎ | 542/744 [34:23<12:48,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100772.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  73%|████▍ | 543/744 [34:27<12:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118660.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  73%|████▍ | 544/744 [34:30<12:41,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103728.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  73%|████▍ | 545/744 [34:34<12:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120455.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  73%|████▍ | 546/744 [34:38<12:33,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103346.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  74%|████▍ | 547/744 [34:42<12:29,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117800.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  74%|████▍ | 548/744 [34:45<12:26,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106912.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  74%|████▍ | 549/744 [34:49<12:22,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115109.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  74%|████▍ | 550/744 [34:53<12:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102487.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  74%|████▍ | 551/744 [34:56<12:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109935.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  74%|████▍ | 552/744 [35:00<12:10,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121040.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  74%|████▍ | 553/744 [35:04<12:06,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107468.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  74%|████▍ | 554/744 [35:08<12:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96358.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  75%|████▍ | 555/744 [35:11<11:59,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108840.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  75%|████▍ | 556/744 [35:15<11:55,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107978.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  75%|████▍ | 557/744 [35:19<11:51,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107453.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  75%|████▌ | 558/744 [35:23<11:47,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108873.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  75%|████▌ | 559/744 [35:27<11:43,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106614.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  75%|████▌ | 560/744 [35:30<11:40,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118294.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  75%|████▌ | 561/744 [35:34<11:36,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114425.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  76%|████▌ | 562/744 [35:38<11:32,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112248.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  76%|████▌ | 563/744 [35:42<11:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117071.3125, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  76%|████▌ | 564/744 [35:46<11:25,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121779.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  76%|████▌ | 565/744 [35:50<11:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115350.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  76%|████▌ | 566/744 [35:54<11:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120909.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  76%|████▌ | 567/744 [35:57<11:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115081.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  76%|████▌ | 568/744 [36:01<11:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111448.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  76%|████▌ | 569/744 [36:05<11:06,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112752.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  77%|████▌ | 570/744 [36:09<11:02,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113887.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  77%|████▌ | 571/744 [36:13<10:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111916.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  77%|████▌ | 572/744 [36:17<10:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115094.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  77%|████▌ | 573/744 [36:21<10:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103552.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  77%|████▋ | 574/744 [36:25<10:47,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106812.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  77%|████▋ | 575/744 [36:28<10:43,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117630.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  77%|████▋ | 576/744 [36:32<10:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113379.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  78%|████▋ | 577/744 [36:36<10:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109446.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  78%|████▋ | 578/744 [36:40<10:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108715.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  78%|████▋ | 579/744 [36:44<10:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114702.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  78%|████▋ | 580/744 [36:48<10:24,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104677.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  78%|████▋ | 581/744 [36:51<10:20,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107236.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  78%|████▋ | 582/744 [36:55<10:16,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117673.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  78%|████▋ | 583/744 [36:59<10:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99300.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  78%|████▋ | 584/744 [37:03<10:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115408.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  79%|████▋ | 585/744 [37:07<10:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113257.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  79%|████▋ | 586/744 [37:11<10:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107496.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  79%|████▋ | 587/744 [37:15<09:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117916.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  79%|████▋ | 588/744 [37:18<09:53,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111028.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  79%|████▊ | 589/744 [37:22<09:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109446.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  79%|████▊ | 590/744 [37:26<09:46,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99126.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  79%|████▊ | 591/744 [37:29<09:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108007.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  80%|████▊ | 592/744 [37:33<09:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107728.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  80%|████▊ | 593/744 [37:37<09:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104359.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7853, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  80%|████▊ | 594/744 [37:41<09:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115974.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  80%|████▊ | 595/744 [37:45<09:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115925.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  80%|████▊ | 596/744 [37:49<09:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101199.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  80%|████▊ | 597/744 [37:53<09:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116356.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  80%|████▊ | 598/744 [37:57<09:16,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108523.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  81%|████▊ | 599/744 [38:01<09:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109957.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  81%|████▊ | 600/744 [38:04<09:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106426.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  81%|████▊ | 601/744 [38:08<09:04,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100878., device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  81%|████▊ | 602/744 [38:12<09:00,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104605.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  81%|████▊ | 603/744 [38:16<08:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116395.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  81%|████▊ | 604/744 [38:20<08:53,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110642.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  81%|████▉ | 605/744 [38:23<08:49,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100429.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  81%|████▉ | 606/744 [38:27<08:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107677.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  82%|████▉ | 607/744 [38:31<08:41,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115961.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  82%|████▉ | 608/744 [38:34<08:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102761.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  82%|████▉ | 609/744 [38:38<08:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120528.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  82%|████▉ | 610/744 [38:42<08:30,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105806.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  82%|████▉ | 611/744 [38:46<08:26,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107413.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  82%|████▉ | 612/744 [38:49<08:22,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115343.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  82%|████▉ | 613/744 [38:53<08:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106205.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  83%|████▉ | 614/744 [38:57<08:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98621.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  83%|████▉ | 615/744 [39:01<08:11,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115640.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  83%|████▉ | 616/744 [39:06<08:07,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126054.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  83%|████▉ | 617/744 [39:10<08:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119618.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  83%|████▉ | 618/744 [39:14<08:00,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100856.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  83%|████▉ | 619/744 [39:18<07:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110208.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  83%|█████ | 620/744 [39:22<07:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119882.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  83%|█████ | 621/744 [39:26<07:48,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109141.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  84%|█████ | 622/744 [39:29<07:44,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124180.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  84%|█████ | 623/744 [39:33<07:41,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114113.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  84%|█████ | 624/744 [39:37<07:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108019.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  84%|█████ | 625/744 [39:41<07:33,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103017.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  84%|█████ | 626/744 [39:45<07:29,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122546.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  84%|█████ | 627/744 [39:49<07:25,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118532.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  84%|█████ | 628/744 [39:53<07:22,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117955.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  85%|█████ | 629/744 [39:57<07:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119359.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  85%|█████ | 630/744 [40:01<07:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115787.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  85%|█████ | 631/744 [40:04<07:10,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110582.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  85%|█████ | 632/744 [40:08<07:06,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98934.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  85%|█████ | 633/744 [40:12<07:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117051.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  85%|█████ | 634/744 [40:16<06:59,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116266.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  85%|█████ | 635/744 [40:19<06:55,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106215.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  85%|█████▏| 636/744 [40:23<06:51,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117086.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  86%|█████▏| 637/744 [40:27<06:47,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125229.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  86%|█████▏| 638/744 [40:30<06:43,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120650.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  86%|█████▏| 639/744 [40:34<06:40,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108334.6719, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  86%|█████▏| 640/744 [40:38<06:36,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107745.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  86%|█████▏| 641/744 [40:42<06:32,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121540.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  86%|█████▏| 642/744 [40:46<06:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107178.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  86%|█████▏| 643/744 [40:50<06:24,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106982.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8819, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  87%|█████▏| 644/744 [40:53<06:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111415.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  87%|█████▏| 645/744 [40:57<06:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112254.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  87%|█████▏| 646/744 [41:01<06:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111455.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  87%|█████▏| 647/744 [41:04<06:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(86264.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  87%|█████▏| 648/744 [41:09<06:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117827.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  87%|█████▏| 649/744 [41:12<06:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109281.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  87%|█████▏| 650/744 [41:16<05:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114083.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  88%|█████▎| 651/744 [41:20<05:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93199.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  88%|█████▎| 652/744 [41:23<05:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111829.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  88%|█████▎| 653/744 [41:27<05:46,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115245.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  88%|█████▎| 654/744 [41:31<05:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112729.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  88%|█████▎| 655/744 [41:35<05:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108689.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  88%|█████▎| 656/744 [41:39<05:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110000.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  88%|█████▎| 657/744 [41:43<05:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117877.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  88%|█████▎| 658/744 [41:46<05:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117664.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  89%|█████▎| 659/744 [41:50<05:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106511.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  89%|█████▎| 660/744 [41:54<05:20,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110179.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  89%|█████▎| 661/744 [41:58<05:16,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121821.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  89%|█████▎| 662/744 [42:02<05:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113981.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  89%|█████▎| 663/744 [42:06<05:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113006.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  89%|█████▎| 664/744 [42:09<05:04,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121456.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  89%|█████▎| 665/744 [42:13<05:00,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102179.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  90%|█████▎| 666/744 [42:17<04:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113664.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  90%|█████▍| 667/744 [42:20<04:53,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115947.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  90%|█████▍| 668/744 [42:24<04:49,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92600.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  90%|█████▍| 669/744 [42:28<04:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119940.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  90%|█████▍| 670/744 [42:32<04:41,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115738.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  90%|█████▍| 671/744 [42:35<04:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95468.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  90%|█████▍| 672/744 [42:39<04:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109368.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  90%|█████▍| 673/744 [42:43<04:30,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96078.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  91%|█████▍| 674/744 [42:47<04:26,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114129.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  91%|█████▍| 675/744 [42:51<04:22,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116310.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  91%|█████▍| 676/744 [42:54<04:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114801.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  91%|█████▍| 677/744 [42:58<04:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104099.4609, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  91%|█████▍| 678/744 [43:02<04:11,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118372.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  91%|█████▍| 679/744 [43:06<04:07,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110966.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  91%|█████▍| 680/744 [43:09<04:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110282.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  92%|█████▍| 681/744 [43:13<03:59,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114854.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  92%|█████▌| 682/744 [43:17<03:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118327.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  92%|█████▌| 683/744 [43:21<03:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106980.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  92%|█████▌| 684/744 [43:25<03:48,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103313.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  92%|█████▌| 685/744 [43:28<03:44,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97393.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  92%|█████▌| 686/744 [43:32<03:40,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117857.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  92%|█████▌| 687/744 [43:36<03:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107878.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  92%|█████▌| 688/744 [43:40<03:33,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112342.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  93%|█████▌| 689/744 [43:43<03:29,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114950.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  93%|█████▌| 690/744 [43:47<03:25,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112184.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  93%|█████▌| 691/744 [43:51<03:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111963.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  93%|█████▌| 692/744 [43:55<03:18,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98910.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  93%|█████▌| 693/744 [43:58<03:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119779.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  93%|█████▌| 694/744 [44:02<03:10,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114804.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  93%|█████▌| 695/744 [44:06<03:06,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119376.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  94%|█████▌| 696/744 [44:10<03:02,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114391.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  94%|█████▌| 697/744 [44:14<02:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104014.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  94%|█████▋| 698/744 [44:17<02:55,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116607.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  94%|█████▋| 699/744 [44:21<02:51,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111627.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  94%|█████▋| 700/744 [44:25<02:47,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110410.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  94%|█████▋| 701/744 [44:29<02:43,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118983.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  94%|█████▋| 702/744 [44:33<02:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105144.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  94%|█████▋| 703/744 [44:36<02:36,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102848.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  95%|█████▋| 704/744 [44:40<02:32,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102628.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  95%|█████▋| 705/744 [44:44<02:28,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112970.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  95%|█████▋| 706/744 [44:48<02:24,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119569.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  95%|█████▋| 707/744 [44:52<02:20,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105307.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  95%|█████▋| 708/744 [44:56<02:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122116.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  95%|█████▋| 709/744 [45:00<02:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119472.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  95%|█████▋| 710/744 [45:03<02:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116842.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  96%|█████▋| 711/744 [45:07<02:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118798.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  96%|█████▋| 712/744 [45:11<02:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114591.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  96%|█████▊| 713/744 [45:14<01:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116346.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  96%|█████▊| 714/744 [45:18<01:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111990.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  96%|█████▊| 715/744 [45:22<01:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104798.8672, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  96%|█████▊| 716/744 [45:26<01:46,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109447.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  96%|█████▊| 717/744 [45:30<01:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114483.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  97%|█████▊| 718/744 [45:34<01:39,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118390.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  97%|█████▊| 719/744 [45:37<01:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116057.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  97%|█████▊| 720/744 [45:41<01:31,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99972.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  97%|█████▊| 721/744 [45:45<01:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113619.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  97%|█████▊| 722/744 [45:49<01:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119677.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  97%|█████▊| 723/744 [45:53<01:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126660.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  97%|█████▊| 724/744 [45:57<01:16,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111911.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  97%|█████▊| 725/744 [46:00<01:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104131.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  98%|█████▊| 726/744 [46:04<01:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113325.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  98%|█████▊| 727/744 [46:08<01:04,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98452.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  98%|█████▊| 728/744 [46:11<01:00,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111496.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  98%|█████▉| 729/744 [46:15<00:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114898.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  98%|█████▉| 730/744 [46:19<00:53,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105887.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  98%|█████▉| 731/744 [46:23<00:49,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100375.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  98%|█████▉| 732/744 [46:27<00:45,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100491.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  99%|█████▉| 733/744 [46:31<00:41,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105273.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  99%|█████▉| 734/744 [46:35<00:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114319.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  99%|█████▉| 735/744 [46:39<00:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115622.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  99%|█████▉| 736/744 [46:43<00:30,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104279.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  99%|█████▉| 737/744 [46:46<00:26,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103896.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  99%|█████▉| 738/744 [46:50<00:22,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114344.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  99%|█████▉| 739/744 [46:54<00:19,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99113.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17:  99%|█████▉| 740/744 [46:58<00:15,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113792.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17: 100%|█████▉| 741/744 [47:01<00:11,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128294.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17: 100%|█████▉| 742/744 [47:05<00:07,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113546.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17: 100%|█████▉| 743/744 [47:08<00:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111771.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   0%|                | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(119433.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   0%|      | 1/744 [00:05<1:02:55,  5.08s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116998.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   0%|        | 2/744 [00:08<53:24,  4.32s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118206.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   0%|        | 3/744 [00:12<51:06,  4.14s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110445.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   1%|        | 4/744 [00:16<49:47,  4.04s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117163.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   1%|        | 5/744 [00:19<49:08,  3.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128128.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   1%|        | 6/744 [00:23<48:22,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125594.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   1%|        | 7/744 [00:27<47:57,  3.90s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110064.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   1%|        | 8/744 [00:31<47:45,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111550.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   1%|        | 9/744 [00:34<47:30,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110195.1953, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   1%|       | 10/744 [00:38<47:22,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101483.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9885, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   1%|       | 11/744 [00:42<47:23,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109123.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   2%|       | 12/744 [00:46<47:22,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111515.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   2%|       | 13/744 [00:50<47:14,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112412.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   2%|▏      | 14/744 [00:54<47:05,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117575.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   2%|▏      | 15/744 [00:58<47:04,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117441.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   2%|▏      | 16/744 [01:01<47:00,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116630.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   2%|▏      | 17/744 [01:05<46:54,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106285.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   2%|▏      | 18/744 [01:09<46:54,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115496.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   3%|▏      | 19/744 [01:13<46:36,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123045.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   3%|▏      | 20/744 [01:17<46:31,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112749.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   3%|▏      | 21/744 [01:20<46:27,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117605.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   3%|▏      | 22/744 [01:24<46:28,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111449.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   3%|▏      | 23/744 [01:28<46:20,  3.86s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114182.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   3%|▏      | 24/744 [01:32<46:09,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122058.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   3%|▏      | 25/744 [01:36<46:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111851.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   3%|▏      | 26/744 [01:39<45:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97722.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   4%|▎      | 27/744 [01:43<45:49,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113774., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   4%|▎      | 28/744 [01:47<45:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115411.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   4%|▎      | 29/744 [01:51<45:48,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113610.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   4%|▎      | 30/744 [01:55<45:50,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107147.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   4%|▎      | 31/744 [01:59<45:43,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111754.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   4%|▎      | 32/744 [02:03<45:42,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114136.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   4%|▎      | 33/744 [02:06<45:34,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107799.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   5%|▎      | 34/744 [02:10<45:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99534.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   5%|▎      | 35/744 [02:14<45:25,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110879.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   5%|▎      | 36/744 [02:18<45:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127073.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   5%|▎      | 37/744 [02:22<45:16,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126750.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   5%|▎      | 38/744 [02:25<45:08,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109221.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   5%|▎      | 39/744 [02:29<45:09,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110247.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   5%|▍      | 40/744 [02:33<45:08,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113742.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   6%|▍      | 41/744 [02:37<45:02,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121877.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   6%|▍      | 42/744 [02:41<44:59,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101112.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   6%|▍      | 43/744 [02:45<44:57,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118219.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   6%|▍      | 44/744 [02:49<44:53,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112288.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   6%|▍      | 45/744 [02:53<44:48,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117661.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   6%|▍      | 46/744 [02:56<44:43,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115145.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   6%|▍      | 47/744 [03:00<44:37,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110487.8047, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   6%|▍      | 48/744 [03:04<44:40,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100926.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   7%|▍      | 49/744 [03:08<44:32,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110762.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   7%|▍      | 50/744 [03:12<44:30,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126003.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   7%|▍      | 51/744 [03:16<44:25,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110070.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   7%|▍      | 52/744 [03:20<44:22,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118714.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   7%|▍      | 53/744 [03:23<44:16,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107922.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   7%|▌      | 54/744 [03:27<44:12,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115503.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   7%|▌      | 55/744 [03:31<44:10,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118382.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   8%|▌      | 56/744 [03:35<44:05,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104507.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   8%|▌      | 57/744 [03:39<43:59,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117642.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   8%|▌      | 58/744 [03:42<43:53,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103680.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   8%|▌      | 59/744 [03:46<43:49,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118512.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   8%|▌      | 60/744 [03:50<43:44,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124130.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   8%|▌      | 61/744 [03:54<43:41,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105864.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   8%|▌      | 62/744 [03:57<43:36,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118685.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   8%|▌      | 63/744 [04:01<43:34,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111474.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   9%|▌      | 64/744 [04:05<43:28,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113471.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   9%|▌      | 65/744 [04:09<43:26,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114849., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   9%|▌      | 66/744 [04:13<43:20,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108302.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   9%|▋      | 67/744 [04:17<43:18,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118637.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   9%|▋      | 68/744 [04:20<43:14,  3.84s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110873.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   9%|▋      | 69/744 [04:24<43:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95844.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:   9%|▋      | 70/744 [04:28<43:03,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111091.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  10%|▋      | 71/744 [04:31<42:57,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126017., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  10%|▋      | 72/744 [04:35<42:51,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108891.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  10%|▋      | 73/744 [04:39<42:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112115.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  10%|▋      | 74/744 [04:43<42:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116978.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  10%|▋      | 75/744 [04:47<42:41,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115387.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  10%|▋      | 76/744 [04:50<42:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104718.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  10%|▋      | 77/744 [04:54<42:32,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109718.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  10%|▋      | 78/744 [04:58<42:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107714.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  11%|▋      | 79/744 [05:02<42:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111485.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  11%|▊      | 80/744 [05:05<42:19,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102434.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  11%|▊      | 81/744 [05:09<42:16,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111513.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  11%|▊      | 82/744 [05:13<42:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111858.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  11%|▊      | 83/744 [05:17<42:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128609.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  11%|▊      | 84/744 [05:21<42:06,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110696.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  11%|▊      | 85/744 [05:25<42:02,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105270.1562, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  12%|▊      | 86/744 [05:29<41:59,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126425.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  12%|▊      | 87/744 [05:33<41:55,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108176.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  12%|▊      | 88/744 [05:36<41:50,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116181.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  12%|▊      | 89/744 [05:40<41:46,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108772.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  12%|▊      | 90/744 [05:44<41:41,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116288.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  12%|▊      | 91/744 [05:48<41:38,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102786.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  12%|▊      | 92/744 [05:52<41:35,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115125.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  12%|▉      | 93/744 [05:55<41:31,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120384.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  13%|▉      | 94/744 [05:59<41:28,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109389.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  13%|▉      | 95/744 [06:03<41:25,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108880.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  13%|▉      | 96/744 [06:07<41:19,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110739.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  13%|▉      | 97/744 [06:11<41:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101679.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  13%|▉      | 98/744 [06:15<41:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128794.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  13%|▉      | 99/744 [06:18<41:08,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112719.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  13%|▊     | 100/744 [06:22<41:04,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111016.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  14%|▊     | 101/744 [06:26<41:01,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103121.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  14%|▊     | 102/744 [06:30<40:56,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122011.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  14%|▊     | 103/744 [06:34<40:52,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120777.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  14%|▊     | 104/744 [06:37<40:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113978.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  14%|▊     | 105/744 [06:41<40:45,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115643.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  14%|▊     | 106/744 [06:45<40:40,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123277.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  14%|▊     | 107/744 [06:49<40:37,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102717.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  15%|▊     | 108/744 [06:53<40:33,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108981.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  15%|▉     | 109/744 [06:57<40:30,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96960.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  15%|▉     | 110/744 [07:00<40:26,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123820.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  15%|▉     | 111/744 [07:04<40:21,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114014.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  15%|▉     | 112/744 [07:08<40:17,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113530.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  15%|▉     | 113/744 [07:12<40:13,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111632.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  15%|▉     | 114/744 [07:16<40:09,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130643.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  15%|▉     | 115/744 [07:19<40:05,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101614.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  16%|▉     | 116/744 [07:23<40:01,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113875.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  16%|▉     | 117/744 [07:27<39:57,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128243.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  16%|▉     | 118/744 [07:31<39:53,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109124.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  16%|▉     | 119/744 [07:34<39:49,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112826.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  16%|▉     | 120/744 [07:38<39:44,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107632.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  16%|▉     | 121/744 [07:42<39:40,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115840.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  16%|▉     | 122/744 [07:46<39:35,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122251.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  17%|▉     | 123/744 [07:49<39:31,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109242.0547, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  17%|█     | 124/744 [07:53<39:26,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107314.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  17%|█     | 125/744 [07:56<39:22,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117198.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  17%|█     | 126/744 [08:00<39:17,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114513.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  17%|█     | 127/744 [08:04<39:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110147.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  17%|█     | 128/744 [08:08<39:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116005.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  17%|█     | 129/744 [08:11<39:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109348.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  17%|█     | 130/744 [08:15<39:00,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111496.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  18%|█     | 131/744 [08:19<38:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112590.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  18%|█     | 132/744 [08:23<38:54,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111625.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  18%|█     | 133/744 [08:27<38:51,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116104.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  18%|█     | 134/744 [08:31<38:47,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123956.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  18%|█     | 135/744 [08:34<38:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116560.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  18%|█     | 136/744 [08:38<38:38,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106777.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  18%|█     | 137/744 [08:42<38:34,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119704.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  19%|█     | 138/744 [08:45<38:29,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113677.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  19%|█     | 139/744 [08:49<38:25,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111903.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  19%|█▏    | 140/744 [08:53<38:22,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126202.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9070, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  19%|█▏    | 141/744 [08:57<38:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113876.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  19%|█▏    | 142/744 [09:00<38:12,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111761.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  19%|█▏    | 143/744 [09:04<38:08,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113949.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  19%|█▏    | 144/744 [09:08<38:04,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128643.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  19%|█▏    | 145/744 [09:12<38:00,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115681.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  20%|█▏    | 146/744 [09:15<37:56,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100154.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  20%|█▏    | 147/744 [09:19<37:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126794.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  20%|█▏    | 148/744 [09:23<37:48,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112711.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  20%|█▏    | 149/744 [09:26<37:43,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113079.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  20%|█▏    | 150/744 [09:30<37:40,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110487.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  20%|█▏    | 151/744 [09:34<37:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115900.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  20%|█▏    | 152/744 [09:38<37:33,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120030.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  21%|█▏    | 153/744 [09:42<37:29,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111221.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  21%|█▏    | 154/744 [09:46<37:25,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99107.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  21%|█▎    | 155/744 [09:49<37:20,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110234.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  21%|█▎    | 156/744 [09:53<37:16,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113177.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  21%|█▎    | 157/744 [09:57<37:14,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112718.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  21%|█▎    | 158/744 [10:01<37:10,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106390.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  21%|█▎    | 159/744 [10:05<37:07,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(96915.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  22%|█▎    | 160/744 [10:09<37:03,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95248.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  22%|█▎    | 161/744 [10:13<37:00,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116716.8281, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  22%|█▎    | 162/744 [10:17<36:57,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120108.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  22%|█▎    | 163/744 [10:20<36:52,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115835.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  22%|█▎    | 164/744 [10:24<36:48,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110656.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  22%|█▎    | 165/744 [10:28<36:44,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121786.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  22%|█▎    | 166/744 [10:32<36:40,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101633.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  22%|█▎    | 167/744 [10:35<36:37,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124300.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  23%|█▎    | 168/744 [10:39<36:33,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117284.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  23%|█▎    | 169/744 [10:43<36:30,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122021.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  23%|█▎    | 170/744 [10:47<36:26,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98241.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  23%|█▍    | 171/744 [10:51<36:21,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113352.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  23%|█▍    | 172/744 [10:54<36:17,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114339.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  23%|█▍    | 173/744 [10:58<36:13,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103309.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  23%|█▍    | 174/744 [11:02<36:09,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121509.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  24%|█▍    | 175/744 [11:05<36:05,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119812.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  24%|█▍    | 176/744 [11:09<36:01,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112674.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  24%|█▍    | 177/744 [11:13<35:58,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114817.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  24%|█▍    | 178/744 [11:17<35:55,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110726.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  24%|█▍    | 179/744 [11:21<35:50,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106785.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  24%|█▍    | 180/744 [11:24<35:46,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114532.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  24%|█▍    | 181/744 [11:28<35:42,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106653.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  24%|█▍    | 182/744 [11:32<35:38,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116094.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  25%|█▍    | 183/744 [11:36<35:34,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110890.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8756, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  25%|█▍    | 184/744 [11:39<35:30,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116284.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  25%|█▍    | 185/744 [11:43<35:26,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112364.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  25%|█▌    | 186/744 [11:47<35:22,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122882.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  25%|█▌    | 187/744 [11:51<35:17,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119326.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  25%|█▌    | 188/744 [11:54<35:13,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114644.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  25%|█▌    | 189/744 [11:58<35:10,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121622.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  26%|█▌    | 190/744 [12:02<35:06,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109456.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  26%|█▌    | 191/744 [12:06<35:02,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108243.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  26%|█▌    | 192/744 [12:09<34:57,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112883.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  26%|█▌    | 193/744 [12:13<34:53,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100801.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  26%|█▌    | 194/744 [12:17<34:50,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121380.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  26%|█▌    | 195/744 [12:20<34:45,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124551.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  26%|█▌    | 196/744 [12:24<34:41,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109371.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  26%|█▌    | 197/744 [12:28<34:37,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109552.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  27%|█▌    | 198/744 [12:32<34:34,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117964.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  27%|█▌    | 199/744 [12:35<34:29,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111066.0625, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  27%|█▌    | 200/744 [12:39<34:25,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99570.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  27%|█▌    | 201/744 [12:43<34:21,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122194.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  27%|█▋    | 202/744 [12:46<34:17,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121533.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  27%|█▋    | 203/744 [12:50<34:13,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115713.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  27%|█▋    | 204/744 [12:54<34:09,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124646.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  28%|█▋    | 205/744 [12:57<34:05,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115166.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  28%|█▋    | 206/744 [13:01<34:00,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111099.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  28%|█▋    | 207/744 [13:05<33:56,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116771.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  28%|█▋    | 208/744 [13:08<33:53,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104191.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  28%|█▋    | 209/744 [13:12<33:48,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120657.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  28%|█▋    | 210/744 [13:16<33:44,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105800.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  28%|█▋    | 211/744 [13:19<33:40,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113174.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  28%|█▋    | 212/744 [13:23<33:36,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109884.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  29%|█▋    | 213/744 [13:27<33:32,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113848.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  29%|█▋    | 214/744 [13:30<33:28,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113461.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  29%|█▋    | 215/744 [13:34<33:25,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118034.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  29%|█▋    | 216/744 [13:38<33:20,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123180.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  29%|█▊    | 217/744 [13:42<33:16,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115486.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  29%|█▊    | 218/744 [13:45<33:12,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118129.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  29%|█▊    | 219/744 [13:49<33:07,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99817.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  30%|█▊    | 220/744 [13:52<33:03,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105031.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  30%|█▊    | 221/744 [13:56<32:59,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(98914.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  30%|█▊    | 222/744 [14:00<32:56,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117776.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  30%|█▊    | 223/744 [14:04<32:52,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105663.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  30%|█▊    | 224/744 [14:07<32:48,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115540.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  30%|█▊    | 225/744 [14:11<32:44,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123537.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  30%|█▊    | 226/744 [14:15<32:40,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112831.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  31%|█▊    | 227/744 [14:18<32:36,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110595.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  31%|█▊    | 228/744 [14:22<32:32,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123567., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  31%|█▊    | 229/744 [14:26<32:28,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103969., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  31%|█▊    | 230/744 [14:30<32:24,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112040.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  31%|█▊    | 231/744 [14:33<32:20,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105520.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  31%|█▊    | 232/744 [14:37<32:16,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119306.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  31%|█▉    | 233/744 [14:41<32:12,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112959.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  31%|█▉    | 234/744 [14:44<32:08,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118949.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  32%|█▉    | 235/744 [14:48<32:04,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116162.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  32%|█▉    | 236/744 [14:52<32:00,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108325.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  32%|█▉    | 237/744 [14:55<31:56,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105819.7969, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  32%|█▉    | 238/744 [14:59<31:52,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123467.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  32%|█▉    | 239/744 [15:03<31:48,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110451.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  32%|█▉    | 240/744 [15:07<31:45,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112998.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  32%|█▉    | 241/744 [15:11<31:41,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103813.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  33%|█▉    | 242/744 [15:15<31:38,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108919.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  33%|█▉    | 243/744 [15:19<31:34,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108716.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  33%|█▉    | 244/744 [15:22<31:31,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117375.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  33%|█▉    | 245/744 [15:26<31:26,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121017.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  33%|█▉    | 246/744 [15:30<31:22,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106755.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  33%|█▉    | 247/744 [15:34<31:19,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111805.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  33%|██    | 248/744 [15:37<31:15,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116350.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  33%|██    | 249/744 [15:41<31:11,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109923.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  34%|██    | 250/744 [15:45<31:07,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107439.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  34%|██    | 251/744 [15:48<31:03,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125399.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  34%|██    | 252/744 [15:52<31:00,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106166.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  34%|██    | 253/744 [15:56<30:56,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118073.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  34%|██    | 254/744 [16:00<30:52,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119720.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  34%|██    | 255/744 [16:03<30:48,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121858.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  34%|██    | 256/744 [16:07<30:44,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119068.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  35%|██    | 257/744 [16:11<30:40,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112304.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  35%|██    | 258/744 [16:15<30:36,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122793.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  35%|██    | 259/744 [16:18<30:32,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116938.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  35%|██    | 260/744 [16:22<30:28,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106452.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  35%|██    | 261/744 [16:26<30:25,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109853.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  35%|██    | 262/744 [16:29<30:21,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123897.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  35%|██    | 263/744 [16:33<30:17,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107982.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  35%|██▏   | 264/744 [16:37<30:13,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107466.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  36%|██▏   | 265/744 [16:41<30:09,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113864.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  36%|██▏   | 266/744 [16:45<30:05,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112982.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  36%|██▏   | 267/744 [16:48<30:02,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126191.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  36%|██▏   | 268/744 [16:52<29:58,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110325.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  36%|██▏   | 269/744 [16:56<29:54,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119813.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  36%|██▏   | 270/744 [16:59<29:49,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102648.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  36%|██▏   | 271/744 [17:03<29:46,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120428.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  37%|██▏   | 272/744 [17:06<29:41,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122849.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  37%|██▏   | 273/744 [17:10<29:38,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120404.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  37%|██▏   | 274/744 [17:14<29:34,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111000.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  37%|██▏   | 275/744 [17:18<29:30,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117010.8203, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_d:   tensor(0.8806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  37%|██▏   | 276/744 [17:22<29:27,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123477.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  37%|██▏   | 277/744 [17:25<29:23,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126588.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  37%|██▏   | 278/744 [17:29<29:19,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118430.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  38%|██▎   | 279/744 [17:33<29:15,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122222.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  38%|██▎   | 280/744 [17:36<29:11,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109137.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  38%|██▎   | 281/744 [17:40<29:07,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124508.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  38%|██▎   | 282/744 [17:44<29:03,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127829.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  38%|██▎   | 283/744 [17:47<28:59,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107840.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  38%|██▎   | 284/744 [17:51<28:55,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122075.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  38%|██▎   | 285/744 [17:55<28:52,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114347.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  38%|██▎   | 286/744 [17:58<28:47,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130081.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  39%|██▎   | 287/744 [18:02<28:44,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118514.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  39%|██▎   | 288/744 [18:06<28:40,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110271.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  39%|██▎   | 289/744 [18:10<28:36,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117459.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  39%|██▎   | 290/744 [18:13<28:32,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128311.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  39%|██▎   | 291/744 [18:17<28:28,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113428.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  39%|██▎   | 292/744 [18:21<28:25,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119337.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  39%|██▎   | 293/744 [18:25<28:21,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113090.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  40%|██▎   | 294/744 [18:28<28:17,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122145.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  40%|██▍   | 295/744 [18:32<28:13,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117898.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  40%|██▍   | 296/744 [18:36<28:09,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107658.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  40%|██▍   | 297/744 [18:40<28:05,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105239.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  40%|██▍   | 298/744 [18:43<28:01,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123950.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  40%|██▍   | 299/744 [18:47<27:57,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112512.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  40%|██▍   | 300/744 [18:51<27:53,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101808.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  40%|██▍   | 301/744 [18:54<27:50,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120385.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  41%|██▍   | 302/744 [18:58<27:46,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126299.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  41%|██▍   | 303/744 [19:02<27:42,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121020.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  41%|██▍   | 304/744 [19:06<27:38,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117951.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  41%|██▍   | 305/744 [19:09<27:34,  3.77s/it, loss=nan, v_num=5.48e+7]loss_d:   tensor(0.9747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  41%|██▍   | 307/744 [19:16<27:26,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113240.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  41%|██▍   | 308/744 [19:20<27:23,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110147.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  42%|██▍   | 309/744 [19:24<27:19,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115863.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  42%|██▌   | 310/744 [19:28<27:15,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118716.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  42%|██▌   | 311/744 [19:32<27:12,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106222.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  42%|██▌   | 312/744 [19:35<27:08,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119558.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  42%|██▌   | 313/744 [19:39<27:04,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108006.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  42%|██▌   | 314/744 [19:43<27:01,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118984.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9162, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  42%|██▌   | 315/744 [19:47<26:57,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108968.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  42%|██▌   | 316/744 [19:51<26:53,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114467.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  43%|██▌   | 317/744 [19:55<26:49,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123044.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  43%|██▌   | 318/744 [19:58<26:45,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112274.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  43%|██▌   | 319/744 [20:02<26:42,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99058.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  43%|██▌   | 320/744 [20:06<26:38,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112488.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  43%|██▌   | 321/744 [20:09<26:34,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106212.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  43%|██▌   | 322/744 [20:13<26:30,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108492.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  43%|██▌   | 323/744 [20:16<26:26,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114026.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  44%|██▌   | 324/744 [20:20<26:22,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122092.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8756, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  44%|██▌   | 325/744 [20:24<26:18,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100841.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  44%|██▋   | 326/744 [20:28<26:14,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113134.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  44%|██▋   | 327/744 [20:31<26:10,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111266.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  44%|██▋   | 328/744 [20:35<26:06,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117834.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  44%|██▋   | 329/744 [20:39<26:02,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124130.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  44%|██▋   | 330/744 [20:42<25:59,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113600.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  44%|██▋   | 331/744 [20:46<25:54,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103921.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  45%|██▋   | 332/744 [20:49<25:50,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127037.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  45%|██▋   | 333/744 [20:53<25:46,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100168.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  45%|██▋   | 334/744 [20:57<25:43,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117699.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  45%|██▋   | 335/744 [21:00<25:39,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104633.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  45%|██▋   | 336/744 [21:04<25:35,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115016.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  45%|██▋   | 337/744 [21:07<25:31,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126845.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  45%|██▋   | 338/744 [21:11<25:27,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122580.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  46%|██▋   | 339/744 [21:15<25:23,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115449.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  46%|██▋   | 340/744 [21:18<25:19,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113662.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  46%|██▊   | 341/744 [21:22<25:15,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120982.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  46%|██▊   | 342/744 [21:25<25:11,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121828.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  46%|██▊   | 343/744 [21:29<25:07,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122225.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  46%|██▊   | 344/744 [21:33<25:03,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110103.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  46%|██▊   | 345/744 [21:37<25:00,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106236.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  47%|██▊   | 346/744 [21:40<24:56,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115336.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  47%|██▊   | 347/744 [21:44<24:52,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122499.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  47%|██▊   | 348/744 [21:48<24:48,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119904.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  47%|██▊   | 349/744 [21:51<24:44,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123245.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8739, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  47%|██▊   | 350/744 [21:55<24:40,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110438.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  47%|██▊   | 351/744 [21:58<24:36,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109959.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  47%|██▊   | 352/744 [22:02<24:32,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124924.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9261, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  47%|██▊   | 353/744 [22:06<24:29,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119298.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  48%|██▊   | 354/744 [22:10<24:25,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111972.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  48%|██▊   | 355/744 [22:13<24:21,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107323.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  48%|██▊   | 356/744 [22:17<24:17,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125941.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  48%|██▉   | 357/744 [22:21<24:13,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126587.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8909, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  48%|██▉   | 358/744 [22:24<24:09,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114770.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  48%|██▉   | 359/744 [22:28<24:05,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115500.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  48%|██▉   | 360/744 [22:32<24:02,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124996.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  49%|██▉   | 361/744 [22:35<23:58,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116841.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  49%|██▉   | 362/744 [22:39<23:54,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113874.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  49%|██▉   | 363/744 [22:42<23:50,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116452.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  49%|██▉   | 364/744 [22:46<23:46,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111961.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  49%|██▉   | 365/744 [22:50<23:42,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112030.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  49%|██▉   | 366/744 [22:53<23:38,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112768.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  49%|██▉   | 367/744 [22:57<23:34,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127442.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  49%|██▉   | 368/744 [23:01<23:31,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110975.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  50%|██▉   | 369/744 [23:04<23:27,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113530.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  50%|██▉   | 370/744 [23:08<23:23,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128837.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  50%|██▉   | 371/744 [23:12<23:19,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(94000.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  50%|███   | 372/744 [23:16<23:16,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107571.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  50%|███   | 373/744 [23:19<23:12,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129524.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  50%|███   | 374/744 [23:23<23:08,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116381.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  50%|███   | 375/744 [23:27<23:04,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116626.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  51%|███   | 376/744 [23:30<23:00,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107301.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  51%|███   | 377/744 [23:34<22:57,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125201.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  51%|███   | 378/744 [23:38<22:53,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119607.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  51%|███   | 379/744 [23:42<22:49,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101216.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  51%|███   | 380/744 [23:45<22:45,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100107.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  51%|███   | 381/744 [23:49<22:41,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112046.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  51%|███   | 382/744 [23:52<22:37,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113420.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  51%|███   | 383/744 [23:56<22:33,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119487.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  52%|███   | 384/744 [23:59<22:29,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118278.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  52%|███   | 385/744 [24:03<22:26,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116706.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  52%|███   | 386/744 [24:07<22:22,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123466.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  52%|███   | 387/744 [24:11<22:18,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126807.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  52%|███▏  | 388/744 [24:14<22:14,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117128.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  52%|███▏  | 389/744 [24:18<22:10,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107596.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  52%|███▏  | 390/744 [24:21<22:06,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107979.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9219, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  53%|███▏  | 391/744 [24:25<22:03,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129129.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  53%|███▏  | 392/744 [24:28<21:59,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126644.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9819, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  53%|███▏  | 393/744 [24:32<21:55,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116799.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  53%|███▏  | 394/744 [24:36<21:51,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118471.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  53%|███▏  | 395/744 [24:40<21:47,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121120.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  53%|███▏  | 396/744 [24:43<21:44,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118280.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  53%|███▏  | 397/744 [24:47<21:40,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120299.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  53%|███▏  | 398/744 [24:51<21:36,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103406.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  54%|███▏  | 399/744 [24:54<21:32,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121196.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  54%|███▏  | 400/744 [24:58<21:29,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108754.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  54%|███▏  | 401/744 [25:02<21:25,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130085.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8917, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  54%|███▏  | 402/744 [25:06<21:21,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121410.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9277, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  54%|███▎  | 403/744 [25:09<21:17,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111497.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  54%|███▎  | 404/744 [25:13<21:13,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112008.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  54%|███▎  | 405/744 [25:16<21:09,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105551.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  55%|███▎  | 406/744 [25:20<21:05,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126845.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  55%|███▎  | 407/744 [25:23<21:01,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119189.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  55%|███▎  | 408/744 [25:27<20:58,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115686.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  55%|███▎  | 409/744 [25:31<20:54,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115294.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  55%|███▎  | 410/744 [25:34<20:50,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117841.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  55%|███▎  | 411/744 [25:38<20:46,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113473.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  55%|███▎  | 412/744 [25:42<20:42,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115369.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  56%|███▎  | 413/744 [25:45<20:38,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128634.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  56%|███▎  | 414/744 [25:49<20:34,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121785.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  56%|███▎  | 415/744 [25:52<20:30,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117085.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  56%|███▎  | 416/744 [25:56<20:27,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119642.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  56%|███▎  | 417/744 [25:59<20:23,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126443.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  56%|███▎  | 418/744 [26:03<20:19,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105877.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  56%|███▍  | 419/744 [26:07<20:15,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114248.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  56%|███▍  | 420/744 [26:10<20:11,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119768.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  57%|███▍  | 421/744 [26:14<20:07,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118946.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  57%|███▍  | 422/744 [26:17<20:04,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115565.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  57%|███▍  | 423/744 [26:21<20:00,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123544.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  57%|███▍  | 424/744 [26:25<19:56,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114605.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  57%|███▍  | 425/744 [26:29<19:52,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117384.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  57%|███▍  | 426/744 [26:32<19:49,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115203.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  57%|███▍  | 427/744 [26:36<19:45,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124473.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  58%|███▍  | 428/744 [26:40<19:41,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113798.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9566, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  58%|███▍  | 429/744 [26:43<19:37,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109623.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  58%|███▍  | 430/744 [26:47<19:33,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130382.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  58%|███▍  | 431/744 [26:51<19:29,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112847.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  58%|███▍  | 432/744 [26:55<19:26,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117385., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  58%|███▍  | 433/744 [26:58<19:22,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103372.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  58%|███▌  | 434/744 [27:02<19:18,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115049.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  58%|███▌  | 435/744 [27:06<19:15,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109625.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  59%|███▌  | 436/744 [27:09<19:11,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121273.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  59%|███▌  | 437/744 [27:13<19:07,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120658.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  59%|███▌  | 438/744 [27:17<19:03,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127052.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  59%|███▌  | 439/744 [27:20<18:59,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110214.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  59%|███▌  | 440/744 [27:24<18:56,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102243.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  59%|███▌  | 441/744 [27:28<18:52,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121119.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  59%|███▌  | 442/744 [27:32<18:48,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118938.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  60%|███▌  | 443/744 [27:35<18:45,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110327.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  60%|███▌  | 444/744 [27:39<18:41,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110378.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  60%|███▌  | 445/744 [27:43<18:37,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115906.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  60%|███▌  | 446/744 [27:46<18:33,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116006.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  60%|███▌  | 447/744 [27:50<18:29,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124263.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8080, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  60%|███▌  | 448/744 [27:54<18:26,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128117.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  60%|███▌  | 449/744 [27:57<18:22,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99518.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  60%|███▋  | 450/744 [28:01<18:18,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134687.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  61%|███▋  | 451/744 [28:05<18:14,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104971.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  61%|███▋  | 452/744 [28:08<18:11,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104975.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  61%|███▋  | 453/744 [28:12<18:07,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115726.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  61%|███▋  | 454/744 [28:16<18:03,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116117.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  61%|███▋  | 455/744 [28:19<17:59,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123717.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  61%|███▋  | 456/744 [28:23<17:55,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106982.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  61%|███▋  | 457/744 [28:27<17:52,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(78625.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  62%|███▋  | 458/744 [28:30<17:48,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119956.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  62%|███▋  | 459/744 [28:34<17:44,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113082.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  62%|███▋  | 460/744 [28:38<17:40,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108754.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  62%|███▋  | 461/744 [28:41<17:37,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110280.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  62%|███▋  | 462/744 [28:45<17:33,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115037.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  62%|███▋  | 463/744 [28:49<17:29,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110743.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  62%|███▋  | 464/744 [28:53<17:25,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107475.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  62%|███▊  | 465/744 [28:56<17:22,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120955.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  63%|███▊  | 466/744 [29:00<17:18,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125015.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9492, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  63%|███▊  | 467/744 [29:04<17:14,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127154.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  63%|███▊  | 468/744 [29:07<17:10,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119429.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  63%|███▊  | 469/744 [29:11<17:07,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125201.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  63%|███▊  | 470/744 [29:15<17:03,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119045.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8609, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  63%|███▊  | 471/744 [29:19<16:59,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117133.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  63%|███▊  | 472/744 [29:22<16:55,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118065.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  64%|███▊  | 473/744 [29:26<16:51,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103396.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  64%|███▊  | 474/744 [29:29<16:48,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116822.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  64%|███▊  | 475/744 [29:33<16:44,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107727.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  64%|███▊  | 476/744 [29:37<16:40,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121675.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  64%|███▊  | 477/744 [29:40<16:36,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121428.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  64%|███▊  | 478/744 [29:44<16:32,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118686.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  64%|███▊  | 479/744 [29:48<16:29,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119574.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  65%|███▊  | 480/744 [29:51<16:25,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113399.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  65%|███▉  | 481/744 [29:55<16:21,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106757.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  65%|███▉  | 482/744 [29:59<16:17,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100070.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  65%|███▉  | 483/744 [30:02<16:14,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122756.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  65%|███▉  | 484/744 [30:06<16:10,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116572.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  65%|███▉  | 485/744 [30:10<16:06,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120956.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  65%|███▉  | 486/744 [30:13<16:02,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120694.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  65%|███▉  | 487/744 [30:17<15:59,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106461.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  66%|███▉  | 488/744 [30:21<15:55,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105495.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  66%|███▉  | 489/744 [30:24<15:51,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118638.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  66%|███▉  | 490/744 [30:28<15:47,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117210.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  66%|███▉  | 491/744 [30:32<15:44,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121541.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  66%|███▉  | 492/744 [30:36<15:40,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111777.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  66%|███▉  | 493/744 [30:39<15:36,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126428.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  66%|███▉  | 494/744 [30:43<15:33,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131852.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  67%|███▉  | 495/744 [30:47<15:29,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123666.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  67%|████  | 496/744 [30:51<15:25,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116481.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  67%|████  | 497/744 [30:54<15:21,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122487.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  67%|████  | 498/744 [30:58<15:18,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114534.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9103, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  67%|████  | 499/744 [31:01<15:14,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121824.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  67%|████  | 500/744 [31:05<15:10,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104707.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  67%|████  | 501/744 [31:09<15:06,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100577.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  67%|████  | 502/744 [31:12<15:02,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111273.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  68%|████  | 503/744 [31:16<14:59,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126447.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  68%|████  | 504/744 [31:19<14:55,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129552.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8933, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  68%|████  | 505/744 [31:23<14:51,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122833.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  68%|████  | 506/744 [31:27<14:47,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115379.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  68%|████  | 507/744 [31:30<14:43,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110703.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  68%|████  | 508/744 [31:34<14:40,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113908.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  68%|████  | 509/744 [31:38<14:36,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114767.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  69%|████  | 510/744 [31:42<14:32,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112483.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  69%|████  | 511/744 [31:45<14:28,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113185.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  69%|████▏ | 512/744 [31:49<14:25,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130596.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  69%|████▏ | 513/744 [31:53<14:21,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114040.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  69%|████▏ | 514/744 [31:56<14:17,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112137.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  69%|████▏ | 515/744 [32:00<14:14,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122770.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  69%|████▏ | 516/744 [32:04<14:10,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126288.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  69%|████▏ | 517/744 [32:07<14:06,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116123.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  70%|████▏ | 518/744 [32:11<14:02,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119682.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  70%|████▏ | 519/744 [32:15<13:59,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122053.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  70%|████▏ | 520/744 [32:18<13:55,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124001.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  70%|████▏ | 521/744 [32:22<13:51,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120895.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  70%|████▏ | 522/744 [32:26<13:47,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106487.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  70%|████▏ | 523/744 [32:29<13:43,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116167.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  70%|████▏ | 524/744 [32:33<13:40,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115998.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  71%|████▏ | 525/744 [32:37<13:36,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109996.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  71%|████▏ | 526/744 [32:40<13:32,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111527.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8601, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  71%|████▎ | 527/744 [32:44<13:28,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109835.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  71%|████▎ | 528/744 [32:47<13:24,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99178.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  71%|████▎ | 529/744 [32:51<13:21,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118379.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  71%|████▎ | 530/744 [32:55<13:17,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116994.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  71%|████▎ | 531/744 [32:58<13:13,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128345.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  72%|████▎ | 532/744 [33:02<13:10,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128590.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  72%|████▎ | 533/744 [33:06<13:06,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111418.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  72%|████▎ | 534/744 [33:10<13:02,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115531.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  72%|████▎ | 535/744 [33:13<12:58,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128470.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  72%|████▎ | 536/744 [33:17<12:55,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109542.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9739, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  72%|████▎ | 537/744 [33:20<12:51,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117117.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  72%|████▎ | 538/744 [33:24<12:47,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124535.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  72%|████▎ | 539/744 [33:28<12:43,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104401.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  73%|████▎ | 540/744 [33:31<12:40,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116518.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  73%|████▎ | 541/744 [33:35<12:36,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103766.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  73%|████▎ | 542/744 [33:39<12:32,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124825.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9385, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  73%|████▍ | 543/744 [33:43<12:28,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122315.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  73%|████▍ | 544/744 [33:46<12:25,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127560.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  73%|████▍ | 545/744 [33:50<12:21,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117307.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  73%|████▍ | 546/744 [33:54<12:17,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125601.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  74%|████▍ | 547/744 [33:58<12:14,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112301.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  74%|████▍ | 548/744 [34:01<12:10,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106452.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  74%|████▍ | 549/744 [34:05<12:06,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102022.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  74%|████▍ | 550/744 [34:09<12:02,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118120.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  74%|████▍ | 551/744 [34:12<11:58,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116279.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  74%|████▍ | 552/744 [34:16<11:55,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102336.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  74%|████▍ | 553/744 [34:19<11:51,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115271.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  74%|████▍ | 554/744 [34:23<11:47,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116791.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8999, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  75%|████▍ | 555/744 [34:27<11:43,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125282.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  75%|████▍ | 556/744 [34:31<11:40,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122858.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  75%|████▍ | 557/744 [34:34<11:36,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121212.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  75%|████▌ | 558/744 [34:38<11:32,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116545.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  75%|████▌ | 559/744 [34:42<11:29,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114137.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  75%|████▌ | 560/744 [34:45<11:25,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124389.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  75%|████▌ | 561/744 [34:49<11:21,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122096.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  76%|████▌ | 562/744 [34:53<11:17,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112039.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  76%|████▌ | 563/744 [34:57<11:14,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113588.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  76%|████▌ | 564/744 [35:01<11:10,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117113.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  76%|████▌ | 565/744 [35:04<11:06,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106544.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  76%|████▌ | 566/744 [35:08<11:03,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124226.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  76%|████▌ | 567/744 [35:12<10:59,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119894.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  76%|████▌ | 568/744 [35:15<10:55,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118637.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  76%|████▌ | 569/744 [35:19<10:51,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121489.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  77%|████▌ | 570/744 [35:23<10:48,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121084.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  77%|████▌ | 571/744 [35:26<10:44,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119584.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  77%|████▌ | 572/744 [35:30<10:40,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112571.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  77%|████▌ | 573/744 [35:34<10:36,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115494.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  77%|████▋ | 574/744 [35:37<10:33,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112966.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  77%|████▋ | 575/744 [35:41<10:29,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121524.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  77%|████▋ | 576/744 [35:45<10:25,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108552.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  78%|████▋ | 577/744 [35:49<10:22,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118672.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  78%|████▋ | 578/744 [35:53<10:18,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111148.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  78%|████▋ | 579/744 [35:57<10:14,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103074.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  78%|████▋ | 580/744 [36:00<10:10,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115410.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9151, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  78%|████▋ | 581/744 [36:04<10:07,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115003.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  78%|████▋ | 582/744 [36:07<10:03,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119017.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  78%|████▋ | 583/744 [36:11<09:59,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118804.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  78%|████▋ | 584/744 [36:15<09:55,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131188.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  79%|████▋ | 585/744 [36:18<09:52,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116103.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  79%|████▋ | 586/744 [36:22<09:48,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120047.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8756, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  79%|████▋ | 587/744 [36:26<09:44,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114272.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  79%|████▋ | 588/744 [36:29<09:40,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125499.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  79%|████▊ | 589/744 [36:33<09:37,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125138.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  79%|████▊ | 590/744 [36:37<09:33,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115890.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  79%|████▊ | 591/744 [36:40<09:29,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109737.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  80%|████▊ | 592/744 [36:44<09:25,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122247.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  80%|████▊ | 593/744 [36:47<09:22,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117383.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  80%|████▊ | 594/744 [36:51<09:18,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108783.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  80%|████▊ | 595/744 [36:55<09:14,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114379.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  80%|████▊ | 596/744 [36:59<09:11,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114116.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  80%|████▊ | 597/744 [37:02<09:07,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114063.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  80%|████▊ | 598/744 [37:06<09:03,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117168.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  81%|████▊ | 599/744 [37:09<08:59,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119830.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  81%|████▊ | 600/744 [37:13<08:56,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117683.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  81%|████▊ | 601/744 [37:17<08:52,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127713.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  81%|████▊ | 602/744 [37:20<08:48,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123157.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  81%|████▊ | 603/744 [37:24<08:44,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110834.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  81%|████▊ | 604/744 [37:28<08:41,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125178.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  81%|████▉ | 605/744 [37:31<08:37,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122464.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  81%|████▉ | 606/744 [37:35<08:33,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121684.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  82%|████▉ | 607/744 [37:39<08:29,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122683.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  82%|████▉ | 608/744 [37:42<08:26,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106157.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  82%|████▉ | 609/744 [37:46<08:22,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113845.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  82%|████▉ | 610/744 [37:50<08:18,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117256.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  82%|████▉ | 611/744 [37:54<08:15,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118685.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  82%|████▉ | 612/744 [37:57<08:11,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119976.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  82%|████▉ | 613/744 [38:01<08:07,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(95130.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  83%|████▉ | 614/744 [38:05<08:03,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110767.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  83%|████▉ | 615/744 [38:08<08:00,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112862.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  83%|████▉ | 616/744 [38:12<07:56,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106165.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  83%|████▉ | 617/744 [38:16<07:52,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120009.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  83%|████▉ | 618/744 [38:19<07:48,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136623.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9877, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  83%|████▉ | 619/744 [38:23<07:45,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108039.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  83%|█████ | 620/744 [38:27<07:41,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118507.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  83%|█████ | 621/744 [38:31<07:37,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116890.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  84%|█████ | 622/744 [38:34<07:34,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115914.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  84%|█████ | 623/744 [38:39<07:30,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114877.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  84%|█████ | 624/744 [38:42<07:26,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105406.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  84%|█████ | 625/744 [38:46<07:22,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123864.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  84%|█████ | 626/744 [38:50<07:19,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112915.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  84%|█████ | 627/744 [38:53<07:15,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131283.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  84%|█████ | 628/744 [38:57<07:11,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114924.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  85%|█████ | 629/744 [39:01<07:08,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116379.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  85%|█████ | 630/744 [39:05<07:04,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124840.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  85%|█████ | 631/744 [39:08<07:00,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113156.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  85%|█████ | 632/744 [39:12<06:56,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116069.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  85%|█████ | 633/744 [39:16<06:53,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135906.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  85%|█████ | 634/744 [39:20<06:49,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118530.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  85%|█████ | 635/744 [39:23<06:45,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108271.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  85%|█████▏| 636/744 [39:27<06:42,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116985.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  86%|█████▏| 637/744 [39:31<06:38,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100410.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  86%|█████▏| 638/744 [39:35<06:34,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124777., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  86%|█████▏| 639/744 [39:38<06:30,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120727.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  86%|█████▏| 640/744 [39:42<06:27,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119518.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  86%|█████▏| 641/744 [39:46<06:23,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(92089.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  86%|█████▏| 642/744 [39:50<06:19,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115521.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  86%|█████▏| 643/744 [39:54<06:16,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120147.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  87%|█████▏| 644/744 [39:58<06:12,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114478.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  87%|█████▏| 645/744 [40:01<06:08,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116431.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  87%|█████▏| 646/744 [40:05<06:04,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107492.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  87%|█████▏| 647/744 [40:09<06:01,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124446.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  87%|█████▏| 648/744 [40:13<05:57,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115272.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  87%|█████▏| 649/744 [40:17<05:53,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112222.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  87%|█████▏| 650/744 [40:20<05:50,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129436.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  88%|█████▎| 651/744 [40:24<05:46,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105370.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  88%|█████▎| 652/744 [40:27<05:42,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117742.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  88%|█████▎| 653/744 [40:31<05:38,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116098.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  88%|█████▎| 654/744 [40:35<05:35,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121278.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  88%|█████▎| 655/744 [40:38<05:31,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118748.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  88%|█████▎| 656/744 [40:42<05:27,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123782.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9900, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  88%|█████▎| 657/744 [40:46<05:23,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117620.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  88%|█████▎| 658/744 [40:49<05:20,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119347.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  89%|█████▎| 659/744 [40:53<05:16,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128717.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  89%|█████▎| 660/744 [40:57<05:12,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104409.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  89%|█████▎| 661/744 [41:01<05:09,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119029.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  89%|█████▎| 662/744 [41:05<05:05,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113363.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  89%|█████▎| 663/744 [41:08<05:01,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112359.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  89%|█████▎| 664/744 [41:12<04:57,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119253.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  89%|█████▎| 665/744 [41:16<04:54,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121242.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  90%|█████▎| 666/744 [41:19<04:50,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123759.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  90%|█████▍| 667/744 [41:23<04:46,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116336.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  90%|█████▍| 668/744 [41:26<04:42,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135196.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  90%|█████▍| 669/744 [41:30<04:39,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125592.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  90%|█████▍| 670/744 [41:34<04:35,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119741.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  90%|█████▍| 671/744 [41:38<04:31,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124907.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  90%|█████▍| 672/744 [41:41<04:28,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111785.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  90%|█████▍| 673/744 [41:45<04:24,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125019.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  91%|█████▍| 674/744 [41:49<04:20,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114112.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  91%|█████▍| 675/744 [41:52<04:16,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123215.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  91%|█████▍| 676/744 [41:56<04:13,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118625.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  91%|█████▍| 677/744 [42:00<04:09,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112628.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  91%|█████▍| 678/744 [42:03<04:05,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116765.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  91%|█████▍| 679/744 [42:07<04:01,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120768.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  91%|█████▍| 680/744 [42:11<03:58,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124418.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  92%|█████▍| 681/744 [42:15<03:54,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125555.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  92%|█████▌| 682/744 [42:18<03:50,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119255.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  92%|█████▌| 683/744 [42:22<03:47,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110074.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  92%|█████▌| 684/744 [42:26<03:43,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115246.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  92%|█████▌| 685/744 [42:30<03:39,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100918.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  92%|█████▌| 686/744 [42:33<03:35,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107608.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9108, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  92%|█████▌| 687/744 [42:37<03:32,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113355.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  92%|█████▌| 688/744 [42:40<03:28,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116015.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  93%|█████▌| 689/744 [42:44<03:24,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120195.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  93%|█████▌| 690/744 [42:48<03:20,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127067.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  93%|█████▌| 691/744 [42:51<03:17,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113479.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  93%|█████▌| 692/744 [42:55<03:13,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125635.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  93%|█████▌| 693/744 [42:59<03:09,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119010.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  93%|█████▌| 694/744 [43:02<03:06,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122744.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9168, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  93%|█████▌| 695/744 [43:06<03:02,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123387.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  94%|█████▌| 696/744 [43:09<02:58,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131815.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8769, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  94%|█████▌| 697/744 [43:13<02:54,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113212.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  94%|█████▋| 698/744 [43:17<02:51,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116918.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  94%|█████▋| 699/744 [43:20<02:47,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115991.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  94%|█████▋| 700/744 [43:24<02:43,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125032.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  94%|█████▋| 701/744 [43:28<02:39,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121098.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  94%|█████▋| 702/744 [43:31<02:36,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110913.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  94%|█████▋| 703/744 [43:35<02:32,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123359.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  95%|█████▋| 704/744 [43:39<02:28,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133145.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  95%|█████▋| 705/744 [43:43<02:25,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121649.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  95%|█████▋| 706/744 [43:46<02:21,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128660.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  95%|█████▋| 707/744 [43:50<02:17,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112961.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  95%|█████▋| 708/744 [43:53<02:13,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115060.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  95%|█████▋| 709/744 [43:57<02:10,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117887.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  95%|█████▋| 710/744 [44:01<02:06,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112348.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8643, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  96%|█████▋| 711/744 [44:04<02:02,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121970.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  96%|█████▋| 712/744 [44:08<01:59,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120770.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  96%|█████▊| 713/744 [44:12<01:55,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124737.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  96%|█████▊| 714/744 [44:15<01:51,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107417.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  96%|█████▊| 715/744 [44:19<01:47,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129251.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  96%|█████▊| 716/744 [44:23<01:44,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109510.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  96%|█████▊| 717/744 [44:27<01:40,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134805.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  97%|█████▊| 718/744 [44:30<01:36,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117666.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  97%|█████▊| 719/744 [44:34<01:32,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106481.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  97%|█████▊| 720/744 [44:37<01:29,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117178., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  97%|█████▊| 721/744 [44:41<01:25,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117767.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  97%|█████▊| 722/744 [44:45<01:21,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118605.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  97%|█████▊| 723/744 [44:48<01:18,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117391.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  97%|█████▊| 724/744 [44:52<01:14,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117460.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  97%|█████▊| 725/744 [44:56<01:10,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111411.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  98%|█████▊| 726/744 [44:59<01:06,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116932.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  98%|█████▊| 727/744 [45:03<01:03,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127438.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  98%|█████▊| 728/744 [45:06<00:59,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123376.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  98%|█████▉| 729/744 [45:10<00:55,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119990.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  98%|█████▉| 730/744 [45:14<00:52,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119621.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  98%|█████▉| 731/744 [45:17<00:48,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129356.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  98%|█████▉| 732/744 [45:21<00:44,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(97990.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8863, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  99%|█████▉| 733/744 [45:25<00:40,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117646.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  99%|█████▉| 734/744 [45:28<00:37,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105683.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  99%|█████▉| 735/744 [45:32<00:33,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127415.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  99%|█████▉| 736/744 [45:36<00:29,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127200.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  99%|█████▉| 737/744 [45:39<00:26,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116689.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  99%|█████▉| 738/744 [45:43<00:22,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118599.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  99%|█████▉| 739/744 [45:46<00:18,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124153.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18:  99%|█████▉| 740/744 [45:50<00:14,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120201.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18: 100%|█████▉| 741/744 [45:54<00:11,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109557.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18: 100%|█████▉| 742/744 [45:57<00:07,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110322.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18: 100%|█████▉| 743/744 [46:01<00:03,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115544.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   0%|                | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(124238.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   0%|      | 1/744 [00:04<1:01:46,  4.99s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128253.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   0%|        | 2/744 [00:08<53:49,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104922.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   0%|        | 3/744 [00:13<53:44,  4.35s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130692.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   1%|        | 4/744 [00:16<51:58,  4.21s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116207.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   1%|        | 5/744 [00:20<50:22,  4.09s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116242.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   1%|        | 6/744 [00:24<49:14,  4.00s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117484.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   1%|        | 7/744 [00:27<48:25,  3.94s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127293.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   1%|        | 8/744 [00:31<47:42,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107332.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   1%|        | 9/744 [00:34<47:10,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111511.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   1%|       | 10/744 [00:38<47:02,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113650.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8958, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   1%|       | 11/744 [00:42<46:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137335.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   2%|       | 12/744 [00:45<46:27,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122416.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   2%|       | 13/744 [00:49<46:23,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123133.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   2%|▏      | 14/744 [00:53<46:10,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(99515.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   2%|▏      | 15/744 [00:56<46:00,  3.79s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129543.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   2%|▏      | 16/744 [01:00<45:48,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127847.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   2%|▏      | 17/744 [01:03<45:30,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104780.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   2%|▏      | 18/744 [01:07<45:15,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125581.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   3%|▏      | 19/744 [01:11<45:09,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114726.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   3%|▏      | 20/744 [01:14<45:01,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117491.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   3%|▏      | 21/744 [01:18<44:55,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127598.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   3%|▏      | 22/744 [01:21<44:50,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122073.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   3%|▏      | 23/744 [01:25<44:43,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118795.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   3%|▏      | 24/744 [01:29<44:34,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114650.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   3%|▏      | 25/744 [01:33<44:36,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116642.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   3%|▏      | 26/744 [01:36<44:27,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118633.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9253, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:   4%|▎      | 27/744 [01:40<44:25,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129428.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   4%|▎      | 28/744 [01:43<44:16,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129810.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   4%|▎      | 29/744 [01:47<44:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110050.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7791, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   4%|▎      | 30/744 [01:51<44:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114554.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   4%|▎      | 31/744 [01:54<43:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116506.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   4%|▎      | 32/744 [01:58<43:50,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130779.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   4%|▎      | 33/744 [02:01<43:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121716.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   5%|▎      | 34/744 [02:05<43:35,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124382.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   5%|▎      | 35/744 [02:08<43:31,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124350.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   5%|▎      | 36/744 [02:12<43:28,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127099.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   5%|▎      | 37/744 [02:16<43:25,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127643.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   5%|▎      | 38/744 [02:20<43:24,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121056.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   5%|▎      | 39/744 [02:23<43:16,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114666.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   5%|▍      | 40/744 [02:27<43:12,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121930.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   6%|▍      | 41/744 [02:30<43:06,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121657.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   6%|▍      | 42/744 [02:34<43:00,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115065.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   6%|▍      | 43/744 [02:38<42:58,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118230.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   6%|▍      | 44/744 [02:41<42:54,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121318.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   6%|▍      | 45/744 [02:45<42:57,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122673.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   6%|▍      | 46/744 [02:49<42:54,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129695.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   6%|▍      | 47/744 [02:53<42:48,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122733.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   6%|▍      | 48/744 [02:56<42:40,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128626.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   7%|▍      | 49/744 [03:00<42:37,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113511.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   7%|▍      | 50/744 [03:03<42:31,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110012.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9609, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   7%|▍      | 51/744 [03:07<42:30,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118635.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   7%|▍      | 52/744 [03:11<42:27,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122790.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   7%|▍      | 53/744 [03:14<42:22,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109179.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   7%|▌      | 54/744 [03:18<42:15,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120906.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   7%|▌      | 55/744 [03:22<42:12,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111273.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   8%|▌      | 56/744 [03:25<42:07,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118777.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   8%|▌      | 57/744 [03:29<42:01,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125123.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   8%|▌      | 58/744 [03:32<41:58,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110007.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   8%|▌      | 59/744 [03:36<41:56,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121081.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   8%|▌      | 60/744 [03:40<41:53,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112696.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   8%|▌      | 61/744 [03:44<41:49,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119360.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   8%|▌      | 62/744 [03:47<41:47,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130011.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   8%|▌      | 63/744 [03:51<41:44,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117647.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   9%|▌      | 64/744 [03:55<41:40,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126929.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8543, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:   9%|▌      | 65/744 [03:58<41:36,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116819.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   9%|▌      | 66/744 [04:02<41:32,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116875.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   9%|▋      | 67/744 [04:06<41:27,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116933.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   9%|▋      | 68/744 [04:09<41:25,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114905.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   9%|▋      | 69/744 [04:13<41:23,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119895.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:   9%|▋      | 70/744 [04:17<41:20,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118092.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9958, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  10%|▋      | 71/744 [04:21<41:16,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118963.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  10%|▋      | 72/744 [04:25<41:13,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118581.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  10%|▋      | 73/744 [04:28<41:09,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107454.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  10%|▋      | 74/744 [04:32<41:05,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123435.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  10%|▋      | 75/744 [04:36<41:02,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125424.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  10%|▋      | 76/744 [04:39<40:58,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124384.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  10%|▋      | 77/744 [04:43<40:56,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106144.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  10%|▋      | 78/744 [04:47<40:52,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122410.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  11%|▋      | 79/744 [04:50<40:49,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123612.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  11%|▊      | 80/744 [04:54<40:45,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132485.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  11%|▊      | 81/744 [04:58<40:44,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114665.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  11%|▊      | 82/744 [05:02<40:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124512.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  11%|▊      | 83/744 [05:06<40:40,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121627.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  11%|▊      | 84/744 [05:10<40:37,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109315.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  11%|▊      | 85/744 [05:13<40:34,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112163.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  12%|▊      | 86/744 [05:18<40:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120692.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  12%|▊      | 87/744 [05:21<40:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124112.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  12%|▊      | 88/744 [05:25<40:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116165.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  12%|▊      | 89/744 [05:29<40:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126705.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  12%|▊      | 90/744 [05:32<40:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130689.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  12%|▊      | 91/744 [05:36<40:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126877.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  12%|▊      | 92/744 [05:40<40:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116308.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  12%|▉      | 93/744 [05:44<40:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119504.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  13%|▉      | 94/744 [05:47<40:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117632.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  13%|▉      | 95/744 [05:51<40:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125894.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  13%|▉      | 96/744 [05:55<39:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130468.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  13%|▉      | 97/744 [05:58<39:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127363.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  13%|▉      | 98/744 [06:02<39:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115510.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  13%|▉      | 99/744 [06:06<39:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118943.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  13%|▊     | 100/744 [06:09<39:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106357.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  14%|▊     | 101/744 [06:13<39:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130616.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  14%|▊     | 102/744 [06:17<39:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123106.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8674, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  14%|▊     | 103/744 [06:21<39:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117372.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  14%|▊     | 104/744 [06:24<39:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132989.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  14%|▊     | 105/744 [06:28<39:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111008.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  14%|▊     | 106/744 [06:32<39:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114814.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  14%|▊     | 107/744 [06:36<39:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106733.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  15%|▊     | 108/744 [06:39<39:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125765.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  15%|▉     | 109/744 [06:43<39:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129593.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  15%|▉     | 110/744 [06:47<39:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128675.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  15%|▉     | 111/744 [06:51<39:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127033.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  15%|▉     | 112/744 [06:54<39:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117984.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  15%|▉     | 113/744 [06:58<38:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128265.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  15%|▉     | 114/744 [07:02<38:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127543.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  15%|▉     | 115/744 [07:05<38:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112771.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  16%|▉     | 116/744 [07:09<38:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133031.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  16%|▉     | 117/744 [07:13<38:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114732.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  16%|▉     | 118/744 [07:16<38:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125857.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  16%|▉     | 119/744 [07:20<38:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113592.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  16%|▉     | 120/744 [07:24<38:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115508.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  16%|▉     | 121/744 [07:27<38:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118115., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  16%|▉     | 122/744 [07:31<38:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116750.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  17%|▉     | 123/744 [07:35<38:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110120.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  17%|█     | 124/744 [07:38<38:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108478.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  17%|█     | 125/744 [07:42<38:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109820.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  17%|█     | 126/744 [07:46<38:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104352.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  17%|█     | 127/744 [07:49<38:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118786.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  17%|█     | 128/744 [07:53<37:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117341.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  17%|█     | 129/744 [07:57<37:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117986.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  17%|█     | 130/744 [08:00<37:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120357.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  18%|█     | 131/744 [08:04<37:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119154.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  18%|█     | 132/744 [08:07<37:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113267.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  18%|█     | 133/744 [08:11<37:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118943.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  18%|█     | 134/744 [08:15<37:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115306.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  18%|█     | 135/744 [08:18<37:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128078.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  18%|█     | 136/744 [08:22<37:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126748.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  18%|█     | 137/744 [08:26<37:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135368.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  19%|█     | 138/744 [08:30<37:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119793.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9125, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  19%|█     | 139/744 [08:33<37:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112261.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  19%|█▏    | 140/744 [08:37<37:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122324.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9194, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  19%|█▏    | 141/744 [08:41<37:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129880.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  19%|█▏    | 142/744 [08:44<37:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130965.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  19%|█▏    | 143/744 [08:48<37:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119657.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  19%|█▏    | 144/744 [08:52<36:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107681.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  19%|█▏    | 145/744 [08:55<36:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116882.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  20%|█▏    | 146/744 [08:59<36:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123797.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  20%|█▏    | 147/744 [09:03<36:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120346.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  20%|█▏    | 148/744 [09:06<36:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113035.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  20%|█▏    | 149/744 [09:10<36:38,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117871.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  20%|█▏    | 150/744 [09:14<36:33,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120008.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  20%|█▏    | 151/744 [09:17<36:31,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118204.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  20%|█▏    | 152/744 [09:22<36:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118827.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  21%|█▏    | 153/744 [09:25<36:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126813.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  21%|█▏    | 154/744 [09:29<36:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127741.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  21%|█▎    | 155/744 [09:33<36:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122643.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  21%|█▎    | 156/744 [09:36<36:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109581.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  21%|█▎    | 157/744 [09:40<36:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109602.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  21%|█▎    | 158/744 [09:44<36:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116206.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  21%|█▎    | 159/744 [09:47<36:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107655.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  22%|█▎    | 160/744 [09:51<35:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119275.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  22%|█▎    | 161/744 [09:54<35:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112090.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  22%|█▎    | 162/744 [09:58<35:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113168.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  22%|█▎    | 163/744 [10:02<35:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117243.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  22%|█▎    | 164/744 [10:06<35:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112252.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  22%|█▎    | 165/744 [10:09<35:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123481.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  22%|█▎    | 166/744 [10:14<35:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134471.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  22%|█▎    | 167/744 [10:17<35:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111721.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  23%|█▎    | 168/744 [10:21<35:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124597.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  23%|█▎    | 169/744 [10:25<35:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117734.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  23%|█▎    | 170/744 [10:28<35:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116940.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  23%|█▍    | 171/744 [10:32<35:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120320.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  23%|█▍    | 172/744 [10:36<35:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109631.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  23%|█▍    | 173/744 [10:40<35:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119520.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  23%|█▍    | 174/744 [10:43<35:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126376.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  24%|█▍    | 175/744 [10:47<35:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114887.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  24%|█▍    | 176/744 [10:51<35:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122586.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  24%|█▍    | 177/744 [10:54<34:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110592.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  24%|█▍    | 178/744 [10:58<34:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122847.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9703, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  24%|█▍    | 179/744 [11:02<34:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129581.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  24%|█▍    | 180/744 [11:05<34:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127272.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  24%|█▍    | 181/744 [11:09<34:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119121.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  24%|█▍    | 182/744 [11:13<34:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114942.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  25%|█▍    | 183/744 [11:16<34:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121869.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  25%|█▍    | 184/744 [11:20<34:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115491.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  25%|█▍    | 185/744 [11:24<34:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123593., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  25%|█▌    | 186/744 [11:27<34:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115428.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  25%|█▌    | 187/744 [11:31<34:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126646.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  25%|█▌    | 188/744 [11:34<34:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107517.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  25%|█▌    | 189/744 [11:38<34:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107128.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  26%|█▌    | 190/744 [11:42<34:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118418.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  26%|█▌    | 191/744 [11:45<34:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121562.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  26%|█▌    | 192/744 [11:49<33:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(93192.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  26%|█▌    | 193/744 [11:52<33:55,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107776.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  26%|█▌    | 194/744 [11:56<33:51,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114649.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  26%|█▌    | 195/744 [12:00<33:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116949.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  26%|█▌    | 196/744 [12:03<33:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127569.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  26%|█▌    | 197/744 [12:07<33:40,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136493.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  27%|█▌    | 198/744 [12:11<33:36,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124955.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  27%|█▌    | 199/744 [12:14<33:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113614.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  27%|█▌    | 200/744 [12:18<33:29,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118161., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  27%|█▌    | 201/744 [12:22<33:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111951.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  27%|█▋    | 202/744 [12:26<33:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121307.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  27%|█▋    | 203/744 [12:30<33:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111811.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  27%|█▋    | 204/744 [12:34<33:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129762.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  28%|█▋    | 205/744 [12:37<33:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108956.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  28%|█▋    | 206/744 [12:41<33:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118670.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  28%|█▋    | 207/744 [12:45<33:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115851.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  28%|█▋    | 208/744 [12:48<33:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120526.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  28%|█▋    | 209/744 [12:52<32:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115309.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  28%|█▋    | 210/744 [12:56<32:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126450.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  28%|█▋    | 211/744 [12:59<32:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133392., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  28%|█▋    | 212/744 [13:03<32:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122219.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  29%|█▋    | 213/744 [13:07<32:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126872.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  29%|█▋    | 214/744 [13:10<32:38,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118727.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  29%|█▋    | 215/744 [13:14<32:33,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126813.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  29%|█▋    | 216/744 [13:17<32:30,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118187.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9501, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  29%|█▊    | 217/744 [13:21<32:26,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132164.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  29%|█▊    | 218/744 [13:25<32:22,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124854.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  29%|█▊    | 219/744 [13:29<32:19,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127205.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8819, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  30%|█▊    | 220/744 [13:32<32:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120675.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  30%|█▊    | 221/744 [13:36<32:12,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120351.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  30%|█▊    | 222/744 [13:40<32:08,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116282.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  30%|█▊    | 223/744 [13:44<32:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111195.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  30%|█▊    | 224/744 [13:47<32:01,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125649.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  30%|█▊    | 225/744 [13:51<31:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124435.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  30%|█▊    | 226/744 [13:54<31:53,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127552.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  31%|█▊    | 227/744 [13:58<31:49,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123627.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  31%|█▊    | 228/744 [14:02<31:46,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122588.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  31%|█▊    | 229/744 [14:06<31:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112922.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  31%|█▊    | 230/744 [14:09<31:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126166.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  31%|█▊    | 231/744 [14:13<31:35,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108123.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  31%|█▊    | 232/744 [14:17<31:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116258.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  31%|█▉    | 233/744 [14:20<31:27,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104013.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  31%|█▉    | 234/744 [14:24<31:24,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120882.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  32%|█▉    | 235/744 [14:28<31:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114069.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  32%|█▉    | 236/744 [14:32<31:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120184.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  32%|█▉    | 237/744 [14:35<31:13,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132721.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  32%|█▉    | 238/744 [14:39<31:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120244.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  32%|█▉    | 239/744 [14:43<31:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132773.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  32%|█▉    | 240/744 [14:47<31:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126516.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  32%|█▉    | 241/744 [14:50<30:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121700.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  33%|█▉    | 242/744 [14:54<30:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126318.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  33%|█▉    | 243/744 [14:57<30:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131760.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  33%|█▉    | 244/744 [15:01<30:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115872.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8909, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  33%|█▉    | 245/744 [15:05<30:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133387.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  33%|█▉    | 246/744 [15:08<30:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108583.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  33%|█▉    | 247/744 [15:12<30:36,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122026.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  33%|██    | 248/744 [15:16<30:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101501.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  33%|██    | 249/744 [15:20<30:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112683.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  34%|██    | 250/744 [15:26<30:30,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121313.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  34%|██    | 251/744 [15:30<30:26,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110983.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  34%|██    | 252/744 [15:33<30:22,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124680.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  34%|██    | 253/744 [15:37<30:19,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125051.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  34%|██    | 254/744 [15:41<30:15,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131420.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9532, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  34%|██    | 255/744 [15:45<30:12,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129990.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  34%|██    | 256/744 [15:48<30:08,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122978.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  35%|██    | 257/744 [15:52<30:04,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130019.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  35%|██    | 258/744 [15:55<30:00,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134772.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  35%|██    | 259/744 [15:59<29:57,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116579.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  35%|██    | 260/744 [16:03<29:53,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118337.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  35%|██    | 261/744 [16:07<29:49,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115618.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8697, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  35%|██    | 262/744 [16:11<29:46,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120788.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  35%|██    | 263/744 [16:14<29:43,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128576.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  35%|██▏   | 264/744 [16:18<29:39,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122295.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  36%|██▏   | 265/744 [16:22<29:36,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132348.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  36%|██▏   | 266/744 [16:26<29:32,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120903.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  36%|██▏   | 267/744 [16:29<29:28,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129174.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  36%|██▏   | 268/744 [16:33<29:24,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114152.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  36%|██▏   | 269/744 [16:37<29:20,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119416.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  36%|██▏   | 270/744 [16:40<29:16,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123274.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  36%|██▏   | 271/744 [16:44<29:12,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128750.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  37%|██▏   | 272/744 [16:47<29:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115870.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  37%|██▏   | 273/744 [16:51<29:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112609.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  37%|██▏   | 274/744 [16:55<29:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127641.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  37%|██▏   | 275/744 [16:58<28:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120657.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  37%|██▏   | 276/744 [17:02<28:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109785.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  37%|██▏   | 277/744 [17:06<28:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120077.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  37%|██▏   | 278/744 [17:09<28:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101045.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  38%|██▎   | 279/744 [17:13<28:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122275.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  38%|██▎   | 280/744 [17:17<28:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138224.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  38%|██▎   | 281/744 [17:21<28:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114653.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  38%|██▎   | 282/744 [17:24<28:31,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124828.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  38%|██▎   | 283/744 [17:28<28:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125839.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  38%|██▎   | 284/744 [17:32<28:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104892.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  38%|██▎   | 285/744 [17:35<28:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123655.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  38%|██▎   | 286/744 [17:39<28:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121289.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  39%|██▎   | 287/744 [17:42<28:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118218.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  39%|██▎   | 288/744 [17:46<28:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122436.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  39%|██▎   | 289/744 [17:50<28:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117657.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  39%|██▎   | 290/744 [17:54<28:02,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125215.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  39%|██▎   | 291/744 [17:58<27:58,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112199.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  39%|██▎   | 292/744 [18:01<27:54,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116648.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8462, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  39%|██▎   | 293/744 [18:05<27:51,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117172.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  40%|██▎   | 294/744 [18:09<27:47,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124872.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  40%|██▍   | 295/744 [18:12<27:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121895.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  40%|██▍   | 296/744 [18:16<27:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122491.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  40%|██▍   | 297/744 [18:20<27:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128016.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  40%|██▍   | 298/744 [18:24<27:32,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129575.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  40%|██▍   | 299/744 [18:27<27:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117038.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  40%|██▍   | 300/744 [18:31<27:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126684.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  40%|██▍   | 301/744 [18:35<27:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119095.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  41%|██▍   | 302/744 [18:38<27:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126510.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  41%|██▍   | 303/744 [18:42<27:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114924.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  41%|██▍   | 304/744 [18:45<27:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123166.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  41%|██▍   | 305/744 [18:49<27:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131593.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  41%|██▍   | 306/744 [18:53<27:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132932.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  41%|██▍   | 307/744 [18:57<26:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112489.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  41%|██▍   | 308/744 [19:00<26:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128599.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  42%|██▍   | 309/744 [19:04<26:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126877.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  42%|██▌   | 310/744 [19:08<26:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107595.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  42%|██▌   | 311/744 [19:11<26:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117400.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  42%|██▌   | 312/744 [19:15<26:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116816.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  42%|██▌   | 313/744 [19:19<26:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126689.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  42%|██▌   | 314/744 [19:22<26:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110635.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  42%|██▌   | 315/744 [19:26<26:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120106.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  42%|██▌   | 316/744 [19:30<26:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123067.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  43%|██▌   | 317/744 [19:33<26:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130004.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  43%|██▌   | 318/744 [19:37<26:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123875.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  43%|██▌   | 319/744 [19:41<26:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126780.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  43%|██▌   | 320/744 [19:44<26:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135532.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  43%|██▌   | 321/744 [19:48<26:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129971.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  43%|██▌   | 322/744 [19:52<26:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125078.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  43%|██▌   | 323/744 [19:55<25:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114363.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  44%|██▌   | 324/744 [19:59<25:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134528.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  44%|██▌   | 325/744 [20:03<25:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122577.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  44%|██▋   | 326/744 [20:07<25:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138314., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  44%|██▋   | 327/744 [20:11<25:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133834.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  44%|██▋   | 328/744 [20:14<25:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125810.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  44%|██▋   | 329/744 [20:18<25:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125398.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8609, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  44%|██▋   | 330/744 [20:21<25:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125333.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9656, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  44%|██▋   | 331/744 [20:25<25:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116036.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  45%|██▋   | 332/744 [20:29<25:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110438.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  45%|██▋   | 333/744 [20:32<25:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118110.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  45%|██▋   | 334/744 [20:36<25:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128865.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  45%|██▋   | 335/744 [20:40<25:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106120.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  45%|██▋   | 336/744 [20:43<25:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123555.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  45%|██▋   | 337/744 [20:47<25:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114518.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  45%|██▋   | 338/744 [20:51<25:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123498.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  46%|██▋   | 339/744 [20:55<24:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121986.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  46%|██▋   | 340/744 [20:58<24:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122607.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  46%|██▊   | 341/744 [21:02<24:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118958.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  46%|██▊   | 342/744 [21:06<24:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104945.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  46%|██▊   | 343/744 [21:10<24:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118698.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  46%|██▊   | 344/744 [21:14<24:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128570.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  46%|██▊   | 345/744 [21:17<24:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112249.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  47%|██▊   | 346/744 [21:21<24:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110194.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  47%|██▊   | 347/744 [21:25<24:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114889.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  47%|██▊   | 348/744 [21:29<24:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125368.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  47%|██▊   | 349/744 [21:32<24:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121587.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  47%|██▊   | 350/744 [21:36<24:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118151.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  47%|██▊   | 351/744 [21:39<24:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127050.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  47%|██▊   | 352/744 [21:43<24:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118870.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  47%|██▊   | 353/744 [21:47<24:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119584.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  48%|██▊   | 354/744 [21:50<24:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116681.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  48%|██▊   | 355/744 [21:54<24:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127236.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  48%|██▊   | 356/744 [21:58<23:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122942.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  48%|██▉   | 357/744 [22:01<23:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109686.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  48%|██▉   | 358/744 [22:05<23:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123104.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  48%|██▉   | 359/744 [22:09<23:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111152.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  48%|██▉   | 360/744 [22:12<23:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117930.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  49%|██▉   | 361/744 [22:16<23:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128099.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  49%|██▉   | 362/744 [22:19<23:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113945.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  49%|██▉   | 363/744 [22:23<23:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124936.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  49%|██▉   | 364/744 [22:27<23:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117306.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  49%|██▉   | 365/744 [22:30<23:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109028.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  49%|██▉   | 366/744 [22:34<23:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129170.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  49%|██▉   | 367/744 [22:38<23:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116237.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  49%|██▉   | 368/744 [22:41<23:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131441.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9457, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  50%|██▉   | 369/744 [22:45<23:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124224.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  50%|██▉   | 370/744 [22:49<23:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107919.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  50%|██▉   | 371/744 [22:52<23:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130699.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  50%|███   | 372/744 [22:56<22:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125739.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  50%|███   | 373/744 [23:00<22:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116766.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  50%|███   | 374/744 [23:03<22:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119759.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  50%|███   | 375/744 [23:07<22:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118974.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  51%|███   | 376/744 [23:10<22:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109408.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  51%|███   | 377/744 [23:14<22:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119557.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  51%|███   | 378/744 [23:18<22:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112352.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  51%|███   | 379/744 [23:22<22:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135063.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  51%|███   | 380/744 [23:25<22:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136348.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  51%|███   | 381/744 [23:29<22:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118059.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  51%|███   | 382/744 [23:33<22:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132841.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  51%|███   | 383/744 [23:36<22:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110676.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  52%|███   | 384/744 [23:40<22:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116958.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  52%|███   | 385/744 [23:44<22:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126749.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  52%|███   | 386/744 [23:48<22:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109437.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  52%|███   | 387/744 [23:51<22:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109702.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  52%|███▏  | 388/744 [23:55<21:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117249.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  52%|███▏  | 389/744 [23:59<21:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128035.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  52%|███▏  | 390/744 [24:02<21:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127878.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  53%|███▏  | 391/744 [24:06<21:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123096.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  53%|███▏  | 392/744 [24:10<21:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129189.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  53%|███▏  | 393/744 [24:13<21:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111144.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  53%|███▏  | 394/744 [24:17<21:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125999.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  53%|███▏  | 395/744 [24:21<21:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130184.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  53%|███▏  | 396/744 [24:24<21:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127937.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  53%|███▏  | 397/744 [24:28<21:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118206.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  53%|███▏  | 398/744 [24:31<21:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123300.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  54%|███▏  | 399/744 [24:35<21:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127593.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  54%|███▏  | 400/744 [24:39<21:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131634.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  54%|███▏  | 401/744 [24:43<21:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119341.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  54%|███▏  | 402/744 [24:46<21:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128522.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  54%|███▎  | 403/744 [24:50<21:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120747.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  54%|███▎  | 404/744 [24:54<20:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120634.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  54%|███▎  | 405/744 [24:57<20:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123798.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  55%|███▎  | 406/744 [25:01<20:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121904.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9675, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  55%|███▎  | 407/744 [25:05<20:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128146.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  55%|███▎  | 408/744 [25:08<20:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119250.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  55%|███▎  | 409/744 [25:12<20:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124276.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  55%|███▎  | 410/744 [25:16<20:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123261.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  55%|███▎  | 411/744 [25:19<20:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121449.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  55%|███▎  | 412/744 [25:23<20:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123354.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  56%|███▎  | 413/744 [25:27<20:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127041.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  56%|███▎  | 414/744 [25:30<20:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131833.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  56%|███▎  | 415/744 [25:34<20:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126433.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  56%|███▎  | 416/744 [25:38<20:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119844.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  56%|███▎  | 417/744 [25:42<20:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117194.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  56%|███▎  | 418/744 [25:46<20:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123376.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  56%|███▍  | 419/744 [25:50<20:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131991.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  56%|███▍  | 420/744 [25:54<19:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117045.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  57%|███▍  | 421/744 [25:57<19:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106602.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  57%|███▍  | 422/744 [26:01<19:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121283.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  57%|███▍  | 423/744 [26:05<19:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119879.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  57%|███▍  | 424/744 [26:08<19:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109596.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  57%|███▍  | 425/744 [26:12<19:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113745.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  57%|███▍  | 426/744 [26:16<19:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124980.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  57%|███▍  | 427/744 [26:19<19:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113088.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  58%|███▍  | 428/744 [26:23<19:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113979.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  58%|███▍  | 429/744 [26:27<19:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137172.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  58%|███▍  | 430/744 [26:31<19:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106192.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  58%|███▍  | 431/744 [26:34<19:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122948.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  58%|███▍  | 432/744 [26:38<19:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126851.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  58%|███▍  | 433/744 [26:42<19:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117083.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  58%|███▌  | 434/744 [26:46<19:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125641.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  58%|███▌  | 435/744 [26:49<19:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115335.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  59%|███▌  | 436/744 [26:53<18:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119484.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  59%|███▌  | 437/744 [26:57<18:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111084.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  59%|███▌  | 438/744 [27:01<18:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122939.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  59%|███▌  | 439/744 [27:04<18:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123823.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  59%|███▌  | 440/744 [27:08<18:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117712.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  59%|███▌  | 441/744 [27:12<18:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123346.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  59%|███▌  | 442/744 [27:15<18:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132467.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  60%|███▌  | 443/744 [27:19<18:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127235.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  60%|███▌  | 444/744 [27:23<18:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127911.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9229, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  60%|███▌  | 445/744 [27:26<18:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136603.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  60%|███▌  | 446/744 [27:30<18:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128871.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  60%|███▌  | 447/744 [27:34<18:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129040.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  60%|███▌  | 448/744 [27:38<18:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111925.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  60%|███▌  | 449/744 [27:41<18:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124706.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  60%|███▋  | 450/744 [27:45<18:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124130.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  61%|███▋  | 451/744 [27:49<18:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114269.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  61%|███▋  | 452/744 [27:53<18:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128231.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  61%|███▋  | 453/744 [27:56<17:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129012.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  61%|███▋  | 454/744 [28:00<17:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120707.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  61%|███▋  | 455/744 [28:04<17:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128538.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  61%|███▋  | 456/744 [28:08<17:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133827.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  61%|███▋  | 457/744 [28:12<17:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110136.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  62%|███▋  | 458/744 [28:15<17:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126602.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  62%|███▋  | 459/744 [28:19<17:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130772.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  62%|███▋  | 460/744 [28:23<17:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112376.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  62%|███▋  | 461/744 [28:27<17:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110680.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  62%|███▋  | 462/744 [28:30<17:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121346.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  62%|███▋  | 463/744 [28:34<17:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120759.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8725, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  62%|███▋  | 464/744 [28:38<17:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115549.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  62%|███▊  | 465/744 [28:41<17:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124622.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  63%|███▊  | 466/744 [28:45<17:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126703.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  63%|███▊  | 467/744 [28:49<17:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116399.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  63%|███▊  | 468/744 [28:52<17:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107990.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  63%|███▊  | 469/744 [28:56<16:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128151.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  63%|███▊  | 470/744 [28:59<16:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123291.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  63%|███▊  | 471/744 [29:03<16:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115920.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  63%|███▊  | 472/744 [29:07<16:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132273.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  64%|███▊  | 473/744 [29:10<16:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117204.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  64%|███▊  | 474/744 [29:14<16:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124326.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  64%|███▊  | 475/744 [29:18<16:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134128.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  64%|███▊  | 476/744 [29:22<16:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128416.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  64%|███▊  | 477/744 [29:25<16:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117742.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  64%|███▊  | 478/744 [29:29<16:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106968.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  64%|███▊  | 479/744 [29:33<16:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123248.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  65%|███▊  | 480/744 [29:37<16:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130563.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  65%|███▉  | 481/744 [29:40<16:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128261.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  65%|███▉  | 482/744 [29:44<16:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123619.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9280, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  65%|███▉  | 483/744 [29:48<16:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127456.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  65%|███▉  | 484/744 [29:51<16:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131195.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  65%|███▉  | 485/744 [29:55<15:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122297.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  65%|███▉  | 486/744 [29:59<15:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121188.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  65%|███▉  | 487/744 [30:03<15:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126664.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  66%|███▉  | 488/744 [30:06<15:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135062.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  66%|███▉  | 489/744 [30:10<15:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127773.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8822, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  66%|███▉  | 490/744 [30:14<15:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100607.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  66%|███▉  | 491/744 [30:17<15:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125185.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  66%|███▉  | 492/744 [30:21<15:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108501.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  66%|███▉  | 493/744 [30:25<15:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132209.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  66%|███▉  | 494/744 [30:28<15:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124433.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  67%|███▉  | 495/744 [30:32<15:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145852.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  67%|████  | 496/744 [30:36<15:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122892.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  67%|████  | 497/744 [30:40<15:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128265.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  67%|████  | 498/744 [30:44<15:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116848.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  67%|████  | 499/744 [30:47<15:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139631., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  67%|████  | 500/744 [30:51<15:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122925.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  67%|████  | 501/744 [30:55<14:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108185.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  67%|████  | 502/744 [30:58<14:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113990.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  68%|████  | 503/744 [31:02<14:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102658.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  68%|████  | 504/744 [31:06<14:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111775.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  68%|████  | 505/744 [31:09<14:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118843.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  68%|████  | 506/744 [31:13<14:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124833.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  68%|████  | 507/744 [31:16<14:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128918.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  68%|████  | 508/744 [31:20<14:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122486.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8909, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  68%|████  | 509/744 [31:24<14:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103968.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  69%|████  | 510/744 [31:27<14:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122047.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  69%|████  | 511/744 [31:31<14:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124061.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  69%|████▏ | 512/744 [31:34<14:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131463.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  69%|████▏ | 513/744 [31:38<14:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114065.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  69%|████▏ | 514/744 [31:42<14:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114708.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  69%|████▏ | 515/744 [31:46<14:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129664.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  69%|████▏ | 516/744 [31:50<14:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101918.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  69%|████▏ | 517/744 [31:53<14:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111704.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  70%|████▏ | 518/744 [31:57<13:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138552.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  70%|████▏ | 519/744 [32:01<13:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111686.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  70%|████▏ | 520/744 [32:04<13:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122283.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9284, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  70%|████▏ | 521/744 [32:08<13:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133882.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  70%|████▏ | 522/744 [32:12<13:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131462.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  70%|████▏ | 523/744 [32:16<13:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127064., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  70%|████▏ | 524/744 [32:19<13:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103101.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8984, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  71%|████▏ | 525/744 [32:23<13:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124081.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  71%|████▏ | 526/744 [32:26<13:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118586.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  71%|████▎ | 527/744 [32:30<13:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127162.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  71%|████▎ | 528/744 [32:34<13:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126364.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  71%|████▎ | 529/744 [32:38<13:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113366.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  71%|████▎ | 530/744 [32:41<13:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127046.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  71%|████▎ | 531/744 [32:45<13:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123820.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  72%|████▎ | 532/744 [32:49<13:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121183.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  72%|████▎ | 533/744 [32:52<13:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109037.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  72%|████▎ | 534/744 [32:56<12:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121569.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  72%|████▎ | 535/744 [33:00<12:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120053.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  72%|████▎ | 536/744 [33:03<12:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118298.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  72%|████▎ | 537/744 [33:07<12:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115341.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8148, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  72%|████▎ | 538/744 [33:11<12:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131122.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  72%|████▎ | 539/744 [33:15<12:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118892.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  73%|████▎ | 540/744 [33:19<12:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136384.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  73%|████▎ | 541/744 [33:22<12:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121551.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  73%|████▎ | 542/744 [33:26<12:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125901.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  73%|████▍ | 543/744 [33:30<12:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122147.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  73%|████▍ | 544/744 [33:34<12:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120047.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  73%|████▍ | 545/744 [33:37<12:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137346.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  73%|████▍ | 546/744 [33:41<12:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120638.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  74%|████▍ | 547/744 [33:45<12:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125678.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  74%|████▍ | 548/744 [33:49<12:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119087.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  74%|████▍ | 549/744 [33:53<12:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115928.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  74%|████▍ | 550/744 [33:56<11:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120436.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  74%|████▍ | 551/744 [34:00<11:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127314.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  74%|████▍ | 552/744 [34:04<11:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121277.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  74%|████▍ | 553/744 [34:07<11:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123766.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  74%|████▍ | 554/744 [34:11<11:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134293.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  75%|████▍ | 555/744 [34:15<11:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118561.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  75%|████▍ | 556/744 [34:19<11:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119980.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  75%|████▍ | 557/744 [34:22<11:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140820.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  75%|████▌ | 558/744 [34:26<11:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116917.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8820, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  75%|████▌ | 559/744 [34:30<11:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121096.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  75%|████▌ | 560/744 [34:33<11:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128566.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  75%|████▌ | 561/744 [34:37<11:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123440.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  76%|████▌ | 562/744 [34:41<11:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126317.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  76%|████▌ | 563/744 [34:44<11:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116576.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  76%|████▌ | 564/744 [34:48<11:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128091.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  76%|████▌ | 565/744 [34:52<11:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134232.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  76%|████▌ | 566/744 [34:55<10:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114011.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  76%|████▌ | 567/744 [34:59<10:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121782.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  76%|████▌ | 568/744 [35:02<10:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122486.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  76%|████▌ | 569/744 [35:06<10:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120793.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  77%|████▌ | 570/744 [35:10<10:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126579.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  77%|████▌ | 571/744 [35:13<10:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125829.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  77%|████▌ | 572/744 [35:17<10:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129128.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  77%|████▌ | 573/744 [35:20<10:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119026.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  77%|████▋ | 574/744 [35:24<10:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116281.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  77%|████▋ | 575/744 [35:28<10:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115080.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  77%|████▋ | 576/744 [35:31<10:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117079.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  78%|████▋ | 577/744 [35:35<10:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129359.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  78%|████▋ | 578/744 [35:39<10:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136695.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  78%|████▋ | 579/744 [35:42<10:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111778.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  78%|████▋ | 580/744 [35:46<10:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104828.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  78%|████▋ | 581/744 [35:50<10:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125676.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  78%|████▋ | 582/744 [35:54<09:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129013.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  78%|████▋ | 583/744 [35:57<09:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130712.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  78%|████▋ | 584/744 [36:01<09:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113147.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  79%|████▋ | 585/744 [36:05<09:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127184.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  79%|████▋ | 586/744 [36:09<09:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128359.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  79%|████▋ | 587/744 [36:12<09:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123064.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  79%|████▋ | 588/744 [36:16<09:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128883.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  79%|████▊ | 589/744 [36:20<09:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120795.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  79%|████▊ | 590/744 [36:23<09:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124497.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  79%|████▊ | 591/744 [36:27<09:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126668.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  80%|████▊ | 592/744 [36:31<09:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128898.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  80%|████▊ | 593/744 [36:35<09:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114243.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  80%|████▊ | 594/744 [36:39<09:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123649.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  80%|████▊ | 595/744 [36:42<09:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121012.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  80%|████▊ | 596/744 [36:46<09:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130438.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  80%|████▊ | 597/744 [36:50<09:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134476.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  80%|████▊ | 598/744 [36:53<09:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122506.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  81%|████▊ | 599/744 [36:57<08:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119310.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  81%|████▊ | 600/744 [37:00<08:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118054.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  81%|████▊ | 601/744 [37:04<08:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129832.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  81%|████▊ | 602/744 [37:08<08:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130715.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  81%|████▊ | 603/744 [37:12<08:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125614.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  81%|████▊ | 604/744 [37:15<08:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120941.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  81%|████▉ | 605/744 [37:19<08:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116659.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  81%|████▉ | 606/744 [37:22<08:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125915.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  82%|████▉ | 607/744 [37:26<08:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123180.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  82%|████▉ | 608/744 [37:30<08:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120686.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  82%|████▉ | 609/744 [37:34<08:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118537.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  82%|████▉ | 610/744 [37:37<08:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121109.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  82%|████▉ | 611/744 [37:41<08:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122652.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  82%|████▉ | 612/744 [37:45<08:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128760.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  82%|████▉ | 613/744 [37:49<08:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120606.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  83%|████▉ | 614/744 [37:52<08:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130555.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  83%|████▉ | 615/744 [37:56<07:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118353.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  83%|████▉ | 616/744 [37:59<07:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119465.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  83%|████▉ | 617/744 [38:03<07:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126977.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  83%|████▉ | 618/744 [38:07<07:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111359.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  83%|████▉ | 619/744 [38:11<07:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125422.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  83%|█████ | 620/744 [38:14<07:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113671.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  83%|█████ | 621/744 [38:18<07:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115269.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  84%|█████ | 622/744 [38:22<07:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126187.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  84%|█████ | 623/744 [38:25<07:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125440.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  84%|█████ | 624/744 [38:29<07:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129534.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  84%|█████ | 625/744 [38:33<07:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120173.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  84%|█████ | 626/744 [38:36<07:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122658.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  84%|█████ | 627/744 [38:40<07:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133986.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  84%|█████ | 628/744 [38:44<07:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132823.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  85%|█████ | 629/744 [38:47<07:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135722.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  85%|█████ | 630/744 [38:51<07:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123112.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8740, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  85%|█████ | 631/744 [38:55<06:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121926.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  85%|█████ | 632/744 [38:58<06:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131364.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  85%|█████ | 633/744 [39:02<06:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132895.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  85%|█████ | 634/744 [39:05<06:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115137.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8074, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  85%|█████ | 635/744 [39:09<06:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133568.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  85%|█████▏| 636/744 [39:13<06:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125520.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  86%|█████▏| 637/744 [39:16<06:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119631.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  86%|█████▏| 638/744 [39:20<06:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127896.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  86%|█████▏| 639/744 [39:24<06:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120624.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  86%|█████▏| 640/744 [39:28<06:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130616.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  86%|█████▏| 641/744 [39:31<06:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128840.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  86%|█████▏| 642/744 [39:35<06:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117686.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  86%|█████▏| 643/744 [39:39<06:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127331.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  87%|█████▏| 644/744 [39:43<06:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125672.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  87%|█████▏| 645/744 [39:46<06:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116062.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  87%|█████▏| 646/744 [39:50<06:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123328.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  87%|█████▏| 647/744 [39:54<05:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126409.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  87%|█████▏| 648/744 [39:57<05:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130541.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  87%|█████▏| 649/744 [40:01<05:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121169.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  87%|█████▏| 650/744 [40:05<05:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126526.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8999, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  88%|█████▎| 651/744 [40:08<05:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126845.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  88%|█████▎| 652/744 [40:12<05:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120914.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  88%|█████▎| 653/744 [40:16<05:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127757.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  88%|█████▎| 654/744 [40:19<05:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126569.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  88%|█████▎| 655/744 [40:23<05:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120507.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  88%|█████▎| 656/744 [40:27<05:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128626.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  88%|█████▎| 657/744 [40:31<05:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128312.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  88%|█████▎| 658/744 [40:35<05:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136207.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  89%|█████▎| 659/744 [40:39<05:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121992.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  89%|█████▎| 660/744 [40:42<05:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119336.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  89%|█████▎| 661/744 [40:46<05:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115278.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  89%|█████▎| 662/744 [40:50<05:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114487.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  89%|█████▎| 663/744 [40:53<04:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119437.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  89%|█████▎| 664/744 [40:57<04:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123382.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  89%|█████▎| 665/744 [41:01<04:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116492.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  90%|█████▎| 666/744 [41:04<04:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129138.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  90%|█████▍| 667/744 [41:08<04:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122111.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  90%|█████▍| 668/744 [41:12<04:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125113.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  90%|█████▍| 669/744 [41:15<04:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122441.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  90%|█████▍| 670/744 [41:19<04:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135191.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  90%|█████▍| 671/744 [41:23<04:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129014.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  90%|█████▍| 672/744 [41:27<04:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126624.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9034, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  90%|█████▍| 673/744 [41:30<04:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126853.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  91%|█████▍| 674/744 [41:34<04:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110394.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  91%|█████▍| 675/744 [41:38<04:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116520.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  91%|█████▍| 676/744 [41:42<04:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128901.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  91%|█████▍| 677/744 [41:45<04:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129126.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  91%|█████▍| 678/744 [41:49<04:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119160.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  91%|█████▍| 679/744 [41:53<04:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120095.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  91%|█████▍| 680/744 [41:56<03:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120172.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  92%|█████▍| 681/744 [42:00<03:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127603.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  92%|█████▌| 682/744 [42:04<03:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119952.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  92%|█████▌| 683/744 [42:08<03:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116475.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8909, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  92%|█████▌| 684/744 [42:11<03:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122203.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  92%|█████▌| 685/744 [42:15<03:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119825.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  92%|█████▌| 686/744 [42:19<03:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127483.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8739, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  92%|█████▌| 687/744 [42:22<03:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106248.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  92%|█████▌| 688/744 [42:26<03:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129496.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  93%|█████▌| 689/744 [42:30<03:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135359.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  93%|█████▌| 690/744 [42:33<03:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128736.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  93%|█████▌| 691/744 [42:37<03:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119051.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  93%|█████▌| 692/744 [42:41<03:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133905.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  93%|█████▌| 693/744 [42:44<03:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134943.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  93%|█████▌| 694/744 [42:48<03:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123980.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  93%|█████▌| 695/744 [42:52<03:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120595.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  94%|█████▌| 696/744 [42:56<02:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124013.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  94%|█████▌| 697/744 [42:59<02:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118525.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  94%|█████▋| 698/744 [43:03<02:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129009.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  94%|█████▋| 699/744 [43:07<02:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127833.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  94%|█████▋| 700/744 [43:10<02:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130169.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  94%|█████▋| 701/744 [43:14<02:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115780.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  94%|█████▋| 702/744 [43:17<02:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121118., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  94%|█████▋| 703/744 [43:21<02:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106183.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  95%|█████▋| 704/744 [43:25<02:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127088.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  95%|█████▋| 705/744 [43:28<02:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129146.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  95%|█████▋| 706/744 [43:32<02:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125128.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  95%|█████▋| 707/744 [43:36<02:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117591.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  95%|█████▋| 708/744 [43:40<02:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111198.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  95%|█████▋| 709/744 [43:44<02:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122112.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  95%|█████▋| 710/744 [43:47<02:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121288.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8555, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  96%|█████▋| 711/744 [43:51<02:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119380.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  96%|█████▋| 712/744 [43:55<01:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138170.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  96%|█████▊| 713/744 [43:58<01:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112149.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  96%|█████▊| 714/744 [44:02<01:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133977.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  96%|█████▊| 715/744 [44:06<01:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115508.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  96%|█████▊| 716/744 [44:10<01:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129264.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  96%|█████▊| 717/744 [44:13<01:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122105.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  97%|█████▊| 718/744 [44:17<01:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131265.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  97%|█████▊| 719/744 [44:21<01:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119942.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  97%|█████▊| 720/744 [44:25<01:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132726.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  97%|█████▊| 721/744 [44:28<01:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119492.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  97%|█████▊| 722/744 [44:32<01:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129264.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  97%|█████▊| 723/744 [44:36<01:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125924.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  97%|█████▊| 724/744 [44:40<01:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111292.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  97%|█████▊| 725/744 [44:43<01:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126211.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  98%|█████▊| 726/744 [44:47<01:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127740.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  98%|█████▊| 727/744 [44:51<01:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123347.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  98%|█████▊| 728/744 [44:54<00:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131924.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  98%|█████▉| 729/744 [44:58<00:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130165.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  98%|█████▉| 730/744 [45:02<00:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136200.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  98%|█████▉| 731/744 [45:06<00:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125055.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  98%|█████▉| 732/744 [45:09<00:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106770.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  99%|█████▉| 733/744 [45:13<00:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128246.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  99%|█████▉| 734/744 [45:17<00:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130115.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  99%|█████▉| 735/744 [45:20<00:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110824.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  99%|█████▉| 736/744 [45:24<00:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124024.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  99%|█████▉| 737/744 [45:28<00:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142224.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  99%|█████▉| 738/744 [45:32<00:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135530.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  99%|█████▉| 739/744 [45:35<00:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129062.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19:  99%|█████▉| 740/744 [45:39<00:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114235.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19: 100%|█████▉| 741/744 [45:43<00:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117624.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19: 100%|█████▉| 742/744 [45:47<00:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117594.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19: 100%|█████▉| 743/744 [45:50<00:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(105919.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   0%|                | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(129093.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   0%|      | 1/744 [00:04<1:01:38,  4.98s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122949.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   0%|        | 2/744 [00:08<53:18,  4.31s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126902.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   0%|        | 3/744 [00:12<50:47,  4.11s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132692.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   1%|        | 4/744 [00:16<49:25,  4.01s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122832.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8498, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:   1%|        | 5/744 [00:19<48:45,  3.96s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116496.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   1%|        | 6/744 [00:23<47:48,  3.89s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127908.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   1%|        | 7/744 [00:27<47:38,  3.88s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117614.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   1%|        | 8/744 [00:30<47:28,  3.87s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130789.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   1%|        | 9/744 [00:34<46:53,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116635.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   1%|       | 10/744 [00:38<46:48,  3.83s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110222.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   1%|       | 11/744 [00:41<46:35,  3.81s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119812.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   2%|       | 12/744 [00:45<46:19,  3.80s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120180.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   2%|       | 13/744 [00:49<46:06,  3.78s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112398.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   2%|▏      | 14/744 [00:52<45:54,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126581.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   2%|▏      | 15/744 [00:56<45:38,  3.76s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121724.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   2%|▏      | 16/744 [01:00<45:32,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115798.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   2%|▏      | 17/744 [01:03<45:17,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134729.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   2%|▏      | 18/744 [01:07<45:16,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124761.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   3%|▏      | 19/744 [01:11<45:11,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133416.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   3%|▏      | 20/744 [01:14<45:06,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116667.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   3%|▏      | 21/744 [01:18<44:57,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109235.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   3%|▏      | 22/744 [01:22<44:57,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109961.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   3%|▏      | 23/744 [01:26<44:58,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116635.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   3%|▏      | 24/744 [01:29<44:50,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122316.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   3%|▏      | 25/744 [01:33<44:45,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127681.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   3%|▏      | 26/744 [01:37<44:45,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123521.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   4%|▎      | 27/744 [01:40<44:41,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141137.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   4%|▎      | 28/744 [01:44<44:37,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101868.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   4%|▎      | 29/744 [01:48<44:39,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139891.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   4%|▎      | 30/744 [01:52<44:36,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125991.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   4%|▎      | 31/744 [01:55<44:27,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132743.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   4%|▎      | 32/744 [01:59<44:23,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130002.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   4%|▎      | 33/744 [02:03<44:24,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131063.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   5%|▎      | 34/744 [02:07<44:19,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128977.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   5%|▎      | 35/744 [02:11<44:14,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116133.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   5%|▎      | 36/744 [02:14<44:09,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131059.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   5%|▎      | 37/744 [02:18<44:02,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129628.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   5%|▎      | 38/744 [02:22<43:58,  3.74s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108491.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   5%|▎      | 39/744 [02:25<43:51,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131233.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   5%|▍      | 40/744 [02:29<43:46,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122365.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   6%|▍      | 41/744 [02:32<43:43,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123215.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   6%|▍      | 42/744 [02:36<43:37,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134260.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8217, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:   6%|▍      | 43/744 [02:40<43:31,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119630.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   6%|▍      | 44/744 [02:43<43:25,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115651.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   6%|▍      | 45/744 [02:47<43:22,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133649.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   6%|▍      | 46/744 [02:51<43:16,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122647.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   6%|▍      | 47/744 [02:54<43:10,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127783.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   6%|▍      | 48/744 [02:58<43:03,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125948.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   7%|▍      | 49/744 [03:01<42:57,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120131.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   7%|▍      | 50/744 [03:05<42:56,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125327.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   7%|▍      | 51/744 [03:09<42:51,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120656.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   7%|▍      | 52/744 [03:12<42:46,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119744.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   7%|▍      | 53/744 [03:16<42:43,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111777.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   7%|▌      | 54/744 [03:20<42:39,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116151.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   7%|▌      | 55/744 [03:24<42:36,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126275.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   8%|▌      | 56/744 [03:28<42:35,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133428.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   8%|▌      | 57/744 [03:31<42:30,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121557.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   8%|▌      | 58/744 [03:35<42:25,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130284.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   8%|▌      | 59/744 [03:38<42:20,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133023.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   8%|▌      | 60/744 [03:42<42:16,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124767.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   8%|▌      | 61/744 [03:46<42:16,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132399.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   8%|▌      | 62/744 [03:50<42:14,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121059.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   8%|▌      | 63/744 [03:54<42:09,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117022.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   9%|▌      | 64/744 [03:57<42:04,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135009.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   9%|▌      | 65/744 [04:01<42:00,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123641.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   9%|▌      | 66/744 [04:05<41:57,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109316.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   9%|▋      | 67/744 [04:08<41:52,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116290.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   9%|▋      | 68/744 [04:12<41:48,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131493.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   9%|▋      | 69/744 [04:16<41:44,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135906.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:   9%|▋      | 70/744 [04:19<41:40,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121445.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  10%|▋      | 71/744 [04:23<41:35,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124301.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  10%|▋      | 72/744 [04:26<41:31,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142559.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  10%|▋      | 73/744 [04:30<41:28,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131213.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  10%|▋      | 74/744 [04:34<41:24,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115279.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  10%|▋      | 75/744 [04:38<41:20,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120683.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  10%|▋      | 76/744 [04:41<41:17,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128771.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  10%|▋      | 77/744 [04:45<41:13,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127475.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  10%|▋      | 78/744 [04:49<41:10,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106567.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  11%|▋      | 79/744 [04:52<41:05,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130487.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  11%|▊      | 80/744 [04:56<41:00,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126129.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8062, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  11%|▊      | 81/744 [05:00<40:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129155.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  11%|▊      | 82/744 [05:04<40:56,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112048.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  11%|▊      | 83/744 [05:07<40:52,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130672.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  11%|▊      | 84/744 [05:11<40:49,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127375.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  11%|▊      | 85/744 [05:15<40:45,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(102670.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  12%|▊      | 86/744 [05:19<40:41,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137983.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  12%|▊      | 87/744 [05:22<40:38,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131269.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  12%|▊      | 88/744 [05:26<40:33,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126915.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  12%|▊      | 89/744 [05:29<40:27,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129983.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  12%|▊      | 90/744 [05:33<40:24,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124581.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8885, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  12%|▊      | 91/744 [05:37<40:19,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131655.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  12%|▊      | 92/744 [05:40<40:16,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106936.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  12%|▉      | 93/744 [05:44<40:12,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129876.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  13%|▉      | 94/744 [05:48<40:08,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137516.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  13%|▉      | 95/744 [05:51<40:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126653.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  13%|▉      | 96/744 [05:55<40:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131577.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  13%|▉      | 97/744 [05:59<39:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135287.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  13%|▉      | 98/744 [06:02<39:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115178.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  13%|▉      | 99/744 [06:06<39:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131007.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  13%|▊     | 100/744 [06:10<39:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130770.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  14%|▊     | 101/744 [06:13<39:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132500.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  14%|▊     | 102/744 [06:17<39:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140071.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  14%|▊     | 103/744 [06:20<39:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136658.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  14%|▊     | 104/744 [06:24<39:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131031.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  14%|▊     | 105/744 [06:28<39:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113653.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  14%|▊     | 106/744 [06:32<39:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116689.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  14%|▊     | 107/744 [06:36<39:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117383.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  15%|▊     | 108/744 [06:39<39:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128245.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  15%|▉     | 109/744 [06:43<39:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121426.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  15%|▉     | 110/744 [06:47<39:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126100.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  15%|▉     | 111/744 [06:50<39:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124627.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  15%|▉     | 112/744 [06:54<38:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126476.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  15%|▉     | 113/744 [06:58<38:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125702.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  15%|▉     | 114/744 [07:01<38:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124799.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  15%|▉     | 115/744 [07:05<38:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120419.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  16%|▉     | 116/744 [07:08<38:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130635.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  16%|▉     | 117/744 [07:12<38:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130681.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  16%|▉     | 118/744 [07:16<38:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124053.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8430, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  16%|▉     | 119/744 [07:19<38:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127380.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  16%|▉     | 120/744 [07:23<38:25,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118993.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  16%|▉     | 121/744 [07:26<38:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126963.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  16%|▉     | 122/744 [07:30<38:17,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124382.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  17%|▉     | 123/744 [07:34<38:14,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134995.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  17%|█     | 124/744 [07:38<38:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136409.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  17%|█     | 125/744 [07:41<38:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120611.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  17%|█     | 126/744 [07:45<38:03,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123829.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  17%|█     | 127/744 [07:49<37:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117263.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  17%|█     | 128/744 [07:53<37:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135944.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  17%|█     | 129/744 [07:56<37:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122177.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  17%|█     | 130/744 [08:00<37:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124921.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  18%|█     | 131/744 [08:04<37:44,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123667.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  18%|█     | 132/744 [08:07<37:40,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133436.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  18%|█     | 133/744 [08:11<37:36,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115659.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  18%|█     | 134/744 [08:14<37:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123801.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  18%|█     | 135/744 [08:18<37:28,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117039.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  18%|█     | 136/744 [08:22<37:25,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132118.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  18%|█     | 137/744 [08:26<37:22,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129280.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  19%|█     | 138/744 [08:30<37:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132222.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  19%|█     | 139/744 [08:33<37:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112385.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  19%|█▏    | 140/744 [08:37<37:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136321.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  19%|█▏    | 141/744 [08:41<37:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117101.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  19%|█▏    | 142/744 [08:44<37:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121414.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  19%|█▏    | 143/744 [08:48<37:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121957.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  19%|█▏    | 144/744 [08:52<36:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124044.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  19%|█▏    | 145/744 [08:56<36:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136305.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  20%|█▏    | 146/744 [08:59<36:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141017.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  20%|█▏    | 147/744 [09:03<36:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124646.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  20%|█▏    | 148/744 [09:07<36:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114676.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  20%|█▏    | 149/744 [09:11<36:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116624.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  20%|█▏    | 150/744 [09:14<36:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126103.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  20%|█▏    | 151/744 [09:18<36:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125688.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  20%|█▏    | 152/744 [09:21<36:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117678.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  21%|█▏    | 153/744 [09:25<36:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111429.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  21%|█▏    | 154/744 [09:29<36:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125207.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  21%|█▎    | 155/744 [09:33<36:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126063.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  21%|█▎    | 156/744 [09:36<36:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123289.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8622, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  21%|█▎    | 157/744 [09:40<36:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123056.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  21%|█▎    | 158/744 [09:43<36:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120426.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  21%|█▎    | 159/744 [09:47<36:00,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123503.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  22%|█▎    | 160/744 [09:51<35:57,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120861.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  22%|█▎    | 161/744 [09:54<35:53,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121573.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  22%|█▎    | 162/744 [09:58<35:49,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123817.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  22%|█▎    | 163/744 [10:01<35:45,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120534.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  22%|█▎    | 164/744 [10:05<35:42,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131897.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  22%|█▎    | 165/744 [10:09<35:38,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126267.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  22%|█▎    | 166/744 [10:13<35:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123376., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  22%|█▎    | 167/744 [10:17<35:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128491.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  23%|█▎    | 168/744 [10:21<35:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132249.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  23%|█▎    | 169/744 [10:24<35:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110468.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  23%|█▎    | 170/744 [10:28<35:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121607.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  23%|█▍    | 171/744 [10:31<35:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124648.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  23%|█▍    | 172/744 [10:35<35:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124555.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  23%|█▍    | 173/744 [10:39<35:09,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145483.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  23%|█▍    | 174/744 [10:42<35:05,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123922.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  24%|█▍    | 175/744 [10:46<35:01,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129464.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  24%|█▍    | 176/744 [10:49<34:57,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130723.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  24%|█▍    | 177/744 [10:53<34:54,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125184.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  24%|█▍    | 178/744 [10:57<34:50,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121205.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  24%|█▍    | 179/744 [11:01<34:46,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129776.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  24%|█▍    | 180/744 [11:04<34:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119017.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  24%|█▍    | 181/744 [11:08<34:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111872.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  24%|█▍    | 182/744 [11:12<34:35,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128716.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  25%|█▍    | 183/744 [11:15<34:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(146109.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  25%|█▍    | 184/744 [11:19<34:27,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110890.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  25%|█▍    | 185/744 [11:23<34:24,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137956.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  25%|█▌    | 186/744 [11:26<34:20,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121413.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  25%|█▌    | 187/744 [11:30<34:17,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132386.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  25%|█▌    | 188/744 [11:34<34:13,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110787.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  25%|█▌    | 189/744 [11:37<34:09,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118758.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  26%|█▌    | 190/744 [11:41<34:05,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131065.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  26%|█▌    | 191/744 [11:45<34:01,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138049.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  26%|█▌    | 192/744 [11:48<33:57,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129529.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  26%|█▌    | 193/744 [11:52<33:53,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127946.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  26%|█▌    | 194/744 [11:56<33:50,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126856.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8384, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  26%|█▌    | 195/744 [12:00<33:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123118.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  26%|█▌    | 196/744 [12:03<33:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124806.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  26%|█▌    | 197/744 [12:07<33:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132357.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  27%|█▌    | 198/744 [12:11<33:36,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131602.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  27%|█▌    | 199/744 [12:14<33:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(101578.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  27%|█▌    | 200/744 [12:18<33:28,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131441.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  27%|█▌    | 201/744 [12:22<33:24,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119688.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  27%|█▋    | 202/744 [12:25<33:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120267.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  27%|█▋    | 203/744 [12:29<33:17,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128461.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  27%|█▋    | 204/744 [12:33<33:13,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123017.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  28%|█▋    | 205/744 [12:36<33:09,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115739.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  28%|█▋    | 206/744 [12:40<33:06,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127300.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  28%|█▋    | 207/744 [12:44<33:02,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117731.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  28%|█▋    | 208/744 [12:47<32:58,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122620.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  28%|█▋    | 209/744 [12:51<32:54,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138839.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  28%|█▋    | 210/744 [12:55<32:51,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120166.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  28%|█▋    | 211/744 [12:58<32:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120319.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  28%|█▋    | 212/744 [13:02<32:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132334.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  29%|█▋    | 213/744 [13:06<32:40,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126320.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  29%|█▋    | 214/744 [13:09<32:36,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122358.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  29%|█▋    | 215/744 [13:13<32:33,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134387.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  29%|█▋    | 216/744 [13:17<32:29,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128929.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  29%|█▊    | 217/744 [13:21<32:26,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109918.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  29%|█▊    | 218/744 [13:25<32:22,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132635.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  29%|█▊    | 219/744 [13:28<32:18,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123336.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  30%|█▊    | 220/744 [13:32<32:14,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127142.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  30%|█▊    | 221/744 [13:35<32:10,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126713.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  30%|█▊    | 222/744 [13:39<32:07,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127209.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  30%|█▊    | 223/744 [13:43<32:03,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137418.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  30%|█▊    | 224/744 [13:46<31:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122176.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  30%|█▊    | 225/744 [13:50<31:55,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131689.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  30%|█▊    | 226/744 [13:54<31:52,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138489.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  31%|█▊    | 227/744 [13:57<31:48,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127662.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  31%|█▊    | 228/744 [14:01<31:44,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112285.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  31%|█▊    | 229/744 [14:05<31:41,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140407.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  31%|█▊    | 230/744 [14:09<31:37,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125627.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  31%|█▊    | 231/744 [14:12<31:33,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142932.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  31%|█▊    | 232/744 [14:16<31:30,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115723.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9096, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  31%|█▉    | 233/744 [14:20<31:26,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123401.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  31%|█▉    | 234/744 [14:23<31:22,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127862.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  32%|█▉    | 235/744 [14:27<31:19,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122769.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  32%|█▉    | 236/744 [14:31<31:15,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126340.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  32%|█▉    | 237/744 [14:35<31:11,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118045.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  32%|█▉    | 238/744 [14:38<31:08,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(147107.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  32%|█▉    | 239/744 [14:42<31:04,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135318.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  32%|█▉    | 240/744 [14:45<31:00,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118322.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  32%|█▉    | 241/744 [14:49<30:56,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128505.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  33%|█▉    | 242/744 [14:53<30:52,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130986.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  33%|█▉    | 243/744 [14:56<30:48,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127998.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  33%|█▉    | 244/744 [15:00<30:45,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132285.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  33%|█▉    | 245/744 [15:04<30:41,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134854.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  33%|█▉    | 246/744 [15:07<30:37,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133941.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  33%|█▉    | 247/744 [15:11<30:33,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122859.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  33%|██    | 248/744 [15:15<30:30,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123364.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  33%|██    | 249/744 [15:18<30:26,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119277.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  34%|██    | 250/744 [15:22<30:23,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108434.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  34%|██    | 251/744 [15:26<30:19,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133454.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  34%|██    | 252/744 [15:29<30:15,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127116.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  34%|██    | 253/744 [15:33<30:12,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122182.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  34%|██    | 254/744 [15:37<30:08,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121802.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  34%|██    | 255/744 [15:41<30:04,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135646.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  34%|██    | 256/744 [15:44<30:01,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125007.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  35%|██    | 257/744 [15:48<29:57,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125622.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  35%|██    | 258/744 [15:52<29:54,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132599.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  35%|██    | 259/744 [15:56<29:51,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117513.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  35%|██    | 260/744 [16:00<29:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129612.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  35%|██    | 261/744 [16:03<29:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129998.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  35%|██    | 262/744 [16:07<29:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119522.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  35%|██    | 263/744 [16:11<29:36,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120191.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  35%|██▏   | 264/744 [16:14<29:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110715.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  36%|██▏   | 265/744 [16:18<29:28,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133498.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  36%|██▏   | 266/744 [16:22<29:25,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136050.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  36%|██▏   | 267/744 [16:25<29:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120499.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  36%|██▏   | 268/744 [16:29<29:17,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125178.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  36%|██▏   | 269/744 [16:33<29:14,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120219.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  36%|██▏   | 270/744 [16:36<29:10,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137350.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8614, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  36%|██▏   | 271/744 [16:40<29:06,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139109.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  37%|██▏   | 272/744 [16:44<29:02,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140135.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  37%|██▏   | 273/744 [16:48<28:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121914.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  37%|██▏   | 274/744 [16:52<28:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134387.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  37%|██▏   | 275/744 [16:56<28:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124611.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  37%|██▏   | 276/744 [16:59<28:49,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128666.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  37%|██▏   | 277/744 [17:03<28:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126922.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  37%|██▏   | 278/744 [17:07<28:41,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136603.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  38%|██▎   | 279/744 [17:10<28:37,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125348.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  38%|██▎   | 280/744 [17:14<28:34,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128365.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  38%|██▎   | 281/744 [17:17<28:30,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118928.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  38%|██▎   | 282/744 [17:21<28:26,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127695.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  38%|██▎   | 283/744 [17:25<28:23,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126947.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  38%|██▎   | 284/744 [17:29<28:19,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115484.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  38%|██▎   | 285/744 [17:32<28:15,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130312.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  38%|██▎   | 286/744 [17:36<28:11,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127963.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  39%|██▎   | 287/744 [17:41<28:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126331.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  39%|██▎   | 288/744 [17:44<28:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137332.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  39%|██▎   | 289/744 [17:48<28:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127638.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  39%|██▎   | 290/744 [17:52<27:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137397.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  39%|██▎   | 291/744 [17:56<27:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129738.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  39%|██▎   | 292/744 [17:59<27:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136943.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  39%|██▎   | 293/744 [18:03<27:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134726.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  40%|██▎   | 294/744 [18:07<27:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133732.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  40%|██▍   | 295/744 [18:11<27:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127554.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  40%|██▍   | 296/744 [18:14<27:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124226.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  40%|██▍   | 297/744 [18:18<27:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125793.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  40%|██▍   | 298/744 [18:22<27:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128299.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  40%|██▍   | 299/744 [18:25<27:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127840.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  40%|██▍   | 300/744 [18:29<27:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136128.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  40%|██▍   | 301/744 [18:33<27:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123753., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  41%|██▍   | 302/744 [18:36<27:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129783.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  41%|██▍   | 303/744 [18:40<27:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126207.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9572, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  41%|██▍   | 304/744 [18:44<27:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135825.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  41%|██▍   | 305/744 [18:47<27:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121700.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  41%|██▍   | 306/744 [18:51<26:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113599.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  41%|██▍   | 307/744 [18:55<26:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138147.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  41%|██▍   | 308/744 [18:59<26:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134712.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9075, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  42%|██▍   | 309/744 [19:02<26:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133941.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  42%|██▌   | 310/744 [19:06<26:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127684.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  42%|██▌   | 311/744 [19:10<26:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117725.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  42%|██▌   | 312/744 [19:13<26:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136014.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  42%|██▌   | 313/744 [19:17<26:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132977.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  42%|██▌   | 314/744 [19:21<26:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124681.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  42%|██▌   | 315/744 [19:25<26:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141054.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  42%|██▌   | 316/744 [19:28<26:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137696.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  43%|██▌   | 317/744 [19:32<26:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121690.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  43%|██▌   | 318/744 [19:36<26:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123807.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  43%|██▌   | 319/744 [19:40<26:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118399.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  43%|██▌   | 320/744 [19:43<26:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121910.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  43%|██▌   | 321/744 [19:47<26:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119710.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  43%|██▌   | 322/744 [19:51<26:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130134.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  43%|██▌   | 323/744 [19:55<25:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128412.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  44%|██▌   | 324/744 [19:58<25:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134271.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8381, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  44%|██▌   | 325/744 [20:02<25:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118979.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  44%|██▋   | 326/744 [20:06<25:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109746.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  44%|██▋   | 327/744 [20:09<25:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136580.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  44%|██▋   | 328/744 [20:13<25:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135814.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  44%|██▋   | 329/744 [20:17<25:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129379.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  44%|██▋   | 330/744 [20:21<25:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123544.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  44%|██▋   | 331/744 [20:25<25:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119125.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  45%|██▋   | 332/744 [20:28<25:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(152101.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  45%|██▋   | 333/744 [20:32<25:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122697.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  45%|██▋   | 334/744 [20:35<25:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123270.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  45%|██▋   | 335/744 [20:39<25:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134347.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  45%|██▋   | 336/744 [20:43<25:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141204.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  45%|██▋   | 337/744 [20:46<25:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120954.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  45%|██▋   | 338/744 [20:50<25:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117024.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  46%|██▋   | 339/744 [20:54<24:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126251.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  46%|██▋   | 340/744 [20:58<24:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134426., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8710, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  46%|██▊   | 341/744 [21:01<24:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126760.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  46%|██▊   | 342/744 [21:05<24:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113790.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  46%|██▊   | 343/744 [21:08<24:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117250.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  46%|██▊   | 344/744 [21:12<24:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116231.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  46%|██▊   | 345/744 [21:16<24:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132161.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  47%|██▊   | 346/744 [21:19<24:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129936.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8576, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  47%|██▊   | 347/744 [21:23<24:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127463.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  47%|██▊   | 348/744 [21:27<24:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131391.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  47%|██▊   | 349/744 [21:30<24:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119537.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  47%|██▊   | 350/744 [21:34<24:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124522.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  47%|██▊   | 351/744 [21:37<24:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134287.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  47%|██▊   | 352/744 [21:41<24:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138774.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  47%|██▊   | 353/744 [21:45<24:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125498.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  48%|██▊   | 354/744 [21:48<24:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129764.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  48%|██▊   | 355/744 [21:52<23:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115899.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  48%|██▊   | 356/744 [21:56<23:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133465.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  48%|██▉   | 357/744 [21:59<23:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121213.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  48%|██▉   | 358/744 [22:03<23:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135025.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  48%|██▉   | 359/744 [22:06<23:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128322.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  48%|██▉   | 360/744 [22:11<23:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124461.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  49%|██▉   | 361/744 [22:14<23:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119132.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  49%|██▉   | 362/744 [22:18<23:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129295.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  49%|██▉   | 363/744 [22:22<23:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136765.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  49%|██▉   | 364/744 [22:25<23:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116047.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  49%|██▉   | 365/744 [22:29<23:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130427.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  49%|██▉   | 366/744 [22:32<23:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130229.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  49%|██▉   | 367/744 [22:36<23:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135246.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  49%|██▉   | 368/744 [22:40<23:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123865.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  50%|██▉   | 369/744 [22:44<23:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145068.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  50%|██▉   | 370/744 [22:48<23:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130140.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  50%|██▉   | 371/744 [22:51<22:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117521.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  50%|███   | 372/744 [22:55<22:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121900.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  50%|███   | 373/744 [22:59<22:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120288.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  50%|███   | 374/744 [23:03<22:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126865.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  50%|███   | 375/744 [23:07<22:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135675.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  51%|███   | 376/744 [23:10<22:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139669.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  51%|███   | 377/744 [23:14<22:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122634.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  51%|███   | 378/744 [23:18<22:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144004.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8958, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  51%|███   | 379/744 [23:21<22:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134920.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  51%|███   | 380/744 [23:25<22:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141841.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  51%|███   | 381/744 [23:29<22:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127362.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  51%|███   | 382/744 [23:33<22:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130780.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  51%|███   | 383/744 [23:36<22:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125872.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  52%|███   | 384/744 [23:40<22:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123588.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8241, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  52%|███   | 385/744 [23:44<22:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126147.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  52%|███   | 386/744 [23:47<22:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144572.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  52%|███   | 387/744 [23:51<22:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124527.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  52%|███▏  | 388/744 [23:55<21:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125763.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  52%|███▏  | 389/744 [23:59<21:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139533.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  52%|███▏  | 390/744 [24:03<21:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119734.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  53%|███▏  | 391/744 [24:06<21:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142725.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  53%|███▏  | 392/744 [24:10<21:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120313.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  53%|███▏  | 393/744 [24:14<21:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119084.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  53%|███▏  | 394/744 [24:17<21:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132874.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  53%|███▏  | 395/744 [24:21<21:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123045.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  53%|███▏  | 396/744 [24:24<21:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120754.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  53%|███▏  | 397/744 [24:28<21:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133209.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  53%|███▏  | 398/744 [24:31<21:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124283.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  54%|███▏  | 399/744 [24:35<21:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141036.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  54%|███▏  | 400/744 [24:39<21:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129293.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  54%|███▏  | 401/744 [24:42<21:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134605.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  54%|███▏  | 402/744 [24:46<21:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145823.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  54%|███▎  | 403/744 [24:50<21:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134398.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  54%|███▎  | 404/744 [24:53<20:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120054.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  54%|███▎  | 405/744 [24:57<20:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122487.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  55%|███▎  | 406/744 [25:01<20:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116695.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  55%|███▎  | 407/744 [25:04<20:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126754.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  55%|███▎  | 408/744 [25:08<20:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134632., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  55%|███▎  | 409/744 [25:12<20:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112008.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  55%|███▎  | 410/744 [25:15<20:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135418.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  55%|███▎  | 411/744 [25:19<20:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128199.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  55%|███▎  | 412/744 [25:23<20:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138693.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  56%|███▎  | 413/744 [25:26<20:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131012.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  56%|███▎  | 414/744 [25:30<20:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133588.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  56%|███▎  | 415/744 [25:34<20:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129575.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  56%|███▎  | 416/744 [25:37<20:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124526.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  56%|███▎  | 417/744 [25:41<20:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115998.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  56%|███▎  | 418/744 [25:45<20:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116424.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  56%|███▍  | 419/744 [25:49<20:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144835.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  56%|███▍  | 420/744 [25:52<19:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122832.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  57%|███▍  | 421/744 [25:56<19:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119130.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  57%|███▍  | 422/744 [26:00<19:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123007.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9152, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  57%|███▍  | 423/744 [26:03<19:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110426.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  57%|███▍  | 424/744 [26:07<19:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120823.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  57%|███▍  | 425/744 [26:11<19:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125349.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  57%|███▍  | 426/744 [26:15<19:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125565.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  57%|███▍  | 427/744 [26:19<19:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127260.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  58%|███▍  | 428/744 [26:22<19:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135968.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  58%|███▍  | 429/744 [26:26<19:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139972.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  58%|███▍  | 430/744 [26:30<19:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136778.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8725, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  58%|███▍  | 431/744 [26:33<19:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124798.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  58%|███▍  | 432/744 [26:37<19:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125212.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  58%|███▍  | 433/744 [26:41<19:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119069.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  58%|███▌  | 434/744 [26:44<19:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127406.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  58%|███▌  | 435/744 [26:48<19:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138046.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  59%|███▌  | 436/744 [26:52<18:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113971.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  59%|███▌  | 437/744 [26:56<18:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129337.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  59%|███▌  | 438/744 [27:00<18:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135504.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  59%|███▌  | 439/744 [27:04<18:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117474.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  59%|███▌  | 440/744 [27:07<18:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127843.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  59%|███▌  | 441/744 [27:11<18:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133565.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  59%|███▌  | 442/744 [27:15<18:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123562.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  60%|███▌  | 443/744 [27:18<18:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141401.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  60%|███▌  | 444/744 [27:22<18:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126819.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  60%|███▌  | 445/744 [27:26<18:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127977.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  60%|███▌  | 446/744 [27:29<18:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114562.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  60%|███▌  | 447/744 [27:33<18:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133319.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  60%|███▌  | 448/744 [27:37<18:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139022.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  60%|███▌  | 449/744 [27:40<18:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124959.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  60%|███▋  | 450/744 [27:44<18:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122474.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  61%|███▋  | 451/744 [27:48<18:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121258.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8885, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  61%|███▋  | 452/744 [27:51<18:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134693.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  61%|███▋  | 453/744 [27:55<17:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133436.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  61%|███▋  | 454/744 [27:59<17:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128509.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  61%|███▋  | 455/744 [28:03<17:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131622.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  61%|███▋  | 456/744 [28:06<17:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129716.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  61%|███▋  | 457/744 [28:10<17:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(152400., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9715, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  62%|███▋  | 458/744 [28:14<17:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129755.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  62%|███▋  | 459/744 [28:17<17:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120677.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  62%|███▋  | 460/744 [28:21<17:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131624.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8046, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  62%|███▋  | 461/744 [28:25<17:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123570.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  62%|███▋  | 462/744 [28:28<17:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120426.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  62%|███▋  | 463/744 [28:32<17:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130941.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  62%|███▋  | 464/744 [28:36<17:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134258.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  62%|███▊  | 465/744 [28:40<17:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117394.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  63%|███▊  | 466/744 [28:44<17:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135693.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  63%|███▊  | 467/744 [28:48<17:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125790.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  63%|███▊  | 468/744 [28:52<17:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122118.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  63%|███▊  | 469/744 [28:55<16:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133451.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  63%|███▊  | 470/744 [28:59<16:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124954.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  63%|███▊  | 471/744 [29:03<16:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133071.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  63%|███▊  | 472/744 [29:06<16:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137326.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  64%|███▊  | 473/744 [29:10<16:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132845.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  64%|███▊  | 474/744 [29:14<16:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131137.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  64%|███▊  | 475/744 [29:18<16:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132945.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  64%|███▊  | 476/744 [29:21<16:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135784.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  64%|███▊  | 477/744 [29:25<16:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142113.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  64%|███▊  | 478/744 [29:29<16:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130159.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  64%|███▊  | 479/744 [29:32<16:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123097.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9609, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  65%|███▊  | 480/744 [29:36<16:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126028.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  65%|███▉  | 481/744 [29:40<16:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136806.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  65%|███▉  | 482/744 [29:44<16:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141478.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  65%|███▉  | 483/744 [29:48<16:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126101.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  65%|███▉  | 484/744 [29:52<16:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120230.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  65%|███▉  | 485/744 [29:55<15:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126420.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  65%|███▉  | 486/744 [29:59<15:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133189.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  65%|███▉  | 487/744 [30:03<15:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125503.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9843, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  66%|███▉  | 488/744 [30:06<15:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136193.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  66%|███▉  | 489/744 [30:10<15:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117768.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  66%|███▉  | 490/744 [30:14<15:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125186.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  66%|███▉  | 491/744 [30:18<15:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126056.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  66%|███▉  | 492/744 [30:22<15:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129099.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  66%|███▉  | 493/744 [30:25<15:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114403.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  66%|███▉  | 494/744 [30:29<15:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126765.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7984, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  67%|███▉  | 495/744 [30:33<15:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143230.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  67%|████  | 496/744 [30:37<15:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132773.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  67%|████  | 497/744 [30:41<15:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137185.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  67%|████  | 498/744 [30:44<15:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127589.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8145, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  67%|████  | 499/744 [30:48<15:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(149479.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  67%|████  | 500/744 [30:51<15:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123935.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  67%|████  | 501/744 [30:55<15:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116407.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  67%|████  | 502/744 [30:59<14:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(146003.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  68%|████  | 503/744 [31:02<14:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121917.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  68%|████  | 504/744 [31:06<14:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119537.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  68%|████  | 505/744 [31:10<14:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136763.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  68%|████  | 506/744 [31:13<14:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139824.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  68%|████  | 507/744 [31:17<14:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141711.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  68%|████  | 508/744 [31:20<14:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118266.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  68%|████  | 509/744 [31:24<14:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130765.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  69%|████  | 510/744 [31:28<14:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138387.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8632, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  69%|████  | 511/744 [31:31<14:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133698.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  69%|████▏ | 512/744 [31:35<14:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123662.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  69%|████▏ | 513/744 [31:38<14:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115495.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9238, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  69%|████▏ | 514/744 [31:42<14:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119733.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  69%|████▏ | 515/744 [31:46<14:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124233.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  69%|████▏ | 516/744 [31:50<14:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121123.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7673, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  69%|████▏ | 517/744 [31:53<14:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131111.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  70%|████▏ | 518/744 [31:57<13:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132204.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  70%|████▏ | 519/744 [32:01<13:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133831.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  70%|████▏ | 520/744 [32:04<13:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120977.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  70%|████▏ | 521/744 [32:08<13:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133663.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  70%|████▏ | 522/744 [32:12<13:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143160.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  70%|████▏ | 523/744 [32:15<13:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125839.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9715, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  70%|████▏ | 524/744 [32:19<13:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128391.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  71%|████▏ | 525/744 [32:23<13:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125624.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  71%|████▏ | 526/744 [32:26<13:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133720.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  71%|████▎ | 527/744 [32:30<13:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119226.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  71%|████▎ | 528/744 [32:34<13:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129106.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  71%|████▎ | 529/744 [32:37<13:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138592.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  71%|████▎ | 530/744 [32:41<13:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114526.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  71%|████▎ | 531/744 [32:45<13:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138854.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  72%|████▎ | 532/744 [32:48<13:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128028.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  72%|████▎ | 533/744 [32:52<13:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125011.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  72%|████▎ | 534/744 [32:56<12:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139357.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  72%|████▎ | 535/744 [33:00<12:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133537.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  72%|████▎ | 536/744 [33:03<12:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114840.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7419, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  72%|████▎ | 537/744 [33:07<12:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(106470.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  72%|████▎ | 538/744 [33:11<12:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131840.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  72%|████▎ | 539/744 [33:14<12:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126070.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  73%|████▎ | 540/744 [33:18<12:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116188.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  73%|████▎ | 541/744 [33:22<12:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133758.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  73%|████▎ | 542/744 [33:25<12:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122831.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  73%|████▍ | 543/744 [33:29<12:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119132.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  73%|████▍ | 544/744 [33:33<12:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115825.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  73%|████▍ | 545/744 [33:36<12:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111006.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  73%|████▍ | 546/744 [33:40<12:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(150348.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  74%|████▍ | 547/744 [33:44<12:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126323.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  74%|████▍ | 548/744 [33:47<12:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125867.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  74%|████▍ | 549/744 [33:51<12:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132605.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  74%|████▍ | 550/744 [33:55<11:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131460.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  74%|████▍ | 551/744 [33:59<11:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127133.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  74%|████▍ | 552/744 [34:02<11:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124332.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  74%|████▍ | 553/744 [34:06<11:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135142.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  74%|████▍ | 554/744 [34:09<11:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140600.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  75%|████▍ | 555/744 [34:13<11:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135498.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  75%|████▍ | 556/744 [34:17<11:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124745.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  75%|████▍ | 557/744 [34:20<11:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137645.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  75%|████▌ | 558/744 [34:24<11:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123855.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  75%|████▌ | 559/744 [34:28<11:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139388.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  75%|████▌ | 560/744 [34:31<11:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116781.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  75%|████▌ | 561/744 [34:35<11:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116343.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  76%|████▌ | 562/744 [34:39<11:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128189.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  76%|████▌ | 563/744 [34:42<11:09,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114629.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  76%|████▌ | 564/744 [34:46<11:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129763.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  76%|████▌ | 565/744 [34:50<11:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129373.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  76%|████▌ | 566/744 [34:54<10:58,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120212.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  76%|████▌ | 567/744 [34:57<10:54,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130063.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  76%|████▌ | 568/744 [35:01<10:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115378.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  76%|████▌ | 569/744 [35:05<10:47,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127722.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  77%|████▌ | 570/744 [35:08<10:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132641.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  77%|████▌ | 571/744 [35:12<10:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130906.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  77%|████▌ | 572/744 [35:15<10:36,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134395.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  77%|████▌ | 573/744 [35:19<10:32,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124111.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  77%|████▋ | 574/744 [35:23<10:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123063.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9084, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  77%|████▋ | 575/744 [35:26<10:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125827.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  77%|████▋ | 576/744 [35:30<10:21,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137241.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  78%|████▋ | 577/744 [35:34<10:17,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125539.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  78%|████▋ | 578/744 [35:37<10:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118755.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  78%|████▋ | 579/744 [35:41<10:10,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129852.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  78%|████▋ | 580/744 [35:44<10:06,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118652.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  78%|████▋ | 581/744 [35:48<10:02,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133234.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  78%|████▋ | 582/744 [35:52<09:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133703.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  78%|████▋ | 583/744 [35:56<09:55,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(100807.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  78%|████▋ | 584/744 [36:00<09:51,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129651.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  79%|████▋ | 585/744 [36:03<09:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132345.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  79%|████▋ | 586/744 [36:07<09:44,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136726.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  79%|████▋ | 587/744 [36:11<09:40,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119181.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  79%|████▋ | 588/744 [36:14<09:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121664.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  79%|████▊ | 589/744 [36:18<09:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121878.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  79%|████▊ | 590/744 [36:22<09:29,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129733.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  79%|████▊ | 591/744 [36:26<09:25,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125759.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  80%|████▊ | 592/744 [36:29<09:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139471.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  80%|████▊ | 593/744 [36:33<09:18,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130086.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  80%|████▊ | 594/744 [36:37<09:14,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143396.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  80%|████▊ | 595/744 [36:40<09:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133800.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  80%|████▊ | 596/744 [36:44<09:07,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(148161.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  80%|████▊ | 597/744 [36:48<09:03,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127786.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  80%|████▊ | 598/744 [36:51<08:59,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136371.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  81%|████▊ | 599/744 [36:55<08:56,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126930.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  81%|████▊ | 600/744 [36:58<08:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132897.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  81%|████▊ | 601/744 [37:02<08:48,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127964.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  81%|████▊ | 602/744 [37:06<08:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117133.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  81%|████▊ | 603/744 [37:09<08:41,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133941.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  81%|████▊ | 604/744 [37:13<08:37,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135644.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  81%|████▉ | 605/744 [37:17<08:33,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128540.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  81%|████▉ | 606/744 [37:20<08:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145709.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  82%|████▉ | 607/744 [37:24<08:26,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117177.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8893, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  82%|████▉ | 608/744 [37:28<08:22,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145364.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  82%|████▉ | 609/744 [37:31<08:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136085.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  82%|████▉ | 610/744 [37:35<08:15,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136049.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  82%|████▉ | 611/744 [37:39<08:11,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140406.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  82%|████▉ | 612/744 [37:42<08:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126413.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8357, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  82%|████▉ | 613/744 [37:46<08:04,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125729.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  83%|████▉ | 614/744 [37:50<08:00,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134948.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  83%|████▉ | 615/744 [37:54<07:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127120.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  83%|████▉ | 616/744 [37:57<07:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125824.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7909, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  83%|████▉ | 617/744 [38:01<07:49,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135302.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  83%|████▉ | 618/744 [38:04<07:45,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130132.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  83%|████▉ | 619/744 [38:08<07:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127901.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  83%|█████ | 620/744 [38:12<07:38,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129001.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  83%|█████ | 621/744 [38:15<07:34,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122899.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  84%|█████ | 622/744 [38:19<07:30,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124512.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  84%|█████ | 623/744 [38:22<07:27,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131129.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  84%|█████ | 624/744 [38:26<07:23,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130546.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  84%|█████ | 625/744 [38:30<07:19,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134850., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  84%|█████ | 626/744 [38:34<07:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115955.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  84%|█████ | 627/744 [38:37<07:12,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135453.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  84%|█████ | 628/744 [38:41<07:08,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128481.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  85%|█████ | 629/744 [38:44<07:05,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134332.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  85%|█████ | 630/744 [38:48<07:01,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138329.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  85%|█████ | 631/744 [38:52<06:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125370.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  85%|█████ | 632/744 [38:55<06:53,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126990.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  85%|█████ | 633/744 [38:59<06:50,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115232.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  85%|█████ | 634/744 [39:03<06:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123037.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  85%|█████ | 635/744 [39:07<06:42,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130287.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  85%|█████▏| 636/744 [39:10<06:39,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125096.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  86%|█████▏| 637/744 [39:14<06:35,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(104261.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  86%|█████▏| 638/744 [39:17<06:31,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120876.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  86%|█████▏| 639/744 [39:21<06:28,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132695.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  86%|█████▏| 640/744 [39:24<06:24,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(107746.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  86%|█████▏| 641/744 [39:28<06:20,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(146178.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  86%|█████▏| 642/744 [39:32<06:16,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109465.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  86%|█████▏| 643/744 [39:35<06:13,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143603.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  87%|█████▏| 644/744 [39:39<06:09,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133859.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  87%|█████▏| 645/744 [39:43<06:05,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130048.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  87%|█████▏| 646/744 [39:46<06:02,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124168.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7863, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  87%|█████▏| 647/744 [39:50<05:58,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128303.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  87%|█████▏| 648/744 [39:54<05:54,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129803.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  87%|█████▏| 649/744 [39:57<05:50,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134439.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  87%|█████▏| 650/744 [40:01<05:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136393.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8645, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  88%|█████▎| 651/744 [40:05<05:43,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133541.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  88%|█████▎| 652/744 [40:09<05:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141326.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  88%|█████▎| 653/744 [40:12<05:36,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143000.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  88%|█████▎| 654/744 [40:16<05:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134910.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  88%|█████▎| 655/744 [40:19<05:28,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131851.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  88%|█████▎| 656/744 [40:23<05:25,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125317.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  88%|█████▎| 657/744 [40:27<05:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130289.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  88%|█████▎| 658/744 [40:30<05:17,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134392.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  89%|█████▎| 659/744 [40:34<05:13,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128139.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  89%|█████▎| 660/744 [40:37<05:10,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138950.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  89%|█████▎| 661/744 [40:41<05:06,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136306.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  89%|█████▎| 662/744 [40:45<05:02,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134897.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  89%|█████▎| 663/744 [40:48<04:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127516.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  89%|█████▎| 664/744 [40:52<04:55,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117640.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  89%|█████▎| 665/744 [40:56<04:51,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134874.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  90%|█████▎| 666/744 [41:00<04:48,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131994.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  90%|█████▍| 667/744 [41:03<04:44,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120649.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  90%|█████▍| 668/744 [41:07<04:40,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127429.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  90%|█████▍| 669/744 [41:11<04:37,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131864.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  90%|█████▍| 670/744 [41:14<04:33,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138919.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  90%|█████▍| 671/744 [41:18<04:29,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138370.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  90%|█████▍| 672/744 [41:22<04:25,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132915.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  90%|█████▍| 673/744 [41:25<04:22,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144656.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  91%|█████▍| 674/744 [41:29<04:18,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131459.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  91%|█████▍| 675/744 [41:33<04:14,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135576.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  91%|█████▍| 676/744 [41:36<04:11,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128944.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  91%|█████▍| 677/744 [41:40<04:07,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137167.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  91%|█████▍| 678/744 [41:44<04:03,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129977.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  91%|█████▍| 679/744 [41:47<04:00,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130053.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  91%|█████▍| 680/744 [41:51<03:56,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130196.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  92%|█████▍| 681/744 [41:54<03:52,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130357.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  92%|█████▌| 682/744 [41:58<03:48,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134695.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  92%|█████▌| 683/744 [42:02<03:45,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135128.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  92%|█████▌| 684/744 [42:05<03:41,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139203.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  92%|█████▌| 685/744 [42:09<03:37,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129302.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  92%|█████▌| 686/744 [42:12<03:34,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109864.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  92%|█████▌| 687/744 [42:16<03:30,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130262.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  92%|█████▌| 688/744 [42:21<03:26,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(147448.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8455, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  93%|█████▌| 689/744 [42:24<03:23,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114834.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  93%|█████▌| 690/744 [42:28<03:19,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136812.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  93%|█████▌| 691/744 [42:32<03:15,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130023.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  93%|█████▌| 692/744 [42:35<03:12,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131135.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  93%|█████▌| 693/744 [42:39<03:08,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138326.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  93%|█████▌| 694/744 [42:43<03:04,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133844.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  93%|█████▌| 695/744 [42:47<03:00,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130733.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  94%|█████▌| 696/744 [42:50<02:57,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127112.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  94%|█████▌| 697/744 [42:54<02:53,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(148066.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  94%|█████▋| 698/744 [42:58<02:49,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136026.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  94%|█████▋| 699/744 [43:01<02:46,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128998.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  94%|█████▋| 700/744 [43:05<02:42,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126977.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  94%|█████▋| 701/744 [43:08<02:38,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130533.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9715, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  94%|█████▋| 702/744 [43:12<02:35,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134316.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  94%|█████▋| 703/744 [43:16<02:31,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140016.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  95%|█████▋| 704/744 [43:19<02:27,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134381.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  95%|█████▋| 705/744 [43:23<02:24,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123826.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  95%|█████▋| 706/744 [43:26<02:20,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138109.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  95%|█████▋| 707/744 [43:30<02:16,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132533.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  95%|█████▋| 708/744 [43:33<02:12,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128139.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  95%|█████▋| 709/744 [43:37<02:09,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130953.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  95%|█████▋| 710/744 [43:41<02:05,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(108736.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  96%|█████▋| 711/744 [43:45<02:01,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131190.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  96%|█████▋| 712/744 [43:48<01:58,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132482.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  96%|█████▊| 713/744 [43:52<01:54,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131283.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  96%|█████▊| 714/744 [43:55<01:50,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120468.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  96%|█████▊| 715/744 [43:59<01:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134560.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  96%|█████▊| 716/744 [44:02<01:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120111.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  96%|█████▊| 717/744 [44:06<01:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124912.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  97%|█████▊| 718/744 [44:09<01:35,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134605.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  97%|█████▊| 719/744 [44:13<01:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(148827.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  97%|█████▊| 720/744 [44:17<01:28,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137751.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  97%|█████▊| 721/744 [44:20<01:24,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136167.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  97%|█████▊| 722/744 [44:24<01:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129926.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  97%|█████▊| 723/744 [44:27<01:17,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127674.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  97%|█████▊| 724/744 [44:31<01:13,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141933.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  97%|█████▊| 725/744 [44:34<01:10,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117660.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  98%|█████▊| 726/744 [44:38<01:06,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133961.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8704, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  98%|█████▊| 727/744 [44:42<01:02,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120615.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  98%|█████▊| 728/744 [44:46<00:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120204.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  98%|█████▉| 729/744 [44:49<00:55,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119399.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  98%|█████▉| 730/744 [44:53<00:51,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129166.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  98%|█████▉| 731/744 [44:56<00:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(147267.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  98%|█████▉| 732/744 [45:00<00:44,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128237.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  99%|█████▉| 733/744 [45:04<00:40,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130124.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  99%|█████▉| 734/744 [45:07<00:36,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128527.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  99%|█████▉| 735/744 [45:11<00:33,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140644.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  99%|█████▉| 736/744 [45:15<00:29,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142093.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  99%|█████▉| 737/744 [45:18<00:25,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132438.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  99%|█████▉| 738/744 [45:22<00:22,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119019.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  99%|█████▉| 739/744 [45:26<00:18,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131596.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20:  99%|█████▉| 740/744 [45:29<00:14,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127908.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20: 100%|█████▉| 741/744 [45:33<00:11,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130711.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20: 100%|█████▉| 742/744 [45:37<00:07,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115053.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20: 100%|█████▉| 743/744 [45:40<00:03,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130511.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9572, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   0%|                | 0/744 [00:00<?, ?it/s, loss=nan, v_num=5.48e+7]loss_g:   tensor(121897.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   0%|      | 1/744 [00:04<1:01:21,  4.95s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127526.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   0%|        | 2/744 [00:08<53:25,  4.32s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133731.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   0%|        | 3/744 [00:12<50:27,  4.09s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133261.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   1%|        | 4/744 [00:15<48:30,  3.93s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137074.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   1%|        | 5/744 [00:19<47:28,  3.85s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118239.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   1%|        | 6/744 [00:22<47:00,  3.82s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127797.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   1%|        | 7/744 [00:26<46:21,  3.77s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130007.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   1%|        | 8/744 [00:29<45:57,  3.75s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139440.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   1%|        | 9/744 [00:33<45:40,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136049.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   1%|       | 10/744 [00:37<45:32,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124752.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   1%|       | 11/744 [00:41<45:35,  3.73s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140308.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   2%|       | 12/744 [00:44<45:15,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121645.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   2%|       | 13/744 [00:48<45:15,  3.71s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130063.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   2%|▏      | 14/744 [00:52<45:14,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133105.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   2%|▏      | 15/744 [00:55<45:10,  3.72s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137051.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   2%|▏      | 16/744 [00:59<44:57,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136565.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   2%|▏      | 17/744 [01:02<44:52,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121261.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   2%|▏      | 18/744 [01:06<44:46,  3.70s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137289.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   3%|▏      | 19/744 [01:10<44:38,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125348.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   3%|▏      | 20/744 [01:13<44:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123796.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8248, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:   3%|▏      | 21/744 [01:17<44:18,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123112.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   3%|▏      | 22/744 [01:20<44:13,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116511.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   3%|▏      | 23/744 [01:24<44:10,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139907.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   3%|▏      | 24/744 [01:28<44:08,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132830.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   3%|▏      | 25/744 [01:31<44:04,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120736.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   3%|▏      | 26/744 [01:35<43:54,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131004.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   4%|▎      | 27/744 [01:39<43:50,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129916.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   4%|▎      | 28/744 [01:42<43:46,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121268.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   4%|▎      | 29/744 [01:46<43:44,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144297.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   4%|▎      | 30/744 [01:50<43:38,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134928.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   4%|▎      | 31/744 [01:53<43:35,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109381.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   4%|▎      | 32/744 [01:57<43:29,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125450.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   4%|▎      | 33/744 [02:00<43:23,  3.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145100.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   5%|▎      | 34/744 [02:04<43:18,  3.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138066.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   5%|▎      | 35/744 [02:08<43:16,  3.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126032.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   5%|▎      | 36/744 [02:11<43:12,  3.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139166.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   5%|▎      | 37/744 [02:15<43:08,  3.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128959.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   5%|▎      | 38/744 [02:19<43:04,  3.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117436.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   5%|▎      | 39/744 [02:22<43:02,  3.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132946.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   5%|▍      | 40/744 [02:26<42:57,  3.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141870.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   6%|▍      | 41/744 [02:30<42:54,  3.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120206.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   6%|▍      | 42/744 [02:33<42:53,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128674.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   6%|▍      | 43/744 [02:37<42:52,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136761.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   6%|▍      | 44/744 [02:41<42:46,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124813.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   6%|▍      | 45/744 [02:45<42:43,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122127.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   6%|▍      | 46/744 [02:48<42:42,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134306.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   6%|▍      | 47/744 [02:52<42:41,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133212.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   6%|▍      | 48/744 [02:56<42:36,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115220.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   7%|▍      | 49/744 [02:59<42:30,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142974.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   7%|▍      | 50/744 [03:03<42:25,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131910.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   7%|▍      | 51/744 [03:06<42:20,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(149244.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   7%|▍      | 52/744 [03:10<42:16,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144958.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   7%|▍      | 53/744 [03:14<42:12,  3.66s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138799.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   7%|▌      | 54/744 [03:18<42:11,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141173.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   7%|▌      | 55/744 [03:21<42:09,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136295.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   8%|▌      | 56/744 [03:25<42:06,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124363.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   8%|▌      | 57/744 [03:29<42:03,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127270.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   8%|▌      | 58/744 [03:33<42:00,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144093.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0005, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:   8%|▌      | 59/744 [03:36<41:54,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123364.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   8%|▌      | 60/744 [03:40<41:50,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132365.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   8%|▌      | 61/744 [03:43<41:46,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130037.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   8%|▌      | 62/744 [03:47<41:43,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133092.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9863, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   8%|▌      | 63/744 [03:51<41:40,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130670.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   9%|▌      | 64/744 [03:55<41:38,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129820.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   9%|▌      | 65/744 [03:58<41:35,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127888.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   9%|▌      | 66/744 [04:02<41:31,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132209.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   9%|▋      | 67/744 [04:06<41:28,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120939.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   9%|▋      | 68/744 [04:09<41:23,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130835.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   9%|▋      | 69/744 [04:13<41:20,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136775.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:   9%|▋      | 70/744 [04:17<41:16,  3.67s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129314.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  10%|▋      | 71/744 [04:21<41:15,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124689.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  10%|▋      | 72/744 [04:24<41:11,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133853.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  10%|▋      | 73/744 [04:28<41:08,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135984.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  10%|▋      | 74/744 [04:32<41:03,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138773.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  10%|▋      | 75/744 [04:35<41:01,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130129.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  10%|▋      | 76/744 [04:39<40:57,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125647.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9764, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  10%|▋      | 77/744 [04:43<40:55,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126552.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  10%|▋      | 78/744 [04:47<40:52,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(152098.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  11%|▋      | 79/744 [04:50<40:48,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136677.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  11%|▊      | 80/744 [04:54<40:43,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129126.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  11%|▊      | 81/744 [04:58<40:40,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136559.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  11%|▊      | 82/744 [05:01<40:36,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124069.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  11%|▊      | 83/744 [05:05<40:32,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128017.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  11%|▊      | 84/744 [05:09<40:29,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118524.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  11%|▊      | 85/744 [05:12<40:25,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118266.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  12%|▊      | 86/744 [05:16<40:20,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133758.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  12%|▊      | 87/744 [05:19<40:16,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134642.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  12%|▊      | 88/744 [05:23<40:12,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133503.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  12%|▊      | 89/744 [05:27<40:08,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143470.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  12%|▊      | 90/744 [05:31<40:07,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139089.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  12%|▊      | 91/744 [05:35<40:05,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127855.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  12%|▊      | 92/744 [05:38<40:01,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132392.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  12%|▉      | 93/744 [05:42<39:57,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129993.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  13%|▉      | 94/744 [05:45<39:52,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125175.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9725, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  13%|▉      | 95/744 [05:50<39:51,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138365.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  13%|▉      | 96/744 [05:53<39:48,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140210.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9978, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  13%|▉      | 97/744 [05:58<39:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133923.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  13%|▉      | 98/744 [06:01<39:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127506.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  13%|▉      | 99/744 [06:05<39:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128226.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  13%|▊     | 100/744 [06:08<39:35,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128117.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  14%|▊     | 101/744 [06:12<39:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133217., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  14%|▊     | 102/744 [06:16<39:28,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135315.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  14%|▊     | 103/744 [06:20<39:24,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123972.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  14%|▊     | 104/744 [06:23<39:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(150194.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  14%|▊     | 105/744 [06:27<39:18,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138275.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  14%|▊     | 106/744 [06:31<39:15,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136634.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  14%|▊     | 107/744 [06:34<39:10,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118294.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  15%|▊     | 108/744 [06:38<39:05,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132586.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  15%|▉     | 109/744 [06:42<39:03,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133444.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  15%|▉     | 110/744 [06:45<38:58,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129271.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  15%|▉     | 111/744 [06:49<38:54,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138463.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  15%|▉     | 112/744 [06:53<38:51,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142820.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  15%|▉     | 113/744 [06:57<38:48,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118653.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  15%|▉     | 114/744 [07:00<38:45,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129531.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  15%|▉     | 115/744 [07:04<38:40,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135300.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  16%|▉     | 116/744 [07:07<38:36,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144487.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  16%|▉     | 117/744 [07:11<38:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125217.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  16%|▉     | 118/744 [07:15<38:28,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139518.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9710, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  16%|▉     | 119/744 [07:18<38:24,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136222.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8277, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  16%|▉     | 120/744 [07:22<38:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(118795.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  16%|▉     | 121/744 [07:26<38:16,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116195.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  16%|▉     | 122/744 [07:29<38:12,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122455.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  17%|▉     | 123/744 [07:33<38:08,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144130.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  17%|█     | 124/744 [07:37<38:05,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121990.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  17%|█     | 125/744 [07:40<38:02,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117551.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  17%|█     | 126/744 [07:44<37:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143566.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  17%|█     | 127/744 [07:48<37:56,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124395.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  17%|█     | 128/744 [07:52<37:51,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133833.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  17%|█     | 129/744 [07:55<37:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134360.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  17%|█     | 130/744 [07:59<37:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127464.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  18%|█     | 131/744 [08:02<37:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131700.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7999, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  18%|█     | 132/744 [08:06<37:35,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130656.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  18%|█     | 133/744 [08:10<37:31,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139546.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  18%|█     | 134/744 [08:13<37:28,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144987.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0488, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  18%|█     | 135/744 [08:17<37:24,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139097., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  18%|█     | 136/744 [08:21<37:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138229.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  18%|█     | 137/744 [08:25<37:17,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124248.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  19%|█     | 138/744 [08:28<37:14,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133278.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  19%|█     | 139/744 [08:32<37:10,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128069.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  19%|█▏    | 140/744 [08:36<37:06,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136311.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  19%|█▏    | 141/744 [08:39<37:01,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126982.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  19%|█▏    | 142/744 [08:43<36:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127171.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  19%|█▏    | 143/744 [08:47<36:55,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130744.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  19%|█▏    | 144/744 [08:50<36:51,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129952.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  19%|█▏    | 145/744 [08:54<36:48,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132057.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  20%|█▏    | 146/744 [08:58<36:45,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127902.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  20%|█▏    | 147/744 [09:02<36:41,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139900.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  20%|█▏    | 148/744 [09:05<36:37,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124844.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  20%|█▏    | 149/744 [09:09<36:33,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128571.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  20%|█▏    | 150/744 [09:12<36:29,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139074.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  20%|█▏    | 151/744 [09:16<36:25,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137576.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  20%|█▏    | 152/744 [09:20<36:21,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135667.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  21%|█▏    | 153/744 [09:23<36:17,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126658.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  21%|█▏    | 154/744 [09:27<36:12,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131392.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  21%|█▎    | 155/744 [09:30<36:08,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134063.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  21%|█▎    | 156/744 [09:34<36:05,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133035.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  21%|█▎    | 157/744 [09:38<36:01,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116894.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  21%|█▎    | 158/744 [09:41<35:57,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130576.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  21%|█▎    | 159/744 [09:45<35:53,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125507.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  22%|█▎    | 160/744 [09:49<35:50,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133284.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  22%|█▎    | 161/744 [09:52<35:46,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140291.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  22%|█▎    | 162/744 [09:56<35:43,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124085.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  22%|█▎    | 163/744 [10:00<35:39,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142825.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  22%|█▎    | 164/744 [10:03<35:36,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(151113.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9277, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  22%|█▎    | 165/744 [10:07<35:32,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(148133.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  22%|█▎    | 166/744 [10:11<35:28,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(152951.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  22%|█▎    | 167/744 [10:15<35:26,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127787.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  23%|█▎    | 168/744 [10:19<35:22,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124029.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  23%|█▎    | 169/744 [10:22<35:19,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144567.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  23%|█▎    | 170/744 [10:26<35:15,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129762.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  23%|█▍    | 171/744 [10:30<35:12,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127900.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  23%|█▍    | 172/744 [10:34<35:09,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126382.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9914, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  23%|█▍    | 173/744 [10:38<35:05,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127970.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  23%|█▍    | 174/744 [10:41<35:02,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135046.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  24%|█▍    | 175/744 [10:45<34:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126315.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  24%|█▍    | 176/744 [10:49<34:55,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133903.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  24%|█▍    | 177/744 [10:53<34:52,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(103739.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  24%|█▍    | 178/744 [10:56<34:49,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133190.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  24%|█▍    | 179/744 [11:00<34:45,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132240.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  24%|█▍    | 180/744 [11:04<34:41,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145750.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  24%|█▍    | 181/744 [11:08<34:38,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116440.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  24%|█▍    | 182/744 [11:11<34:33,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144889.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  25%|█▍    | 183/744 [11:15<34:29,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(146752.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  25%|█▍    | 184/744 [11:18<34:26,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145941.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  25%|█▍    | 185/744 [11:22<34:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122590.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  25%|█▌    | 186/744 [11:26<34:18,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(110319.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  25%|█▌    | 187/744 [11:29<34:14,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136475.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  25%|█▌    | 188/744 [11:33<34:09,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137282.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  25%|█▌    | 189/744 [11:37<34:06,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132979.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  26%|█▌    | 190/744 [11:40<34:03,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140466.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  26%|█▌    | 191/744 [11:44<33:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120485.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  26%|█▌    | 192/744 [11:48<33:56,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124175.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  26%|█▌    | 193/744 [11:52<33:52,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122773.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  26%|█▌    | 194/744 [11:55<33:48,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136819.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  26%|█▌    | 195/744 [11:59<33:44,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128203.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  26%|█▌    | 196/744 [12:02<33:41,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135182.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  26%|█▌    | 197/744 [12:06<33:37,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138671.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  27%|█▌    | 198/744 [12:10<33:33,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111357.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  27%|█▌    | 199/744 [12:13<33:29,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145844.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  27%|█▌    | 200/744 [12:17<33:25,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140119.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  27%|█▌    | 201/744 [12:21<33:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122460.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  27%|█▋    | 202/744 [12:24<33:18,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122926.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  27%|█▋    | 203/744 [12:28<33:14,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125016.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  27%|█▋    | 204/744 [12:32<33:10,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133912.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  28%|█▋    | 205/744 [12:35<33:06,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141747.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  28%|█▋    | 206/744 [12:39<33:03,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138151.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  28%|█▋    | 207/744 [12:42<32:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136590.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  28%|█▋    | 208/744 [12:46<32:55,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127693.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  28%|█▋    | 209/744 [12:50<32:51,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143935.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  28%|█▋    | 210/744 [12:53<32:47,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135864.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0081, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  28%|█▋    | 211/744 [12:57<32:43,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133163.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  28%|█▋    | 212/744 [13:01<32:40,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124946.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  29%|█▋    | 213/744 [13:04<32:36,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139021.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  29%|█▋    | 214/744 [13:08<32:32,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133158.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  29%|█▋    | 215/744 [13:11<32:28,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121092.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  29%|█▋    | 216/744 [13:15<32:24,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117909.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  29%|█▊    | 217/744 [13:19<32:20,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(109385.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  29%|█▊    | 218/744 [13:22<32:17,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144909.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  29%|█▊    | 219/744 [13:26<32:13,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137055.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  30%|█▊    | 220/744 [13:30<32:09,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133361.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  30%|█▊    | 221/744 [13:34<32:06,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141095.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  30%|█▊    | 222/744 [13:37<32:02,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138549.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  30%|█▊    | 223/744 [13:41<31:59,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122989.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  30%|█▊    | 224/744 [13:45<31:55,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133499.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  30%|█▊    | 225/744 [13:48<31:51,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142389.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  30%|█▊    | 226/744 [13:52<31:48,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129118.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  31%|█▊    | 227/744 [13:56<31:44,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137716.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  31%|█▊    | 228/744 [13:59<31:40,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135015.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  31%|█▊    | 229/744 [14:03<31:36,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130035.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  31%|█▊    | 230/744 [14:07<31:33,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142173., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9756, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  31%|█▊    | 231/744 [14:10<31:29,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128990.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  31%|█▊    | 232/744 [14:14<31:25,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124435.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  31%|█▉    | 233/744 [14:17<31:21,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141361.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  31%|█▉    | 234/744 [14:21<31:17,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122182.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  32%|█▉    | 235/744 [14:25<31:14,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124772.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7984, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  32%|█▉    | 236/744 [14:29<31:10,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131553.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  32%|█▉    | 237/744 [14:32<31:06,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128081.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  32%|█▉    | 238/744 [14:36<31:03,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130501.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  32%|█▉    | 239/744 [14:40<30:59,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125354.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  32%|█▉    | 240/744 [14:43<30:56,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127951.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  32%|█▉    | 241/744 [14:47<30:52,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128643.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  33%|█▉    | 242/744 [14:51<30:48,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126201.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  33%|█▉    | 243/744 [14:55<30:45,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125734.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  33%|█▉    | 244/744 [14:58<30:41,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141431.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  33%|█▉    | 245/744 [15:02<30:37,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141664.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  33%|█▉    | 246/744 [15:05<30:33,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129857.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  33%|█▉    | 247/744 [15:09<30:29,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131325.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  33%|██    | 248/744 [15:13<30:26,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130623.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9513, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  33%|██    | 249/744 [15:16<30:22,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130967.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  34%|██    | 250/744 [15:20<30:19,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125960.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  34%|██    | 251/744 [15:24<30:16,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120231.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  34%|██    | 252/744 [15:28<30:12,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129277.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9277, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  34%|██    | 253/744 [15:31<30:08,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136300.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  34%|██    | 254/744 [15:35<30:04,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135249.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  34%|██    | 255/744 [15:38<30:00,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(113160.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  34%|██    | 256/744 [15:42<29:57,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125934.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  35%|██    | 257/744 [15:46<29:53,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130391.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7756, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  35%|██    | 258/744 [15:50<29:49,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138324.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  35%|██    | 259/744 [15:53<29:46,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127832.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  35%|██    | 260/744 [15:57<29:42,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130201.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  35%|██    | 261/744 [16:01<29:38,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145559.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  35%|██    | 262/744 [16:04<29:34,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131218.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  35%|██    | 263/744 [16:08<29:31,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131024.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  35%|██▏   | 264/744 [16:12<29:27,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129507.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  36%|██▏   | 265/744 [16:16<29:24,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112691.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  36%|██▏   | 266/744 [16:19<29:21,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(112794.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  36%|██▏   | 267/744 [16:23<29:17,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128409.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  36%|██▏   | 268/744 [16:27<29:13,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134364.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  36%|██▏   | 269/744 [16:31<29:10,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(151077.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  36%|██▏   | 270/744 [16:34<29:06,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137122.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8843, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  36%|██▏   | 271/744 [16:38<29:03,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135255.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  37%|██▏   | 272/744 [16:42<28:59,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142702.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  37%|██▏   | 273/744 [16:46<28:55,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124897.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  37%|██▏   | 274/744 [16:49<28:51,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135374.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  37%|██▏   | 275/744 [16:53<28:47,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134314.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  37%|██▏   | 276/744 [16:56<28:43,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114281.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  37%|██▏   | 277/744 [17:00<28:40,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125300.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  37%|██▏   | 278/744 [17:04<28:36,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125191.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  38%|██▎   | 279/744 [17:07<28:33,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128288.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  38%|██▎   | 280/744 [17:11<28:29,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142384.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  38%|██▎   | 281/744 [17:14<28:25,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(116683.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  38%|██▎   | 282/744 [17:18<28:21,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133833.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  38%|██▎   | 283/744 [17:22<28:17,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(147594.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  38%|██▎   | 284/744 [17:25<28:13,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129985.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  38%|██▎   | 285/744 [17:29<28:10,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133303.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.6907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  38%|██▎   | 286/744 [17:33<28:06,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137876.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9064, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  39%|██▎   | 287/744 [17:36<28:02,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139572.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  39%|██▎   | 288/744 [17:40<27:59,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129848.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  39%|██▎   | 289/744 [17:44<27:56,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139996.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  39%|██▎   | 290/744 [17:48<27:52,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139401.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  39%|██▎   | 291/744 [17:51<27:48,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130282.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  39%|██▎   | 292/744 [17:55<27:44,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135768.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  39%|██▎   | 293/744 [17:59<27:41,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143588.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  40%|██▎   | 294/744 [18:03<27:37,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130580.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  40%|██▍   | 295/744 [18:07<27:34,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141380.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  40%|██▍   | 296/744 [18:10<27:30,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(126884.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  40%|██▍   | 297/744 [18:14<27:27,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127701.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  40%|██▍   | 298/744 [18:18<27:23,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135343.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  40%|██▍   | 299/744 [18:21<27:19,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(117013.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  40%|██▍   | 300/744 [18:25<27:16,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145922.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  40%|██▍   | 301/744 [18:29<27:12,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124658.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  41%|██▍   | 302/744 [18:32<27:08,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128906.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  41%|██▍   | 303/744 [18:36<27:05,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121782.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  41%|██▍   | 304/744 [18:39<27:01,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(148543.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  41%|██▍   | 305/744 [18:43<26:57,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(146260.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  41%|██▍   | 306/744 [18:47<26:53,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124814.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  41%|██▍   | 307/744 [18:51<26:50,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140342.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  41%|██▍   | 308/744 [18:54<26:46,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130605.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  42%|██▍   | 309/744 [18:58<26:42,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138481.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  42%|██▌   | 310/744 [19:01<26:38,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127628.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  42%|██▌   | 311/744 [19:05<26:35,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(148726.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  42%|██▌   | 312/744 [19:09<26:31,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129404.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  42%|██▌   | 313/744 [19:13<26:27,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125510.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  42%|██▌   | 314/744 [19:16<26:24,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127521.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  42%|██▌   | 315/744 [19:20<26:20,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(146737.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  42%|██▌   | 316/744 [19:24<26:16,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134180.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  43%|██▌   | 317/744 [19:27<26:12,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(157663.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  43%|██▌   | 318/744 [19:31<26:09,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133621.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  43%|██▌   | 319/744 [19:35<26:05,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145834.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  43%|██▌   | 320/744 [19:38<26:01,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(114786.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  43%|██▌   | 321/744 [19:42<25:58,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144145.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  43%|██▌   | 322/744 [19:46<25:54,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141418.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  43%|██▌   | 323/744 [19:49<25:50,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141354.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  44%|██▌   | 324/744 [19:53<25:47,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134554.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8563, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  44%|██▌   | 325/744 [19:57<25:43,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129463.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  44%|██▋   | 326/744 [20:00<25:39,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145888.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  44%|██▋   | 327/744 [20:04<25:36,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131328.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  44%|██▋   | 328/744 [20:08<25:32,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(156285.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  44%|██▋   | 329/744 [20:12<25:28,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127351.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  44%|██▋   | 330/744 [20:15<25:25,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140262.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  44%|██▋   | 331/744 [20:19<25:21,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130841.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  45%|██▋   | 332/744 [20:23<25:18,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130587.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  45%|██▋   | 333/744 [20:26<25:14,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(120126.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  45%|██▋   | 334/744 [20:30<25:11,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130972.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  45%|██▋   | 335/744 [20:34<25:07,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139696.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  45%|██▋   | 336/744 [20:38<25:03,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(125881.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  45%|██▋   | 337/744 [20:42<25:00,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133721.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  45%|██▋   | 338/744 [20:46<24:56,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141646.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  46%|██▋   | 339/744 [20:49<24:53,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121434.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  46%|██▋   | 340/744 [20:53<24:49,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(151285.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  46%|██▊   | 341/744 [20:56<24:45,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133512.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  46%|██▊   | 342/744 [21:00<24:41,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135565.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  46%|██▊   | 343/744 [21:04<24:38,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137410.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  46%|██▊   | 344/744 [21:07<24:34,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119682.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  46%|██▊   | 345/744 [21:11<24:30,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129197.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  47%|██▊   | 346/744 [21:15<24:26,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145594.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  47%|██▊   | 347/744 [21:18<24:23,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129275.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  47%|██▊   | 348/744 [21:22<24:19,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132294.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  47%|██▊   | 349/744 [21:25<24:15,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139074.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  47%|██▊   | 350/744 [21:29<24:11,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130314.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  47%|██▊   | 351/744 [21:33<24:07,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138028.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  47%|██▊   | 352/744 [21:36<24:04,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(147783.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  47%|██▊   | 353/744 [21:40<24:00,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(147812.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  48%|██▊   | 354/744 [21:44<23:57,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127059.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  48%|██▊   | 355/744 [21:48<23:53,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121817.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  48%|██▊   | 356/744 [21:51<23:49,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139362.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  48%|██▉   | 357/744 [21:55<23:46,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131929.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  48%|██▉   | 358/744 [21:59<23:42,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135989.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  48%|██▉   | 359/744 [22:03<23:38,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144613.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  48%|██▉   | 360/744 [22:06<23:35,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137820.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  49%|██▉   | 361/744 [22:10<23:31,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140287.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  49%|██▉   | 362/744 [22:14<23:28,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135822.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9923, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  49%|██▉   | 363/744 [22:18<23:24,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143564.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  49%|██▉   | 364/744 [22:22<23:21,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133182.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  49%|██▉   | 365/744 [22:25<23:17,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134233.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  49%|██▉   | 366/744 [22:29<23:13,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139721.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  49%|██▉   | 367/744 [22:33<23:09,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129208.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7756, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  49%|██▉   | 368/744 [22:36<23:06,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(121248.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  50%|██▉   | 369/744 [22:40<23:02,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127521.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  50%|██▉   | 370/744 [22:44<22:58,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145778.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  50%|██▉   | 371/744 [22:47<22:55,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134547.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  50%|███   | 372/744 [22:51<22:51,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136243.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  50%|███   | 373/744 [22:54<22:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(145462.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  50%|███   | 374/744 [22:58<22:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128937.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  50%|███   | 375/744 [23:02<22:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136378.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  51%|███   | 376/744 [23:05<22:36,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140155.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  51%|███   | 377/744 [23:09<22:32,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134442.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  51%|███   | 378/744 [23:12<22:28,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(115737.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  51%|███   | 379/744 [23:16<22:25,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132813.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  51%|███   | 380/744 [23:20<22:21,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134298.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  51%|███   | 381/744 [23:23<22:17,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131594.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  51%|███   | 382/744 [23:27<22:13,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(144297.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  51%|███   | 383/744 [23:31<22:10,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133974.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  52%|███   | 384/744 [23:34<22:06,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143726.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  52%|███   | 385/744 [23:38<22:02,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111803.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  52%|███   | 386/744 [23:42<21:59,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128673.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  52%|███   | 387/744 [23:45<21:55,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130863.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  52%|███▏  | 388/744 [23:49<21:51,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137820.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  52%|███▏  | 389/744 [23:53<21:48,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(139997.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  52%|███▏  | 390/744 [23:57<21:44,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(136379.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  53%|███▏  | 391/744 [24:00<21:40,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129103.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  53%|███▏  | 392/744 [24:04<21:36,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134997.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  53%|███▏  | 393/744 [24:07<21:33,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(128533.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  53%|███▏  | 394/744 [24:11<21:29,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137864.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  53%|███▏  | 395/744 [24:15<21:25,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(123571.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  53%|███▏  | 396/744 [24:19<21:22,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131995.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  53%|███▏  | 397/744 [24:22<21:18,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137649.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  53%|███▏  | 398/744 [24:26<21:14,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137528.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9125, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  54%|███▏  | 399/744 [24:29<21:10,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(135823.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  54%|███▏  | 400/744 [24:33<21:07,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(134070.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(1.0059, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  54%|███▏  | 401/744 [24:37<21:03,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138233.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  54%|███▏  | 402/744 [24:41<20:59,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132584.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  54%|███▎  | 403/744 [24:44<20:56,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131544.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  54%|███▎  | 404/744 [24:48<20:52,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119515.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  54%|███▎  | 405/744 [24:51<20:48,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(143652.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  55%|███▎  | 406/744 [24:55<20:45,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142315.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  55%|███▎  | 407/744 [24:59<20:41,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(124408.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  55%|███▎  | 408/744 [25:03<20:37,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(129400.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  55%|███▎  | 409/744 [25:06<20:34,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138718.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  55%|███▎  | 410/744 [25:10<20:30,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(132562.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  55%|███▎  | 411/744 [25:14<20:27,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(137537.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  55%|███▎  | 412/744 [25:18<20:23,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(127405.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  56%|███▎  | 413/744 [25:21<20:19,  3.68s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(111500.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  56%|███▎  | 414/744 [25:25<20:16,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(131228.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  56%|███▎  | 415/744 [25:29<20:12,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(133492.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  56%|███▎  | 416/744 [25:33<20:08,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(147054.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  56%|███▎  | 417/744 [25:37<20:05,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(119961.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  56%|███▎  | 418/744 [25:40<20:01,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(140829.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  56%|███▍  | 419/744 [25:44<19:58,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(130161.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  56%|███▍  | 420/744 [25:48<19:54,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(142759.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  57%|███▍  | 421/744 [25:52<19:50,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(122019.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.7779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  57%|███▍  | 422/744 [25:55<19:47,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138835.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  57%|███▍  | 423/744 [25:59<19:43,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(138192.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.8314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  57%|███▍  | 424/744 [26:02<19:39,  3.69s/it, loss=nan, v_num=5.48e+7]loss_g:   tensor(141549.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_d:   tensor(0.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21:  57%|███▍  | 425/744 [26:06<19:35,  3.69s/it, loss=nan, v_num=5.48e+7]"
     ]
    }
   ],
   "source": [
    "!python light.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "------------ Options -------------\n",
      "batchSize: 4\n",
      "batch_size: 4\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ../data/cityscapes/\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "ganFeat_loss: True\n",
      "gpu_ids: [0]\n",
      "input_nc: 1\n",
      "isTrain: True\n",
      "label_nc: 34\n",
      "lambda_feat: 10.0\n",
      "loadSize: 512\n",
      "load_features: False\n",
      "load_pretrain: ./checkpoints/label2face_512p\n",
      "local_rank: 0\n",
      "lr: 5e-05\n",
      "lsgan: True\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: label2face_512p\n",
      "ndf: 64\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_html: False\n",
      "no_instance: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 16\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "vae_path: ../../CelebAMask-HQ/MaskGAN_demo/checkpoint_vae/000070.pt\n",
      "verbose: False\n",
      "vgg_loss: True\n",
      "weight_decay: 0.0001\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "------------ Options -------------\n",
      "batchSize: 4\n",
      "batch_size: 4\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ../data/cityscapes/\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "ganFeat_loss: True\n",
      "gpu_ids: [0]\n",
      "input_nc: 1\n",
      "isTrain: True\n",
      "label_nc: 34\n",
      "lambda_feat: 10.0\n",
      "loadSize: 512\n",
      "load_features: False\n",
      "load_pretrain: ./checkpoints/label2face_512p\n",
      "local_rank: 0\n",
      "lr: 5e-05\n",
      "lsgan: True\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: label2face_512p\n",
      "ndf: 64\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_html: False\n",
      "no_instance: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 16\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "vae_path: ../../CelebAMask-HQ/MaskGAN_demo/checkpoint_vae/000070.pt\n",
      "verbose: False\n",
      "vgg_loss: True\n",
      "weight_decay: 0.0001\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(34, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (21): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (24): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (27): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (30): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (33): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (34): Tanh()\n",
      "  )\n",
      "  (enc_style): StyleEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_middle): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_last): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Conv2d(64, 16384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sft1): SFTLayer(\n",
      "      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_scale_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sft2): SFTLayer(\n",
      "      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_scale_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (enc_label): LabelEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(34, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_last): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (3): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiscaleDiscriminator(\n",
      "  (scale0_layer0): Sequential(\n",
      "    (0): Conv2d(37, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (scale1_layer0): Sequential(\n",
      "    (0): Conv2d(37, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
      ")\n",
      "BlendGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(6, 32, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (17): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (20): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (21): ReLU(inplace=True)\n",
      "    (22): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (23): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (26): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (27): Sigmoid()\n",
      "  )\n",
      ")\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Disable automatic optimization with the trainer flag is deprecated and will be removed in v1.3.0!Please use the property on the LightningModule for disabling automatic optimization\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Set SLURM handle signals.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I1124 15:33:15.941715 47880190508800 slurm_connector.py:80] Set SLURM handle signals.\n",
      "\n",
      "  | Name          | Type                    | Params\n",
      "----------------------------------------------------------\n",
      "0 | netVAE        | VAE                     | 170 M \n",
      "1 | netG          | GlobalGenerator         | 89.8 M\n",
      "2 | netD          | MultiscaleDiscriminator | 5.6 M \n",
      "3 | netB          | BlendGenerator          | 4.3 M \n",
      "4 | criterionGAN  | GANLoss                 | 0     \n",
      "5 | criterionFeat | L1Loss                  | 0     \n",
      "6 | criterionVGG  | VGGLoss                 | 12.9 M\n",
      "I1124 15:33:15.956542 47880190508800 lightning.py:1488] \n",
      "  | Name          | Type                    | Params\n",
      "----------------------------------------------------------\n",
      "0 | netVAE        | VAE                     | 170 M \n",
      "1 | netG          | GlobalGenerator         | 89.8 M\n",
      "2 | netD          | MultiscaleDiscriminator | 5.6 M \n",
      "3 | netB          | BlendGenerator          | 4.3 M \n",
      "4 | criterionGAN  | GANLoss                 | 0     \n",
      "5 | criterionFeat | L1Loss                  | 0     \n",
      "6 | criterionVGG  | VGGLoss                 | 12.9 M\n",
      "Epoch 0:  26%|▎| 190/744 [07:36<22:10,  2.40s/it, loss=nan, v_num=5.5e+7, d_trai^C\n"
     ]
    }
   ],
   "source": [
    "!python light.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/project/6007383/shimash/model_zoo/maskgan/maskVAE'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

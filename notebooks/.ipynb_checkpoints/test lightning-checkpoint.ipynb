{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"cdSet\" in globals():\n",
    "    %cd -q ..\n",
    "    cdSet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "------------ Options -------------\n",
      "batchSize: 8\n",
      "batch_size: 4\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ../data/cityscapes/\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "ganFeat_loss: True\n",
      "gpu_ids: [0]\n",
      "input_nc: 1\n",
      "isTrain: True\n",
      "label_nc: 34\n",
      "lambda_feat: 10.0\n",
      "loadSize: 512\n",
      "load_features: False\n",
      "load_pretrain: ./checkpoints/label2face_512p\n",
      "local_rank: 0\n",
      "lr: 5e-05\n",
      "lsgan: True\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: label2face_512p\n",
      "ndf: 64\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_html: False\n",
      "no_instance: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 16\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "vae_path: ../../CelebAMask-HQ/MaskGAN_demo/checkpoint_vae/000070.pt\n",
      "verbose: False\n",
      "vgg_loss: True\n",
      "weight_decay: 0.0001\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "------------ Options -------------\n",
      "batchSize: 8\n",
      "batch_size: 4\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ../data/cityscapes/\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "ganFeat_loss: True\n",
      "gpu_ids: [0]\n",
      "input_nc: 1\n",
      "isTrain: True\n",
      "label_nc: 34\n",
      "lambda_feat: 10.0\n",
      "loadSize: 512\n",
      "load_features: False\n",
      "load_pretrain: ./checkpoints/label2face_512p\n",
      "local_rank: 0\n",
      "lr: 5e-05\n",
      "lsgan: True\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: label2face_512p\n",
      "ndf: 64\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_html: False\n",
      "no_instance: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 16\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "vae_path: ../../CelebAMask-HQ/MaskGAN_demo/checkpoint_vae/000070.pt\n",
      "verbose: False\n",
      "vgg_loss: True\n",
      "weight_decay: 0.0001\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(34, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (21): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (24): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (27): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (30): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (33): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (34): Tanh()\n",
      "  )\n",
      "  (enc_style): StyleEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_middle): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_last): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Conv2d(64, 16384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sft1): SFTLayer(\n",
      "      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_scale_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sft2): SFTLayer(\n",
      "      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_scale_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (enc_label): LabelEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(34, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_last): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (3): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiscaleDiscriminator(\n",
      "  (scale0_layer0): Sequential(\n",
      "    (0): Conv2d(37, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (scale1_layer0): Sequential(\n",
      "    (0): Conv2d(37, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
      ")\n",
      "BlendGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(6, 32, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (17): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (20): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (21): ReLU(inplace=True)\n",
      "    (22): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (23): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (26): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (27): Sigmoid()\n",
      "  )\n",
      ")\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Disable automatic optimization with the trainer flag is deprecated and will be removed in v1.3.0!Please use the property on the LightningModule for disabling automatic optimization\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Set SLURM handle signals.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I1124 17:16:49.671613 47984567242496 slurm_connector.py:80] Set SLURM handle signals.\n",
      "\n",
      "  | Name          | Type                    | Params\n",
      "----------------------------------------------------------\n",
      "0 | netVAE        | VAE                     | 170 M \n",
      "1 | netG          | GlobalGenerator         | 89.8 M\n",
      "2 | netD          | MultiscaleDiscriminator | 5.6 M \n",
      "3 | netB          | BlendGenerator          | 4.3 M \n",
      "4 | criterionGAN  | GANLoss                 | 0     \n",
      "5 | criterionFeat | L1Loss                  | 0     \n",
      "6 | criterionVGG  | VGGLoss                 | 12.9 M\n",
      "I1124 17:16:49.679080 47984567242496 lightning.py:1488] \n",
      "  | Name          | Type                    | Params\n",
      "----------------------------------------------------------\n",
      "0 | netVAE        | VAE                     | 170 M \n",
      "1 | netG          | GlobalGenerator         | 89.8 M\n",
      "2 | netD          | MultiscaleDiscriminator | 5.6 M \n",
      "3 | netB          | BlendGenerator          | 4.3 M \n",
      "4 | criterionGAN  | GANLoss                 | 0     \n",
      "5 | criterionFeat | L1Loss                  | 0     \n",
      "6 | criterionVGG  | VGGLoss                 | 12.9 M\n",
      "Epoch 0:   0%|                                          | 0/744 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"light.py\", line 422, in <module>\n",
      "    trainer.fit(model)\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 469, in fit\n",
      "    results = self.accelerator_backend.train()\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 64, in train\n",
      "    results = self.train_or_test()\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 66, in train_or_test\n",
      "    results = self.trainer.train()\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 521, in train\n",
      "    self.train_loop.run_training_epoch()\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 539, in run_training_epoch\n",
      "    batch_output = self.run_training_batch(batch, batch_idx, dataloader_idx)\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 698, in run_training_batch\n",
      "    self.trainer.hiddens\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 324, in training_step\n",
      "    training_step_output = self.trainer.accelerator_backend.training_step(args)\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 72, in training_step\n",
      "    output = self.__training_step(args)\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 80, in __training_step\n",
      "    output = self.trainer.model.training_step(*args)\n",
      "  File \"light.py\", line 230, in training_step\n",
      "    self.manual_backward(loss_g, opt_g)\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\", line 1118, in manual_backward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    self.trainer.train_loop.backward(loss, optimizer, -1, *args, **kwargs)\r\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 798, in backward\r\n",
      "    self.trainer.accelerator_backend.backward(result, optimizer, opt_idx, *args, **kwargs)\r\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 95, in backward\r\n",
      "    model.backward(closure_loss, optimizer, opt_idx, *args, **kwargs)\r\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\", line 1287, in backward\r\n",
      "    loss.backward(*args, **kwargs)\r\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/torch/tensor.py\", line 198, in backward\r\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n",
      "  File \"/project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 100, in backward\r\n",
      "    allow_unreachable=True)  # allow_unreachable flag\r\n",
      "RuntimeError: Function MulBackward0 returned an invalid gradient at index 1 - expected type TensorOptions(dtype=float, device=cuda:0, layout=Strided, requires_grad=false) but got TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false) (validate_outputs at /pytorch/torch/csrc/autograd/engine.cpp:484)\r\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x2ba49eeb9536 in /project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/torch/lib/libc10.so)\r\n",
      "frame #1: <unknown function> + 0x2d84224 (0x2ba455c41224 in /project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\n",
      "frame #2: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x548 (0x2ba455c42d58 in /project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\n",
      "frame #3: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x2ba455c44ce2 in /project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\n",
      "frame #4: torch::autograd::Engine::thread_init(int) + 0x39 (0x2ba455c3d359 in /project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\n",
      "frame #5: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x2ba45222f4d8 in /project/6007383/shimash/stylegan-3.6/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\r\n",
      "frame #6: <unknown function> + 0xcb880 (0x2ba4513d1880 in /cvmfs/soft.computecanada.ca/nix/var/nix/profiles/16.09/lib/libstdc++.so.6)\r\n",
      "frame #7: <unknown function> + 0x71f4 (0x2ba4478891f4 in /cvmfs/soft.computecanada.ca/nix/var/nix/profiles/16.09/lib/libpthread.so.0)\r\n",
      "frame #8: clone + 0x5f (0x2ba44829316f in /cvmfs/soft.computecanada.ca/nix/var/nix/profiles/16.09/lib/libc.so.6)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python light.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 24 17:12:03 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    42W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    42W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    41W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    42W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

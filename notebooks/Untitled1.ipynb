{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/6007383/shimash/model_zoo/CelebAMask-HQ/MaskGAN_demo\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "------------ Options -------------\n",
      "batchSize: 8\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ../../maskgan/data/cityscapes/\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "gpu_ids: [0, 1, 2, 3]\n",
      "input_nc: 1\n",
      "isTrain: True\n",
      "label_nc: 34\n",
      "lambda_feat: 10.0\n",
      "loadSize: 512\n",
      "load_features: False\n",
      "load_pretrain: ./checkpoints/label2face_512p\n",
      "local_rank: 0\n",
      "lr: 5e-05\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: label2face_512p\n",
      "ndf: 64\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_ganFeat_loss: False\n",
      "no_html: False\n",
      "no_instance: False\n",
      "no_lsgan: False\n",
      "no_vgg_loss: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 16\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "verbose: False\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "opt.distributed:  False\n",
      "VAE(\n",
      "  (e1): Conv2d(34, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e6): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e7): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=32768, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=32768, out_features=1024, bias=True)\n",
      "  (d1): Linear(in_features=1024, out_features=32768, bias=True)\n",
      "  (up1): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd1): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d2): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn8): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up2): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd2): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d3): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn9): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up3): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd3): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn10): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up4): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd4): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn11): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up5): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd5): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn12): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up6): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd6): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d7): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn13): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up7): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd7): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d8): Conv2d(32, 34, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Number of parameters: 170631586\n",
      "Training ...\n",
      "epoch #0 train_iter #0 : train loss is 3.6094181537628174\n",
      "epoch #0 train_iter #1 : train loss is 3.5545101165771484\n",
      "epoch #0 train_iter #2 : train loss is 3.4654977321624756\n",
      "epoch #0 train_iter #3 : train loss is 3.4210078716278076\n",
      "epoch #0 train_iter #4 : train loss is 3.389248847961426\n",
      "epoch #0 train_iter #5 : train loss is 3.3531272411346436\n",
      "epoch #0 train_iter #6 : train loss is 3.3030996322631836\n",
      "epoch #0 train_iter #7 : train loss is 3.2888641357421875\n",
      "epoch #0 train_iter #8 : train loss is 3.2449629306793213\n",
      "epoch #0 train_iter #9 : train loss is 3.1984219551086426\n",
      "epoch #0 train_iter #10 : train loss is 3.19433856010437\n",
      "epoch #0 train_iter #11 : train loss is 3.1384470462799072\n",
      "epoch #0 train_iter #12 : train loss is 3.09336256980896\n",
      "epoch #0 train_iter #13 : train loss is 3.0918233394622803\n",
      "epoch #0 train_iter #14 : train loss is 3.049776792526245\n",
      "epoch #0 train_iter #15 : train loss is 3.065335750579834\n",
      "epoch #0 train_iter #16 : train loss is 3.051582098007202\n",
      "epoch #0 train_iter #17 : train loss is 3.0692086219787598\n",
      "epoch #0 train_iter #18 : train loss is 2.980771541595459\n",
      "epoch #0 train_iter #19 : train loss is 3.009315013885498\n",
      "epoch #0 train_iter #20 : train loss is 2.938196897506714\n",
      "epoch #0 train_iter #21 : train loss is 2.910404920578003\n",
      "epoch #0 train_iter #22 : train loss is 2.9602291584014893\n",
      "epoch #0 train_iter #23 : train loss is 2.923572540283203\n",
      "epoch #0 train_iter #24 : train loss is 2.890489101409912\n",
      "epoch #0 train_iter #25 : train loss is 2.8795154094696045\n",
      "epoch #0 train_iter #26 : train loss is 2.8247811794281006\n",
      "epoch #0 train_iter #27 : train loss is 2.9400546550750732\n",
      "epoch #0 train_iter #28 : train loss is 2.887849807739258\n",
      "epoch #0 train_iter #29 : train loss is 2.8100059032440186\n",
      "epoch #0 train_iter #30 : train loss is 2.9180636405944824\n",
      "epoch #0 train_iter #31 : train loss is 2.8304340839385986\n",
      "epoch #0 train_iter #32 : train loss is 2.8864598274230957\n",
      "epoch #0 train_iter #33 : train loss is 2.8097729682922363\n",
      "epoch #0 train_iter #34 : train loss is 2.8788797855377197\n",
      "epoch #0 train_iter #35 : train loss is 2.7839267253875732\n",
      "epoch #0 train_iter #36 : train loss is 2.863581895828247\n",
      "epoch #0 train_iter #37 : train loss is 2.78347110748291\n",
      "epoch #0 train_iter #38 : train loss is 2.797550916671753\n",
      "epoch #0 train_iter #39 : train loss is 2.751919984817505\n",
      "epoch #0 train_iter #40 : train loss is 2.7475736141204834\n",
      "epoch #0 train_iter #41 : train loss is 2.7469592094421387\n",
      "epoch #0 train_iter #42 : train loss is 2.747419595718384\n",
      "epoch #0 train_iter #43 : train loss is 2.7818551063537598\n",
      "epoch #0 train_iter #44 : train loss is 2.7465548515319824\n",
      "epoch #0 train_iter #45 : train loss is 2.6667914390563965\n",
      "epoch #0 train_iter #46 : train loss is 2.831881284713745\n",
      "epoch #0 train_iter #47 : train loss is 2.5771679878234863\n",
      "epoch #0 train_iter #48 : train loss is 2.816260576248169\n",
      "epoch #0 train_iter #49 : train loss is 2.713480234146118\n",
      "epoch #0 train_iter #50 : train loss is 2.71523380279541\n",
      "epoch #0 train_iter #51 : train loss is 2.6761772632598877\n",
      "epoch #0 train_iter #52 : train loss is 2.640623092651367\n",
      "epoch #0 train_iter #53 : train loss is 2.6749823093414307\n",
      "epoch #0 train_iter #54 : train loss is 2.6629738807678223\n",
      "epoch #0 train_iter #55 : train loss is 2.6249303817749023\n",
      "epoch #0 train_iter #56 : train loss is 2.649199962615967\n",
      "epoch #0 train_iter #57 : train loss is 2.67063307762146\n",
      "epoch #0 train_iter #58 : train loss is 2.7927052974700928\n",
      "epoch #0 train_iter #59 : train loss is 2.677743911743164\n",
      "epoch #0 train_iter #60 : train loss is 2.652299165725708\n",
      "epoch #0 train_iter #61 : train loss is 2.60892653465271\n",
      "epoch #0 train_iter #62 : train loss is 2.5876309871673584\n",
      "epoch #0 train_iter #63 : train loss is 2.5623316764831543\n",
      "epoch #0 train_iter #64 : train loss is 2.5616915225982666\n",
      "epoch #0 train_iter #65 : train loss is 2.6069791316986084\n",
      "epoch #0 train_iter #66 : train loss is 2.6451916694641113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0 train_iter #67 : train loss is 2.5610039234161377\n",
      "epoch #0 train_iter #68 : train loss is 2.6242363452911377\n",
      "epoch #0 train_iter #69 : train loss is 2.574732542037964\n",
      "epoch #0 train_iter #70 : train loss is 2.629789352416992\n",
      "epoch #0 train_iter #71 : train loss is 2.5974347591400146\n",
      "epoch #0 train_iter #72 : train loss is 2.4889605045318604\n",
      "epoch #0 train_iter #73 : train loss is 2.5410451889038086\n",
      "epoch #0 train_iter #74 : train loss is 2.5737931728363037\n",
      "epoch #0 train_iter #75 : train loss is 2.5500590801239014\n",
      "epoch #0 train_iter #76 : train loss is 2.592374324798584\n",
      "epoch #0 train_iter #77 : train loss is 2.535163402557373\n",
      "epoch #0 train_iter #78 : train loss is 2.5676896572113037\n",
      "epoch #0 train_iter #79 : train loss is 2.570636510848999\n",
      "epoch #0 train_iter #80 : train loss is 2.561519145965576\n",
      "epoch #0 train_iter #81 : train loss is 2.6058168411254883\n",
      "epoch #0 train_iter #82 : train loss is 2.5378916263580322\n",
      "epoch #0 train_iter #83 : train loss is 2.5150721073150635\n",
      "epoch #0 train_iter #84 : train loss is 2.5700955390930176\n",
      "epoch #0 train_iter #85 : train loss is 2.546435832977295\n",
      "epoch #0 train_iter #86 : train loss is 2.5236141681671143\n",
      "epoch #0 train_iter #87 : train loss is 2.562934637069702\n",
      "epoch #0 train_iter #88 : train loss is 2.5311760902404785\n",
      "epoch #0 train_iter #89 : train loss is 2.4640307426452637\n",
      "epoch #0 train_iter #90 : train loss is 2.4893503189086914\n",
      "epoch #0 train_iter #91 : train loss is 2.4950520992279053\n",
      "epoch #0 train_iter #92 : train loss is 2.528616189956665\n",
      "epoch #0 train_iter #93 : train loss is 2.434001922607422\n",
      "epoch #0 train_iter #94 : train loss is 2.5287787914276123\n",
      "epoch #0 train_iter #95 : train loss is 2.4958198070526123\n",
      "epoch #0 train_iter #96 : train loss is 2.485775947570801\n",
      "epoch #0 train_iter #97 : train loss is 2.4741084575653076\n",
      "epoch #0 train_iter #98 : train loss is 2.515338897705078\n",
      "epoch #0 train_iter #99 : train loss is 2.394752264022827\n",
      "epoch #0 train_iter #100 : train loss is 2.450714349746704\n",
      "epoch #0 train_iter #101 : train loss is 2.4351413249969482\n",
      "epoch #0 train_iter #102 : train loss is 2.469261407852173\n",
      "epoch #0 train_iter #103 : train loss is 2.4661967754364014\n",
      "epoch #0 train_iter #104 : train loss is 2.4523277282714844\n",
      "epoch #0 train_iter #105 : train loss is 2.472778797149658\n",
      "epoch #0 train_iter #106 : train loss is 2.4008631706237793\n",
      "epoch #0 train_iter #107 : train loss is 2.446873426437378\n",
      "epoch #0 train_iter #108 : train loss is 2.391461133956909\n",
      "epoch #0 train_iter #109 : train loss is 2.4684369564056396\n",
      "epoch #0 train_iter #110 : train loss is 2.4601340293884277\n",
      "epoch #0 train_iter #111 : train loss is 2.4723665714263916\n",
      "epoch #0 train_iter #112 : train loss is 2.403148889541626\n",
      "epoch #0 train_iter #113 : train loss is 2.369236469268799\n",
      "epoch #0 train_iter #114 : train loss is 2.399207592010498\n",
      "epoch #0 train_iter #115 : train loss is 2.3940634727478027\n",
      "epoch #0 train_iter #116 : train loss is 2.3929734230041504\n",
      "epoch #0 train_iter #117 : train loss is 2.4626877307891846\n",
      "epoch #0 train_iter #118 : train loss is 2.392199993133545\n",
      "epoch #0 train_iter #119 : train loss is 2.418933391571045\n",
      "epoch #0 train_iter #120 : train loss is 2.4155430793762207\n",
      "epoch #0 train_iter #121 : train loss is 2.355247974395752\n",
      "epoch #0 train_iter #122 : train loss is 2.393902540206909\n",
      "epoch #0 train_iter #123 : train loss is 2.398979425430298\n",
      "epoch #0 train_iter #124 : train loss is 2.351828098297119\n",
      "epoch #0 train_iter #125 : train loss is 2.4119012355804443\n",
      "epoch #0 train_iter #126 : train loss is 2.3685994148254395\n",
      "epoch #0 train_iter #127 : train loss is 2.301664352416992\n",
      "epoch #0 train_iter #128 : train loss is 2.3006348609924316\n",
      "epoch #0 train_iter #129 : train loss is 2.3073787689208984\n",
      "epoch #0 train_iter #130 : train loss is 2.3084137439727783\n",
      "epoch #0 train_iter #131 : train loss is 2.331864356994629\n",
      "epoch #0 train_iter #132 : train loss is 2.2986481189727783\n",
      "epoch #0 train_iter #133 : train loss is 2.37675404548645\n",
      "epoch #0 train_iter #134 : train loss is 2.4273271560668945\n",
      "epoch #0 train_iter #135 : train loss is 2.3515050411224365\n",
      "epoch #0 train_iter #136 : train loss is 2.4027786254882812\n",
      "epoch #0 train_iter #137 : train loss is 2.3429365158081055\n",
      "epoch #0 train_iter #138 : train loss is 2.313610076904297\n",
      "epoch #0 train_iter #139 : train loss is 2.383878707885742\n",
      "epoch #0 train_iter #140 : train loss is 2.4006030559539795\n",
      "epoch #0 train_iter #141 : train loss is 2.2984983921051025\n",
      "epoch #0 train_iter #142 : train loss is 2.3651130199432373\n",
      "epoch #0 train_iter #143 : train loss is 2.291332721710205\n",
      "epoch #0 train_iter #144 : train loss is 2.3798983097076416\n",
      "epoch #0 train_iter #145 : train loss is 2.3388261795043945\n"
     ]
    }
   ],
   "source": [
    "! python train_vae.py --gpu_ids '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -m torch.distributed.launch --nproc_per_node=4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/6007383/shimash/model_zoo/CelebAMask-HQ/MaskGAN_demo\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "------------ Options -------------\n",
      "aspect_ratio: 1.0\n",
      "batchSize: 1\n",
      "checkpoints_dir: ./checkpoints\n",
      "cluster_path: features_clustered_010.npy\n",
      "data_type: 32\n",
      "display_winsize: 512\n",
      "engine: None\n",
      "export_onnx: None\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "gpu_ids: [0]\n",
      "how_many: 1000\n",
      "input_nc: 3\n",
      "isTrain: False\n",
      "label_nc: 19\n",
      "loadSize: 512\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_local_enhancers: 1\n",
      "name: label2face_512p\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "norm: instance\n",
      "ntest: inf\n",
      "onnx: None\n",
      "output_nc: 3\n",
      "path: ../../maskgan/data/cityscapes/\n",
      "phase: test\n",
      "resize_or_crop: scale_width\n",
      "results_dir: ./results/\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "use_encoded_image: False\n",
      "verbose: False\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(19, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (21): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (24): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (27): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (30): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (33): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (34): Tanh()\n",
      "  )\n",
      "  (enc_style): StyleEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_middle): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_last): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Conv2d(64, 16384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sft1): SFTLayer(\n",
      "      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_scale_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sft2): SFTLayer(\n",
      "      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_scale_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (enc_label): LabelEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(19, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_last): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (3): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "latest_net_G.pth\n",
      "qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, wayland-egl, wayland, wayland-xcomposite-egl, wayland-xcomposite-glx, webgl, xcb.\n",
      "\n",
      "Fatal Python error: Aborted\n",
      "\n",
      "Current thread 0x00002b43401f2f00 (most recent call first):\n",
      "  File \"demo.py\", line 246 in <module>\n"
     ]
    }
   ],
   "source": [
    "! python demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "------------ Options -------------\n",
      "batchSize: 2\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ../../maskgan/data/cityscapes/\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "gpu_ids: [0]\n",
      "input_nc: 1\n",
      "isTrain: True\n",
      "label_nc: 19\n",
      "lambda_feat: 10.0\n",
      "loadSize: 512\n",
      "load_features: False\n",
      "load_pretrain: ./checkpoints/label2face_512p\n",
      "lr: 5e-05\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: label2face_512p\n",
      "ndf: 64\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_ganFeat_loss: False\n",
      "no_html: False\n",
      "no_instance: False\n",
      "no_lsgan: False\n",
      "no_vgg_loss: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 16\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: True\n",
      "use_dropout: False\n",
      "verbose: False\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "CustomDatasetDataLoader\n",
      "dataset [CityscapesDataset] was created\n",
      "#training images = 2975\n",
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(19, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): AdaptiveInstanceNorm2d(1024)\n",
      "          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (21): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (24): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (27): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (30): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (33): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (34): Tanh()\n",
      "  )\n",
      "  (enc_style): StyleEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_middle): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_last): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Conv2d(64, 16384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sft1): SFTLayer(\n",
      "      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_scale_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sft2): SFTLayer(\n",
      "      (SFT_scale_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_scale_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (SFT_shift_conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (enc_label): LabelEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(19, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (model_last): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "      (3): ConvBlock(\n",
      "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiscaleDiscriminator(\n",
      "  (scale0_layer0): Sequential(\n",
      "    (0): Conv2d(22, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (scale1_layer0): Sequential(\n",
      "    (0): Conv2d(22, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
      ")\n",
      "BlendGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(6, 32, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (activation): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (17): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (20): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (21): ReLU(inplace=True)\n",
      "    (22): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (23): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (26): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (27): Sigmoid()\n",
      "  )\n",
      ")\n",
      "./checkpoints/label2face_512p\n",
      "latest_net_G.pth\n",
      "latest_net_B.pth\n",
      "latest_net_D.pth\n",
      "VAE(\n",
      "  (e1): Conv2d(19, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e6): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e7): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=32768, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=32768, out_features=1024, bias=True)\n",
      "  (d1): Linear(in_features=1024, out_features=32768, bias=True)\n",
      "  (up1): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd1): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d2): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn8): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up2): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd2): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d3): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn9): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up3): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd3): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn10): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up4): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd4): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn11): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up5): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd5): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn12): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up6): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd6): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d7): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn13): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up7): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd7): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d8): Conv2d(32, 19, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "VAE(\n",
      "  (e1): Conv2d(19, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e6): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (e7): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (bn7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=32768, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=32768, out_features=1024, bias=True)\n",
      "  (d1): Linear(in_features=1024, out_features=32768, bias=True)\n",
      "  (up1): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd1): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d2): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn8): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up2): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd2): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d3): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn9): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up3): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd3): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn10): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up4): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd4): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn11): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up5): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd5): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn12): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up6): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd6): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d7): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn13): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up7): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
      "  (pd7): ReplicationPad2d((1, 1, 1, 1))\n",
      "  (d8): Conv2d(32, 19, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Total number of parameters: 170619571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_idx:  124 index:  137\n",
      "random_idx:  905 index:  2493\n",
      "random_idx:  838 index:  728\n",
      "random_idx:  2717 index:  2901\n",
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n",
      "random_idx:  1931 index:  159\n",
      "tensor([[[[38, 45, 28],\n",
      "          [39, 46, 30],\n",
      "          [40, 47, 31],\n",
      "          ...,\n",
      "          [ 0,  0,  0],\n",
      "          [ 0,  0,  0],\n",
      "          [ 0,  0,  0]],\n",
      "\n",
      "         [[32, 46, 20],\n",
      "          [34, 47, 23],\n",
      "          [35, 48, 25],\n",
      "          ...,\n",
      "          [ 0,  0,  0],\n",
      "          [ 0,  0,  0],\n",
      "          [ 0,  0,  0]],\n",
      "\n",
      "         [[40, 52, 30],\n",
      "          [40, 52, 31],\n",
      "          [41, 53, 33],\n",
      "          ...,\n",
      "          [ 0,  0,  0],\n",
      "          [ 0,  0,  0],\n",
      "          [ 0,  0,  0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[53, 63, 52],\n",
      "          [53, 63, 50],\n",
      "          [52, 62, 49],\n",
      "          ...,\n",
      "          [47, 55, 45],\n",
      "          [47, 54, 44],\n",
      "          [46, 54, 44]],\n",
      "\n",
      "         [[53, 63, 51],\n",
      "          [53, 63, 50],\n",
      "          [52, 62, 49],\n",
      "          ...,\n",
      "          [49, 56, 46],\n",
      "          [49, 56, 46],\n",
      "          [49, 56, 46]],\n",
      "\n",
      "         [[53, 63, 51],\n",
      "          [53, 63, 50],\n",
      "          [52, 62, 49],\n",
      "          ...,\n",
      "          [47, 54, 45],\n",
      "          [47, 54, 45],\n",
      "          [47, 54, 44]]],\n",
      "\n",
      "\n",
      "        [[[25, 24, 22],\n",
      "          [23, 24, 21],\n",
      "          [22, 24, 22],\n",
      "          ...,\n",
      "          [59, 65, 49],\n",
      "          [57, 63, 47],\n",
      "          [56, 62, 45]],\n",
      "\n",
      "         [[24, 24, 21],\n",
      "          [22, 24, 21],\n",
      "          [21, 23, 21],\n",
      "          ...,\n",
      "          [59, 65, 49],\n",
      "          [56, 63, 47],\n",
      "          [54, 61, 45]],\n",
      "\n",
      "         [[23, 23, 20],\n",
      "          [22, 23, 19],\n",
      "          [21, 23, 19],\n",
      "          ...,\n",
      "          [59, 65, 50],\n",
      "          [56, 63, 49],\n",
      "          [55, 63, 48]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[33, 45, 38],\n",
      "          [33, 45, 39],\n",
      "          [35, 45, 39],\n",
      "          ...,\n",
      "          [44, 55, 48],\n",
      "          [44, 55, 48],\n",
      "          [44, 55, 48]],\n",
      "\n",
      "         [[33, 45, 38],\n",
      "          [33, 45, 39],\n",
      "          [35, 45, 39],\n",
      "          ...,\n",
      "          [41, 54, 47],\n",
      "          [41, 54, 47],\n",
      "          [42, 54, 47]],\n",
      "\n",
      "         [[33, 45, 38],\n",
      "          [33, 45, 39],\n",
      "          [35, 45, 39],\n",
      "          ...,\n",
      "          [43, 56, 47],\n",
      "          [43, 56, 48],\n",
      "          [43, 57, 48]]]], dtype=torch.uint8) tensor([[[3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         ...,\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3]],\n",
      "\n",
      "        [[3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         ...,\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3]]], dtype=torch.int32) tensor([[[[ 80,  97,  69],\n",
      "          [ 77,  95,  66],\n",
      "          [ 74,  92,  63],\n",
      "          ...,\n",
      "          [174, 197, 187],\n",
      "          [181, 203, 192],\n",
      "          [175, 209, 198]],\n",
      "\n",
      "         [[ 81,  95,  72],\n",
      "          [ 79,  93,  69],\n",
      "          [ 77,  92,  67],\n",
      "          ...,\n",
      "          [172, 196, 186],\n",
      "          [180, 201, 190],\n",
      "          [173, 207, 196]],\n",
      "\n",
      "         [[ 69,  84,  37],\n",
      "          [ 67,  83,  38],\n",
      "          [ 65,  82,  39],\n",
      "          ...,\n",
      "          [171, 194, 184],\n",
      "          [178, 199, 188],\n",
      "          [172, 206, 193]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[114, 131, 120],\n",
      "          [114, 129, 120],\n",
      "          [113, 127, 118],\n",
      "          ...,\n",
      "          [ 43,  55,  52],\n",
      "          [ 41,  52,  51],\n",
      "          [ 38,  50,  49]],\n",
      "\n",
      "         [[114, 131, 120],\n",
      "          [114, 129, 120],\n",
      "          [113, 127, 118],\n",
      "          ...,\n",
      "          [ 46,  59,  57],\n",
      "          [ 44,  57,  55],\n",
      "          [ 42,  54,  53]],\n",
      "\n",
      "         [[114, 131, 120],\n",
      "          [114, 129, 120],\n",
      "          [113, 127, 118],\n",
      "          ...,\n",
      "          [ 45,  59,  58],\n",
      "          [ 43,  57,  57],\n",
      "          [ 41,  55,  55]]],\n",
      "\n",
      "\n",
      "        [[[ 49,  74,  46],\n",
      "          [ 46,  72,  45],\n",
      "          [ 45,  70,  45],\n",
      "          ...,\n",
      "          [ 13,  18,  11],\n",
      "          [ 13,  18,  11],\n",
      "          [ 12,  17,  11]],\n",
      "\n",
      "         [[ 47,  72,  44],\n",
      "          [ 45,  70,  43],\n",
      "          [ 45,  70,  43],\n",
      "          ...,\n",
      "          [ 14,  18,  12],\n",
      "          [ 14,  18,  12],\n",
      "          [ 13,  18,  12]],\n",
      "\n",
      "         [[ 43,  68,  41],\n",
      "          [ 43,  68,  40],\n",
      "          [ 43,  68,  40],\n",
      "          ...,\n",
      "          [ 13,  18,  12],\n",
      "          [ 13,  18,  12],\n",
      "          [ 12,  16,  12]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[114, 135,  98],\n",
      "          [113, 134,  97],\n",
      "          [108, 130, 100],\n",
      "          ...,\n",
      "          [ 25,  34,  30],\n",
      "          [ 25,  34,  29],\n",
      "          [ 25,  34,  30]],\n",
      "\n",
      "         [[114, 135,  98],\n",
      "          [113, 134,  97],\n",
      "          [108, 130, 100],\n",
      "          ...,\n",
      "          [ 25,  34,  30],\n",
      "          [ 25,  34,  30],\n",
      "          [ 26,  35,  32]],\n",
      "\n",
      "         [[114, 135,  98],\n",
      "          [113, 134,  97],\n",
      "          [108, 130, 100],\n",
      "          ...,\n",
      "          [ 24,  34,  30],\n",
      "          [ 24,  33,  29],\n",
      "          [ 25,  34,  30]]]], dtype=torch.uint8) tensor([[[3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         ...,\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3]],\n",
      "\n",
      "        [[3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         ...,\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3]]], dtype=torch.int32)\n",
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n",
      "random_idx:  944 index:  1743\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 88, in <module>\n",
      "    losses, generated = model(inter_label_1, inter_label_2, image = image, label = label, label_ref = label_ref,image_ref = image_ref, infer=save_fake)\n",
      "NameError: name 'inter_label_1' is not defined\n"
     ]
    }
   ],
   "source": [
    "! python train.py --tf_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/6007383/shimash/model_zoo/CelebAMask-HQ/MaskGAN_demo\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "------------ Options -------------\n",
      "batchSize: 8\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ../../maskgan/data/cityscapes/\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "gpu_ids: [0]\n",
      "input_nc: 1\n",
      "isTrain: True\n",
      "label_nc: 34\n",
      "lambda_feat: 10.0\n",
      "loadSize: 512\n",
      "load_features: False\n",
      "load_pretrain: ./checkpoints/label2face_512p\n",
      "local_rank: 0\n",
      "lr: 5e-05\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 4\n",
      "n_blocks_local: 3\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: label2face_512p\n",
      "ndf: 64\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_ganFeat_loss: False\n",
      "no_html: False\n",
      "no_instance: False\n",
      "no_lsgan: False\n",
      "no_vgg_loss: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 16\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "verbose: False\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "opt.distributed:  False\n",
      "Number of parameters: 170631586\n",
      "Training ...\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.21575\n",
      "kldivergence:   6531.16\n",
      "variational_beta * kldivergence:  0.65312\n",
      "batch accuracy: 92.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.23485\n",
      "kldivergence:   5965.13\n",
      "variational_beta * kldivergence:  0.59651\n",
      "batch accuracy: 91.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.24902\n",
      "kldivergence:   5394.84\n",
      "variational_beta * kldivergence:  0.53948\n",
      "batch accuracy: 91.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.16816\n",
      "kldivergence:   4622.94\n",
      "variational_beta * kldivergence:  0.46229\n",
      "batch accuracy: 94.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.20814\n",
      "kldivergence:   4042.07\n",
      "variational_beta * kldivergence:  0.40421\n",
      "batch accuracy: 92.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.20492\n",
      "kldivergence:   3818.05\n",
      "variational_beta * kldivergence:  0.38180\n",
      "batch accuracy: 92.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.25816\n",
      "kldivergence:   3718.77\n",
      "variational_beta * kldivergence:  0.37188\n",
      "batch accuracy: 91.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.26819\n",
      "kldivergence:   3644.03\n",
      "variational_beta * kldivergence:  0.36440\n",
      "batch accuracy: 91.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.26720\n",
      "kldivergence:   3289.78\n",
      "variational_beta * kldivergence:  0.32898\n",
      "batch accuracy: 90.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.26687\n",
      "kldivergence:   2941.93\n",
      "variational_beta * kldivergence:  0.29419\n",
      "batch accuracy: 90.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28046\n",
      "kldivergence:   2840.29\n",
      "variational_beta * kldivergence:  0.28403\n",
      "batch accuracy: 90.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32728\n",
      "kldivergence:   3369.81\n",
      "variational_beta * kldivergence:  0.33698\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.25726\n",
      "kldivergence:   2713.77\n",
      "variational_beta * kldivergence:  0.27138\n",
      "batch accuracy: 91.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29841\n",
      "kldivergence:   2414.16\n",
      "variational_beta * kldivergence:  0.24142\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30014\n",
      "kldivergence:   2624.60\n",
      "variational_beta * kldivergence:  0.26246\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32331\n",
      "kldivergence:   2499.40\n",
      "variational_beta * kldivergence:  0.24994\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32453\n",
      "kldivergence:   2398.86\n",
      "variational_beta * kldivergence:  0.23989\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33888\n",
      "kldivergence:   2563.93\n",
      "variational_beta * kldivergence:  0.25639\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31936\n",
      "kldivergence:   2277.72\n",
      "variational_beta * kldivergence:  0.22777\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31385\n",
      "kldivergence:   2590.80\n",
      "variational_beta * kldivergence:  0.25908\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29299\n",
      "kldivergence:   2547.50\n",
      "variational_beta * kldivergence:  0.25475\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33675\n",
      "kldivergence:   2586.72\n",
      "variational_beta * kldivergence:  0.25867\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.40045\n",
      "kldivergence:   2463.70\n",
      "variational_beta * kldivergence:  0.24637\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.27682\n",
      "kldivergence:   2646.31\n",
      "variational_beta * kldivergence:  0.26463\n",
      "batch accuracy: 90.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30613\n",
      "kldivergence:   3042.64\n",
      "variational_beta * kldivergence:  0.30426\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29174\n",
      "kldivergence:   2324.90\n",
      "variational_beta * kldivergence:  0.23249\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33262\n",
      "kldivergence:   2502.09\n",
      "variational_beta * kldivergence:  0.25021\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37226\n",
      "kldivergence:   2495.66\n",
      "variational_beta * kldivergence:  0.24957\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.25909\n",
      "kldivergence:   2308.92\n",
      "variational_beta * kldivergence:  0.23089\n",
      "batch accuracy: 91.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33609\n",
      "kldivergence:   2534.36\n",
      "variational_beta * kldivergence:  0.25344\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30550\n",
      "kldivergence:   2721.68\n",
      "variational_beta * kldivergence:  0.27217\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30664\n",
      "kldivergence:   2588.39\n",
      "variational_beta * kldivergence:  0.25884\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28164\n",
      "kldivergence:   2562.27\n",
      "variational_beta * kldivergence:  0.25623\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31771\n",
      "kldivergence:   2539.66\n",
      "variational_beta * kldivergence:  0.25397\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29867\n",
      "kldivergence:   2380.05\n",
      "variational_beta * kldivergence:  0.23801\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28945\n",
      "kldivergence:   2594.01\n",
      "variational_beta * kldivergence:  0.25940\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29534\n",
      "kldivergence:   2302.70\n",
      "variational_beta * kldivergence:  0.23027\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28505\n",
      "kldivergence:   2277.08\n",
      "variational_beta * kldivergence:  0.22771\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29519\n",
      "kldivergence:   2028.79\n",
      "variational_beta * kldivergence:  0.20288\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31623\n",
      "kldivergence:   2265.58\n",
      "variational_beta * kldivergence:  0.22656\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33014\n",
      "kldivergence:   2190.19\n",
      "variational_beta * kldivergence:  0.21902\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30680\n",
      "kldivergence:   2502.16\n",
      "variational_beta * kldivergence:  0.25022\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35369\n",
      "kldivergence:   2743.83\n",
      "variational_beta * kldivergence:  0.27438\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30454\n",
      "kldivergence:   2791.63\n",
      "variational_beta * kldivergence:  0.27916\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36298\n",
      "kldivergence:   2330.54\n",
      "variational_beta * kldivergence:  0.23305\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30622\n",
      "kldivergence:   2493.04\n",
      "variational_beta * kldivergence:  0.24930\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33587\n",
      "kldivergence:   2621.57\n",
      "variational_beta * kldivergence:  0.26216\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34150\n",
      "kldivergence:   2242.78\n",
      "variational_beta * kldivergence:  0.22428\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31295\n",
      "kldivergence:   2387.55\n",
      "variational_beta * kldivergence:  0.23875\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30467\n",
      "kldivergence:   2227.81\n",
      "variational_beta * kldivergence:  0.22278\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32532\n",
      "kldivergence:   2331.87\n",
      "variational_beta * kldivergence:  0.23319\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34226\n",
      "kldivergence:   2256.19\n",
      "variational_beta * kldivergence:  0.22562\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29547\n",
      "kldivergence:   2129.86\n",
      "variational_beta * kldivergence:  0.21299\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32201\n",
      "kldivergence:   2305.40\n",
      "variational_beta * kldivergence:  0.23054\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33777\n",
      "kldivergence:   2109.02\n",
      "variational_beta * kldivergence:  0.21090\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31696\n",
      "kldivergence:   2027.56\n",
      "variational_beta * kldivergence:  0.20276\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30685\n",
      "kldivergence:   1978.36\n",
      "variational_beta * kldivergence:  0.19784\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35560\n",
      "kldivergence:   2080.91\n",
      "variational_beta * kldivergence:  0.20809\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30975\n",
      "kldivergence:   1998.25\n",
      "variational_beta * kldivergence:  0.19983\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35357\n",
      "kldivergence:   2244.14\n",
      "variational_beta * kldivergence:  0.22441\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34028\n",
      "kldivergence:   2185.02\n",
      "variational_beta * kldivergence:  0.21850\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33645\n",
      "kldivergence:   2357.58\n",
      "variational_beta * kldivergence:  0.23576\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34928\n",
      "kldivergence:   2182.52\n",
      "variational_beta * kldivergence:  0.21825\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29637\n",
      "kldivergence:   2085.64\n",
      "variational_beta * kldivergence:  0.20856\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29461\n",
      "kldivergence:   1988.06\n",
      "variational_beta * kldivergence:  0.19881\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33664\n",
      "kldivergence:   2212.30\n",
      "variational_beta * kldivergence:  0.22123\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32526\n",
      "kldivergence:   2158.65\n",
      "variational_beta * kldivergence:  0.21587\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35106\n",
      "kldivergence:   2059.11\n",
      "variational_beta * kldivergence:  0.20591\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33958\n",
      "kldivergence:   2231.16\n",
      "variational_beta * kldivergence:  0.22312\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.40846\n",
      "kldivergence:   2062.77\n",
      "variational_beta * kldivergence:  0.20628\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35505\n",
      "kldivergence:   2333.90\n",
      "variational_beta * kldivergence:  0.23339\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30750\n",
      "kldivergence:   2226.57\n",
      "variational_beta * kldivergence:  0.22266\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34333\n",
      "kldivergence:   2216.14\n",
      "variational_beta * kldivergence:  0.22161\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36281\n",
      "kldivergence:   2627.19\n",
      "variational_beta * kldivergence:  0.26272\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29424\n",
      "kldivergence:   2029.75\n",
      "variational_beta * kldivergence:  0.20298\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34052\n",
      "kldivergence:   2314.37\n",
      "variational_beta * kldivergence:  0.23144\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32889\n",
      "kldivergence:   2157.96\n",
      "variational_beta * kldivergence:  0.21580\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29426\n",
      "kldivergence:   2023.71\n",
      "variational_beta * kldivergence:  0.20237\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32983\n",
      "kldivergence:   2300.98\n",
      "variational_beta * kldivergence:  0.23010\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34148\n",
      "kldivergence:   2232.69\n",
      "variational_beta * kldivergence:  0.22327\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30119\n",
      "kldivergence:   1935.36\n",
      "variational_beta * kldivergence:  0.19354\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28657\n",
      "kldivergence:   2152.79\n",
      "variational_beta * kldivergence:  0.21528\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37509\n",
      "kldivergence:   2242.97\n",
      "variational_beta * kldivergence:  0.22430\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32735\n",
      "kldivergence:   1899.85\n",
      "variational_beta * kldivergence:  0.18998\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30494\n",
      "kldivergence:   1876.85\n",
      "variational_beta * kldivergence:  0.18768\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.38445\n",
      "kldivergence:   2294.36\n",
      "variational_beta * kldivergence:  0.22944\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36768\n",
      "kldivergence:   2359.23\n",
      "variational_beta * kldivergence:  0.23592\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32282\n",
      "kldivergence:   2384.15\n",
      "variational_beta * kldivergence:  0.23841\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31154\n",
      "kldivergence:   1932.22\n",
      "variational_beta * kldivergence:  0.19322\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28379\n",
      "kldivergence:   1889.63\n",
      "variational_beta * kldivergence:  0.18896\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31685\n",
      "kldivergence:   1966.53\n",
      "variational_beta * kldivergence:  0.19665\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35265\n",
      "kldivergence:   2161.76\n",
      "variational_beta * kldivergence:  0.21618\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29751\n",
      "kldivergence:   2151.50\n",
      "variational_beta * kldivergence:  0.21515\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32586\n",
      "kldivergence:   2047.21\n",
      "variational_beta * kldivergence:  0.20472\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31851\n",
      "kldivergence:   2241.78\n",
      "variational_beta * kldivergence:  0.22418\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.26418\n",
      "kldivergence:   2148.78\n",
      "variational_beta * kldivergence:  0.21488\n",
      "batch accuracy: 90.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33296\n",
      "kldivergence:   2171.49\n",
      "variational_beta * kldivergence:  0.21715\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31233\n",
      "kldivergence:   2231.94\n",
      "variational_beta * kldivergence:  0.22319\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31490\n",
      "kldivergence:   2186.17\n",
      "variational_beta * kldivergence:  0.21862\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35501\n",
      "kldivergence:   2157.24\n",
      "variational_beta * kldivergence:  0.21572\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35061\n",
      "kldivergence:   2270.19\n",
      "variational_beta * kldivergence:  0.22702\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36743\n",
      "kldivergence:   2283.13\n",
      "variational_beta * kldivergence:  0.22831\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31867\n",
      "kldivergence:   2045.41\n",
      "variational_beta * kldivergence:  0.20454\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31370\n",
      "kldivergence:   2024.01\n",
      "variational_beta * kldivergence:  0.20240\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34305\n",
      "kldivergence:   2128.72\n",
      "variational_beta * kldivergence:  0.21287\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33209\n",
      "kldivergence:   1975.45\n",
      "variational_beta * kldivergence:  0.19755\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33637\n",
      "kldivergence:   2482.09\n",
      "variational_beta * kldivergence:  0.24821\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33267\n",
      "kldivergence:   2051.39\n",
      "variational_beta * kldivergence:  0.20514\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31917\n",
      "kldivergence:   1925.01\n",
      "variational_beta * kldivergence:  0.19250\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29788\n",
      "kldivergence:   2068.57\n",
      "variational_beta * kldivergence:  0.20686\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33589\n",
      "kldivergence:   2007.16\n",
      "variational_beta * kldivergence:  0.20072\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31204\n",
      "kldivergence:   1953.54\n",
      "variational_beta * kldivergence:  0.19535\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31939\n",
      "kldivergence:   1823.01\n",
      "variational_beta * kldivergence:  0.18230\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36104\n",
      "kldivergence:   2207.42\n",
      "variational_beta * kldivergence:  0.22074\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30815\n",
      "kldivergence:   2194.74\n",
      "variational_beta * kldivergence:  0.21947\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29561\n",
      "kldivergence:   2005.80\n",
      "variational_beta * kldivergence:  0.20058\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37911\n",
      "kldivergence:   2172.98\n",
      "variational_beta * kldivergence:  0.21730\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36861\n",
      "kldivergence:   2000.02\n",
      "variational_beta * kldivergence:  0.20000\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36314\n",
      "kldivergence:   2031.31\n",
      "variational_beta * kldivergence:  0.20313\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36161\n",
      "kldivergence:   1726.19\n",
      "variational_beta * kldivergence:  0.17262\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33555\n",
      "kldivergence:   1863.99\n",
      "variational_beta * kldivergence:  0.18640\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33884\n",
      "kldivergence:   1939.60\n",
      "variational_beta * kldivergence:  0.19396\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31226\n",
      "kldivergence:   2082.85\n",
      "variational_beta * kldivergence:  0.20829\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32625\n",
      "kldivergence:   2058.48\n",
      "variational_beta * kldivergence:  0.20585\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32704\n",
      "kldivergence:   2018.32\n",
      "variational_beta * kldivergence:  0.20183\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31302\n",
      "kldivergence:   2246.57\n",
      "variational_beta * kldivergence:  0.22466\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31921\n",
      "kldivergence:   1772.42\n",
      "variational_beta * kldivergence:  0.17724\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28184\n",
      "kldivergence:   2100.23\n",
      "variational_beta * kldivergence:  0.21002\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28089\n",
      "kldivergence:   1703.47\n",
      "variational_beta * kldivergence:  0.17035\n",
      "batch accuracy: 90.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30090\n",
      "kldivergence:   2093.46\n",
      "variational_beta * kldivergence:  0.20935\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35116\n",
      "kldivergence:   1994.98\n",
      "variational_beta * kldivergence:  0.19950\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32522\n",
      "kldivergence:   2205.40\n",
      "variational_beta * kldivergence:  0.22054\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32291\n",
      "kldivergence:   2070.33\n",
      "variational_beta * kldivergence:  0.20703\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37997\n",
      "kldivergence:   1960.11\n",
      "variational_beta * kldivergence:  0.19601\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33873\n",
      "kldivergence:   2082.52\n",
      "variational_beta * kldivergence:  0.20825\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37736\n",
      "kldivergence:   1809.01\n",
      "variational_beta * kldivergence:  0.18090\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32309\n",
      "kldivergence:   1928.80\n",
      "variational_beta * kldivergence:  0.19288\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.27687\n",
      "kldivergence:   1808.95\n",
      "variational_beta * kldivergence:  0.18090\n",
      "batch accuracy: 90.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35253\n",
      "kldivergence:   1944.40\n",
      "variational_beta * kldivergence:  0.19444\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34017\n",
      "kldivergence:   1892.33\n",
      "variational_beta * kldivergence:  0.18923\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37158\n",
      "kldivergence:   1949.33\n",
      "variational_beta * kldivergence:  0.19493\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34155\n",
      "kldivergence:   2201.00\n",
      "variational_beta * kldivergence:  0.22010\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34322\n",
      "kldivergence:   1949.64\n",
      "variational_beta * kldivergence:  0.19496\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30454\n",
      "kldivergence:   1841.70\n",
      "variational_beta * kldivergence:  0.18417\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33594\n",
      "kldivergence:   2196.25\n",
      "variational_beta * kldivergence:  0.21962\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33693\n",
      "kldivergence:   2222.04\n",
      "variational_beta * kldivergence:  0.22220\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34917\n",
      "kldivergence:   2126.95\n",
      "variational_beta * kldivergence:  0.21269\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32731\n",
      "kldivergence:   2018.60\n",
      "variational_beta * kldivergence:  0.20186\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32622\n",
      "kldivergence:   2131.45\n",
      "variational_beta * kldivergence:  0.21314\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.39488\n",
      "kldivergence:   2057.69\n",
      "variational_beta * kldivergence:  0.20577\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31510\n",
      "kldivergence:   1869.72\n",
      "variational_beta * kldivergence:  0.18697\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37408\n",
      "kldivergence:   2376.02\n",
      "variational_beta * kldivergence:  0.23760\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33992\n",
      "kldivergence:   2423.72\n",
      "variational_beta * kldivergence:  0.24237\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32274\n",
      "kldivergence:   2054.92\n",
      "variational_beta * kldivergence:  0.20549\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32994\n",
      "kldivergence:   2145.42\n",
      "variational_beta * kldivergence:  0.21454\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32107\n",
      "kldivergence:   2062.82\n",
      "variational_beta * kldivergence:  0.20628\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.27607\n",
      "kldivergence:   1988.22\n",
      "variational_beta * kldivergence:  0.19882\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34661\n",
      "kldivergence:   2128.81\n",
      "variational_beta * kldivergence:  0.21288\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34066\n",
      "kldivergence:   2142.65\n",
      "variational_beta * kldivergence:  0.21426\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34271\n",
      "kldivergence:   2084.85\n",
      "variational_beta * kldivergence:  0.20849\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34232\n",
      "kldivergence:   1980.56\n",
      "variational_beta * kldivergence:  0.19806\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33070\n",
      "kldivergence:   1828.33\n",
      "variational_beta * kldivergence:  0.18283\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33483\n",
      "kldivergence:   1988.42\n",
      "variational_beta * kldivergence:  0.19884\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30165\n",
      "kldivergence:   1980.88\n",
      "variational_beta * kldivergence:  0.19809\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.26495\n",
      "kldivergence:   1935.02\n",
      "variational_beta * kldivergence:  0.19350\n",
      "batch accuracy: 90.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34082\n",
      "kldivergence:   2578.24\n",
      "variational_beta * kldivergence:  0.25782\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32331\n",
      "kldivergence:   2125.83\n",
      "variational_beta * kldivergence:  0.21258\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37281\n",
      "kldivergence:   2034.92\n",
      "variational_beta * kldivergence:  0.20349\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32419\n",
      "kldivergence:   1998.90\n",
      "variational_beta * kldivergence:  0.19989\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32847\n",
      "kldivergence:   2197.53\n",
      "variational_beta * kldivergence:  0.21975\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.41236\n",
      "kldivergence:   2331.45\n",
      "variational_beta * kldivergence:  0.23314\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.43804\n",
      "kldivergence:   2131.53\n",
      "variational_beta * kldivergence:  0.21315\n",
      "batch accuracy: 85.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32839\n",
      "kldivergence:   1832.00\n",
      "variational_beta * kldivergence:  0.18320\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37374\n",
      "kldivergence:   2227.25\n",
      "variational_beta * kldivergence:  0.22272\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.38656\n",
      "kldivergence:   2058.74\n",
      "variational_beta * kldivergence:  0.20587\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37811\n",
      "kldivergence:   2247.37\n",
      "variational_beta * kldivergence:  0.22474\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31745\n",
      "kldivergence:   2039.02\n",
      "variational_beta * kldivergence:  0.20390\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29244\n",
      "kldivergence:   2171.29\n",
      "variational_beta * kldivergence:  0.21713\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34919\n",
      "kldivergence:   2032.07\n",
      "variational_beta * kldivergence:  0.20321\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.39138\n",
      "kldivergence:   2148.92\n",
      "variational_beta * kldivergence:  0.21489\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35047\n",
      "kldivergence:   1992.75\n",
      "variational_beta * kldivergence:  0.19927\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30547\n",
      "kldivergence:   1772.49\n",
      "variational_beta * kldivergence:  0.17725\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32129\n",
      "kldivergence:   2040.82\n",
      "variational_beta * kldivergence:  0.20408\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33427\n",
      "kldivergence:   1783.70\n",
      "variational_beta * kldivergence:  0.17837\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36603\n",
      "kldivergence:   1911.66\n",
      "variational_beta * kldivergence:  0.19117\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36346\n",
      "kldivergence:   2043.61\n",
      "variational_beta * kldivergence:  0.20436\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33100\n",
      "kldivergence:   2143.39\n",
      "variational_beta * kldivergence:  0.21434\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31091\n",
      "kldivergence:   1878.40\n",
      "variational_beta * kldivergence:  0.18784\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31992\n",
      "kldivergence:   1936.13\n",
      "variational_beta * kldivergence:  0.19361\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33071\n",
      "kldivergence:   1812.73\n",
      "variational_beta * kldivergence:  0.18127\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29384\n",
      "kldivergence:   2038.77\n",
      "variational_beta * kldivergence:  0.20388\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30354\n",
      "kldivergence:   1925.85\n",
      "variational_beta * kldivergence:  0.19258\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.40262\n",
      "kldivergence:   2337.99\n",
      "variational_beta * kldivergence:  0.23380\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35569\n",
      "kldivergence:   2006.48\n",
      "variational_beta * kldivergence:  0.20065\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36754\n",
      "kldivergence:   1954.55\n",
      "variational_beta * kldivergence:  0.19546\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33422\n",
      "kldivergence:   1907.78\n",
      "variational_beta * kldivergence:  0.19078\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34904\n",
      "kldivergence:   2160.03\n",
      "variational_beta * kldivergence:  0.21600\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34306\n",
      "kldivergence:   1724.86\n",
      "variational_beta * kldivergence:  0.17249\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37693\n",
      "kldivergence:   2153.48\n",
      "variational_beta * kldivergence:  0.21535\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33579\n",
      "kldivergence:   1991.83\n",
      "variational_beta * kldivergence:  0.19918\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28696\n",
      "kldivergence:   2030.68\n",
      "variational_beta * kldivergence:  0.20307\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31148\n",
      "kldivergence:   1843.91\n",
      "variational_beta * kldivergence:  0.18439\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33847\n",
      "kldivergence:   1719.23\n",
      "variational_beta * kldivergence:  0.17192\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.25665\n",
      "kldivergence:   1700.13\n",
      "variational_beta * kldivergence:  0.17001\n",
      "batch accuracy: 91.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35436\n",
      "kldivergence:   2034.32\n",
      "variational_beta * kldivergence:  0.20343\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29652\n",
      "kldivergence:   1795.11\n",
      "variational_beta * kldivergence:  0.17951\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36821\n",
      "kldivergence:   1944.83\n",
      "variational_beta * kldivergence:  0.19448\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30433\n",
      "kldivergence:   2020.30\n",
      "variational_beta * kldivergence:  0.20203\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32505\n",
      "kldivergence:   2112.46\n",
      "variational_beta * kldivergence:  0.21125\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32066\n",
      "kldivergence:   2100.26\n",
      "variational_beta * kldivergence:  0.21003\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.38430\n",
      "kldivergence:   1887.63\n",
      "variational_beta * kldivergence:  0.18876\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32602\n",
      "kldivergence:   1997.81\n",
      "variational_beta * kldivergence:  0.19978\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36727\n",
      "kldivergence:   1926.92\n",
      "variational_beta * kldivergence:  0.19269\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32527\n",
      "kldivergence:   1975.59\n",
      "variational_beta * kldivergence:  0.19756\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36542\n",
      "kldivergence:   2252.12\n",
      "variational_beta * kldivergence:  0.22521\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28193\n",
      "kldivergence:   1789.08\n",
      "variational_beta * kldivergence:  0.17891\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.25201\n",
      "kldivergence:   2377.64\n",
      "variational_beta * kldivergence:  0.23776\n",
      "batch accuracy: 91.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33770\n",
      "kldivergence:   2267.01\n",
      "variational_beta * kldivergence:  0.22670\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33949\n",
      "kldivergence:   2229.23\n",
      "variational_beta * kldivergence:  0.22292\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34414\n",
      "kldivergence:   2105.89\n",
      "variational_beta * kldivergence:  0.21059\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36940\n",
      "kldivergence:   2118.67\n",
      "variational_beta * kldivergence:  0.21187\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32173\n",
      "kldivergence:   2148.24\n",
      "variational_beta * kldivergence:  0.21482\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34527\n",
      "kldivergence:   2116.56\n",
      "variational_beta * kldivergence:  0.21166\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30057\n",
      "kldivergence:   2274.00\n",
      "variational_beta * kldivergence:  0.22740\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32078\n",
      "kldivergence:   2054.48\n",
      "variational_beta * kldivergence:  0.20545\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29113\n",
      "kldivergence:   1880.01\n",
      "variational_beta * kldivergence:  0.18800\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31159\n",
      "kldivergence:   2124.14\n",
      "variational_beta * kldivergence:  0.21241\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30381\n",
      "kldivergence:   2148.23\n",
      "variational_beta * kldivergence:  0.21482\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.39059\n",
      "kldivergence:   2109.78\n",
      "variational_beta * kldivergence:  0.21098\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37775\n",
      "kldivergence:   1956.77\n",
      "variational_beta * kldivergence:  0.19568\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28200\n",
      "kldivergence:   1919.60\n",
      "variational_beta * kldivergence:  0.19196\n",
      "batch accuracy: 90.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30117\n",
      "kldivergence:   1841.46\n",
      "variational_beta * kldivergence:  0.18415\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33871\n",
      "kldivergence:   2126.11\n",
      "variational_beta * kldivergence:  0.21261\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32536\n",
      "kldivergence:   1928.57\n",
      "variational_beta * kldivergence:  0.19286\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33527\n",
      "kldivergence:   1883.58\n",
      "variational_beta * kldivergence:  0.18836\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33817\n",
      "kldivergence:   2056.07\n",
      "variational_beta * kldivergence:  0.20561\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34170\n",
      "kldivergence:   2074.15\n",
      "variational_beta * kldivergence:  0.20741\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34540\n",
      "kldivergence:   2217.64\n",
      "variational_beta * kldivergence:  0.22176\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31703\n",
      "kldivergence:   1903.86\n",
      "variational_beta * kldivergence:  0.19039\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28669\n",
      "kldivergence:   1840.98\n",
      "variational_beta * kldivergence:  0.18410\n",
      "batch accuracy: 90.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31153\n",
      "kldivergence:   1967.70\n",
      "variational_beta * kldivergence:  0.19677\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37291\n",
      "kldivergence:   1755.52\n",
      "variational_beta * kldivergence:  0.17555\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34968\n",
      "kldivergence:   2041.59\n",
      "variational_beta * kldivergence:  0.20416\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33830\n",
      "kldivergence:   1684.26\n",
      "variational_beta * kldivergence:  0.16843\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31718\n",
      "kldivergence:   1903.91\n",
      "variational_beta * kldivergence:  0.19039\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33400\n",
      "kldivergence:   1977.61\n",
      "variational_beta * kldivergence:  0.19776\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31783\n",
      "kldivergence:   1907.66\n",
      "variational_beta * kldivergence:  0.19077\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32960\n",
      "kldivergence:   1868.29\n",
      "variational_beta * kldivergence:  0.18683\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37476\n",
      "kldivergence:   1818.59\n",
      "variational_beta * kldivergence:  0.18186\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33061\n",
      "kldivergence:   2125.21\n",
      "variational_beta * kldivergence:  0.21252\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32260\n",
      "kldivergence:   1687.43\n",
      "variational_beta * kldivergence:  0.16874\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34821\n",
      "kldivergence:   2126.67\n",
      "variational_beta * kldivergence:  0.21267\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28136\n",
      "kldivergence:   1834.45\n",
      "variational_beta * kldivergence:  0.18344\n",
      "batch accuracy: 90.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35634\n",
      "kldivergence:   2080.77\n",
      "variational_beta * kldivergence:  0.20808\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29271\n",
      "kldivergence:   1850.46\n",
      "variational_beta * kldivergence:  0.18505\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.39077\n",
      "kldivergence:   2274.80\n",
      "variational_beta * kldivergence:  0.22748\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32625\n",
      "kldivergence:   1985.38\n",
      "variational_beta * kldivergence:  0.19854\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32421\n",
      "kldivergence:   2015.93\n",
      "variational_beta * kldivergence:  0.20159\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30832\n",
      "kldivergence:   1839.68\n",
      "variational_beta * kldivergence:  0.18397\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34095\n",
      "kldivergence:   2054.18\n",
      "variational_beta * kldivergence:  0.20542\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.25504\n",
      "kldivergence:   2322.64\n",
      "variational_beta * kldivergence:  0.23226\n",
      "batch accuracy: 91.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30454\n",
      "kldivergence:   2405.15\n",
      "variational_beta * kldivergence:  0.24051\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34542\n",
      "kldivergence:   2253.04\n",
      "variational_beta * kldivergence:  0.22530\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34254\n",
      "kldivergence:   1976.75\n",
      "variational_beta * kldivergence:  0.19768\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31537\n",
      "kldivergence:   1999.82\n",
      "variational_beta * kldivergence:  0.19998\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29209\n",
      "kldivergence:   1761.69\n",
      "variational_beta * kldivergence:  0.17617\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33806\n",
      "kldivergence:   1902.91\n",
      "variational_beta * kldivergence:  0.19029\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.27559\n",
      "kldivergence:   1596.94\n",
      "variational_beta * kldivergence:  0.15969\n",
      "batch accuracy: 90.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.38024\n",
      "kldivergence:   1955.58\n",
      "variational_beta * kldivergence:  0.19556\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30460\n",
      "kldivergence:   1962.31\n",
      "variational_beta * kldivergence:  0.19623\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.27508\n",
      "kldivergence:   1888.27\n",
      "variational_beta * kldivergence:  0.18883\n",
      "batch accuracy: 91.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35207\n",
      "kldivergence:   1926.09\n",
      "variational_beta * kldivergence:  0.19261\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33980\n",
      "kldivergence:   1825.24\n",
      "variational_beta * kldivergence:  0.18252\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31317\n",
      "kldivergence:   1638.47\n",
      "variational_beta * kldivergence:  0.16385\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33285\n",
      "kldivergence:   1969.94\n",
      "variational_beta * kldivergence:  0.19699\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34600\n",
      "kldivergence:   1734.16\n",
      "variational_beta * kldivergence:  0.17342\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31657\n",
      "kldivergence:   1706.87\n",
      "variational_beta * kldivergence:  0.17069\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.27458\n",
      "kldivergence:   1686.64\n",
      "variational_beta * kldivergence:  0.16866\n",
      "batch accuracy: 90.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34938\n",
      "kldivergence:   2394.40\n",
      "variational_beta * kldivergence:  0.23944\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32504\n",
      "kldivergence:   1896.86\n",
      "variational_beta * kldivergence:  0.18969\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.41286\n",
      "kldivergence:   2047.42\n",
      "variational_beta * kldivergence:  0.20474\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31404\n",
      "kldivergence:   2010.29\n",
      "variational_beta * kldivergence:  0.20103\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.39146\n",
      "kldivergence:   2092.20\n",
      "variational_beta * kldivergence:  0.20922\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32126\n",
      "kldivergence:   1873.79\n",
      "variational_beta * kldivergence:  0.18738\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35122\n",
      "kldivergence:   1795.47\n",
      "variational_beta * kldivergence:  0.17955\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32340\n",
      "kldivergence:   1952.70\n",
      "variational_beta * kldivergence:  0.19527\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31978\n",
      "kldivergence:   2075.22\n",
      "variational_beta * kldivergence:  0.20752\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29647\n",
      "kldivergence:   1785.62\n",
      "variational_beta * kldivergence:  0.17856\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30442\n",
      "kldivergence:   1858.81\n",
      "variational_beta * kldivergence:  0.18588\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34460\n",
      "kldivergence:   1771.54\n",
      "variational_beta * kldivergence:  0.17715\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29564\n",
      "kldivergence:   1870.83\n",
      "variational_beta * kldivergence:  0.18708\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34972\n",
      "kldivergence:   2260.55\n",
      "variational_beta * kldivergence:  0.22606\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32017\n",
      "kldivergence:   1842.63\n",
      "variational_beta * kldivergence:  0.18426\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31345\n",
      "kldivergence:   1875.66\n",
      "variational_beta * kldivergence:  0.18757\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.39706\n",
      "kldivergence:   2330.17\n",
      "variational_beta * kldivergence:  0.23302\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29350\n",
      "kldivergence:   1655.52\n",
      "variational_beta * kldivergence:  0.16555\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.27442\n",
      "kldivergence:   1788.74\n",
      "variational_beta * kldivergence:  0.17887\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34298\n",
      "kldivergence:   1818.23\n",
      "variational_beta * kldivergence:  0.18182\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35413\n",
      "kldivergence:   1952.95\n",
      "variational_beta * kldivergence:  0.19530\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33833\n",
      "kldivergence:   2003.47\n",
      "variational_beta * kldivergence:  0.20035\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32672\n",
      "kldivergence:   1970.84\n",
      "variational_beta * kldivergence:  0.19708\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.38823\n",
      "kldivergence:   2419.79\n",
      "variational_beta * kldivergence:  0.24198\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31403\n",
      "kldivergence:   2037.02\n",
      "variational_beta * kldivergence:  0.20370\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35715\n",
      "kldivergence:   1855.55\n",
      "variational_beta * kldivergence:  0.18556\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34460\n",
      "kldivergence:   2239.68\n",
      "variational_beta * kldivergence:  0.22397\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36912\n",
      "kldivergence:   2029.52\n",
      "variational_beta * kldivergence:  0.20295\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32588\n",
      "kldivergence:   1909.21\n",
      "variational_beta * kldivergence:  0.19092\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35254\n",
      "kldivergence:   2174.47\n",
      "variational_beta * kldivergence:  0.21745\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34117\n",
      "kldivergence:   2172.69\n",
      "variational_beta * kldivergence:  0.21727\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32882\n",
      "kldivergence:   1797.83\n",
      "variational_beta * kldivergence:  0.17978\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29295\n",
      "kldivergence:   2021.32\n",
      "variational_beta * kldivergence:  0.20213\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36402\n",
      "kldivergence:   1841.38\n",
      "variational_beta * kldivergence:  0.18414\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37343\n",
      "kldivergence:   2184.28\n",
      "variational_beta * kldivergence:  0.21843\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31471\n",
      "kldivergence:   1809.91\n",
      "variational_beta * kldivergence:  0.18099\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.27462\n",
      "kldivergence:   1838.60\n",
      "variational_beta * kldivergence:  0.18386\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34172\n",
      "kldivergence:   1814.98\n",
      "variational_beta * kldivergence:  0.18150\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33743\n",
      "kldivergence:   1881.61\n",
      "variational_beta * kldivergence:  0.18816\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35954\n",
      "kldivergence:   1871.06\n",
      "variational_beta * kldivergence:  0.18711\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32328\n",
      "kldivergence:   1912.56\n",
      "variational_beta * kldivergence:  0.19126\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.41472\n",
      "kldivergence:   2016.70\n",
      "variational_beta * kldivergence:  0.20167\n",
      "batch accuracy: 86.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33696\n",
      "kldivergence:   1903.62\n",
      "variational_beta * kldivergence:  0.19036\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34861\n",
      "kldivergence:   2012.26\n",
      "variational_beta * kldivergence:  0.20123\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36824\n",
      "kldivergence:   2237.58\n",
      "variational_beta * kldivergence:  0.22376\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36199\n",
      "kldivergence:   1922.11\n",
      "variational_beta * kldivergence:  0.19221\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31942\n",
      "kldivergence:   2014.56\n",
      "variational_beta * kldivergence:  0.20146\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31238\n",
      "kldivergence:   2335.66\n",
      "variational_beta * kldivergence:  0.23357\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34522\n",
      "kldivergence:   1882.01\n",
      "variational_beta * kldivergence:  0.18820\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35914\n",
      "kldivergence:   2095.04\n",
      "variational_beta * kldivergence:  0.20950\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.39271\n",
      "kldivergence:   2054.29\n",
      "variational_beta * kldivergence:  0.20543\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35554\n",
      "kldivergence:   1885.28\n",
      "variational_beta * kldivergence:  0.18853\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36948\n",
      "kldivergence:   2228.74\n",
      "variational_beta * kldivergence:  0.22287\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31901\n",
      "kldivergence:   1814.90\n",
      "variational_beta * kldivergence:  0.18149\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33967\n",
      "kldivergence:   1778.02\n",
      "variational_beta * kldivergence:  0.17780\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.38607\n",
      "kldivergence:   2127.86\n",
      "variational_beta * kldivergence:  0.21279\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29829\n",
      "kldivergence:   1870.79\n",
      "variational_beta * kldivergence:  0.18708\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.28789\n",
      "kldivergence:   1972.56\n",
      "variational_beta * kldivergence:  0.19726\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30159\n",
      "kldivergence:   1830.92\n",
      "variational_beta * kldivergence:  0.18309\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33715\n",
      "kldivergence:   2187.83\n",
      "variational_beta * kldivergence:  0.21878\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33290\n",
      "kldivergence:   2206.01\n",
      "variational_beta * kldivergence:  0.22060\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33465\n",
      "kldivergence:   2155.48\n",
      "variational_beta * kldivergence:  0.21555\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.32888\n",
      "kldivergence:   1932.86\n",
      "variational_beta * kldivergence:  0.19329\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30221\n",
      "kldivergence:   1910.86\n",
      "variational_beta * kldivergence:  0.19109\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37876\n",
      "kldivergence:   2184.42\n",
      "variational_beta * kldivergence:  0.21844\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.26638\n",
      "kldivergence:   1934.81\n",
      "variational_beta * kldivergence:  0.19348\n",
      "batch accuracy: 91.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30625\n",
      "kldivergence:   2158.37\n",
      "variational_beta * kldivergence:  0.21584\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31920\n",
      "kldivergence:   2005.99\n",
      "variational_beta * kldivergence:  0.20060\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37924\n",
      "kldivergence:   2216.65\n",
      "variational_beta * kldivergence:  0.22167\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.38120\n",
      "kldivergence:   2216.47\n",
      "variational_beta * kldivergence:  0.22165\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30528\n",
      "kldivergence:   2055.22\n",
      "variational_beta * kldivergence:  0.20552\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30880\n",
      "kldivergence:   1797.92\n",
      "variational_beta * kldivergence:  0.17979\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.38049\n",
      "kldivergence:   2218.51\n",
      "variational_beta * kldivergence:  0.22185\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34691\n",
      "kldivergence:   2031.75\n",
      "variational_beta * kldivergence:  0.20318\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.35929\n",
      "kldivergence:   1716.81\n",
      "variational_beta * kldivergence:  0.17168\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.27436\n",
      "kldivergence:   1844.53\n",
      "variational_beta * kldivergence:  0.18445\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33873\n",
      "kldivergence:   1742.30\n",
      "variational_beta * kldivergence:  0.17423\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29919\n",
      "kldivergence:   1730.14\n",
      "variational_beta * kldivergence:  0.17301\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34679\n",
      "kldivergence:   1670.91\n",
      "variational_beta * kldivergence:  0.16709\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.29223\n",
      "kldivergence:   1689.09\n",
      "variational_beta * kldivergence:  0.16891\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.33243\n",
      "kldivergence:   1886.87\n",
      "variational_beta * kldivergence:  0.18869\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30944\n",
      "kldivergence:   1757.70\n",
      "variational_beta * kldivergence:  0.17577\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34137\n",
      "kldivergence:   2362.77\n",
      "variational_beta * kldivergence:  0.23628\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31417\n",
      "kldivergence:   1923.07\n",
      "variational_beta * kldivergence:  0.19231\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.31625\n",
      "kldivergence:   1775.86\n",
      "variational_beta * kldivergence:  0.17759\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34013\n",
      "kldivergence:   1965.17\n",
      "variational_beta * kldivergence:  0.19652\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37874\n",
      "kldivergence:   2255.69\n",
      "variational_beta * kldivergence:  0.22557\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.37802\n",
      "kldivergence:   1987.67\n",
      "variational_beta * kldivergence:  0.19877\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.39907\n",
      "kldivergence:   2129.80\n",
      "variational_beta * kldivergence:  0.21298\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.36346\n",
      "kldivergence:   1976.42\n",
      "variational_beta * kldivergence:  0.19764\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34191\n",
      "kldivergence:   1998.52\n",
      "variational_beta * kldivergence:  0.19985\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.30648\n",
      "kldivergence:   2036.02\n",
      "variational_beta * kldivergence:  0.20360\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #0\n",
      "reconstruction loss: 0.34166\n",
      "kldivergence:   2052.11\n",
      "variational_beta * kldivergence:  0.20521\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.48248\n",
      "kldivergence:   1899.10\n",
      "variational_beta * kldivergence:  0.18991\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.43985\n",
      "kldivergence:   1930.62\n",
      "variational_beta * kldivergence:  0.19306\n",
      "batch accuracy: 86.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.51768\n",
      "kldivergence:   1890.40\n",
      "variational_beta * kldivergence:  0.18904\n",
      "batch accuracy: 84.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.40684\n",
      "kldivergence:   1838.62\n",
      "variational_beta * kldivergence:  0.18386\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.42003\n",
      "kldivergence:   1830.79\n",
      "variational_beta * kldivergence:  0.18308\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.45905\n",
      "kldivergence:   1819.53\n",
      "variational_beta * kldivergence:  0.18195\n",
      "batch accuracy: 85.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.39363\n",
      "kldivergence:   1726.44\n",
      "variational_beta * kldivergence:  0.17264\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.43820\n",
      "kldivergence:   1848.82\n",
      "variational_beta * kldivergence:  0.18488\n",
      "batch accuracy: 86.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.46019\n",
      "kldivergence:   1811.38\n",
      "variational_beta * kldivergence:  0.18114\n",
      "batch accuracy: 85.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.45731\n",
      "kldivergence:   2038.83\n",
      "variational_beta * kldivergence:  0.20388\n",
      "batch accuracy: 86.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.40310\n",
      "kldivergence:   1704.32\n",
      "variational_beta * kldivergence:  0.17043\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.47151\n",
      "kldivergence:   1755.10\n",
      "variational_beta * kldivergence:  0.17551\n",
      "batch accuracy: 85.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.37829\n",
      "kldivergence:   1655.92\n",
      "variational_beta * kldivergence:  0.16559\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.45738\n",
      "kldivergence:   1999.64\n",
      "variational_beta * kldivergence:  0.19996\n",
      "batch accuracy: 85.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.46624\n",
      "kldivergence:   1954.16\n",
      "variational_beta * kldivergence:  0.19542\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.44301\n",
      "kldivergence:   1872.28\n",
      "variational_beta * kldivergence:  0.18723\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.46004\n",
      "kldivergence:   1893.14\n",
      "variational_beta * kldivergence:  0.18931\n",
      "batch accuracy: 86.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.43432\n",
      "kldivergence:   1856.80\n",
      "variational_beta * kldivergence:  0.18568\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.42733\n",
      "kldivergence:   1817.91\n",
      "variational_beta * kldivergence:  0.18179\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.40456\n",
      "kldivergence:   1766.91\n",
      "variational_beta * kldivergence:  0.17669\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.46302\n",
      "kldivergence:   2052.38\n",
      "variational_beta * kldivergence:  0.20524\n",
      "batch accuracy: 85.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.41623\n",
      "kldivergence:   1881.36\n",
      "variational_beta * kldivergence:  0.18814\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.39636\n",
      "kldivergence:   1807.99\n",
      "variational_beta * kldivergence:  0.18080\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.42842\n",
      "kldivergence:   1921.54\n",
      "variational_beta * kldivergence:  0.19215\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.52383\n",
      "kldivergence:   2078.54\n",
      "variational_beta * kldivergence:  0.20785\n",
      "batch accuracy: 83.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.47410\n",
      "kldivergence:   2064.06\n",
      "variational_beta * kldivergence:  0.20641\n",
      "batch accuracy: 85.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.42106\n",
      "kldivergence:   1859.08\n",
      "variational_beta * kldivergence:  0.18591\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.49092\n",
      "kldivergence:   1886.92\n",
      "variational_beta * kldivergence:  0.18869\n",
      "batch accuracy: 85.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.47246\n",
      "kldivergence:   1966.78\n",
      "variational_beta * kldivergence:  0.19668\n",
      "batch accuracy: 85.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.41806\n",
      "kldivergence:   1945.45\n",
      "variational_beta * kldivergence:  0.19455\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.51247\n",
      "kldivergence:   1979.26\n",
      "variational_beta * kldivergence:  0.19793\n",
      "batch accuracy: 84.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.47306\n",
      "kldivergence:   1910.30\n",
      "variational_beta * kldivergence:  0.19103\n",
      "batch accuracy: 85.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.41333\n",
      "kldivergence:   1832.52\n",
      "variational_beta * kldivergence:  0.18325\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.40132\n",
      "kldivergence:   1779.36\n",
      "variational_beta * kldivergence:  0.17794\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.49346\n",
      "kldivergence:   2013.18\n",
      "variational_beta * kldivergence:  0.20132\n",
      "batch accuracy: 85.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.40035\n",
      "kldivergence:   1703.78\n",
      "variational_beta * kldivergence:  0.17038\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.39389\n",
      "kldivergence:   1664.85\n",
      "variational_beta * kldivergence:  0.16649\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.43107\n",
      "kldivergence:   1717.31\n",
      "variational_beta * kldivergence:  0.17173\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.58653\n",
      "kldivergence:   2008.37\n",
      "variational_beta * kldivergence:  0.20084\n",
      "batch accuracy: 82.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.58953\n",
      "kldivergence:   2090.97\n",
      "variational_beta * kldivergence:  0.20910\n",
      "batch accuracy: 82.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.49854\n",
      "kldivergence:   1869.24\n",
      "variational_beta * kldivergence:  0.18692\n",
      "batch accuracy: 84.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.40938\n",
      "kldivergence:   1815.98\n",
      "variational_beta * kldivergence:  0.18160\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.55586\n",
      "kldivergence:   2007.74\n",
      "variational_beta * kldivergence:  0.20077\n",
      "batch accuracy: 83.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.49398\n",
      "kldivergence:   1982.27\n",
      "variational_beta * kldivergence:  0.19823\n",
      "batch accuracy: 85.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.53671\n",
      "kldivergence:   2025.12\n",
      "variational_beta * kldivergence:  0.20251\n",
      "batch accuracy: 83.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.48152\n",
      "kldivergence:   1889.15\n",
      "variational_beta * kldivergence:  0.18891\n",
      "batch accuracy: 85.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.51465\n",
      "kldivergence:   2000.36\n",
      "variational_beta * kldivergence:  0.20004\n",
      "batch accuracy: 84.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.40775\n",
      "kldivergence:   1841.54\n",
      "variational_beta * kldivergence:  0.18415\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.39255\n",
      "kldivergence:   1845.76\n",
      "variational_beta * kldivergence:  0.18458\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.43535\n",
      "kldivergence:   1908.32\n",
      "variational_beta * kldivergence:  0.19083\n",
      "batch accuracy: 86.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.49289\n",
      "kldivergence:   1913.66\n",
      "variational_beta * kldivergence:  0.19137\n",
      "batch accuracy: 84.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.41482\n",
      "kldivergence:   1781.07\n",
      "variational_beta * kldivergence:  0.17811\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.48134\n",
      "kldivergence:   1886.31\n",
      "variational_beta * kldivergence:  0.18863\n",
      "batch accuracy: 85.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.36914\n",
      "kldivergence:   1559.91\n",
      "variational_beta * kldivergence:  0.15599\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.50971\n",
      "kldivergence:   2036.22\n",
      "variational_beta * kldivergence:  0.20362\n",
      "batch accuracy: 84.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.41943\n",
      "kldivergence:   1800.97\n",
      "variational_beta * kldivergence:  0.18010\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.49482\n",
      "kldivergence:   1901.66\n",
      "variational_beta * kldivergence:  0.19017\n",
      "batch accuracy: 85.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.41760\n",
      "kldivergence:   1883.94\n",
      "variational_beta * kldivergence:  0.18839\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.40505\n",
      "kldivergence:   1864.12\n",
      "variational_beta * kldivergence:  0.18641\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.55126\n",
      "kldivergence:   2171.71\n",
      "variational_beta * kldivergence:  0.21717\n",
      "batch accuracy: 83.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #0\n",
      "reconstruction loss: 0.39503\n",
      "kldivergence:   1645.09\n",
      "variational_beta * kldivergence:  0.16451\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "saved samples\n",
      "Epoch [1 / 150] average reconstruction error: 0.542527\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31777\n",
      "kldivergence:   2324.87\n",
      "variational_beta * kldivergence:  0.23249\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38981\n",
      "kldivergence:   2120.65\n",
      "variational_beta * kldivergence:  0.21207\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33445\n",
      "kldivergence:   1942.19\n",
      "variational_beta * kldivergence:  0.19422\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32474\n",
      "kldivergence:   2012.51\n",
      "variational_beta * kldivergence:  0.20125\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32626\n",
      "kldivergence:   1870.53\n",
      "variational_beta * kldivergence:  0.18705\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33455\n",
      "kldivergence:   2125.64\n",
      "variational_beta * kldivergence:  0.21256\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36028\n",
      "kldivergence:   1816.66\n",
      "variational_beta * kldivergence:  0.18167\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29360\n",
      "kldivergence:   1917.61\n",
      "variational_beta * kldivergence:  0.19176\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28773\n",
      "kldivergence:   1924.50\n",
      "variational_beta * kldivergence:  0.19245\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34616\n",
      "kldivergence:   1848.44\n",
      "variational_beta * kldivergence:  0.18484\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37971\n",
      "kldivergence:   1977.77\n",
      "variational_beta * kldivergence:  0.19778\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.39191\n",
      "kldivergence:   1837.11\n",
      "variational_beta * kldivergence:  0.18371\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33278\n",
      "kldivergence:   1820.83\n",
      "variational_beta * kldivergence:  0.18208\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35457\n",
      "kldivergence:   1703.32\n",
      "variational_beta * kldivergence:  0.17033\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33165\n",
      "kldivergence:   2161.15\n",
      "variational_beta * kldivergence:  0.21611\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34151\n",
      "kldivergence:   1773.29\n",
      "variational_beta * kldivergence:  0.17733\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30666\n",
      "kldivergence:   1982.11\n",
      "variational_beta * kldivergence:  0.19821\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33709\n",
      "kldivergence:   1856.32\n",
      "variational_beta * kldivergence:  0.18563\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.41214\n",
      "kldivergence:   1852.93\n",
      "variational_beta * kldivergence:  0.18529\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32442\n",
      "kldivergence:   1971.45\n",
      "variational_beta * kldivergence:  0.19714\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32167\n",
      "kldivergence:   2005.63\n",
      "variational_beta * kldivergence:  0.20056\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29853\n",
      "kldivergence:   2232.16\n",
      "variational_beta * kldivergence:  0.22322\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.39303\n",
      "kldivergence:   2256.73\n",
      "variational_beta * kldivergence:  0.22567\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.41006\n",
      "kldivergence:   2070.18\n",
      "variational_beta * kldivergence:  0.20702\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34178\n",
      "kldivergence:   2188.20\n",
      "variational_beta * kldivergence:  0.21882\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34128\n",
      "kldivergence:   2331.56\n",
      "variational_beta * kldivergence:  0.23316\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31478\n",
      "kldivergence:   2120.32\n",
      "variational_beta * kldivergence:  0.21203\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32271\n",
      "kldivergence:   2144.62\n",
      "variational_beta * kldivergence:  0.21446\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31391\n",
      "kldivergence:   2388.66\n",
      "variational_beta * kldivergence:  0.23887\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.40312\n",
      "kldivergence:   2670.69\n",
      "variational_beta * kldivergence:  0.26707\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36985\n",
      "kldivergence:   2481.93\n",
      "variational_beta * kldivergence:  0.24819\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.24053\n",
      "kldivergence:   1877.97\n",
      "variational_beta * kldivergence:  0.18780\n",
      "batch accuracy: 92.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29771\n",
      "kldivergence:   2255.96\n",
      "variational_beta * kldivergence:  0.22560\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33053\n",
      "kldivergence:   2112.41\n",
      "variational_beta * kldivergence:  0.21124\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28614\n",
      "kldivergence:   2062.81\n",
      "variational_beta * kldivergence:  0.20628\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30089\n",
      "kldivergence:   1988.05\n",
      "variational_beta * kldivergence:  0.19880\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33364\n",
      "kldivergence:   2277.58\n",
      "variational_beta * kldivergence:  0.22776\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34159\n",
      "kldivergence:   1972.01\n",
      "variational_beta * kldivergence:  0.19720\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30845\n",
      "kldivergence:   1998.32\n",
      "variational_beta * kldivergence:  0.19983\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29083\n",
      "kldivergence:   2080.44\n",
      "variational_beta * kldivergence:  0.20804\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33392\n",
      "kldivergence:   1954.49\n",
      "variational_beta * kldivergence:  0.19545\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33483\n",
      "kldivergence:   2090.46\n",
      "variational_beta * kldivergence:  0.20905\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35337\n",
      "kldivergence:   1976.76\n",
      "variational_beta * kldivergence:  0.19768\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34030\n",
      "kldivergence:   2114.88\n",
      "variational_beta * kldivergence:  0.21149\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36057\n",
      "kldivergence:   2079.25\n",
      "variational_beta * kldivergence:  0.20793\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37944\n",
      "kldivergence:   1844.35\n",
      "variational_beta * kldivergence:  0.18444\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36169\n",
      "kldivergence:   2226.24\n",
      "variational_beta * kldivergence:  0.22262\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32828\n",
      "kldivergence:   1909.84\n",
      "variational_beta * kldivergence:  0.19098\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38297\n",
      "kldivergence:   1813.78\n",
      "variational_beta * kldivergence:  0.18138\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31671\n",
      "kldivergence:   1724.62\n",
      "variational_beta * kldivergence:  0.17246\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33169\n",
      "kldivergence:   2026.40\n",
      "variational_beta * kldivergence:  0.20264\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33316\n",
      "kldivergence:   1794.33\n",
      "variational_beta * kldivergence:  0.17943\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30284\n",
      "kldivergence:   1811.59\n",
      "variational_beta * kldivergence:  0.18116\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38834\n",
      "kldivergence:   2216.13\n",
      "variational_beta * kldivergence:  0.22161\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30210\n",
      "kldivergence:   1558.07\n",
      "variational_beta * kldivergence:  0.15581\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33760\n",
      "kldivergence:   1998.43\n",
      "variational_beta * kldivergence:  0.19984\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29171\n",
      "kldivergence:   1738.52\n",
      "variational_beta * kldivergence:  0.17385\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34047\n",
      "kldivergence:   1877.19\n",
      "variational_beta * kldivergence:  0.18772\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37183\n",
      "kldivergence:   1824.92\n",
      "variational_beta * kldivergence:  0.18249\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35420\n",
      "kldivergence:   1950.94\n",
      "variational_beta * kldivergence:  0.19509\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36889\n",
      "kldivergence:   2085.14\n",
      "variational_beta * kldivergence:  0.20851\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28404\n",
      "kldivergence:   1717.89\n",
      "variational_beta * kldivergence:  0.17179\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30813\n",
      "kldivergence:   1717.06\n",
      "variational_beta * kldivergence:  0.17171\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35768\n",
      "kldivergence:   1938.65\n",
      "variational_beta * kldivergence:  0.19386\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34003\n",
      "kldivergence:   1930.68\n",
      "variational_beta * kldivergence:  0.19307\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31028\n",
      "kldivergence:   1993.80\n",
      "variational_beta * kldivergence:  0.19938\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29202\n",
      "kldivergence:   1658.83\n",
      "variational_beta * kldivergence:  0.16588\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28037\n",
      "kldivergence:   1997.86\n",
      "variational_beta * kldivergence:  0.19979\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35183\n",
      "kldivergence:   2117.17\n",
      "variational_beta * kldivergence:  0.21172\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28390\n",
      "kldivergence:   1763.69\n",
      "variational_beta * kldivergence:  0.17637\n",
      "batch accuracy: 90.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.40375\n",
      "kldivergence:   2126.61\n",
      "variational_beta * kldivergence:  0.21266\n",
      "batch accuracy: 86.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38643\n",
      "kldivergence:   2414.24\n",
      "variational_beta * kldivergence:  0.24142\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31448\n",
      "kldivergence:   1947.34\n",
      "variational_beta * kldivergence:  0.19473\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35290\n",
      "kldivergence:   1971.37\n",
      "variational_beta * kldivergence:  0.19714\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33265\n",
      "kldivergence:   2150.51\n",
      "variational_beta * kldivergence:  0.21505\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32422\n",
      "kldivergence:   1881.49\n",
      "variational_beta * kldivergence:  0.18815\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33626\n",
      "kldivergence:   2212.53\n",
      "variational_beta * kldivergence:  0.22125\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36541\n",
      "kldivergence:   1799.24\n",
      "variational_beta * kldivergence:  0.17992\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31777\n",
      "kldivergence:   1806.51\n",
      "variational_beta * kldivergence:  0.18065\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37050\n",
      "kldivergence:   2017.10\n",
      "variational_beta * kldivergence:  0.20171\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36141\n",
      "kldivergence:   1908.92\n",
      "variational_beta * kldivergence:  0.19089\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29561\n",
      "kldivergence:   1869.41\n",
      "variational_beta * kldivergence:  0.18694\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31855\n",
      "kldivergence:   1745.08\n",
      "variational_beta * kldivergence:  0.17451\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35420\n",
      "kldivergence:   2007.35\n",
      "variational_beta * kldivergence:  0.20074\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32019\n",
      "kldivergence:   1875.43\n",
      "variational_beta * kldivergence:  0.18754\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36500\n",
      "kldivergence:   1997.25\n",
      "variational_beta * kldivergence:  0.19972\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37289\n",
      "kldivergence:   2341.71\n",
      "variational_beta * kldivergence:  0.23417\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35768\n",
      "kldivergence:   2340.03\n",
      "variational_beta * kldivergence:  0.23400\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29089\n",
      "kldivergence:   1684.63\n",
      "variational_beta * kldivergence:  0.16846\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38917\n",
      "kldivergence:   2054.24\n",
      "variational_beta * kldivergence:  0.20542\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35017\n",
      "kldivergence:   1961.66\n",
      "variational_beta * kldivergence:  0.19617\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28111\n",
      "kldivergence:   1654.35\n",
      "variational_beta * kldivergence:  0.16544\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30548\n",
      "kldivergence:   1613.60\n",
      "variational_beta * kldivergence:  0.16136\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35157\n",
      "kldivergence:   1847.05\n",
      "variational_beta * kldivergence:  0.18470\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37465\n",
      "kldivergence:   2098.32\n",
      "variational_beta * kldivergence:  0.20983\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35738\n",
      "kldivergence:   2425.84\n",
      "variational_beta * kldivergence:  0.24258\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33055\n",
      "kldivergence:   1662.60\n",
      "variational_beta * kldivergence:  0.16626\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34558\n",
      "kldivergence:   1942.12\n",
      "variational_beta * kldivergence:  0.19421\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35271\n",
      "kldivergence:   1646.18\n",
      "variational_beta * kldivergence:  0.16462\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36435\n",
      "kldivergence:   2322.72\n",
      "variational_beta * kldivergence:  0.23227\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32493\n",
      "kldivergence:   2233.74\n",
      "variational_beta * kldivergence:  0.22337\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34338\n",
      "kldivergence:   1777.39\n",
      "variational_beta * kldivergence:  0.17774\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32757\n",
      "kldivergence:   1784.59\n",
      "variational_beta * kldivergence:  0.17846\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35581\n",
      "kldivergence:   1981.96\n",
      "variational_beta * kldivergence:  0.19820\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34695\n",
      "kldivergence:   1801.38\n",
      "variational_beta * kldivergence:  0.18014\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.26324\n",
      "kldivergence:   1936.72\n",
      "variational_beta * kldivergence:  0.19367\n",
      "batch accuracy: 91.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37304\n",
      "kldivergence:   1912.71\n",
      "variational_beta * kldivergence:  0.19127\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34464\n",
      "kldivergence:   1967.47\n",
      "variational_beta * kldivergence:  0.19675\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37709\n",
      "kldivergence:   1919.58\n",
      "variational_beta * kldivergence:  0.19196\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.39184\n",
      "kldivergence:   2094.91\n",
      "variational_beta * kldivergence:  0.20949\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31562\n",
      "kldivergence:   1765.52\n",
      "variational_beta * kldivergence:  0.17655\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29947\n",
      "kldivergence:   1899.37\n",
      "variational_beta * kldivergence:  0.18994\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.26272\n",
      "kldivergence:   1627.56\n",
      "variational_beta * kldivergence:  0.16276\n",
      "batch accuracy: 91.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29996\n",
      "kldivergence:   1776.90\n",
      "variational_beta * kldivergence:  0.17769\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30761\n",
      "kldivergence:   1918.70\n",
      "variational_beta * kldivergence:  0.19187\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.39393\n",
      "kldivergence:   2065.47\n",
      "variational_beta * kldivergence:  0.20655\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32353\n",
      "kldivergence:   1830.58\n",
      "variational_beta * kldivergence:  0.18306\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36615\n",
      "kldivergence:   2144.83\n",
      "variational_beta * kldivergence:  0.21448\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34852\n",
      "kldivergence:   2141.87\n",
      "variational_beta * kldivergence:  0.21419\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.39608\n",
      "kldivergence:   2507.19\n",
      "variational_beta * kldivergence:  0.25072\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35384\n",
      "kldivergence:   2086.56\n",
      "variational_beta * kldivergence:  0.20866\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38950\n",
      "kldivergence:   1982.11\n",
      "variational_beta * kldivergence:  0.19821\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31154\n",
      "kldivergence:   1866.46\n",
      "variational_beta * kldivergence:  0.18665\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38539\n",
      "kldivergence:   1876.38\n",
      "variational_beta * kldivergence:  0.18764\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29300\n",
      "kldivergence:   1814.08\n",
      "variational_beta * kldivergence:  0.18141\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32963\n",
      "kldivergence:   1974.83\n",
      "variational_beta * kldivergence:  0.19748\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38017\n",
      "kldivergence:   1886.90\n",
      "variational_beta * kldivergence:  0.18869\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38357\n",
      "kldivergence:   1920.69\n",
      "variational_beta * kldivergence:  0.19207\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33804\n",
      "kldivergence:   2100.85\n",
      "variational_beta * kldivergence:  0.21009\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34895\n",
      "kldivergence:   1760.59\n",
      "variational_beta * kldivergence:  0.17606\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.39318\n",
      "kldivergence:   1960.06\n",
      "variational_beta * kldivergence:  0.19601\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.40605\n",
      "kldivergence:   2081.64\n",
      "variational_beta * kldivergence:  0.20816\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36494\n",
      "kldivergence:   2034.82\n",
      "variational_beta * kldivergence:  0.20348\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33056\n",
      "kldivergence:   1667.85\n",
      "variational_beta * kldivergence:  0.16678\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30730\n",
      "kldivergence:   2058.88\n",
      "variational_beta * kldivergence:  0.20589\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35190\n",
      "kldivergence:   1798.10\n",
      "variational_beta * kldivergence:  0.17981\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31221\n",
      "kldivergence:   2058.85\n",
      "variational_beta * kldivergence:  0.20588\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33181\n",
      "kldivergence:   1740.88\n",
      "variational_beta * kldivergence:  0.17409\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31346\n",
      "kldivergence:   1805.79\n",
      "variational_beta * kldivergence:  0.18058\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37041\n",
      "kldivergence:   1904.62\n",
      "variational_beta * kldivergence:  0.19046\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31144\n",
      "kldivergence:   1745.26\n",
      "variational_beta * kldivergence:  0.17453\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37552\n",
      "kldivergence:   2279.42\n",
      "variational_beta * kldivergence:  0.22794\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37948\n",
      "kldivergence:   2131.09\n",
      "variational_beta * kldivergence:  0.21311\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35610\n",
      "kldivergence:   1921.11\n",
      "variational_beta * kldivergence:  0.19211\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34632\n",
      "kldivergence:   1956.52\n",
      "variational_beta * kldivergence:  0.19565\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34031\n",
      "kldivergence:   1871.01\n",
      "variational_beta * kldivergence:  0.18710\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33210\n",
      "kldivergence:   1747.01\n",
      "variational_beta * kldivergence:  0.17470\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34480\n",
      "kldivergence:   1764.69\n",
      "variational_beta * kldivergence:  0.17647\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34849\n",
      "kldivergence:   2183.45\n",
      "variational_beta * kldivergence:  0.21834\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35754\n",
      "kldivergence:   1756.67\n",
      "variational_beta * kldivergence:  0.17567\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31696\n",
      "kldivergence:   2024.08\n",
      "variational_beta * kldivergence:  0.20241\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35138\n",
      "kldivergence:   1868.73\n",
      "variational_beta * kldivergence:  0.18687\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34606\n",
      "kldivergence:   1976.12\n",
      "variational_beta * kldivergence:  0.19761\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34518\n",
      "kldivergence:   2017.72\n",
      "variational_beta * kldivergence:  0.20177\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38315\n",
      "kldivergence:   2291.64\n",
      "variational_beta * kldivergence:  0.22916\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31806\n",
      "kldivergence:   1804.12\n",
      "variational_beta * kldivergence:  0.18041\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37787\n",
      "kldivergence:   2279.74\n",
      "variational_beta * kldivergence:  0.22797\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32762\n",
      "kldivergence:   2124.04\n",
      "variational_beta * kldivergence:  0.21240\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29320\n",
      "kldivergence:   1770.95\n",
      "variational_beta * kldivergence:  0.17709\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31300\n",
      "kldivergence:   1682.37\n",
      "variational_beta * kldivergence:  0.16824\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33810\n",
      "kldivergence:   2173.99\n",
      "variational_beta * kldivergence:  0.21740\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.27668\n",
      "kldivergence:   1716.22\n",
      "variational_beta * kldivergence:  0.17162\n",
      "batch accuracy: 90.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32512\n",
      "kldivergence:   1753.96\n",
      "variational_beta * kldivergence:  0.17540\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.40633\n",
      "kldivergence:   1784.14\n",
      "variational_beta * kldivergence:  0.17841\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29304\n",
      "kldivergence:   2116.64\n",
      "variational_beta * kldivergence:  0.21166\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34275\n",
      "kldivergence:   1911.83\n",
      "variational_beta * kldivergence:  0.19118\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31416\n",
      "kldivergence:   2041.07\n",
      "variational_beta * kldivergence:  0.20411\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33489\n",
      "kldivergence:   2051.71\n",
      "variational_beta * kldivergence:  0.20517\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37931\n",
      "kldivergence:   2025.65\n",
      "variational_beta * kldivergence:  0.20256\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30970\n",
      "kldivergence:   2103.26\n",
      "variational_beta * kldivergence:  0.21033\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35679\n",
      "kldivergence:   2108.89\n",
      "variational_beta * kldivergence:  0.21089\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30246\n",
      "kldivergence:   1487.75\n",
      "variational_beta * kldivergence:  0.14878\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37115\n",
      "kldivergence:   1950.87\n",
      "variational_beta * kldivergence:  0.19509\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32272\n",
      "kldivergence:   1856.67\n",
      "variational_beta * kldivergence:  0.18567\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33331\n",
      "kldivergence:   1886.60\n",
      "variational_beta * kldivergence:  0.18866\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33812\n",
      "kldivergence:   1981.03\n",
      "variational_beta * kldivergence:  0.19810\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36947\n",
      "kldivergence:   1675.56\n",
      "variational_beta * kldivergence:  0.16756\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30972\n",
      "kldivergence:   1771.30\n",
      "variational_beta * kldivergence:  0.17713\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29003\n",
      "kldivergence:   1675.01\n",
      "variational_beta * kldivergence:  0.16750\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36187\n",
      "kldivergence:   2061.63\n",
      "variational_beta * kldivergence:  0.20616\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34337\n",
      "kldivergence:   1883.04\n",
      "variational_beta * kldivergence:  0.18830\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33675\n",
      "kldivergence:   2108.32\n",
      "variational_beta * kldivergence:  0.21083\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34196\n",
      "kldivergence:   1895.03\n",
      "variational_beta * kldivergence:  0.18950\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30258\n",
      "kldivergence:   1650.89\n",
      "variational_beta * kldivergence:  0.16509\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33976\n",
      "kldivergence:   1948.32\n",
      "variational_beta * kldivergence:  0.19483\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37630\n",
      "kldivergence:   1978.54\n",
      "variational_beta * kldivergence:  0.19785\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34662\n",
      "kldivergence:   1833.35\n",
      "variational_beta * kldivergence:  0.18334\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34505\n",
      "kldivergence:   1965.02\n",
      "variational_beta * kldivergence:  0.19650\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34426\n",
      "kldivergence:   1914.96\n",
      "variational_beta * kldivergence:  0.19150\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32198\n",
      "kldivergence:   2026.14\n",
      "variational_beta * kldivergence:  0.20261\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30768\n",
      "kldivergence:   1883.56\n",
      "variational_beta * kldivergence:  0.18836\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33059\n",
      "kldivergence:   1837.08\n",
      "variational_beta * kldivergence:  0.18371\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30732\n",
      "kldivergence:   1776.97\n",
      "variational_beta * kldivergence:  0.17770\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34729\n",
      "kldivergence:   2122.89\n",
      "variational_beta * kldivergence:  0.21229\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38082\n",
      "kldivergence:   1772.44\n",
      "variational_beta * kldivergence:  0.17724\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32151\n",
      "kldivergence:   1586.73\n",
      "variational_beta * kldivergence:  0.15867\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33461\n",
      "kldivergence:   2054.86\n",
      "variational_beta * kldivergence:  0.20549\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34854\n",
      "kldivergence:   1935.94\n",
      "variational_beta * kldivergence:  0.19359\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33190\n",
      "kldivergence:   1992.90\n",
      "variational_beta * kldivergence:  0.19929\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38875\n",
      "kldivergence:   1992.49\n",
      "variational_beta * kldivergence:  0.19925\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33400\n",
      "kldivergence:   1861.15\n",
      "variational_beta * kldivergence:  0.18612\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37683\n",
      "kldivergence:   1950.83\n",
      "variational_beta * kldivergence:  0.19508\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34482\n",
      "kldivergence:   1676.26\n",
      "variational_beta * kldivergence:  0.16763\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33165\n",
      "kldivergence:   1724.64\n",
      "variational_beta * kldivergence:  0.17246\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32868\n",
      "kldivergence:   1759.88\n",
      "variational_beta * kldivergence:  0.17599\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32876\n",
      "kldivergence:   1751.18\n",
      "variational_beta * kldivergence:  0.17512\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30270\n",
      "kldivergence:   1712.38\n",
      "variational_beta * kldivergence:  0.17124\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32216\n",
      "kldivergence:   1764.68\n",
      "variational_beta * kldivergence:  0.17647\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28310\n",
      "kldivergence:   1660.63\n",
      "variational_beta * kldivergence:  0.16606\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30403\n",
      "kldivergence:   1727.88\n",
      "variational_beta * kldivergence:  0.17279\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32619\n",
      "kldivergence:   1867.95\n",
      "variational_beta * kldivergence:  0.18680\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30021\n",
      "kldivergence:   1705.46\n",
      "variational_beta * kldivergence:  0.17055\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29167\n",
      "kldivergence:   1778.57\n",
      "variational_beta * kldivergence:  0.17786\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33029\n",
      "kldivergence:   2063.31\n",
      "variational_beta * kldivergence:  0.20633\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34745\n",
      "kldivergence:   2196.21\n",
      "variational_beta * kldivergence:  0.21962\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.39493\n",
      "kldivergence:   2339.11\n",
      "variational_beta * kldivergence:  0.23391\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31773\n",
      "kldivergence:   1935.79\n",
      "variational_beta * kldivergence:  0.19358\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37782\n",
      "kldivergence:   2222.10\n",
      "variational_beta * kldivergence:  0.22221\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29207\n",
      "kldivergence:   1997.02\n",
      "variational_beta * kldivergence:  0.19970\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29227\n",
      "kldivergence:   1641.06\n",
      "variational_beta * kldivergence:  0.16411\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35749\n",
      "kldivergence:   1970.02\n",
      "variational_beta * kldivergence:  0.19700\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34071\n",
      "kldivergence:   1957.82\n",
      "variational_beta * kldivergence:  0.19578\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30255\n",
      "kldivergence:   1698.03\n",
      "variational_beta * kldivergence:  0.16980\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36984\n",
      "kldivergence:   2046.37\n",
      "variational_beta * kldivergence:  0.20464\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33422\n",
      "kldivergence:   1936.36\n",
      "variational_beta * kldivergence:  0.19364\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29896\n",
      "kldivergence:   1964.29\n",
      "variational_beta * kldivergence:  0.19643\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34971\n",
      "kldivergence:   1854.54\n",
      "variational_beta * kldivergence:  0.18545\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34736\n",
      "kldivergence:   1887.87\n",
      "variational_beta * kldivergence:  0.18879\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35226\n",
      "kldivergence:   2119.35\n",
      "variational_beta * kldivergence:  0.21194\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34911\n",
      "kldivergence:   1873.72\n",
      "variational_beta * kldivergence:  0.18737\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30099\n",
      "kldivergence:   1790.64\n",
      "variational_beta * kldivergence:  0.17906\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29610\n",
      "kldivergence:   1683.29\n",
      "variational_beta * kldivergence:  0.16833\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36087\n",
      "kldivergence:   1822.48\n",
      "variational_beta * kldivergence:  0.18225\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32733\n",
      "kldivergence:   2169.62\n",
      "variational_beta * kldivergence:  0.21696\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28772\n",
      "kldivergence:   1802.43\n",
      "variational_beta * kldivergence:  0.18024\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28545\n",
      "kldivergence:   2317.61\n",
      "variational_beta * kldivergence:  0.23176\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37871\n",
      "kldivergence:   2189.60\n",
      "variational_beta * kldivergence:  0.21896\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30761\n",
      "kldivergence:   2226.90\n",
      "variational_beta * kldivergence:  0.22269\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31720\n",
      "kldivergence:   1670.73\n",
      "variational_beta * kldivergence:  0.16707\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34906\n",
      "kldivergence:   1956.49\n",
      "variational_beta * kldivergence:  0.19565\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.39928\n",
      "kldivergence:   1997.99\n",
      "variational_beta * kldivergence:  0.19980\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35145\n",
      "kldivergence:   1856.55\n",
      "variational_beta * kldivergence:  0.18565\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32422\n",
      "kldivergence:   1867.99\n",
      "variational_beta * kldivergence:  0.18680\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38128\n",
      "kldivergence:   2113.43\n",
      "variational_beta * kldivergence:  0.21134\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33131\n",
      "kldivergence:   1774.41\n",
      "variational_beta * kldivergence:  0.17744\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.40702\n",
      "kldivergence:   1956.73\n",
      "variational_beta * kldivergence:  0.19567\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32913\n",
      "kldivergence:   1725.74\n",
      "variational_beta * kldivergence:  0.17257\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29564\n",
      "kldivergence:   1776.12\n",
      "variational_beta * kldivergence:  0.17761\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38298\n",
      "kldivergence:   2021.74\n",
      "variational_beta * kldivergence:  0.20217\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34049\n",
      "kldivergence:   1896.23\n",
      "variational_beta * kldivergence:  0.18962\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32486\n",
      "kldivergence:   1820.74\n",
      "variational_beta * kldivergence:  0.18207\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35869\n",
      "kldivergence:   1924.14\n",
      "variational_beta * kldivergence:  0.19241\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.25160\n",
      "kldivergence:   1714.61\n",
      "variational_beta * kldivergence:  0.17146\n",
      "batch accuracy: 91.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34459\n",
      "kldivergence:   2026.12\n",
      "variational_beta * kldivergence:  0.20261\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31519\n",
      "kldivergence:   1759.07\n",
      "variational_beta * kldivergence:  0.17591\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31236\n",
      "kldivergence:   1729.61\n",
      "variational_beta * kldivergence:  0.17296\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32842\n",
      "kldivergence:   1908.64\n",
      "variational_beta * kldivergence:  0.19086\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.41690\n",
      "kldivergence:   1955.54\n",
      "variational_beta * kldivergence:  0.19555\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32109\n",
      "kldivergence:   1793.46\n",
      "variational_beta * kldivergence:  0.17935\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37184\n",
      "kldivergence:   1934.23\n",
      "variational_beta * kldivergence:  0.19342\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33513\n",
      "kldivergence:   1783.00\n",
      "variational_beta * kldivergence:  0.17830\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28708\n",
      "kldivergence:   2202.77\n",
      "variational_beta * kldivergence:  0.22028\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.27677\n",
      "kldivergence:   1905.37\n",
      "variational_beta * kldivergence:  0.19054\n",
      "batch accuracy: 90.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36996\n",
      "kldivergence:   2060.74\n",
      "variational_beta * kldivergence:  0.20607\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34831\n",
      "kldivergence:   1897.00\n",
      "variational_beta * kldivergence:  0.18970\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35007\n",
      "kldivergence:   2097.80\n",
      "variational_beta * kldivergence:  0.20978\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33626\n",
      "kldivergence:   1878.82\n",
      "variational_beta * kldivergence:  0.18788\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33831\n",
      "kldivergence:   2106.35\n",
      "variational_beta * kldivergence:  0.21064\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38080\n",
      "kldivergence:   1949.11\n",
      "variational_beta * kldivergence:  0.19491\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34374\n",
      "kldivergence:   1834.27\n",
      "variational_beta * kldivergence:  0.18343\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32796\n",
      "kldivergence:   1867.31\n",
      "variational_beta * kldivergence:  0.18673\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31698\n",
      "kldivergence:   1998.60\n",
      "variational_beta * kldivergence:  0.19986\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32956\n",
      "kldivergence:   1875.71\n",
      "variational_beta * kldivergence:  0.18757\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34631\n",
      "kldivergence:   1806.93\n",
      "variational_beta * kldivergence:  0.18069\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34820\n",
      "kldivergence:   1752.62\n",
      "variational_beta * kldivergence:  0.17526\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37670\n",
      "kldivergence:   1983.44\n",
      "variational_beta * kldivergence:  0.19834\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.42709\n",
      "kldivergence:   2077.14\n",
      "variational_beta * kldivergence:  0.20771\n",
      "batch accuracy: 85.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31610\n",
      "kldivergence:   1814.06\n",
      "variational_beta * kldivergence:  0.18141\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32310\n",
      "kldivergence:   1711.57\n",
      "variational_beta * kldivergence:  0.17116\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31452\n",
      "kldivergence:   1700.41\n",
      "variational_beta * kldivergence:  0.17004\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35123\n",
      "kldivergence:   2220.67\n",
      "variational_beta * kldivergence:  0.22207\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.27211\n",
      "kldivergence:   1641.22\n",
      "variational_beta * kldivergence:  0.16412\n",
      "batch accuracy: 91.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38374\n",
      "kldivergence:   1717.14\n",
      "variational_beta * kldivergence:  0.17171\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29345\n",
      "kldivergence:   1784.26\n",
      "variational_beta * kldivergence:  0.17843\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31382\n",
      "kldivergence:   1775.01\n",
      "variational_beta * kldivergence:  0.17750\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32993\n",
      "kldivergence:   1679.00\n",
      "variational_beta * kldivergence:  0.16790\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29636\n",
      "kldivergence:   1735.39\n",
      "variational_beta * kldivergence:  0.17354\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28300\n",
      "kldivergence:   1702.28\n",
      "variational_beta * kldivergence:  0.17023\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34998\n",
      "kldivergence:   1794.96\n",
      "variational_beta * kldivergence:  0.17950\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35704\n",
      "kldivergence:   1910.12\n",
      "variational_beta * kldivergence:  0.19101\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32650\n",
      "kldivergence:   1882.98\n",
      "variational_beta * kldivergence:  0.18830\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35530\n",
      "kldivergence:   1646.28\n",
      "variational_beta * kldivergence:  0.16463\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29748\n",
      "kldivergence:   1497.57\n",
      "variational_beta * kldivergence:  0.14976\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35762\n",
      "kldivergence:   1949.04\n",
      "variational_beta * kldivergence:  0.19490\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33590\n",
      "kldivergence:   1784.46\n",
      "variational_beta * kldivergence:  0.17845\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34818\n",
      "kldivergence:   1812.38\n",
      "variational_beta * kldivergence:  0.18124\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32687\n",
      "kldivergence:   1771.03\n",
      "variational_beta * kldivergence:  0.17710\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33559\n",
      "kldivergence:   1806.11\n",
      "variational_beta * kldivergence:  0.18061\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33752\n",
      "kldivergence:   1962.65\n",
      "variational_beta * kldivergence:  0.19627\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37911\n",
      "kldivergence:   2061.41\n",
      "variational_beta * kldivergence:  0.20614\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35114\n",
      "kldivergence:   1842.40\n",
      "variational_beta * kldivergence:  0.18424\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38917\n",
      "kldivergence:   2054.90\n",
      "variational_beta * kldivergence:  0.20549\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32005\n",
      "kldivergence:   1876.45\n",
      "variational_beta * kldivergence:  0.18764\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38433\n",
      "kldivergence:   2089.78\n",
      "variational_beta * kldivergence:  0.20898\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36907\n",
      "kldivergence:   1748.10\n",
      "variational_beta * kldivergence:  0.17481\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35148\n",
      "kldivergence:   2013.66\n",
      "variational_beta * kldivergence:  0.20137\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30373\n",
      "kldivergence:   1823.20\n",
      "variational_beta * kldivergence:  0.18232\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28185\n",
      "kldivergence:   1748.87\n",
      "variational_beta * kldivergence:  0.17489\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30262\n",
      "kldivergence:   1761.13\n",
      "variational_beta * kldivergence:  0.17611\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34004\n",
      "kldivergence:   1836.32\n",
      "variational_beta * kldivergence:  0.18363\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36497\n",
      "kldivergence:   1892.85\n",
      "variational_beta * kldivergence:  0.18928\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38386\n",
      "kldivergence:   1904.95\n",
      "variational_beta * kldivergence:  0.19050\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34383\n",
      "kldivergence:   1946.69\n",
      "variational_beta * kldivergence:  0.19467\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33358\n",
      "kldivergence:   1847.29\n",
      "variational_beta * kldivergence:  0.18473\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.28436\n",
      "kldivergence:   1786.80\n",
      "variational_beta * kldivergence:  0.17868\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33825\n",
      "kldivergence:   2034.56\n",
      "variational_beta * kldivergence:  0.20346\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32272\n",
      "kldivergence:   1834.73\n",
      "variational_beta * kldivergence:  0.18347\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35120\n",
      "kldivergence:   1704.78\n",
      "variational_beta * kldivergence:  0.17048\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31450\n",
      "kldivergence:   1715.14\n",
      "variational_beta * kldivergence:  0.17151\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34697\n",
      "kldivergence:   1820.57\n",
      "variational_beta * kldivergence:  0.18206\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33821\n",
      "kldivergence:   2028.38\n",
      "variational_beta * kldivergence:  0.20284\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35548\n",
      "kldivergence:   1916.31\n",
      "variational_beta * kldivergence:  0.19163\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31280\n",
      "kldivergence:   1781.86\n",
      "variational_beta * kldivergence:  0.17819\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33780\n",
      "kldivergence:   1877.99\n",
      "variational_beta * kldivergence:  0.18780\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33653\n",
      "kldivergence:   1898.90\n",
      "variational_beta * kldivergence:  0.18989\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.27898\n",
      "kldivergence:   2034.66\n",
      "variational_beta * kldivergence:  0.20347\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31633\n",
      "kldivergence:   1941.74\n",
      "variational_beta * kldivergence:  0.19417\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32364\n",
      "kldivergence:   1717.28\n",
      "variational_beta * kldivergence:  0.17173\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29385\n",
      "kldivergence:   1924.56\n",
      "variational_beta * kldivergence:  0.19246\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31457\n",
      "kldivergence:   1641.18\n",
      "variational_beta * kldivergence:  0.16412\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35611\n",
      "kldivergence:   1880.77\n",
      "variational_beta * kldivergence:  0.18808\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37117\n",
      "kldivergence:   2060.63\n",
      "variational_beta * kldivergence:  0.20606\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32718\n",
      "kldivergence:   1810.43\n",
      "variational_beta * kldivergence:  0.18104\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37107\n",
      "kldivergence:   1948.18\n",
      "variational_beta * kldivergence:  0.19482\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33938\n",
      "kldivergence:   1875.87\n",
      "variational_beta * kldivergence:  0.18759\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37771\n",
      "kldivergence:   1867.01\n",
      "variational_beta * kldivergence:  0.18670\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32196\n",
      "kldivergence:   2036.75\n",
      "variational_beta * kldivergence:  0.20367\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29986\n",
      "kldivergence:   1810.02\n",
      "variational_beta * kldivergence:  0.18100\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35962\n",
      "kldivergence:   1949.80\n",
      "variational_beta * kldivergence:  0.19498\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.41810\n",
      "kldivergence:   2139.05\n",
      "variational_beta * kldivergence:  0.21390\n",
      "batch accuracy: 85.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31919\n",
      "kldivergence:   1778.96\n",
      "variational_beta * kldivergence:  0.17790\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34758\n",
      "kldivergence:   1731.87\n",
      "variational_beta * kldivergence:  0.17319\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.33886\n",
      "kldivergence:   1847.43\n",
      "variational_beta * kldivergence:  0.18474\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32037\n",
      "kldivergence:   1715.10\n",
      "variational_beta * kldivergence:  0.17151\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31677\n",
      "kldivergence:   1862.56\n",
      "variational_beta * kldivergence:  0.18626\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29445\n",
      "kldivergence:   2214.96\n",
      "variational_beta * kldivergence:  0.22150\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31099\n",
      "kldivergence:   1607.00\n",
      "variational_beta * kldivergence:  0.16070\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34033\n",
      "kldivergence:   1834.87\n",
      "variational_beta * kldivergence:  0.18349\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38762\n",
      "kldivergence:   1916.29\n",
      "variational_beta * kldivergence:  0.19163\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32482\n",
      "kldivergence:   1824.48\n",
      "variational_beta * kldivergence:  0.18245\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30816\n",
      "kldivergence:   1715.13\n",
      "variational_beta * kldivergence:  0.17151\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32113\n",
      "kldivergence:   1777.79\n",
      "variational_beta * kldivergence:  0.17778\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32507\n",
      "kldivergence:   2091.04\n",
      "variational_beta * kldivergence:  0.20910\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.39563\n",
      "kldivergence:   1925.86\n",
      "variational_beta * kldivergence:  0.19259\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.30238\n",
      "kldivergence:   1797.92\n",
      "variational_beta * kldivergence:  0.17979\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34803\n",
      "kldivergence:   1892.45\n",
      "variational_beta * kldivergence:  0.18925\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34595\n",
      "kldivergence:   1748.71\n",
      "variational_beta * kldivergence:  0.17487\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32275\n",
      "kldivergence:   1842.58\n",
      "variational_beta * kldivergence:  0.18426\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.29643\n",
      "kldivergence:   1893.67\n",
      "variational_beta * kldivergence:  0.18937\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.40120\n",
      "kldivergence:   2170.94\n",
      "variational_beta * kldivergence:  0.21709\n",
      "batch accuracy: 86.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32183\n",
      "kldivergence:   1766.12\n",
      "variational_beta * kldivergence:  0.17661\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.38389\n",
      "kldivergence:   1835.03\n",
      "variational_beta * kldivergence:  0.18350\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34243\n",
      "kldivergence:   1747.85\n",
      "variational_beta * kldivergence:  0.17478\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.31035\n",
      "kldivergence:   1729.46\n",
      "variational_beta * kldivergence:  0.17295\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.37979\n",
      "kldivergence:   2114.98\n",
      "variational_beta * kldivergence:  0.21150\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.34781\n",
      "kldivergence:   1892.70\n",
      "variational_beta * kldivergence:  0.18927\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.35841\n",
      "kldivergence:   1798.98\n",
      "variational_beta * kldivergence:  0.17990\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.32835\n",
      "kldivergence:   1963.28\n",
      "variational_beta * kldivergence:  0.19633\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #1\n",
      "reconstruction loss: 0.36041\n",
      "kldivergence:   1824.47\n",
      "variational_beta * kldivergence:  0.18245\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.41601\n",
      "kldivergence:   1699.55\n",
      "variational_beta * kldivergence:  0.16996\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.44606\n",
      "kldivergence:   1726.06\n",
      "variational_beta * kldivergence:  0.17261\n",
      "batch accuracy: 86.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.38926\n",
      "kldivergence:   1643.12\n",
      "variational_beta * kldivergence:  0.16431\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.42744\n",
      "kldivergence:   1730.71\n",
      "variational_beta * kldivergence:  0.17307\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.44988\n",
      "kldivergence:   1755.46\n",
      "variational_beta * kldivergence:  0.17555\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.43042\n",
      "kldivergence:   1826.74\n",
      "variational_beta * kldivergence:  0.18267\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.47502\n",
      "kldivergence:   1810.92\n",
      "variational_beta * kldivergence:  0.18109\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.42809\n",
      "kldivergence:   1861.67\n",
      "variational_beta * kldivergence:  0.18617\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.40549\n",
      "kldivergence:   1609.68\n",
      "variational_beta * kldivergence:  0.16097\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.49113\n",
      "kldivergence:   1772.98\n",
      "variational_beta * kldivergence:  0.17730\n",
      "batch accuracy: 85.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.41793\n",
      "kldivergence:   1694.26\n",
      "variational_beta * kldivergence:  0.16943\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.45501\n",
      "kldivergence:   1769.68\n",
      "variational_beta * kldivergence:  0.17697\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.37925\n",
      "kldivergence:   1676.19\n",
      "variational_beta * kldivergence:  0.16762\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.54280\n",
      "kldivergence:   1933.08\n",
      "variational_beta * kldivergence:  0.19331\n",
      "batch accuracy: 84.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.45445\n",
      "kldivergence:   1689.12\n",
      "variational_beta * kldivergence:  0.16891\n",
      "batch accuracy: 85.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.54343\n",
      "kldivergence:   1908.83\n",
      "variational_beta * kldivergence:  0.19088\n",
      "batch accuracy: 83.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.45533\n",
      "kldivergence:   1884.07\n",
      "variational_beta * kldivergence:  0.18841\n",
      "batch accuracy: 85.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.36018\n",
      "kldivergence:   1511.94\n",
      "variational_beta * kldivergence:  0.15119\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.44663\n",
      "kldivergence:   1784.49\n",
      "variational_beta * kldivergence:  0.17845\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.44978\n",
      "kldivergence:   1819.82\n",
      "variational_beta * kldivergence:  0.18198\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.44678\n",
      "kldivergence:   1810.17\n",
      "variational_beta * kldivergence:  0.18102\n",
      "batch accuracy: 86.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.49959\n",
      "kldivergence:   1768.51\n",
      "variational_beta * kldivergence:  0.17685\n",
      "batch accuracy: 85.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.55093\n",
      "kldivergence:   1930.59\n",
      "variational_beta * kldivergence:  0.19306\n",
      "batch accuracy: 84.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.36864\n",
      "kldivergence:   1762.55\n",
      "variational_beta * kldivergence:  0.17626\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.46860\n",
      "kldivergence:   1835.93\n",
      "variational_beta * kldivergence:  0.18359\n",
      "batch accuracy: 84.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.54340\n",
      "kldivergence:   2044.38\n",
      "variational_beta * kldivergence:  0.20444\n",
      "batch accuracy: 83.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.41563\n",
      "kldivergence:   1789.71\n",
      "variational_beta * kldivergence:  0.17897\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.43404\n",
      "kldivergence:   1697.61\n",
      "variational_beta * kldivergence:  0.16976\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.46013\n",
      "kldivergence:   1826.17\n",
      "variational_beta * kldivergence:  0.18262\n",
      "batch accuracy: 85.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.50822\n",
      "kldivergence:   1852.88\n",
      "variational_beta * kldivergence:  0.18529\n",
      "batch accuracy: 84.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.50218\n",
      "kldivergence:   1952.50\n",
      "variational_beta * kldivergence:  0.19525\n",
      "batch accuracy: 84.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.41949\n",
      "kldivergence:   1733.73\n",
      "variational_beta * kldivergence:  0.17337\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.42986\n",
      "kldivergence:   1698.57\n",
      "variational_beta * kldivergence:  0.16986\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.44793\n",
      "kldivergence:   1757.14\n",
      "variational_beta * kldivergence:  0.17571\n",
      "batch accuracy: 86.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.44739\n",
      "kldivergence:   1731.80\n",
      "variational_beta * kldivergence:  0.17318\n",
      "batch accuracy: 86.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.48494\n",
      "kldivergence:   1744.31\n",
      "variational_beta * kldivergence:  0.17443\n",
      "batch accuracy: 85.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.54490\n",
      "kldivergence:   1892.61\n",
      "variational_beta * kldivergence:  0.18926\n",
      "batch accuracy: 83.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.48534\n",
      "kldivergence:   1808.81\n",
      "variational_beta * kldivergence:  0.18088\n",
      "batch accuracy: 84.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.41510\n",
      "kldivergence:   1728.30\n",
      "variational_beta * kldivergence:  0.17283\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.49368\n",
      "kldivergence:   1761.44\n",
      "variational_beta * kldivergence:  0.17614\n",
      "batch accuracy: 85.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.42261\n",
      "kldivergence:   1742.55\n",
      "variational_beta * kldivergence:  0.17425\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.45870\n",
      "kldivergence:   1752.22\n",
      "variational_beta * kldivergence:  0.17522\n",
      "batch accuracy: 86.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.43573\n",
      "kldivergence:   1784.60\n",
      "variational_beta * kldivergence:  0.17846\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.49554\n",
      "kldivergence:   1882.98\n",
      "variational_beta * kldivergence:  0.18830\n",
      "batch accuracy: 85.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.59158\n",
      "kldivergence:   1981.07\n",
      "variational_beta * kldivergence:  0.19811\n",
      "batch accuracy: 82.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.36881\n",
      "kldivergence:   1597.35\n",
      "variational_beta * kldivergence:  0.15973\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.48631\n",
      "kldivergence:   1812.96\n",
      "variational_beta * kldivergence:  0.18130\n",
      "batch accuracy: 85.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.43663\n",
      "kldivergence:   1784.11\n",
      "variational_beta * kldivergence:  0.17841\n",
      "batch accuracy: 86.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.39353\n",
      "kldivergence:   1627.85\n",
      "variational_beta * kldivergence:  0.16279\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.39024\n",
      "kldivergence:   1621.53\n",
      "variational_beta * kldivergence:  0.16215\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.49878\n",
      "kldivergence:   1736.65\n",
      "variational_beta * kldivergence:  0.17366\n",
      "batch accuracy: 85.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.43875\n",
      "kldivergence:   1778.61\n",
      "variational_beta * kldivergence:  0.17786\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.58159\n",
      "kldivergence:   1949.86\n",
      "variational_beta * kldivergence:  0.19499\n",
      "batch accuracy: 82.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.45310\n",
      "kldivergence:   1721.91\n",
      "variational_beta * kldivergence:  0.17219\n",
      "batch accuracy: 85.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.38667\n",
      "kldivergence:   1641.32\n",
      "variational_beta * kldivergence:  0.16413\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.41720\n",
      "kldivergence:   1772.38\n",
      "variational_beta * kldivergence:  0.17724\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.41208\n",
      "kldivergence:   1731.84\n",
      "variational_beta * kldivergence:  0.17318\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.41760\n",
      "kldivergence:   1666.72\n",
      "variational_beta * kldivergence:  0.16667\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.45675\n",
      "kldivergence:   1776.70\n",
      "variational_beta * kldivergence:  0.17767\n",
      "batch accuracy: 86.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.53452\n",
      "kldivergence:   1917.43\n",
      "variational_beta * kldivergence:  0.19174\n",
      "batch accuracy: 84.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.48448\n",
      "kldivergence:   1830.52\n",
      "variational_beta * kldivergence:  0.18305\n",
      "batch accuracy: 85.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #1\n",
      "reconstruction loss: 0.55908\n",
      "kldivergence:   1971.94\n",
      "variational_beta * kldivergence:  0.19719\n",
      "batch accuracy: 82.93\n",
      "\n",
      "\n",
      "epoch # 1 : train loss is [197.2111171493633] and validation loss is [0.10644122968381481] \n",
      "Epoch [2 / 150] average reconstruction error: 0.531566\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31801\n",
      "kldivergence:   2049.31\n",
      "variational_beta * kldivergence:  0.20493\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33577\n",
      "kldivergence:   1663.72\n",
      "variational_beta * kldivergence:  0.16637\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35590\n",
      "kldivergence:   2048.33\n",
      "variational_beta * kldivergence:  0.20483\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33498\n",
      "kldivergence:   1872.02\n",
      "variational_beta * kldivergence:  0.18720\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34076\n",
      "kldivergence:   1880.34\n",
      "variational_beta * kldivergence:  0.18803\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31112\n",
      "kldivergence:   1656.91\n",
      "variational_beta * kldivergence:  0.16569\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32474\n",
      "kldivergence:   2041.56\n",
      "variational_beta * kldivergence:  0.20416\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33298\n",
      "kldivergence:   2038.71\n",
      "variational_beta * kldivergence:  0.20387\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36250\n",
      "kldivergence:   2006.93\n",
      "variational_beta * kldivergence:  0.20069\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33871\n",
      "kldivergence:   2039.02\n",
      "variational_beta * kldivergence:  0.20390\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33509\n",
      "kldivergence:   1896.31\n",
      "variational_beta * kldivergence:  0.18963\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33545\n",
      "kldivergence:   2226.14\n",
      "variational_beta * kldivergence:  0.22261\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30245\n",
      "kldivergence:   1860.27\n",
      "variational_beta * kldivergence:  0.18603\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31468\n",
      "kldivergence:   1648.68\n",
      "variational_beta * kldivergence:  0.16487\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33702\n",
      "kldivergence:   1866.59\n",
      "variational_beta * kldivergence:  0.18666\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.26217\n",
      "kldivergence:   1985.63\n",
      "variational_beta * kldivergence:  0.19856\n",
      "batch accuracy: 91.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34589\n",
      "kldivergence:   1982.25\n",
      "variational_beta * kldivergence:  0.19823\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38474\n",
      "kldivergence:   1885.74\n",
      "variational_beta * kldivergence:  0.18857\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30330\n",
      "kldivergence:   1793.01\n",
      "variational_beta * kldivergence:  0.17930\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30768\n",
      "kldivergence:   1841.85\n",
      "variational_beta * kldivergence:  0.18418\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31069\n",
      "kldivergence:   1886.40\n",
      "variational_beta * kldivergence:  0.18864\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28628\n",
      "kldivergence:   1806.06\n",
      "variational_beta * kldivergence:  0.18061\n",
      "batch accuracy: 90.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37326\n",
      "kldivergence:   2036.23\n",
      "variational_beta * kldivergence:  0.20362\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32414\n",
      "kldivergence:   1753.31\n",
      "variational_beta * kldivergence:  0.17533\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37812\n",
      "kldivergence:   1981.88\n",
      "variational_beta * kldivergence:  0.19819\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32310\n",
      "kldivergence:   1858.16\n",
      "variational_beta * kldivergence:  0.18582\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37394\n",
      "kldivergence:   1714.83\n",
      "variational_beta * kldivergence:  0.17148\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30837\n",
      "kldivergence:   1810.78\n",
      "variational_beta * kldivergence:  0.18108\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35411\n",
      "kldivergence:   1952.54\n",
      "variational_beta * kldivergence:  0.19525\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35435\n",
      "kldivergence:   1991.79\n",
      "variational_beta * kldivergence:  0.19918\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34981\n",
      "kldivergence:   1936.43\n",
      "variational_beta * kldivergence:  0.19364\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33216\n",
      "kldivergence:   1702.63\n",
      "variational_beta * kldivergence:  0.17026\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36899\n",
      "kldivergence:   1698.46\n",
      "variational_beta * kldivergence:  0.16985\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37131\n",
      "kldivergence:   1986.99\n",
      "variational_beta * kldivergence:  0.19870\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32277\n",
      "kldivergence:   1784.43\n",
      "variational_beta * kldivergence:  0.17844\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32787\n",
      "kldivergence:   1739.83\n",
      "variational_beta * kldivergence:  0.17398\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28884\n",
      "kldivergence:   2015.43\n",
      "variational_beta * kldivergence:  0.20154\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35480\n",
      "kldivergence:   1901.48\n",
      "variational_beta * kldivergence:  0.19015\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30379\n",
      "kldivergence:   1820.00\n",
      "variational_beta * kldivergence:  0.18200\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.39348\n",
      "kldivergence:   2060.11\n",
      "variational_beta * kldivergence:  0.20601\n",
      "batch accuracy: 86.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37167\n",
      "kldivergence:   1962.81\n",
      "variational_beta * kldivergence:  0.19628\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32289\n",
      "kldivergence:   1687.12\n",
      "variational_beta * kldivergence:  0.16871\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29844\n",
      "kldivergence:   2043.64\n",
      "variational_beta * kldivergence:  0.20436\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35736\n",
      "kldivergence:   1668.49\n",
      "variational_beta * kldivergence:  0.16685\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34024\n",
      "kldivergence:   1847.08\n",
      "variational_beta * kldivergence:  0.18471\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37907\n",
      "kldivergence:   2256.37\n",
      "variational_beta * kldivergence:  0.22564\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30152\n",
      "kldivergence:   1729.14\n",
      "variational_beta * kldivergence:  0.17291\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35447\n",
      "kldivergence:   1848.46\n",
      "variational_beta * kldivergence:  0.18485\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37746\n",
      "kldivergence:   1784.63\n",
      "variational_beta * kldivergence:  0.17846\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37264\n",
      "kldivergence:   2106.29\n",
      "variational_beta * kldivergence:  0.21063\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30438\n",
      "kldivergence:   1600.37\n",
      "variational_beta * kldivergence:  0.16004\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.39793\n",
      "kldivergence:   1844.11\n",
      "variational_beta * kldivergence:  0.18441\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30339\n",
      "kldivergence:   1726.36\n",
      "variational_beta * kldivergence:  0.17264\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31591\n",
      "kldivergence:   1672.39\n",
      "variational_beta * kldivergence:  0.16724\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30488\n",
      "kldivergence:   1697.88\n",
      "variational_beta * kldivergence:  0.16979\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32369\n",
      "kldivergence:   1642.78\n",
      "variational_beta * kldivergence:  0.16428\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37302\n",
      "kldivergence:   2102.44\n",
      "variational_beta * kldivergence:  0.21024\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35616\n",
      "kldivergence:   1771.03\n",
      "variational_beta * kldivergence:  0.17710\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34576\n",
      "kldivergence:   1587.22\n",
      "variational_beta * kldivergence:  0.15872\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.39917\n",
      "kldivergence:   1829.04\n",
      "variational_beta * kldivergence:  0.18290\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32522\n",
      "kldivergence:   1780.28\n",
      "variational_beta * kldivergence:  0.17803\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31837\n",
      "kldivergence:   1831.30\n",
      "variational_beta * kldivergence:  0.18313\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37292\n",
      "kldivergence:   2155.17\n",
      "variational_beta * kldivergence:  0.21552\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33826\n",
      "kldivergence:   2062.75\n",
      "variational_beta * kldivergence:  0.20627\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29603\n",
      "kldivergence:   1863.87\n",
      "variational_beta * kldivergence:  0.18639\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29106\n",
      "kldivergence:   2240.96\n",
      "variational_beta * kldivergence:  0.22410\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35882\n",
      "kldivergence:   1817.46\n",
      "variational_beta * kldivergence:  0.18175\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31913\n",
      "kldivergence:   2196.98\n",
      "variational_beta * kldivergence:  0.21970\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36207\n",
      "kldivergence:   2044.66\n",
      "variational_beta * kldivergence:  0.20447\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30651\n",
      "kldivergence:   1758.67\n",
      "variational_beta * kldivergence:  0.17587\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29776\n",
      "kldivergence:   1925.80\n",
      "variational_beta * kldivergence:  0.19258\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32585\n",
      "kldivergence:   1767.18\n",
      "variational_beta * kldivergence:  0.17672\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31511\n",
      "kldivergence:   1780.02\n",
      "variational_beta * kldivergence:  0.17800\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28794\n",
      "kldivergence:   1655.17\n",
      "variational_beta * kldivergence:  0.16552\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.27466\n",
      "kldivergence:   1717.23\n",
      "variational_beta * kldivergence:  0.17172\n",
      "batch accuracy: 91.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32522\n",
      "kldivergence:   2032.45\n",
      "variational_beta * kldivergence:  0.20324\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31469\n",
      "kldivergence:   2045.97\n",
      "variational_beta * kldivergence:  0.20460\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38038\n",
      "kldivergence:   2183.67\n",
      "variational_beta * kldivergence:  0.21837\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33556\n",
      "kldivergence:   1676.31\n",
      "variational_beta * kldivergence:  0.16763\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31892\n",
      "kldivergence:   1734.70\n",
      "variational_beta * kldivergence:  0.17347\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.27595\n",
      "kldivergence:   1681.84\n",
      "variational_beta * kldivergence:  0.16818\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.27233\n",
      "kldivergence:   1731.82\n",
      "variational_beta * kldivergence:  0.17318\n",
      "batch accuracy: 90.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36502\n",
      "kldivergence:   1803.85\n",
      "variational_beta * kldivergence:  0.18038\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31819\n",
      "kldivergence:   1738.67\n",
      "variational_beta * kldivergence:  0.17387\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36315\n",
      "kldivergence:   1772.11\n",
      "variational_beta * kldivergence:  0.17721\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33182\n",
      "kldivergence:   1663.85\n",
      "variational_beta * kldivergence:  0.16639\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36794\n",
      "kldivergence:   1970.71\n",
      "variational_beta * kldivergence:  0.19707\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35708\n",
      "kldivergence:   1837.24\n",
      "variational_beta * kldivergence:  0.18372\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.27479\n",
      "kldivergence:   1679.41\n",
      "variational_beta * kldivergence:  0.16794\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33417\n",
      "kldivergence:   2020.78\n",
      "variational_beta * kldivergence:  0.20208\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32518\n",
      "kldivergence:   1667.71\n",
      "variational_beta * kldivergence:  0.16677\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30498\n",
      "kldivergence:   1688.29\n",
      "variational_beta * kldivergence:  0.16883\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35001\n",
      "kldivergence:   1696.69\n",
      "variational_beta * kldivergence:  0.16967\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36712\n",
      "kldivergence:   1866.11\n",
      "variational_beta * kldivergence:  0.18661\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35242\n",
      "kldivergence:   1778.99\n",
      "variational_beta * kldivergence:  0.17790\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31566\n",
      "kldivergence:   1996.19\n",
      "variational_beta * kldivergence:  0.19962\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35854\n",
      "kldivergence:   1773.56\n",
      "variational_beta * kldivergence:  0.17736\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32542\n",
      "kldivergence:   1881.13\n",
      "variational_beta * kldivergence:  0.18811\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37583\n",
      "kldivergence:   2114.03\n",
      "variational_beta * kldivergence:  0.21140\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37355\n",
      "kldivergence:   2024.37\n",
      "variational_beta * kldivergence:  0.20244\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33432\n",
      "kldivergence:   1994.64\n",
      "variational_beta * kldivergence:  0.19946\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30717\n",
      "kldivergence:   1833.64\n",
      "variational_beta * kldivergence:  0.18336\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33593\n",
      "kldivergence:   1970.01\n",
      "variational_beta * kldivergence:  0.19700\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29831\n",
      "kldivergence:   1587.42\n",
      "variational_beta * kldivergence:  0.15874\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32775\n",
      "kldivergence:   1710.82\n",
      "variational_beta * kldivergence:  0.17108\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30876\n",
      "kldivergence:   1545.08\n",
      "variational_beta * kldivergence:  0.15451\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32645\n",
      "kldivergence:   1940.93\n",
      "variational_beta * kldivergence:  0.19409\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33696\n",
      "kldivergence:   1590.40\n",
      "variational_beta * kldivergence:  0.15904\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33120\n",
      "kldivergence:   2201.96\n",
      "variational_beta * kldivergence:  0.22020\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33773\n",
      "kldivergence:   1840.07\n",
      "variational_beta * kldivergence:  0.18401\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36855\n",
      "kldivergence:   1666.24\n",
      "variational_beta * kldivergence:  0.16662\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32939\n",
      "kldivergence:   1554.65\n",
      "variational_beta * kldivergence:  0.15546\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28205\n",
      "kldivergence:   1527.81\n",
      "variational_beta * kldivergence:  0.15278\n",
      "batch accuracy: 91.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36305\n",
      "kldivergence:   1907.43\n",
      "variational_beta * kldivergence:  0.19074\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34227\n",
      "kldivergence:   2145.82\n",
      "variational_beta * kldivergence:  0.21458\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32717\n",
      "kldivergence:   1711.42\n",
      "variational_beta * kldivergence:  0.17114\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35290\n",
      "kldivergence:   1750.72\n",
      "variational_beta * kldivergence:  0.17507\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35319\n",
      "kldivergence:   1698.71\n",
      "variational_beta * kldivergence:  0.16987\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32109\n",
      "kldivergence:   1672.75\n",
      "variational_beta * kldivergence:  0.16728\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37577\n",
      "kldivergence:   1735.81\n",
      "variational_beta * kldivergence:  0.17358\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.40036\n",
      "kldivergence:   1813.91\n",
      "variational_beta * kldivergence:  0.18139\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30200\n",
      "kldivergence:   1844.34\n",
      "variational_beta * kldivergence:  0.18443\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34683\n",
      "kldivergence:   2450.12\n",
      "variational_beta * kldivergence:  0.24501\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36672\n",
      "kldivergence:   1886.24\n",
      "variational_beta * kldivergence:  0.18862\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30463\n",
      "kldivergence:   1734.02\n",
      "variational_beta * kldivergence:  0.17340\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35245\n",
      "kldivergence:   1822.40\n",
      "variational_beta * kldivergence:  0.18224\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30388\n",
      "kldivergence:   1685.17\n",
      "variational_beta * kldivergence:  0.16852\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29984\n",
      "kldivergence:   1849.25\n",
      "variational_beta * kldivergence:  0.18493\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35139\n",
      "kldivergence:   1731.09\n",
      "variational_beta * kldivergence:  0.17311\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35236\n",
      "kldivergence:   1893.06\n",
      "variational_beta * kldivergence:  0.18931\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28238\n",
      "kldivergence:   1703.50\n",
      "variational_beta * kldivergence:  0.17035\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31415\n",
      "kldivergence:   1954.57\n",
      "variational_beta * kldivergence:  0.19546\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38958\n",
      "kldivergence:   2046.93\n",
      "variational_beta * kldivergence:  0.20469\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33653\n",
      "kldivergence:   1797.40\n",
      "variational_beta * kldivergence:  0.17974\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34591\n",
      "kldivergence:   2095.24\n",
      "variational_beta * kldivergence:  0.20952\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28876\n",
      "kldivergence:   1837.81\n",
      "variational_beta * kldivergence:  0.18378\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33933\n",
      "kldivergence:   1870.38\n",
      "variational_beta * kldivergence:  0.18704\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33613\n",
      "kldivergence:   1803.11\n",
      "variational_beta * kldivergence:  0.18031\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34075\n",
      "kldivergence:   1952.30\n",
      "variational_beta * kldivergence:  0.19523\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29626\n",
      "kldivergence:   1843.37\n",
      "variational_beta * kldivergence:  0.18434\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33121\n",
      "kldivergence:   1823.70\n",
      "variational_beta * kldivergence:  0.18237\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37377\n",
      "kldivergence:   1881.73\n",
      "variational_beta * kldivergence:  0.18817\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30692\n",
      "kldivergence:   1990.13\n",
      "variational_beta * kldivergence:  0.19901\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33048\n",
      "kldivergence:   1810.94\n",
      "variational_beta * kldivergence:  0.18109\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35186\n",
      "kldivergence:   1887.58\n",
      "variational_beta * kldivergence:  0.18876\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35115\n",
      "kldivergence:   1885.45\n",
      "variational_beta * kldivergence:  0.18854\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37185\n",
      "kldivergence:   2275.70\n",
      "variational_beta * kldivergence:  0.22757\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35805\n",
      "kldivergence:   1595.77\n",
      "variational_beta * kldivergence:  0.15958\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30570\n",
      "kldivergence:   1680.47\n",
      "variational_beta * kldivergence:  0.16805\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35122\n",
      "kldivergence:   2074.12\n",
      "variational_beta * kldivergence:  0.20741\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33013\n",
      "kldivergence:   1881.63\n",
      "variational_beta * kldivergence:  0.18816\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35464\n",
      "kldivergence:   1752.06\n",
      "variational_beta * kldivergence:  0.17521\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37629\n",
      "kldivergence:   1897.53\n",
      "variational_beta * kldivergence:  0.18975\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34748\n",
      "kldivergence:   2202.73\n",
      "variational_beta * kldivergence:  0.22027\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.25688\n",
      "kldivergence:   1708.23\n",
      "variational_beta * kldivergence:  0.17082\n",
      "batch accuracy: 91.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30273\n",
      "kldivergence:   1737.62\n",
      "variational_beta * kldivergence:  0.17376\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30425\n",
      "kldivergence:   1742.08\n",
      "variational_beta * kldivergence:  0.17421\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32600\n",
      "kldivergence:   1948.36\n",
      "variational_beta * kldivergence:  0.19484\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.39839\n",
      "kldivergence:   1905.39\n",
      "variational_beta * kldivergence:  0.19054\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28051\n",
      "kldivergence:   1941.41\n",
      "variational_beta * kldivergence:  0.19414\n",
      "batch accuracy: 91.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33514\n",
      "kldivergence:   2040.36\n",
      "variational_beta * kldivergence:  0.20404\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36262\n",
      "kldivergence:   2009.00\n",
      "variational_beta * kldivergence:  0.20090\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38287\n",
      "kldivergence:   1907.73\n",
      "variational_beta * kldivergence:  0.19077\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32131\n",
      "kldivergence:   1817.24\n",
      "variational_beta * kldivergence:  0.18172\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37678\n",
      "kldivergence:   1762.94\n",
      "variational_beta * kldivergence:  0.17629\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30796\n",
      "kldivergence:   1974.61\n",
      "variational_beta * kldivergence:  0.19746\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29808\n",
      "kldivergence:   1648.04\n",
      "variational_beta * kldivergence:  0.16480\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32616\n",
      "kldivergence:   2173.37\n",
      "variational_beta * kldivergence:  0.21734\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35872\n",
      "kldivergence:   2087.69\n",
      "variational_beta * kldivergence:  0.20877\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34267\n",
      "kldivergence:   1838.12\n",
      "variational_beta * kldivergence:  0.18381\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36764\n",
      "kldivergence:   2099.47\n",
      "variational_beta * kldivergence:  0.20995\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.39875\n",
      "kldivergence:   1986.17\n",
      "variational_beta * kldivergence:  0.19862\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31260\n",
      "kldivergence:   2248.03\n",
      "variational_beta * kldivergence:  0.22480\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32761\n",
      "kldivergence:   1916.95\n",
      "variational_beta * kldivergence:  0.19170\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38515\n",
      "kldivergence:   1886.92\n",
      "variational_beta * kldivergence:  0.18869\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30460\n",
      "kldivergence:   1913.38\n",
      "variational_beta * kldivergence:  0.19134\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33390\n",
      "kldivergence:   2063.12\n",
      "variational_beta * kldivergence:  0.20631\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33986\n",
      "kldivergence:   1918.08\n",
      "variational_beta * kldivergence:  0.19181\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33319\n",
      "kldivergence:   2017.44\n",
      "variational_beta * kldivergence:  0.20174\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30995\n",
      "kldivergence:   1879.30\n",
      "variational_beta * kldivergence:  0.18793\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34907\n",
      "kldivergence:   1982.54\n",
      "variational_beta * kldivergence:  0.19825\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35566\n",
      "kldivergence:   2085.54\n",
      "variational_beta * kldivergence:  0.20855\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32021\n",
      "kldivergence:   2014.46\n",
      "variational_beta * kldivergence:  0.20145\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38126\n",
      "kldivergence:   2034.42\n",
      "variational_beta * kldivergence:  0.20344\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37243\n",
      "kldivergence:   1863.64\n",
      "variational_beta * kldivergence:  0.18636\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33834\n",
      "kldivergence:   2041.38\n",
      "variational_beta * kldivergence:  0.20414\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33955\n",
      "kldivergence:   1724.85\n",
      "variational_beta * kldivergence:  0.17248\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36589\n",
      "kldivergence:   1763.72\n",
      "variational_beta * kldivergence:  0.17637\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32515\n",
      "kldivergence:   1900.68\n",
      "variational_beta * kldivergence:  0.19007\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33403\n",
      "kldivergence:   1896.98\n",
      "variational_beta * kldivergence:  0.18970\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35389\n",
      "kldivergence:   2210.59\n",
      "variational_beta * kldivergence:  0.22106\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.27685\n",
      "kldivergence:   1821.44\n",
      "variational_beta * kldivergence:  0.18214\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32288\n",
      "kldivergence:   1972.06\n",
      "variational_beta * kldivergence:  0.19721\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35761\n",
      "kldivergence:   1847.44\n",
      "variational_beta * kldivergence:  0.18474\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33915\n",
      "kldivergence:   1819.25\n",
      "variational_beta * kldivergence:  0.18192\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35182\n",
      "kldivergence:   1880.20\n",
      "variational_beta * kldivergence:  0.18802\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35754\n",
      "kldivergence:   2270.16\n",
      "variational_beta * kldivergence:  0.22702\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36387\n",
      "kldivergence:   1759.37\n",
      "variational_beta * kldivergence:  0.17594\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35566\n",
      "kldivergence:   1715.75\n",
      "variational_beta * kldivergence:  0.17157\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29784\n",
      "kldivergence:   1697.26\n",
      "variational_beta * kldivergence:  0.16973\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32204\n",
      "kldivergence:   1829.30\n",
      "variational_beta * kldivergence:  0.18293\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38075\n",
      "kldivergence:   1914.42\n",
      "variational_beta * kldivergence:  0.19144\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33301\n",
      "kldivergence:   1810.95\n",
      "variational_beta * kldivergence:  0.18110\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36942\n",
      "kldivergence:   1763.13\n",
      "variational_beta * kldivergence:  0.17631\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28355\n",
      "kldivergence:   1854.10\n",
      "variational_beta * kldivergence:  0.18541\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.39124\n",
      "kldivergence:   2097.81\n",
      "variational_beta * kldivergence:  0.20978\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31928\n",
      "kldivergence:   1769.53\n",
      "variational_beta * kldivergence:  0.17695\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31219\n",
      "kldivergence:   1657.36\n",
      "variational_beta * kldivergence:  0.16574\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33550\n",
      "kldivergence:   1721.62\n",
      "variational_beta * kldivergence:  0.17216\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38561\n",
      "kldivergence:   1796.69\n",
      "variational_beta * kldivergence:  0.17967\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37161\n",
      "kldivergence:   1842.31\n",
      "variational_beta * kldivergence:  0.18423\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34245\n",
      "kldivergence:   1953.76\n",
      "variational_beta * kldivergence:  0.19538\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.39318\n",
      "kldivergence:   2051.56\n",
      "variational_beta * kldivergence:  0.20516\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33592\n",
      "kldivergence:   1912.37\n",
      "variational_beta * kldivergence:  0.19124\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36006\n",
      "kldivergence:   1906.04\n",
      "variational_beta * kldivergence:  0.19060\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35419\n",
      "kldivergence:   1779.09\n",
      "variational_beta * kldivergence:  0.17791\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31484\n",
      "kldivergence:   1764.51\n",
      "variational_beta * kldivergence:  0.17645\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37004\n",
      "kldivergence:   1818.43\n",
      "variational_beta * kldivergence:  0.18184\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.42027\n",
      "kldivergence:   1736.50\n",
      "variational_beta * kldivergence:  0.17365\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35513\n",
      "kldivergence:   2110.64\n",
      "variational_beta * kldivergence:  0.21106\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30198\n",
      "kldivergence:   1779.16\n",
      "variational_beta * kldivergence:  0.17792\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28998\n",
      "kldivergence:   1539.27\n",
      "variational_beta * kldivergence:  0.15393\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.25772\n",
      "kldivergence:   1592.98\n",
      "variational_beta * kldivergence:  0.15930\n",
      "batch accuracy: 91.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.40567\n",
      "kldivergence:   1999.98\n",
      "variational_beta * kldivergence:  0.20000\n",
      "batch accuracy: 85.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34015\n",
      "kldivergence:   1850.39\n",
      "variational_beta * kldivergence:  0.18504\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29504\n",
      "kldivergence:   1672.84\n",
      "variational_beta * kldivergence:  0.16728\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32312\n",
      "kldivergence:   1829.87\n",
      "variational_beta * kldivergence:  0.18299\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32379\n",
      "kldivergence:   1873.93\n",
      "variational_beta * kldivergence:  0.18739\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31598\n",
      "kldivergence:   1909.24\n",
      "variational_beta * kldivergence:  0.19092\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30684\n",
      "kldivergence:   1692.21\n",
      "variational_beta * kldivergence:  0.16922\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31360\n",
      "kldivergence:   1950.56\n",
      "variational_beta * kldivergence:  0.19506\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.39011\n",
      "kldivergence:   1868.18\n",
      "variational_beta * kldivergence:  0.18682\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33122\n",
      "kldivergence:   1820.35\n",
      "variational_beta * kldivergence:  0.18204\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36140\n",
      "kldivergence:   1858.41\n",
      "variational_beta * kldivergence:  0.18584\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35240\n",
      "kldivergence:   1932.38\n",
      "variational_beta * kldivergence:  0.19324\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33373\n",
      "kldivergence:   1888.96\n",
      "variational_beta * kldivergence:  0.18890\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32551\n",
      "kldivergence:   1757.37\n",
      "variational_beta * kldivergence:  0.17574\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34879\n",
      "kldivergence:   1827.79\n",
      "variational_beta * kldivergence:  0.18278\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38077\n",
      "kldivergence:   1868.69\n",
      "variational_beta * kldivergence:  0.18687\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34049\n",
      "kldivergence:   2120.73\n",
      "variational_beta * kldivergence:  0.21207\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34923\n",
      "kldivergence:   1890.65\n",
      "variational_beta * kldivergence:  0.18906\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36544\n",
      "kldivergence:   1897.95\n",
      "variational_beta * kldivergence:  0.18980\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37387\n",
      "kldivergence:   2152.95\n",
      "variational_beta * kldivergence:  0.21530\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36699\n",
      "kldivergence:   1900.10\n",
      "variational_beta * kldivergence:  0.19001\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37257\n",
      "kldivergence:   2169.07\n",
      "variational_beta * kldivergence:  0.21691\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34490\n",
      "kldivergence:   1827.94\n",
      "variational_beta * kldivergence:  0.18279\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.39576\n",
      "kldivergence:   1771.88\n",
      "variational_beta * kldivergence:  0.17719\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33386\n",
      "kldivergence:   1678.35\n",
      "variational_beta * kldivergence:  0.16784\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31496\n",
      "kldivergence:   1654.41\n",
      "variational_beta * kldivergence:  0.16544\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32967\n",
      "kldivergence:   1940.35\n",
      "variational_beta * kldivergence:  0.19403\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38244\n",
      "kldivergence:   1929.55\n",
      "variational_beta * kldivergence:  0.19295\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37114\n",
      "kldivergence:   1868.13\n",
      "variational_beta * kldivergence:  0.18681\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34147\n",
      "kldivergence:   1663.18\n",
      "variational_beta * kldivergence:  0.16632\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33691\n",
      "kldivergence:   1629.06\n",
      "variational_beta * kldivergence:  0.16291\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33255\n",
      "kldivergence:   2027.10\n",
      "variational_beta * kldivergence:  0.20271\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29207\n",
      "kldivergence:   1662.29\n",
      "variational_beta * kldivergence:  0.16623\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38074\n",
      "kldivergence:   1859.78\n",
      "variational_beta * kldivergence:  0.18598\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31559\n",
      "kldivergence:   1678.48\n",
      "variational_beta * kldivergence:  0.16785\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34901\n",
      "kldivergence:   1864.56\n",
      "variational_beta * kldivergence:  0.18646\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35375\n",
      "kldivergence:   1772.55\n",
      "variational_beta * kldivergence:  0.17726\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31176\n",
      "kldivergence:   1830.92\n",
      "variational_beta * kldivergence:  0.18309\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34752\n",
      "kldivergence:   1785.46\n",
      "variational_beta * kldivergence:  0.17855\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31533\n",
      "kldivergence:   1754.03\n",
      "variational_beta * kldivergence:  0.17540\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34251\n",
      "kldivergence:   1812.36\n",
      "variational_beta * kldivergence:  0.18124\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34112\n",
      "kldivergence:   1965.17\n",
      "variational_beta * kldivergence:  0.19652\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32424\n",
      "kldivergence:   1782.42\n",
      "variational_beta * kldivergence:  0.17824\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33890\n",
      "kldivergence:   1844.83\n",
      "variational_beta * kldivergence:  0.18448\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35882\n",
      "kldivergence:   1948.75\n",
      "variational_beta * kldivergence:  0.19488\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35768\n",
      "kldivergence:   1936.88\n",
      "variational_beta * kldivergence:  0.19369\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35595\n",
      "kldivergence:   1806.34\n",
      "variational_beta * kldivergence:  0.18063\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33117\n",
      "kldivergence:   1923.04\n",
      "variational_beta * kldivergence:  0.19230\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32272\n",
      "kldivergence:   2042.89\n",
      "variational_beta * kldivergence:  0.20429\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32601\n",
      "kldivergence:   1752.15\n",
      "variational_beta * kldivergence:  0.17521\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30963\n",
      "kldivergence:   1960.68\n",
      "variational_beta * kldivergence:  0.19607\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38040\n",
      "kldivergence:   1925.33\n",
      "variational_beta * kldivergence:  0.19253\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33669\n",
      "kldivergence:   1796.22\n",
      "variational_beta * kldivergence:  0.17962\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.37507\n",
      "kldivergence:   1932.15\n",
      "variational_beta * kldivergence:  0.19322\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35941\n",
      "kldivergence:   1831.48\n",
      "variational_beta * kldivergence:  0.18315\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34509\n",
      "kldivergence:   1893.36\n",
      "variational_beta * kldivergence:  0.18934\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35818\n",
      "kldivergence:   1752.24\n",
      "variational_beta * kldivergence:  0.17522\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34719\n",
      "kldivergence:   1880.26\n",
      "variational_beta * kldivergence:  0.18803\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.27787\n",
      "kldivergence:   1684.25\n",
      "variational_beta * kldivergence:  0.16843\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29479\n",
      "kldivergence:   1892.11\n",
      "variational_beta * kldivergence:  0.18921\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35662\n",
      "kldivergence:   2052.78\n",
      "variational_beta * kldivergence:  0.20528\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31744\n",
      "kldivergence:   1703.95\n",
      "variational_beta * kldivergence:  0.17039\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33120\n",
      "kldivergence:   1719.23\n",
      "variational_beta * kldivergence:  0.17192\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36954\n",
      "kldivergence:   1964.40\n",
      "variational_beta * kldivergence:  0.19644\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.29368\n",
      "kldivergence:   1777.08\n",
      "variational_beta * kldivergence:  0.17771\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31356\n",
      "kldivergence:   1767.99\n",
      "variational_beta * kldivergence:  0.17680\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34152\n",
      "kldivergence:   1789.13\n",
      "variational_beta * kldivergence:  0.17891\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33164\n",
      "kldivergence:   1675.19\n",
      "variational_beta * kldivergence:  0.16752\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34358\n",
      "kldivergence:   1736.44\n",
      "variational_beta * kldivergence:  0.17364\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30034\n",
      "kldivergence:   1860.01\n",
      "variational_beta * kldivergence:  0.18600\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33487\n",
      "kldivergence:   1592.65\n",
      "variational_beta * kldivergence:  0.15926\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32243\n",
      "kldivergence:   1898.60\n",
      "variational_beta * kldivergence:  0.18986\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32783\n",
      "kldivergence:   1848.83\n",
      "variational_beta * kldivergence:  0.18488\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31165\n",
      "kldivergence:   1719.56\n",
      "variational_beta * kldivergence:  0.17196\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38211\n",
      "kldivergence:   2109.55\n",
      "variational_beta * kldivergence:  0.21096\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32123\n",
      "kldivergence:   1888.36\n",
      "variational_beta * kldivergence:  0.18884\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.30729\n",
      "kldivergence:   1845.43\n",
      "variational_beta * kldivergence:  0.18454\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32411\n",
      "kldivergence:   1628.77\n",
      "variational_beta * kldivergence:  0.16288\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38499\n",
      "kldivergence:   1956.79\n",
      "variational_beta * kldivergence:  0.19568\n",
      "batch accuracy: 86.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.41508\n",
      "kldivergence:   1979.07\n",
      "variational_beta * kldivergence:  0.19791\n",
      "batch accuracy: 86.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36385\n",
      "kldivergence:   1893.75\n",
      "variational_beta * kldivergence:  0.18937\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36436\n",
      "kldivergence:   2067.25\n",
      "variational_beta * kldivergence:  0.20672\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.38275\n",
      "kldivergence:   2178.65\n",
      "variational_beta * kldivergence:  0.21786\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.31885\n",
      "kldivergence:   1771.79\n",
      "variational_beta * kldivergence:  0.17718\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35713\n",
      "kldivergence:   1702.35\n",
      "variational_beta * kldivergence:  0.17023\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.34175\n",
      "kldivergence:   2062.08\n",
      "variational_beta * kldivergence:  0.20621\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33754\n",
      "kldivergence:   2209.35\n",
      "variational_beta * kldivergence:  0.22094\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33796\n",
      "kldivergence:   2320.13\n",
      "variational_beta * kldivergence:  0.23201\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.45545\n",
      "kldivergence:   2046.13\n",
      "variational_beta * kldivergence:  0.20461\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36989\n",
      "kldivergence:   2264.74\n",
      "variational_beta * kldivergence:  0.22647\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28902\n",
      "kldivergence:   1899.82\n",
      "variational_beta * kldivergence:  0.18998\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.36085\n",
      "kldivergence:   2207.12\n",
      "variational_beta * kldivergence:  0.22071\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.25406\n",
      "kldivergence:   1670.82\n",
      "variational_beta * kldivergence:  0.16708\n",
      "batch accuracy: 91.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.28785\n",
      "kldivergence:   2021.39\n",
      "variational_beta * kldivergence:  0.20214\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.32394\n",
      "kldivergence:   1987.33\n",
      "variational_beta * kldivergence:  0.19873\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.35289\n",
      "kldivergence:   2015.00\n",
      "variational_beta * kldivergence:  0.20150\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33107\n",
      "kldivergence:   2186.93\n",
      "variational_beta * kldivergence:  0.21869\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #2\n",
      "reconstruction loss: 0.33275\n",
      "kldivergence:   2167.10\n",
      "variational_beta * kldivergence:  0.21671\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.52944\n",
      "kldivergence:   2092.99\n",
      "variational_beta * kldivergence:  0.20930\n",
      "batch accuracy: 84.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.55591\n",
      "kldivergence:   2090.03\n",
      "variational_beta * kldivergence:  0.20900\n",
      "batch accuracy: 83.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.51992\n",
      "kldivergence:   2134.45\n",
      "variational_beta * kldivergence:  0.21345\n",
      "batch accuracy: 84.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.52922\n",
      "kldivergence:   2088.90\n",
      "variational_beta * kldivergence:  0.20889\n",
      "batch accuracy: 84.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.49599\n",
      "kldivergence:   2007.23\n",
      "variational_beta * kldivergence:  0.20072\n",
      "batch accuracy: 85.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.50164\n",
      "kldivergence:   2128.70\n",
      "variational_beta * kldivergence:  0.21287\n",
      "batch accuracy: 84.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.41454\n",
      "kldivergence:   1813.54\n",
      "variational_beta * kldivergence:  0.18135\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.52043\n",
      "kldivergence:   2142.11\n",
      "variational_beta * kldivergence:  0.21421\n",
      "batch accuracy: 84.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.45644\n",
      "kldivergence:   1934.63\n",
      "variational_beta * kldivergence:  0.19346\n",
      "batch accuracy: 86.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.48890\n",
      "kldivergence:   1766.80\n",
      "variational_beta * kldivergence:  0.17668\n",
      "batch accuracy: 85.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.43702\n",
      "kldivergence:   1931.90\n",
      "variational_beta * kldivergence:  0.19319\n",
      "batch accuracy: 86.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.51509\n",
      "kldivergence:   2052.31\n",
      "variational_beta * kldivergence:  0.20523\n",
      "batch accuracy: 84.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.45408\n",
      "kldivergence:   2123.56\n",
      "variational_beta * kldivergence:  0.21236\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.55020\n",
      "kldivergence:   2137.42\n",
      "variational_beta * kldivergence:  0.21374\n",
      "batch accuracy: 83.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.45633\n",
      "kldivergence:   2157.73\n",
      "variational_beta * kldivergence:  0.21577\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.48864\n",
      "kldivergence:   1747.15\n",
      "variational_beta * kldivergence:  0.17472\n",
      "batch accuracy: 85.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.49647\n",
      "kldivergence:   2135.58\n",
      "variational_beta * kldivergence:  0.21356\n",
      "batch accuracy: 85.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.45815\n",
      "kldivergence:   1862.41\n",
      "variational_beta * kldivergence:  0.18624\n",
      "batch accuracy: 85.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.51329\n",
      "kldivergence:   2063.97\n",
      "variational_beta * kldivergence:  0.20640\n",
      "batch accuracy: 84.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.48381\n",
      "kldivergence:   2007.25\n",
      "variational_beta * kldivergence:  0.20072\n",
      "batch accuracy: 85.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.41127\n",
      "kldivergence:   1848.19\n",
      "variational_beta * kldivergence:  0.18482\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.38285\n",
      "kldivergence:   1877.62\n",
      "variational_beta * kldivergence:  0.18776\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.40212\n",
      "kldivergence:   1796.41\n",
      "variational_beta * kldivergence:  0.17964\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.50437\n",
      "kldivergence:   1936.77\n",
      "variational_beta * kldivergence:  0.19368\n",
      "batch accuracy: 85.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.45124\n",
      "kldivergence:   1991.42\n",
      "variational_beta * kldivergence:  0.19914\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.43736\n",
      "kldivergence:   1783.36\n",
      "variational_beta * kldivergence:  0.17834\n",
      "batch accuracy: 86.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.43624\n",
      "kldivergence:   1799.94\n",
      "variational_beta * kldivergence:  0.17999\n",
      "batch accuracy: 86.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.56606\n",
      "kldivergence:   2038.41\n",
      "variational_beta * kldivergence:  0.20384\n",
      "batch accuracy: 84.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.45906\n",
      "kldivergence:   1970.40\n",
      "variational_beta * kldivergence:  0.19704\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.55233\n",
      "kldivergence:   2054.48\n",
      "variational_beta * kldivergence:  0.20545\n",
      "batch accuracy: 83.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.57449\n",
      "kldivergence:   2026.93\n",
      "variational_beta * kldivergence:  0.20269\n",
      "batch accuracy: 83.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.54673\n",
      "kldivergence:   2035.74\n",
      "variational_beta * kldivergence:  0.20357\n",
      "batch accuracy: 83.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.45532\n",
      "kldivergence:   1922.78\n",
      "variational_beta * kldivergence:  0.19228\n",
      "batch accuracy: 85.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.41376\n",
      "kldivergence:   1689.15\n",
      "variational_beta * kldivergence:  0.16892\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.55302\n",
      "kldivergence:   2108.46\n",
      "variational_beta * kldivergence:  0.21085\n",
      "batch accuracy: 83.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.45216\n",
      "kldivergence:   1828.71\n",
      "variational_beta * kldivergence:  0.18287\n",
      "batch accuracy: 86.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.48168\n",
      "kldivergence:   1984.37\n",
      "variational_beta * kldivergence:  0.19844\n",
      "batch accuracy: 85.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.68203\n",
      "kldivergence:   2415.40\n",
      "variational_beta * kldivergence:  0.24154\n",
      "batch accuracy: 79.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.44531\n",
      "kldivergence:   1908.98\n",
      "variational_beta * kldivergence:  0.19090\n",
      "batch accuracy: 86.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.41567\n",
      "kldivergence:   1924.70\n",
      "variational_beta * kldivergence:  0.19247\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.46082\n",
      "kldivergence:   1929.92\n",
      "variational_beta * kldivergence:  0.19299\n",
      "batch accuracy: 85.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.43748\n",
      "kldivergence:   1863.04\n",
      "variational_beta * kldivergence:  0.18630\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.43046\n",
      "kldivergence:   1805.33\n",
      "variational_beta * kldivergence:  0.18053\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.48051\n",
      "kldivergence:   2129.73\n",
      "variational_beta * kldivergence:  0.21297\n",
      "batch accuracy: 84.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.52062\n",
      "kldivergence:   1820.73\n",
      "variational_beta * kldivergence:  0.18207\n",
      "batch accuracy: 84.69\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.60645\n",
      "kldivergence:   2181.83\n",
      "variational_beta * kldivergence:  0.21818\n",
      "batch accuracy: 84.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.50481\n",
      "kldivergence:   2032.50\n",
      "variational_beta * kldivergence:  0.20325\n",
      "batch accuracy: 84.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.49109\n",
      "kldivergence:   2058.70\n",
      "variational_beta * kldivergence:  0.20587\n",
      "batch accuracy: 84.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.44701\n",
      "kldivergence:   1944.54\n",
      "variational_beta * kldivergence:  0.19445\n",
      "batch accuracy: 86.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.45434\n",
      "kldivergence:   2051.25\n",
      "variational_beta * kldivergence:  0.20512\n",
      "batch accuracy: 85.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.60307\n",
      "kldivergence:   2060.49\n",
      "variational_beta * kldivergence:  0.20605\n",
      "batch accuracy: 81.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.40132\n",
      "kldivergence:   1800.39\n",
      "variational_beta * kldivergence:  0.18004\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.44531\n",
      "kldivergence:   1857.24\n",
      "variational_beta * kldivergence:  0.18572\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.45046\n",
      "kldivergence:   1795.66\n",
      "variational_beta * kldivergence:  0.17957\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.38985\n",
      "kldivergence:   1847.18\n",
      "variational_beta * kldivergence:  0.18472\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.51085\n",
      "kldivergence:   2071.28\n",
      "variational_beta * kldivergence:  0.20713\n",
      "batch accuracy: 84.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.44539\n",
      "kldivergence:   2009.89\n",
      "variational_beta * kldivergence:  0.20099\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.46472\n",
      "kldivergence:   1988.93\n",
      "variational_beta * kldivergence:  0.19889\n",
      "batch accuracy: 86.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.42058\n",
      "kldivergence:   1989.48\n",
      "variational_beta * kldivergence:  0.19895\n",
      "batch accuracy: 87.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.46819\n",
      "kldivergence:   1914.00\n",
      "variational_beta * kldivergence:  0.19140\n",
      "batch accuracy: 85.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.50641\n",
      "kldivergence:   2009.94\n",
      "variational_beta * kldivergence:  0.20099\n",
      "batch accuracy: 85.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #2\n",
      "reconstruction loss: 0.51993\n",
      "kldivergence:   2036.43\n",
      "variational_beta * kldivergence:  0.20364\n",
      "batch accuracy: 84.39\n",
      "\n",
      "\n",
      "epoch # 2 : train loss is [195.19390309041984] and validation loss is [0.11404489306132926] \n",
      "Epoch [3 / 150] average reconstruction error: 0.526129\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29956\n",
      "kldivergence:   2067.46\n",
      "variational_beta * kldivergence:  0.20675\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35232\n",
      "kldivergence:   2334.69\n",
      "variational_beta * kldivergence:  0.23347\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35823\n",
      "kldivergence:   2153.75\n",
      "variational_beta * kldivergence:  0.21538\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35737\n",
      "kldivergence:   1981.90\n",
      "variational_beta * kldivergence:  0.19819\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38375\n",
      "kldivergence:   1970.99\n",
      "variational_beta * kldivergence:  0.19710\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31723\n",
      "kldivergence:   1876.34\n",
      "variational_beta * kldivergence:  0.18763\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34071\n",
      "kldivergence:   2385.59\n",
      "variational_beta * kldivergence:  0.23856\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33722\n",
      "kldivergence:   1896.90\n",
      "variational_beta * kldivergence:  0.18969\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30834\n",
      "kldivergence:   1956.35\n",
      "variational_beta * kldivergence:  0.19564\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36517\n",
      "kldivergence:   2129.76\n",
      "variational_beta * kldivergence:  0.21298\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31862\n",
      "kldivergence:   1832.92\n",
      "variational_beta * kldivergence:  0.18329\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33769\n",
      "kldivergence:   1923.70\n",
      "variational_beta * kldivergence:  0.19237\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35480\n",
      "kldivergence:   2004.13\n",
      "variational_beta * kldivergence:  0.20041\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37267\n",
      "kldivergence:   2039.09\n",
      "variational_beta * kldivergence:  0.20391\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29880\n",
      "kldivergence:   1670.70\n",
      "variational_beta * kldivergence:  0.16707\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.27989\n",
      "kldivergence:   1653.29\n",
      "variational_beta * kldivergence:  0.16533\n",
      "batch accuracy: 90.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32889\n",
      "kldivergence:   1795.38\n",
      "variational_beta * kldivergence:  0.17954\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33530\n",
      "kldivergence:   1780.92\n",
      "variational_beta * kldivergence:  0.17809\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35536\n",
      "kldivergence:   2148.55\n",
      "variational_beta * kldivergence:  0.21486\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30139\n",
      "kldivergence:   1849.85\n",
      "variational_beta * kldivergence:  0.18499\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28863\n",
      "kldivergence:   1874.18\n",
      "variational_beta * kldivergence:  0.18742\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36992\n",
      "kldivergence:   1955.04\n",
      "variational_beta * kldivergence:  0.19550\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36538\n",
      "kldivergence:   2346.78\n",
      "variational_beta * kldivergence:  0.23468\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30732\n",
      "kldivergence:   1592.57\n",
      "variational_beta * kldivergence:  0.15926\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.43138\n",
      "kldivergence:   2132.16\n",
      "variational_beta * kldivergence:  0.21322\n",
      "batch accuracy: 85.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36880\n",
      "kldivergence:   1840.22\n",
      "variational_beta * kldivergence:  0.18402\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35286\n",
      "kldivergence:   1676.00\n",
      "variational_beta * kldivergence:  0.16760\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.42620\n",
      "kldivergence:   1916.14\n",
      "variational_beta * kldivergence:  0.19161\n",
      "batch accuracy: 85.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35776\n",
      "kldivergence:   1804.33\n",
      "variational_beta * kldivergence:  0.18043\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36744\n",
      "kldivergence:   2239.33\n",
      "variational_beta * kldivergence:  0.22393\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31077\n",
      "kldivergence:   1690.69\n",
      "variational_beta * kldivergence:  0.16907\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.41080\n",
      "kldivergence:   1782.85\n",
      "variational_beta * kldivergence:  0.17829\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33664\n",
      "kldivergence:   1917.95\n",
      "variational_beta * kldivergence:  0.19179\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33583\n",
      "kldivergence:   2162.59\n",
      "variational_beta * kldivergence:  0.21626\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37589\n",
      "kldivergence:   1847.24\n",
      "variational_beta * kldivergence:  0.18472\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32902\n",
      "kldivergence:   1712.74\n",
      "variational_beta * kldivergence:  0.17127\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32547\n",
      "kldivergence:   1835.30\n",
      "variational_beta * kldivergence:  0.18353\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33073\n",
      "kldivergence:   1904.26\n",
      "variational_beta * kldivergence:  0.19043\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34014\n",
      "kldivergence:   1965.53\n",
      "variational_beta * kldivergence:  0.19655\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28369\n",
      "kldivergence:   1677.50\n",
      "variational_beta * kldivergence:  0.16775\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36518\n",
      "kldivergence:   2065.67\n",
      "variational_beta * kldivergence:  0.20657\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38149\n",
      "kldivergence:   1690.03\n",
      "variational_beta * kldivergence:  0.16900\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35979\n",
      "kldivergence:   2065.43\n",
      "variational_beta * kldivergence:  0.20654\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.42309\n",
      "kldivergence:   1818.12\n",
      "variational_beta * kldivergence:  0.18181\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33058\n",
      "kldivergence:   1891.54\n",
      "variational_beta * kldivergence:  0.18915\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36658\n",
      "kldivergence:   1908.39\n",
      "variational_beta * kldivergence:  0.19084\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32649\n",
      "kldivergence:   1932.95\n",
      "variational_beta * kldivergence:  0.19329\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36755\n",
      "kldivergence:   1862.60\n",
      "variational_beta * kldivergence:  0.18626\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32313\n",
      "kldivergence:   1828.35\n",
      "variational_beta * kldivergence:  0.18284\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33282\n",
      "kldivergence:   2019.66\n",
      "variational_beta * kldivergence:  0.20197\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34591\n",
      "kldivergence:   1789.40\n",
      "variational_beta * kldivergence:  0.17894\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36446\n",
      "kldivergence:   2183.36\n",
      "variational_beta * kldivergence:  0.21834\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35895\n",
      "kldivergence:   1854.57\n",
      "variational_beta * kldivergence:  0.18546\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38636\n",
      "kldivergence:   1793.89\n",
      "variational_beta * kldivergence:  0.17939\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28462\n",
      "kldivergence:   1649.49\n",
      "variational_beta * kldivergence:  0.16495\n",
      "batch accuracy: 90.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.24079\n",
      "kldivergence:   1682.22\n",
      "variational_beta * kldivergence:  0.16822\n",
      "batch accuracy: 91.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31878\n",
      "kldivergence:   1693.49\n",
      "variational_beta * kldivergence:  0.16935\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29568\n",
      "kldivergence:   1631.37\n",
      "variational_beta * kldivergence:  0.16314\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.39862\n",
      "kldivergence:   1934.99\n",
      "variational_beta * kldivergence:  0.19350\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29919\n",
      "kldivergence:   1690.31\n",
      "variational_beta * kldivergence:  0.16903\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32685\n",
      "kldivergence:   1745.46\n",
      "variational_beta * kldivergence:  0.17455\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31131\n",
      "kldivergence:   1618.99\n",
      "variational_beta * kldivergence:  0.16190\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31900\n",
      "kldivergence:   2077.72\n",
      "variational_beta * kldivergence:  0.20777\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37347\n",
      "kldivergence:   1826.34\n",
      "variational_beta * kldivergence:  0.18263\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38304\n",
      "kldivergence:   1824.24\n",
      "variational_beta * kldivergence:  0.18242\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31500\n",
      "kldivergence:   1850.47\n",
      "variational_beta * kldivergence:  0.18505\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32590\n",
      "kldivergence:   1882.34\n",
      "variational_beta * kldivergence:  0.18823\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38443\n",
      "kldivergence:   1851.98\n",
      "variational_beta * kldivergence:  0.18520\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.27795\n",
      "kldivergence:   1671.31\n",
      "variational_beta * kldivergence:  0.16713\n",
      "batch accuracy: 90.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35563\n",
      "kldivergence:   2340.56\n",
      "variational_beta * kldivergence:  0.23406\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36941\n",
      "kldivergence:   2119.02\n",
      "variational_beta * kldivergence:  0.21190\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32220\n",
      "kldivergence:   1647.62\n",
      "variational_beta * kldivergence:  0.16476\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32340\n",
      "kldivergence:   1968.83\n",
      "variational_beta * kldivergence:  0.19688\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30214\n",
      "kldivergence:   1783.63\n",
      "variational_beta * kldivergence:  0.17836\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33348\n",
      "kldivergence:   1820.03\n",
      "variational_beta * kldivergence:  0.18200\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37394\n",
      "kldivergence:   1967.03\n",
      "variational_beta * kldivergence:  0.19670\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34249\n",
      "kldivergence:   1834.46\n",
      "variational_beta * kldivergence:  0.18345\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38753\n",
      "kldivergence:   1888.63\n",
      "variational_beta * kldivergence:  0.18886\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34161\n",
      "kldivergence:   1714.46\n",
      "variational_beta * kldivergence:  0.17145\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36390\n",
      "kldivergence:   1621.00\n",
      "variational_beta * kldivergence:  0.16210\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33753\n",
      "kldivergence:   1993.50\n",
      "variational_beta * kldivergence:  0.19935\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36757\n",
      "kldivergence:   1793.36\n",
      "variational_beta * kldivergence:  0.17934\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.40734\n",
      "kldivergence:   1933.16\n",
      "variational_beta * kldivergence:  0.19332\n",
      "batch accuracy: 86.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34580\n",
      "kldivergence:   1932.15\n",
      "variational_beta * kldivergence:  0.19322\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31603\n",
      "kldivergence:   1801.96\n",
      "variational_beta * kldivergence:  0.18020\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35814\n",
      "kldivergence:   1868.98\n",
      "variational_beta * kldivergence:  0.18690\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37221\n",
      "kldivergence:   1785.83\n",
      "variational_beta * kldivergence:  0.17858\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31211\n",
      "kldivergence:   1554.24\n",
      "variational_beta * kldivergence:  0.15542\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35539\n",
      "kldivergence:   1923.93\n",
      "variational_beta * kldivergence:  0.19239\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33613\n",
      "kldivergence:   1801.67\n",
      "variational_beta * kldivergence:  0.18017\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34743\n",
      "kldivergence:   1834.18\n",
      "variational_beta * kldivergence:  0.18342\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31369\n",
      "kldivergence:   1756.29\n",
      "variational_beta * kldivergence:  0.17563\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35554\n",
      "kldivergence:   1719.45\n",
      "variational_beta * kldivergence:  0.17194\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31391\n",
      "kldivergence:   2044.29\n",
      "variational_beta * kldivergence:  0.20443\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37181\n",
      "kldivergence:   1900.42\n",
      "variational_beta * kldivergence:  0.19004\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.40685\n",
      "kldivergence:   1852.05\n",
      "variational_beta * kldivergence:  0.18520\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35100\n",
      "kldivergence:   1929.03\n",
      "variational_beta * kldivergence:  0.19290\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36105\n",
      "kldivergence:   1871.67\n",
      "variational_beta * kldivergence:  0.18717\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29588\n",
      "kldivergence:   1662.23\n",
      "variational_beta * kldivergence:  0.16622\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35286\n",
      "kldivergence:   2290.18\n",
      "variational_beta * kldivergence:  0.22902\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32812\n",
      "kldivergence:   1639.44\n",
      "variational_beta * kldivergence:  0.16394\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31045\n",
      "kldivergence:   1970.28\n",
      "variational_beta * kldivergence:  0.19703\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36166\n",
      "kldivergence:   1862.54\n",
      "variational_beta * kldivergence:  0.18625\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35106\n",
      "kldivergence:   2067.93\n",
      "variational_beta * kldivergence:  0.20679\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.41278\n",
      "kldivergence:   1842.60\n",
      "variational_beta * kldivergence:  0.18426\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34182\n",
      "kldivergence:   2013.23\n",
      "variational_beta * kldivergence:  0.20132\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31376\n",
      "kldivergence:   1940.70\n",
      "variational_beta * kldivergence:  0.19407\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31951\n",
      "kldivergence:   1672.90\n",
      "variational_beta * kldivergence:  0.16729\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32509\n",
      "kldivergence:   1670.34\n",
      "variational_beta * kldivergence:  0.16703\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36217\n",
      "kldivergence:   1717.80\n",
      "variational_beta * kldivergence:  0.17178\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32023\n",
      "kldivergence:   1980.25\n",
      "variational_beta * kldivergence:  0.19802\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38405\n",
      "kldivergence:   1820.31\n",
      "variational_beta * kldivergence:  0.18203\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33515\n",
      "kldivergence:   2035.85\n",
      "variational_beta * kldivergence:  0.20358\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29255\n",
      "kldivergence:   1771.65\n",
      "variational_beta * kldivergence:  0.17717\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32394\n",
      "kldivergence:   1595.68\n",
      "variational_beta * kldivergence:  0.15957\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29932\n",
      "kldivergence:   1824.42\n",
      "variational_beta * kldivergence:  0.18244\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30659\n",
      "kldivergence:   1650.54\n",
      "variational_beta * kldivergence:  0.16505\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34490\n",
      "kldivergence:   1899.06\n",
      "variational_beta * kldivergence:  0.18991\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35667\n",
      "kldivergence:   1836.43\n",
      "variational_beta * kldivergence:  0.18364\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34488\n",
      "kldivergence:   1742.92\n",
      "variational_beta * kldivergence:  0.17429\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33440\n",
      "kldivergence:   1627.57\n",
      "variational_beta * kldivergence:  0.16276\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36662\n",
      "kldivergence:   1759.48\n",
      "variational_beta * kldivergence:  0.17595\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33357\n",
      "kldivergence:   1898.21\n",
      "variational_beta * kldivergence:  0.18982\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38539\n",
      "kldivergence:   1878.51\n",
      "variational_beta * kldivergence:  0.18785\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32270\n",
      "kldivergence:   1998.96\n",
      "variational_beta * kldivergence:  0.19990\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33177\n",
      "kldivergence:   1919.49\n",
      "variational_beta * kldivergence:  0.19195\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32119\n",
      "kldivergence:   1620.29\n",
      "variational_beta * kldivergence:  0.16203\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30390\n",
      "kldivergence:   1826.54\n",
      "variational_beta * kldivergence:  0.18265\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31806\n",
      "kldivergence:   1859.86\n",
      "variational_beta * kldivergence:  0.18599\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37806\n",
      "kldivergence:   1646.72\n",
      "variational_beta * kldivergence:  0.16467\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34948\n",
      "kldivergence:   1757.11\n",
      "variational_beta * kldivergence:  0.17571\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32360\n",
      "kldivergence:   1763.51\n",
      "variational_beta * kldivergence:  0.17635\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36126\n",
      "kldivergence:   1737.07\n",
      "variational_beta * kldivergence:  0.17371\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33261\n",
      "kldivergence:   1798.46\n",
      "variational_beta * kldivergence:  0.17985\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31119\n",
      "kldivergence:   1853.01\n",
      "variational_beta * kldivergence:  0.18530\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33564\n",
      "kldivergence:   1687.43\n",
      "variational_beta * kldivergence:  0.16874\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.27146\n",
      "kldivergence:   2044.55\n",
      "variational_beta * kldivergence:  0.20446\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34843\n",
      "kldivergence:   1707.50\n",
      "variational_beta * kldivergence:  0.17075\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31531\n",
      "kldivergence:   1958.49\n",
      "variational_beta * kldivergence:  0.19585\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29503\n",
      "kldivergence:   2018.36\n",
      "variational_beta * kldivergence:  0.20184\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33129\n",
      "kldivergence:   1733.68\n",
      "variational_beta * kldivergence:  0.17337\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32725\n",
      "kldivergence:   1813.82\n",
      "variational_beta * kldivergence:  0.18138\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32537\n",
      "kldivergence:   1697.52\n",
      "variational_beta * kldivergence:  0.16975\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34796\n",
      "kldivergence:   1594.14\n",
      "variational_beta * kldivergence:  0.15941\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34345\n",
      "kldivergence:   1900.09\n",
      "variational_beta * kldivergence:  0.19001\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33841\n",
      "kldivergence:   1732.95\n",
      "variational_beta * kldivergence:  0.17329\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.39177\n",
      "kldivergence:   1862.23\n",
      "variational_beta * kldivergence:  0.18622\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30187\n",
      "kldivergence:   1705.28\n",
      "variational_beta * kldivergence:  0.17053\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30926\n",
      "kldivergence:   2017.88\n",
      "variational_beta * kldivergence:  0.20179\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32502\n",
      "kldivergence:   1665.99\n",
      "variational_beta * kldivergence:  0.16660\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.39429\n",
      "kldivergence:   2089.34\n",
      "variational_beta * kldivergence:  0.20893\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32801\n",
      "kldivergence:   1937.32\n",
      "variational_beta * kldivergence:  0.19373\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30860\n",
      "kldivergence:   1694.60\n",
      "variational_beta * kldivergence:  0.16946\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.39126\n",
      "kldivergence:   1725.52\n",
      "variational_beta * kldivergence:  0.17255\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36752\n",
      "kldivergence:   2084.96\n",
      "variational_beta * kldivergence:  0.20850\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34668\n",
      "kldivergence:   1863.70\n",
      "variational_beta * kldivergence:  0.18637\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32437\n",
      "kldivergence:   1924.90\n",
      "variational_beta * kldivergence:  0.19249\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29787\n",
      "kldivergence:   1767.30\n",
      "variational_beta * kldivergence:  0.17673\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32861\n",
      "kldivergence:   1805.07\n",
      "variational_beta * kldivergence:  0.18051\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28875\n",
      "kldivergence:   2054.61\n",
      "variational_beta * kldivergence:  0.20546\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37800\n",
      "kldivergence:   1853.04\n",
      "variational_beta * kldivergence:  0.18530\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37047\n",
      "kldivergence:   1867.46\n",
      "variational_beta * kldivergence:  0.18675\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33035\n",
      "kldivergence:   1917.88\n",
      "variational_beta * kldivergence:  0.19179\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30954\n",
      "kldivergence:   2005.17\n",
      "variational_beta * kldivergence:  0.20052\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30586\n",
      "kldivergence:   1690.83\n",
      "variational_beta * kldivergence:  0.16908\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34797\n",
      "kldivergence:   2095.15\n",
      "variational_beta * kldivergence:  0.20951\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28494\n",
      "kldivergence:   2104.23\n",
      "variational_beta * kldivergence:  0.21042\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29779\n",
      "kldivergence:   1668.19\n",
      "variational_beta * kldivergence:  0.16682\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30681\n",
      "kldivergence:   1880.89\n",
      "variational_beta * kldivergence:  0.18809\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35199\n",
      "kldivergence:   2160.18\n",
      "variational_beta * kldivergence:  0.21602\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31341\n",
      "kldivergence:   1689.50\n",
      "variational_beta * kldivergence:  0.16895\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35770\n",
      "kldivergence:   2049.45\n",
      "variational_beta * kldivergence:  0.20495\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36175\n",
      "kldivergence:   2083.89\n",
      "variational_beta * kldivergence:  0.20839\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35625\n",
      "kldivergence:   1689.78\n",
      "variational_beta * kldivergence:  0.16898\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29792\n",
      "kldivergence:   1732.87\n",
      "variational_beta * kldivergence:  0.17329\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33847\n",
      "kldivergence:   1930.59\n",
      "variational_beta * kldivergence:  0.19306\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31396\n",
      "kldivergence:   1702.08\n",
      "variational_beta * kldivergence:  0.17021\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35836\n",
      "kldivergence:   1840.54\n",
      "variational_beta * kldivergence:  0.18405\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36022\n",
      "kldivergence:   1982.13\n",
      "variational_beta * kldivergence:  0.19821\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33793\n",
      "kldivergence:   1666.86\n",
      "variational_beta * kldivergence:  0.16669\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34435\n",
      "kldivergence:   1805.45\n",
      "variational_beta * kldivergence:  0.18055\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33852\n",
      "kldivergence:   2011.48\n",
      "variational_beta * kldivergence:  0.20115\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38184\n",
      "kldivergence:   1826.17\n",
      "variational_beta * kldivergence:  0.18262\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36404\n",
      "kldivergence:   1859.66\n",
      "variational_beta * kldivergence:  0.18597\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38264\n",
      "kldivergence:   1895.61\n",
      "variational_beta * kldivergence:  0.18956\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33487\n",
      "kldivergence:   1543.48\n",
      "variational_beta * kldivergence:  0.15435\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34578\n",
      "kldivergence:   1692.60\n",
      "variational_beta * kldivergence:  0.16926\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34049\n",
      "kldivergence:   1509.90\n",
      "variational_beta * kldivergence:  0.15099\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35927\n",
      "kldivergence:   1614.77\n",
      "variational_beta * kldivergence:  0.16148\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35862\n",
      "kldivergence:   1798.14\n",
      "variational_beta * kldivergence:  0.17981\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32988\n",
      "kldivergence:   1622.47\n",
      "variational_beta * kldivergence:  0.16225\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29901\n",
      "kldivergence:   1756.02\n",
      "variational_beta * kldivergence:  0.17560\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32328\n",
      "kldivergence:   1775.27\n",
      "variational_beta * kldivergence:  0.17753\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33954\n",
      "kldivergence:   1657.09\n",
      "variational_beta * kldivergence:  0.16571\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32484\n",
      "kldivergence:   1770.54\n",
      "variational_beta * kldivergence:  0.17705\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38435\n",
      "kldivergence:   1665.61\n",
      "variational_beta * kldivergence:  0.16656\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33226\n",
      "kldivergence:   1851.18\n",
      "variational_beta * kldivergence:  0.18512\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34365\n",
      "kldivergence:   1977.81\n",
      "variational_beta * kldivergence:  0.19778\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30204\n",
      "kldivergence:   1861.62\n",
      "variational_beta * kldivergence:  0.18616\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36344\n",
      "kldivergence:   1918.90\n",
      "variational_beta * kldivergence:  0.19189\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31805\n",
      "kldivergence:   1963.35\n",
      "variational_beta * kldivergence:  0.19634\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34668\n",
      "kldivergence:   1677.23\n",
      "variational_beta * kldivergence:  0.16772\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33846\n",
      "kldivergence:   1813.57\n",
      "variational_beta * kldivergence:  0.18136\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29732\n",
      "kldivergence:   2043.16\n",
      "variational_beta * kldivergence:  0.20432\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35464\n",
      "kldivergence:   1960.45\n",
      "variational_beta * kldivergence:  0.19605\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31865\n",
      "kldivergence:   1925.72\n",
      "variational_beta * kldivergence:  0.19257\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30560\n",
      "kldivergence:   1685.37\n",
      "variational_beta * kldivergence:  0.16854\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37983\n",
      "kldivergence:   1944.25\n",
      "variational_beta * kldivergence:  0.19442\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30721\n",
      "kldivergence:   1769.11\n",
      "variational_beta * kldivergence:  0.17691\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30632\n",
      "kldivergence:   1986.64\n",
      "variational_beta * kldivergence:  0.19866\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35738\n",
      "kldivergence:   1789.93\n",
      "variational_beta * kldivergence:  0.17899\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30746\n",
      "kldivergence:   1741.75\n",
      "variational_beta * kldivergence:  0.17418\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35831\n",
      "kldivergence:   1942.79\n",
      "variational_beta * kldivergence:  0.19428\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33989\n",
      "kldivergence:   1805.06\n",
      "variational_beta * kldivergence:  0.18051\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32948\n",
      "kldivergence:   1862.32\n",
      "variational_beta * kldivergence:  0.18623\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32386\n",
      "kldivergence:   1929.81\n",
      "variational_beta * kldivergence:  0.19298\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35880\n",
      "kldivergence:   1745.34\n",
      "variational_beta * kldivergence:  0.17453\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37150\n",
      "kldivergence:   1790.88\n",
      "variational_beta * kldivergence:  0.17909\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36530\n",
      "kldivergence:   1739.20\n",
      "variational_beta * kldivergence:  0.17392\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.40459\n",
      "kldivergence:   2128.37\n",
      "variational_beta * kldivergence:  0.21284\n",
      "batch accuracy: 86.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.38521\n",
      "kldivergence:   1817.59\n",
      "variational_beta * kldivergence:  0.18176\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35126\n",
      "kldivergence:   1861.72\n",
      "variational_beta * kldivergence:  0.18617\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36994\n",
      "kldivergence:   1908.19\n",
      "variational_beta * kldivergence:  0.19082\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37039\n",
      "kldivergence:   1941.30\n",
      "variational_beta * kldivergence:  0.19413\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33531\n",
      "kldivergence:   1396.06\n",
      "variational_beta * kldivergence:  0.13961\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33399\n",
      "kldivergence:   1719.50\n",
      "variational_beta * kldivergence:  0.17195\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31189\n",
      "kldivergence:   1805.34\n",
      "variational_beta * kldivergence:  0.18053\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34366\n",
      "kldivergence:   1853.10\n",
      "variational_beta * kldivergence:  0.18531\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33292\n",
      "kldivergence:   1912.83\n",
      "variational_beta * kldivergence:  0.19128\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35529\n",
      "kldivergence:   1968.24\n",
      "variational_beta * kldivergence:  0.19682\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32599\n",
      "kldivergence:   1823.34\n",
      "variational_beta * kldivergence:  0.18233\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36347\n",
      "kldivergence:   1917.29\n",
      "variational_beta * kldivergence:  0.19173\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36654\n",
      "kldivergence:   1797.42\n",
      "variational_beta * kldivergence:  0.17974\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35153\n",
      "kldivergence:   1847.02\n",
      "variational_beta * kldivergence:  0.18470\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.39205\n",
      "kldivergence:   1750.10\n",
      "variational_beta * kldivergence:  0.17501\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35165\n",
      "kldivergence:   1686.65\n",
      "variational_beta * kldivergence:  0.16867\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31390\n",
      "kldivergence:   1624.93\n",
      "variational_beta * kldivergence:  0.16249\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33780\n",
      "kldivergence:   1996.38\n",
      "variational_beta * kldivergence:  0.19964\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36089\n",
      "kldivergence:   1906.18\n",
      "variational_beta * kldivergence:  0.19062\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.45407\n",
      "kldivergence:   1798.05\n",
      "variational_beta * kldivergence:  0.17980\n",
      "batch accuracy: 85.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33846\n",
      "kldivergence:   1999.01\n",
      "variational_beta * kldivergence:  0.19990\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33001\n",
      "kldivergence:   1877.00\n",
      "variational_beta * kldivergence:  0.18770\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33600\n",
      "kldivergence:   1732.82\n",
      "variational_beta * kldivergence:  0.17328\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37348\n",
      "kldivergence:   2000.07\n",
      "variational_beta * kldivergence:  0.20001\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37765\n",
      "kldivergence:   1841.46\n",
      "variational_beta * kldivergence:  0.18415\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.27057\n",
      "kldivergence:   1776.33\n",
      "variational_beta * kldivergence:  0.17763\n",
      "batch accuracy: 91.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36419\n",
      "kldivergence:   1793.00\n",
      "variational_beta * kldivergence:  0.17930\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32652\n",
      "kldivergence:   1964.57\n",
      "variational_beta * kldivergence:  0.19646\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32525\n",
      "kldivergence:   1774.86\n",
      "variational_beta * kldivergence:  0.17749\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33337\n",
      "kldivergence:   2037.07\n",
      "variational_beta * kldivergence:  0.20371\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36226\n",
      "kldivergence:   2056.60\n",
      "variational_beta * kldivergence:  0.20566\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37289\n",
      "kldivergence:   1862.08\n",
      "variational_beta * kldivergence:  0.18621\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32962\n",
      "kldivergence:   2149.03\n",
      "variational_beta * kldivergence:  0.21490\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30835\n",
      "kldivergence:   1884.88\n",
      "variational_beta * kldivergence:  0.18849\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28751\n",
      "kldivergence:   1628.37\n",
      "variational_beta * kldivergence:  0.16284\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31086\n",
      "kldivergence:   1891.90\n",
      "variational_beta * kldivergence:  0.18919\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36710\n",
      "kldivergence:   1955.56\n",
      "variational_beta * kldivergence:  0.19556\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28127\n",
      "kldivergence:   1904.15\n",
      "variational_beta * kldivergence:  0.19042\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34738\n",
      "kldivergence:   1863.35\n",
      "variational_beta * kldivergence:  0.18633\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33115\n",
      "kldivergence:   2008.36\n",
      "variational_beta * kldivergence:  0.20084\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31428\n",
      "kldivergence:   2080.92\n",
      "variational_beta * kldivergence:  0.20809\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31469\n",
      "kldivergence:   1813.31\n",
      "variational_beta * kldivergence:  0.18133\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30951\n",
      "kldivergence:   1835.76\n",
      "variational_beta * kldivergence:  0.18358\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34404\n",
      "kldivergence:   1878.24\n",
      "variational_beta * kldivergence:  0.18782\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35775\n",
      "kldivergence:   1963.90\n",
      "variational_beta * kldivergence:  0.19639\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31821\n",
      "kldivergence:   1732.34\n",
      "variational_beta * kldivergence:  0.17323\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32323\n",
      "kldivergence:   1858.79\n",
      "variational_beta * kldivergence:  0.18588\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30486\n",
      "kldivergence:   1859.29\n",
      "variational_beta * kldivergence:  0.18593\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33789\n",
      "kldivergence:   1799.30\n",
      "variational_beta * kldivergence:  0.17993\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37126\n",
      "kldivergence:   1769.87\n",
      "variational_beta * kldivergence:  0.17699\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34447\n",
      "kldivergence:   1666.34\n",
      "variational_beta * kldivergence:  0.16663\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31126\n",
      "kldivergence:   1599.89\n",
      "variational_beta * kldivergence:  0.15999\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33173\n",
      "kldivergence:   1887.97\n",
      "variational_beta * kldivergence:  0.18880\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34889\n",
      "kldivergence:   1794.11\n",
      "variational_beta * kldivergence:  0.17941\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28967\n",
      "kldivergence:   1564.18\n",
      "variational_beta * kldivergence:  0.15642\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36063\n",
      "kldivergence:   1717.70\n",
      "variational_beta * kldivergence:  0.17177\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34661\n",
      "kldivergence:   1924.54\n",
      "variational_beta * kldivergence:  0.19245\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34541\n",
      "kldivergence:   1691.58\n",
      "variational_beta * kldivergence:  0.16916\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34290\n",
      "kldivergence:   2020.76\n",
      "variational_beta * kldivergence:  0.20208\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32652\n",
      "kldivergence:   1677.10\n",
      "variational_beta * kldivergence:  0.16771\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34986\n",
      "kldivergence:   1917.42\n",
      "variational_beta * kldivergence:  0.19174\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29071\n",
      "kldivergence:   1650.97\n",
      "variational_beta * kldivergence:  0.16510\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30056\n",
      "kldivergence:   1504.63\n",
      "variational_beta * kldivergence:  0.15046\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33442\n",
      "kldivergence:   1683.28\n",
      "variational_beta * kldivergence:  0.16833\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35100\n",
      "kldivergence:   1694.24\n",
      "variational_beta * kldivergence:  0.16942\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32714\n",
      "kldivergence:   1813.69\n",
      "variational_beta * kldivergence:  0.18137\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36489\n",
      "kldivergence:   2126.79\n",
      "variational_beta * kldivergence:  0.21268\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31677\n",
      "kldivergence:   1750.54\n",
      "variational_beta * kldivergence:  0.17505\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37305\n",
      "kldivergence:   1908.36\n",
      "variational_beta * kldivergence:  0.19084\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31868\n",
      "kldivergence:   1830.26\n",
      "variational_beta * kldivergence:  0.18303\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31112\n",
      "kldivergence:   1632.97\n",
      "variational_beta * kldivergence:  0.16330\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.40723\n",
      "kldivergence:   1895.34\n",
      "variational_beta * kldivergence:  0.18953\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28618\n",
      "kldivergence:   1790.43\n",
      "variational_beta * kldivergence:  0.17904\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33519\n",
      "kldivergence:   1920.33\n",
      "variational_beta * kldivergence:  0.19203\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.40148\n",
      "kldivergence:   1826.32\n",
      "variational_beta * kldivergence:  0.18263\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35155\n",
      "kldivergence:   1843.06\n",
      "variational_beta * kldivergence:  0.18431\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34011\n",
      "kldivergence:   1700.55\n",
      "variational_beta * kldivergence:  0.17005\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33728\n",
      "kldivergence:   1827.04\n",
      "variational_beta * kldivergence:  0.18270\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34828\n",
      "kldivergence:   1592.09\n",
      "variational_beta * kldivergence:  0.15921\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.45213\n",
      "kldivergence:   1996.27\n",
      "variational_beta * kldivergence:  0.19963\n",
      "batch accuracy: 85.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30409\n",
      "kldivergence:   1949.72\n",
      "variational_beta * kldivergence:  0.19497\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35908\n",
      "kldivergence:   2228.24\n",
      "variational_beta * kldivergence:  0.22282\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36130\n",
      "kldivergence:   1642.21\n",
      "variational_beta * kldivergence:  0.16422\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31923\n",
      "kldivergence:   1668.22\n",
      "variational_beta * kldivergence:  0.16682\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35428\n",
      "kldivergence:   1715.32\n",
      "variational_beta * kldivergence:  0.17153\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29393\n",
      "kldivergence:   1670.71\n",
      "variational_beta * kldivergence:  0.16707\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37874\n",
      "kldivergence:   1716.54\n",
      "variational_beta * kldivergence:  0.17165\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36420\n",
      "kldivergence:   1871.84\n",
      "variational_beta * kldivergence:  0.18718\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35043\n",
      "kldivergence:   1710.52\n",
      "variational_beta * kldivergence:  0.17105\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37708\n",
      "kldivergence:   1679.20\n",
      "variational_beta * kldivergence:  0.16792\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.40188\n",
      "kldivergence:   1892.81\n",
      "variational_beta * kldivergence:  0.18928\n",
      "batch accuracy: 86.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31927\n",
      "kldivergence:   1800.83\n",
      "variational_beta * kldivergence:  0.18008\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31760\n",
      "kldivergence:   1727.21\n",
      "variational_beta * kldivergence:  0.17272\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37382\n",
      "kldivergence:   1770.94\n",
      "variational_beta * kldivergence:  0.17709\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36420\n",
      "kldivergence:   1681.33\n",
      "variational_beta * kldivergence:  0.16813\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35122\n",
      "kldivergence:   1867.44\n",
      "variational_beta * kldivergence:  0.18674\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34020\n",
      "kldivergence:   1822.10\n",
      "variational_beta * kldivergence:  0.18221\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.29830\n",
      "kldivergence:   1669.61\n",
      "variational_beta * kldivergence:  0.16696\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36138\n",
      "kldivergence:   2031.45\n",
      "variational_beta * kldivergence:  0.20314\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35297\n",
      "kldivergence:   1895.07\n",
      "variational_beta * kldivergence:  0.18951\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34863\n",
      "kldivergence:   1683.15\n",
      "variational_beta * kldivergence:  0.16831\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34461\n",
      "kldivergence:   1821.98\n",
      "variational_beta * kldivergence:  0.18220\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35049\n",
      "kldivergence:   1807.37\n",
      "variational_beta * kldivergence:  0.18074\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32704\n",
      "kldivergence:   1708.05\n",
      "variational_beta * kldivergence:  0.17081\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32220\n",
      "kldivergence:   1665.52\n",
      "variational_beta * kldivergence:  0.16655\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30533\n",
      "kldivergence:   1634.82\n",
      "variational_beta * kldivergence:  0.16348\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32427\n",
      "kldivergence:   1814.21\n",
      "variational_beta * kldivergence:  0.18142\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33586\n",
      "kldivergence:   1806.23\n",
      "variational_beta * kldivergence:  0.18062\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.27747\n",
      "kldivergence:   1634.68\n",
      "variational_beta * kldivergence:  0.16347\n",
      "batch accuracy: 91.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34796\n",
      "kldivergence:   1782.63\n",
      "variational_beta * kldivergence:  0.17826\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32453\n",
      "kldivergence:   1695.07\n",
      "variational_beta * kldivergence:  0.16951\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33312\n",
      "kldivergence:   1886.29\n",
      "variational_beta * kldivergence:  0.18863\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31359\n",
      "kldivergence:   1633.25\n",
      "variational_beta * kldivergence:  0.16332\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33929\n",
      "kldivergence:   1738.61\n",
      "variational_beta * kldivergence:  0.17386\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36195\n",
      "kldivergence:   1709.47\n",
      "variational_beta * kldivergence:  0.17095\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34102\n",
      "kldivergence:   1819.41\n",
      "variational_beta * kldivergence:  0.18194\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33562\n",
      "kldivergence:   1725.20\n",
      "variational_beta * kldivergence:  0.17252\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30219\n",
      "kldivergence:   1787.96\n",
      "variational_beta * kldivergence:  0.17880\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33558\n",
      "kldivergence:   1878.19\n",
      "variational_beta * kldivergence:  0.18782\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37144\n",
      "kldivergence:   1812.43\n",
      "variational_beta * kldivergence:  0.18124\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30284\n",
      "kldivergence:   1783.68\n",
      "variational_beta * kldivergence:  0.17837\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37050\n",
      "kldivergence:   2046.01\n",
      "variational_beta * kldivergence:  0.20460\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28970\n",
      "kldivergence:   1532.63\n",
      "variational_beta * kldivergence:  0.15326\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.39287\n",
      "kldivergence:   2010.08\n",
      "variational_beta * kldivergence:  0.20101\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.37745\n",
      "kldivergence:   1970.65\n",
      "variational_beta * kldivergence:  0.19707\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31225\n",
      "kldivergence:   2137.38\n",
      "variational_beta * kldivergence:  0.21374\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36864\n",
      "kldivergence:   1727.09\n",
      "variational_beta * kldivergence:  0.17271\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.39678\n",
      "kldivergence:   1939.09\n",
      "variational_beta * kldivergence:  0.19391\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30885\n",
      "kldivergence:   1803.30\n",
      "variational_beta * kldivergence:  0.18033\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34664\n",
      "kldivergence:   1701.19\n",
      "variational_beta * kldivergence:  0.17012\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.34446\n",
      "kldivergence:   1941.48\n",
      "variational_beta * kldivergence:  0.19415\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28262\n",
      "kldivergence:   1792.10\n",
      "variational_beta * kldivergence:  0.17921\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35268\n",
      "kldivergence:   1841.58\n",
      "variational_beta * kldivergence:  0.18416\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30606\n",
      "kldivergence:   1675.65\n",
      "variational_beta * kldivergence:  0.16757\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.40639\n",
      "kldivergence:   1970.89\n",
      "variational_beta * kldivergence:  0.19709\n",
      "batch accuracy: 86.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31732\n",
      "kldivergence:   1648.28\n",
      "variational_beta * kldivergence:  0.16483\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35169\n",
      "kldivergence:   1981.72\n",
      "variational_beta * kldivergence:  0.19817\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.36712\n",
      "kldivergence:   1700.54\n",
      "variational_beta * kldivergence:  0.17005\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32470\n",
      "kldivergence:   1692.94\n",
      "variational_beta * kldivergence:  0.16929\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32388\n",
      "kldivergence:   1755.41\n",
      "variational_beta * kldivergence:  0.17554\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35646\n",
      "kldivergence:   1932.71\n",
      "variational_beta * kldivergence:  0.19327\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.40099\n",
      "kldivergence:   1915.17\n",
      "variational_beta * kldivergence:  0.19152\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35798\n",
      "kldivergence:   1935.03\n",
      "variational_beta * kldivergence:  0.19350\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32571\n",
      "kldivergence:   1672.98\n",
      "variational_beta * kldivergence:  0.16730\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.33181\n",
      "kldivergence:   1829.21\n",
      "variational_beta * kldivergence:  0.18292\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.30204\n",
      "kldivergence:   1721.78\n",
      "variational_beta * kldivergence:  0.17218\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.35089\n",
      "kldivergence:   1957.48\n",
      "variational_beta * kldivergence:  0.19575\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28389\n",
      "kldivergence:   2018.61\n",
      "variational_beta * kldivergence:  0.20186\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.32686\n",
      "kldivergence:   1914.73\n",
      "variational_beta * kldivergence:  0.19147\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.28644\n",
      "kldivergence:   2027.17\n",
      "variational_beta * kldivergence:  0.20272\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #3\n",
      "reconstruction loss: 0.31428\n",
      "kldivergence:   1528.54\n",
      "variational_beta * kldivergence:  0.15285\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.38594\n",
      "kldivergence:   1626.29\n",
      "variational_beta * kldivergence:  0.16263\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.43172\n",
      "kldivergence:   1688.80\n",
      "variational_beta * kldivergence:  0.16888\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.46478\n",
      "kldivergence:   1611.60\n",
      "variational_beta * kldivergence:  0.16116\n",
      "batch accuracy: 85.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.44550\n",
      "kldivergence:   1723.83\n",
      "variational_beta * kldivergence:  0.17238\n",
      "batch accuracy: 85.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.38538\n",
      "kldivergence:   1717.40\n",
      "variational_beta * kldivergence:  0.17174\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.47233\n",
      "kldivergence:   1815.26\n",
      "variational_beta * kldivergence:  0.18153\n",
      "batch accuracy: 84.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.40358\n",
      "kldivergence:   1733.41\n",
      "variational_beta * kldivergence:  0.17334\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.42973\n",
      "kldivergence:   1642.42\n",
      "variational_beta * kldivergence:  0.16424\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.60155\n",
      "kldivergence:   1912.15\n",
      "variational_beta * kldivergence:  0.19121\n",
      "batch accuracy: 82.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.48591\n",
      "kldivergence:   1769.74\n",
      "variational_beta * kldivergence:  0.17697\n",
      "batch accuracy: 85.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.48339\n",
      "kldivergence:   1815.05\n",
      "variational_beta * kldivergence:  0.18150\n",
      "batch accuracy: 85.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.48100\n",
      "kldivergence:   1871.45\n",
      "variational_beta * kldivergence:  0.18714\n",
      "batch accuracy: 85.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.43153\n",
      "kldivergence:   1641.77\n",
      "variational_beta * kldivergence:  0.16418\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.46943\n",
      "kldivergence:   1746.52\n",
      "variational_beta * kldivergence:  0.17465\n",
      "batch accuracy: 85.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.43959\n",
      "kldivergence:   1659.76\n",
      "variational_beta * kldivergence:  0.16598\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.40448\n",
      "kldivergence:   1662.97\n",
      "variational_beta * kldivergence:  0.16630\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.39431\n",
      "kldivergence:   1686.37\n",
      "variational_beta * kldivergence:  0.16864\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.57494\n",
      "kldivergence:   2058.16\n",
      "variational_beta * kldivergence:  0.20582\n",
      "batch accuracy: 82.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.44242\n",
      "kldivergence:   1667.48\n",
      "variational_beta * kldivergence:  0.16675\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.45240\n",
      "kldivergence:   1817.45\n",
      "variational_beta * kldivergence:  0.18174\n",
      "batch accuracy: 85.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.39920\n",
      "kldivergence:   1591.13\n",
      "variational_beta * kldivergence:  0.15911\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.49634\n",
      "kldivergence:   1798.65\n",
      "variational_beta * kldivergence:  0.17987\n",
      "batch accuracy: 85.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.56566\n",
      "kldivergence:   1976.44\n",
      "variational_beta * kldivergence:  0.19764\n",
      "batch accuracy: 82.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.55682\n",
      "kldivergence:   1842.68\n",
      "variational_beta * kldivergence:  0.18427\n",
      "batch accuracy: 83.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.48657\n",
      "kldivergence:   1734.80\n",
      "variational_beta * kldivergence:  0.17348\n",
      "batch accuracy: 85.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.47789\n",
      "kldivergence:   1845.87\n",
      "variational_beta * kldivergence:  0.18459\n",
      "batch accuracy: 85.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.47101\n",
      "kldivergence:   1789.15\n",
      "variational_beta * kldivergence:  0.17892\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.43841\n",
      "kldivergence:   1726.20\n",
      "variational_beta * kldivergence:  0.17262\n",
      "batch accuracy: 86.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.46797\n",
      "kldivergence:   1717.05\n",
      "variational_beta * kldivergence:  0.17171\n",
      "batch accuracy: 85.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.44212\n",
      "kldivergence:   1701.77\n",
      "variational_beta * kldivergence:  0.17018\n",
      "batch accuracy: 86.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.46720\n",
      "kldivergence:   1767.57\n",
      "variational_beta * kldivergence:  0.17676\n",
      "batch accuracy: 85.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.55571\n",
      "kldivergence:   1866.86\n",
      "variational_beta * kldivergence:  0.18669\n",
      "batch accuracy: 82.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.39944\n",
      "kldivergence:   1594.25\n",
      "variational_beta * kldivergence:  0.15943\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.42401\n",
      "kldivergence:   1674.59\n",
      "variational_beta * kldivergence:  0.16746\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.42453\n",
      "kldivergence:   1693.00\n",
      "variational_beta * kldivergence:  0.16930\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.38937\n",
      "kldivergence:   1606.85\n",
      "variational_beta * kldivergence:  0.16068\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.42941\n",
      "kldivergence:   1762.42\n",
      "variational_beta * kldivergence:  0.17624\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.43373\n",
      "kldivergence:   1775.00\n",
      "variational_beta * kldivergence:  0.17750\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.39898\n",
      "kldivergence:   1599.20\n",
      "variational_beta * kldivergence:  0.15992\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.48917\n",
      "kldivergence:   1785.94\n",
      "variational_beta * kldivergence:  0.17859\n",
      "batch accuracy: 85.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.49866\n",
      "kldivergence:   1829.56\n",
      "variational_beta * kldivergence:  0.18296\n",
      "batch accuracy: 84.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.43837\n",
      "kldivergence:   1591.16\n",
      "variational_beta * kldivergence:  0.15912\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.43216\n",
      "kldivergence:   1650.09\n",
      "variational_beta * kldivergence:  0.16501\n",
      "batch accuracy: 86.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.53559\n",
      "kldivergence:   1847.29\n",
      "variational_beta * kldivergence:  0.18473\n",
      "batch accuracy: 84.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.41357\n",
      "kldivergence:   1647.48\n",
      "variational_beta * kldivergence:  0.16475\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.41805\n",
      "kldivergence:   1580.96\n",
      "variational_beta * kldivergence:  0.15810\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.44724\n",
      "kldivergence:   1710.87\n",
      "variational_beta * kldivergence:  0.17109\n",
      "batch accuracy: 86.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.56285\n",
      "kldivergence:   1778.54\n",
      "variational_beta * kldivergence:  0.17785\n",
      "batch accuracy: 83.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.46241\n",
      "kldivergence:   1746.49\n",
      "variational_beta * kldivergence:  0.17465\n",
      "batch accuracy: 86.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.46401\n",
      "kldivergence:   1743.86\n",
      "variational_beta * kldivergence:  0.17439\n",
      "batch accuracy: 85.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.40460\n",
      "kldivergence:   1508.67\n",
      "variational_beta * kldivergence:  0.15087\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.54514\n",
      "kldivergence:   1841.46\n",
      "variational_beta * kldivergence:  0.18415\n",
      "batch accuracy: 83.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.40577\n",
      "kldivergence:   1671.60\n",
      "variational_beta * kldivergence:  0.16716\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.42867\n",
      "kldivergence:   1756.40\n",
      "variational_beta * kldivergence:  0.17564\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.44205\n",
      "kldivergence:   1736.39\n",
      "variational_beta * kldivergence:  0.17364\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.44530\n",
      "kldivergence:   1664.47\n",
      "variational_beta * kldivergence:  0.16645\n",
      "batch accuracy: 85.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.50825\n",
      "kldivergence:   1846.65\n",
      "variational_beta * kldivergence:  0.18466\n",
      "batch accuracy: 84.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.38047\n",
      "kldivergence:   1629.86\n",
      "variational_beta * kldivergence:  0.16299\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.43604\n",
      "kldivergence:   1620.07\n",
      "variational_beta * kldivergence:  0.16201\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.45848\n",
      "kldivergence:   1824.89\n",
      "variational_beta * kldivergence:  0.18249\n",
      "batch accuracy: 85.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.38212\n",
      "kldivergence:   1644.19\n",
      "variational_beta * kldivergence:  0.16442\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #3\n",
      "reconstruction loss: 0.48625\n",
      "kldivergence:   1761.86\n",
      "variational_beta * kldivergence:  0.17619\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "epoch # 3 : train loss is [195.0683380288305] and validation loss is [0.1054946720446838] \n",
      "saved samples\n",
      "Epoch [4 / 150] average reconstruction error: 0.525791\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31974\n",
      "kldivergence:   2145.26\n",
      "variational_beta * kldivergence:  0.21453\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30582\n",
      "kldivergence:   1874.39\n",
      "variational_beta * kldivergence:  0.18744\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31174\n",
      "kldivergence:   1888.97\n",
      "variational_beta * kldivergence:  0.18890\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35812\n",
      "kldivergence:   1855.27\n",
      "variational_beta * kldivergence:  0.18553\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34113\n",
      "kldivergence:   1985.16\n",
      "variational_beta * kldivergence:  0.19852\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33539\n",
      "kldivergence:   1587.56\n",
      "variational_beta * kldivergence:  0.15876\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34162\n",
      "kldivergence:   1639.13\n",
      "variational_beta * kldivergence:  0.16391\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29691\n",
      "kldivergence:   1700.88\n",
      "variational_beta * kldivergence:  0.17009\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32762\n",
      "kldivergence:   1725.37\n",
      "variational_beta * kldivergence:  0.17254\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35542\n",
      "kldivergence:   1907.76\n",
      "variational_beta * kldivergence:  0.19078\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36098\n",
      "kldivergence:   1921.75\n",
      "variational_beta * kldivergence:  0.19218\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34035\n",
      "kldivergence:   1863.03\n",
      "variational_beta * kldivergence:  0.18630\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33427\n",
      "kldivergence:   1767.28\n",
      "variational_beta * kldivergence:  0.17673\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34854\n",
      "kldivergence:   1961.90\n",
      "variational_beta * kldivergence:  0.19619\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36387\n",
      "kldivergence:   1772.79\n",
      "variational_beta * kldivergence:  0.17728\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29137\n",
      "kldivergence:   1777.90\n",
      "variational_beta * kldivergence:  0.17779\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33878\n",
      "kldivergence:   1841.72\n",
      "variational_beta * kldivergence:  0.18417\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31293\n",
      "kldivergence:   1732.92\n",
      "variational_beta * kldivergence:  0.17329\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33850\n",
      "kldivergence:   1704.07\n",
      "variational_beta * kldivergence:  0.17041\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31033\n",
      "kldivergence:   1677.76\n",
      "variational_beta * kldivergence:  0.16778\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32276\n",
      "kldivergence:   1672.34\n",
      "variational_beta * kldivergence:  0.16723\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31583\n",
      "kldivergence:   1687.88\n",
      "variational_beta * kldivergence:  0.16879\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35798\n",
      "kldivergence:   1618.50\n",
      "variational_beta * kldivergence:  0.16185\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34600\n",
      "kldivergence:   1730.22\n",
      "variational_beta * kldivergence:  0.17302\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36680\n",
      "kldivergence:   1913.62\n",
      "variational_beta * kldivergence:  0.19136\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33909\n",
      "kldivergence:   1700.81\n",
      "variational_beta * kldivergence:  0.17008\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34177\n",
      "kldivergence:   1615.78\n",
      "variational_beta * kldivergence:  0.16158\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37729\n",
      "kldivergence:   1568.19\n",
      "variational_beta * kldivergence:  0.15682\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29116\n",
      "kldivergence:   1717.05\n",
      "variational_beta * kldivergence:  0.17170\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29724\n",
      "kldivergence:   1495.58\n",
      "variational_beta * kldivergence:  0.14956\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32802\n",
      "kldivergence:   1672.08\n",
      "variational_beta * kldivergence:  0.16721\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33888\n",
      "kldivergence:   1605.12\n",
      "variational_beta * kldivergence:  0.16051\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37129\n",
      "kldivergence:   2075.55\n",
      "variational_beta * kldivergence:  0.20755\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29755\n",
      "kldivergence:   1603.90\n",
      "variational_beta * kldivergence:  0.16039\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33228\n",
      "kldivergence:   1815.05\n",
      "variational_beta * kldivergence:  0.18151\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29465\n",
      "kldivergence:   1676.94\n",
      "variational_beta * kldivergence:  0.16769\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30669\n",
      "kldivergence:   1559.52\n",
      "variational_beta * kldivergence:  0.15595\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.25364\n",
      "kldivergence:   1717.09\n",
      "variational_beta * kldivergence:  0.17171\n",
      "batch accuracy: 91.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33248\n",
      "kldivergence:   1869.15\n",
      "variational_beta * kldivergence:  0.18691\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34521\n",
      "kldivergence:   1839.14\n",
      "variational_beta * kldivergence:  0.18391\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29473\n",
      "kldivergence:   1814.04\n",
      "variational_beta * kldivergence:  0.18140\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30645\n",
      "kldivergence:   1467.41\n",
      "variational_beta * kldivergence:  0.14674\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33822\n",
      "kldivergence:   1688.64\n",
      "variational_beta * kldivergence:  0.16886\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35489\n",
      "kldivergence:   1790.69\n",
      "variational_beta * kldivergence:  0.17907\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36118\n",
      "kldivergence:   2060.10\n",
      "variational_beta * kldivergence:  0.20601\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34293\n",
      "kldivergence:   1755.61\n",
      "variational_beta * kldivergence:  0.17556\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.38387\n",
      "kldivergence:   1840.90\n",
      "variational_beta * kldivergence:  0.18409\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32461\n",
      "kldivergence:   1746.72\n",
      "variational_beta * kldivergence:  0.17467\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36070\n",
      "kldivergence:   1824.94\n",
      "variational_beta * kldivergence:  0.18249\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33266\n",
      "kldivergence:   1868.19\n",
      "variational_beta * kldivergence:  0.18682\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36345\n",
      "kldivergence:   1803.49\n",
      "variational_beta * kldivergence:  0.18035\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.39652\n",
      "kldivergence:   1739.52\n",
      "variational_beta * kldivergence:  0.17395\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34256\n",
      "kldivergence:   1967.70\n",
      "variational_beta * kldivergence:  0.19677\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32184\n",
      "kldivergence:   1649.95\n",
      "variational_beta * kldivergence:  0.16499\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36396\n",
      "kldivergence:   1655.62\n",
      "variational_beta * kldivergence:  0.16556\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37138\n",
      "kldivergence:   1554.48\n",
      "variational_beta * kldivergence:  0.15545\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36647\n",
      "kldivergence:   1721.51\n",
      "variational_beta * kldivergence:  0.17215\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33357\n",
      "kldivergence:   1596.56\n",
      "variational_beta * kldivergence:  0.15966\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32107\n",
      "kldivergence:   1684.74\n",
      "variational_beta * kldivergence:  0.16847\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.44289\n",
      "kldivergence:   2457.80\n",
      "variational_beta * kldivergence:  0.24578\n",
      "batch accuracy: 85.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.39693\n",
      "kldivergence:   1837.21\n",
      "variational_beta * kldivergence:  0.18372\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29531\n",
      "kldivergence:   1770.48\n",
      "variational_beta * kldivergence:  0.17705\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30888\n",
      "kldivergence:   1708.70\n",
      "variational_beta * kldivergence:  0.17087\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29074\n",
      "kldivergence:   2089.12\n",
      "variational_beta * kldivergence:  0.20891\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.39983\n",
      "kldivergence:   2141.15\n",
      "variational_beta * kldivergence:  0.21412\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33507\n",
      "kldivergence:   1801.32\n",
      "variational_beta * kldivergence:  0.18013\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.28006\n",
      "kldivergence:   2056.11\n",
      "variational_beta * kldivergence:  0.20561\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32736\n",
      "kldivergence:   2054.95\n",
      "variational_beta * kldivergence:  0.20550\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33803\n",
      "kldivergence:   1707.22\n",
      "variational_beta * kldivergence:  0.17072\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33978\n",
      "kldivergence:   1828.64\n",
      "variational_beta * kldivergence:  0.18286\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35799\n",
      "kldivergence:   1882.45\n",
      "variational_beta * kldivergence:  0.18825\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35901\n",
      "kldivergence:   1825.48\n",
      "variational_beta * kldivergence:  0.18255\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36108\n",
      "kldivergence:   1768.24\n",
      "variational_beta * kldivergence:  0.17682\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34425\n",
      "kldivergence:   1796.66\n",
      "variational_beta * kldivergence:  0.17967\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36407\n",
      "kldivergence:   2007.72\n",
      "variational_beta * kldivergence:  0.20077\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34430\n",
      "kldivergence:   2077.85\n",
      "variational_beta * kldivergence:  0.20778\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29090\n",
      "kldivergence:   1772.80\n",
      "variational_beta * kldivergence:  0.17728\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34696\n",
      "kldivergence:   1773.93\n",
      "variational_beta * kldivergence:  0.17739\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35579\n",
      "kldivergence:   1534.07\n",
      "variational_beta * kldivergence:  0.15341\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37794\n",
      "kldivergence:   1765.65\n",
      "variational_beta * kldivergence:  0.17656\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34163\n",
      "kldivergence:   1547.02\n",
      "variational_beta * kldivergence:  0.15470\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33942\n",
      "kldivergence:   1724.13\n",
      "variational_beta * kldivergence:  0.17241\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35910\n",
      "kldivergence:   1706.92\n",
      "variational_beta * kldivergence:  0.17069\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35801\n",
      "kldivergence:   1732.62\n",
      "variational_beta * kldivergence:  0.17326\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30576\n",
      "kldivergence:   1734.19\n",
      "variational_beta * kldivergence:  0.17342\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36455\n",
      "kldivergence:   2180.08\n",
      "variational_beta * kldivergence:  0.21801\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32718\n",
      "kldivergence:   1816.97\n",
      "variational_beta * kldivergence:  0.18170\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.39421\n",
      "kldivergence:   1854.93\n",
      "variational_beta * kldivergence:  0.18549\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36059\n",
      "kldivergence:   2014.05\n",
      "variational_beta * kldivergence:  0.20140\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33675\n",
      "kldivergence:   1906.00\n",
      "variational_beta * kldivergence:  0.19060\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32585\n",
      "kldivergence:   1628.99\n",
      "variational_beta * kldivergence:  0.16290\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37754\n",
      "kldivergence:   1949.79\n",
      "variational_beta * kldivergence:  0.19498\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31203\n",
      "kldivergence:   2091.86\n",
      "variational_beta * kldivergence:  0.20919\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36384\n",
      "kldivergence:   1779.00\n",
      "variational_beta * kldivergence:  0.17790\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35006\n",
      "kldivergence:   1991.62\n",
      "variational_beta * kldivergence:  0.19916\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37793\n",
      "kldivergence:   2121.99\n",
      "variational_beta * kldivergence:  0.21220\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29165\n",
      "kldivergence:   1776.40\n",
      "variational_beta * kldivergence:  0.17764\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31740\n",
      "kldivergence:   1950.55\n",
      "variational_beta * kldivergence:  0.19506\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34843\n",
      "kldivergence:   2310.77\n",
      "variational_beta * kldivergence:  0.23108\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32564\n",
      "kldivergence:   1755.49\n",
      "variational_beta * kldivergence:  0.17555\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.38060\n",
      "kldivergence:   1881.93\n",
      "variational_beta * kldivergence:  0.18819\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.41671\n",
      "kldivergence:   1751.69\n",
      "variational_beta * kldivergence:  0.17517\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35282\n",
      "kldivergence:   2068.25\n",
      "variational_beta * kldivergence:  0.20682\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32956\n",
      "kldivergence:   1923.70\n",
      "variational_beta * kldivergence:  0.19237\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34883\n",
      "kldivergence:   2085.02\n",
      "variational_beta * kldivergence:  0.20850\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36542\n",
      "kldivergence:   2031.75\n",
      "variational_beta * kldivergence:  0.20318\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30754\n",
      "kldivergence:   1850.45\n",
      "variational_beta * kldivergence:  0.18504\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.40130\n",
      "kldivergence:   1901.07\n",
      "variational_beta * kldivergence:  0.19011\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34005\n",
      "kldivergence:   1937.99\n",
      "variational_beta * kldivergence:  0.19380\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33235\n",
      "kldivergence:   1924.08\n",
      "variational_beta * kldivergence:  0.19241\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.28782\n",
      "kldivergence:   1697.10\n",
      "variational_beta * kldivergence:  0.16971\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31004\n",
      "kldivergence:   1684.13\n",
      "variational_beta * kldivergence:  0.16841\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32118\n",
      "kldivergence:   2025.31\n",
      "variational_beta * kldivergence:  0.20253\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33337\n",
      "kldivergence:   1963.87\n",
      "variational_beta * kldivergence:  0.19639\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35804\n",
      "kldivergence:   1929.49\n",
      "variational_beta * kldivergence:  0.19295\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35412\n",
      "kldivergence:   2109.23\n",
      "variational_beta * kldivergence:  0.21092\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32644\n",
      "kldivergence:   1669.44\n",
      "variational_beta * kldivergence:  0.16694\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33158\n",
      "kldivergence:   1601.32\n",
      "variational_beta * kldivergence:  0.16013\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32163\n",
      "kldivergence:   1727.20\n",
      "variational_beta * kldivergence:  0.17272\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33053\n",
      "kldivergence:   1964.69\n",
      "variational_beta * kldivergence:  0.19647\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35488\n",
      "kldivergence:   1821.89\n",
      "variational_beta * kldivergence:  0.18219\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32327\n",
      "kldivergence:   1547.41\n",
      "variational_beta * kldivergence:  0.15474\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37962\n",
      "kldivergence:   2068.02\n",
      "variational_beta * kldivergence:  0.20680\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32888\n",
      "kldivergence:   1879.80\n",
      "variational_beta * kldivergence:  0.18798\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34210\n",
      "kldivergence:   1873.51\n",
      "variational_beta * kldivergence:  0.18735\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32756\n",
      "kldivergence:   1631.31\n",
      "variational_beta * kldivergence:  0.16313\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32098\n",
      "kldivergence:   1741.12\n",
      "variational_beta * kldivergence:  0.17411\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31328\n",
      "kldivergence:   1932.53\n",
      "variational_beta * kldivergence:  0.19325\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33004\n",
      "kldivergence:   1672.92\n",
      "variational_beta * kldivergence:  0.16729\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34054\n",
      "kldivergence:   1756.87\n",
      "variational_beta * kldivergence:  0.17569\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35584\n",
      "kldivergence:   2027.19\n",
      "variational_beta * kldivergence:  0.20272\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32314\n",
      "kldivergence:   1566.22\n",
      "variational_beta * kldivergence:  0.15662\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30947\n",
      "kldivergence:   1927.01\n",
      "variational_beta * kldivergence:  0.19270\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.40384\n",
      "kldivergence:   1907.24\n",
      "variational_beta * kldivergence:  0.19072\n",
      "batch accuracy: 86.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35533\n",
      "kldivergence:   1635.39\n",
      "variational_beta * kldivergence:  0.16354\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37022\n",
      "kldivergence:   2034.80\n",
      "variational_beta * kldivergence:  0.20348\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34845\n",
      "kldivergence:   1618.82\n",
      "variational_beta * kldivergence:  0.16188\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30851\n",
      "kldivergence:   1656.91\n",
      "variational_beta * kldivergence:  0.16569\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29041\n",
      "kldivergence:   1600.14\n",
      "variational_beta * kldivergence:  0.16001\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35358\n",
      "kldivergence:   1766.24\n",
      "variational_beta * kldivergence:  0.17662\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.41914\n",
      "kldivergence:   2079.71\n",
      "variational_beta * kldivergence:  0.20797\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32773\n",
      "kldivergence:   1650.96\n",
      "variational_beta * kldivergence:  0.16510\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34680\n",
      "kldivergence:   1568.04\n",
      "variational_beta * kldivergence:  0.15680\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33770\n",
      "kldivergence:   1684.66\n",
      "variational_beta * kldivergence:  0.16847\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30425\n",
      "kldivergence:   1575.14\n",
      "variational_beta * kldivergence:  0.15751\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33640\n",
      "kldivergence:   1974.31\n",
      "variational_beta * kldivergence:  0.19743\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32945\n",
      "kldivergence:   1690.89\n",
      "variational_beta * kldivergence:  0.16909\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.40173\n",
      "kldivergence:   1958.85\n",
      "variational_beta * kldivergence:  0.19589\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30823\n",
      "kldivergence:   1844.72\n",
      "variational_beta * kldivergence:  0.18447\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31748\n",
      "kldivergence:   2142.43\n",
      "variational_beta * kldivergence:  0.21424\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.40339\n",
      "kldivergence:   2104.90\n",
      "variational_beta * kldivergence:  0.21049\n",
      "batch accuracy: 86.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33224\n",
      "kldivergence:   1782.56\n",
      "variational_beta * kldivergence:  0.17826\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33737\n",
      "kldivergence:   1729.61\n",
      "variational_beta * kldivergence:  0.17296\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36239\n",
      "kldivergence:   2010.89\n",
      "variational_beta * kldivergence:  0.20109\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33132\n",
      "kldivergence:   2015.61\n",
      "variational_beta * kldivergence:  0.20156\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.28052\n",
      "kldivergence:   1867.89\n",
      "variational_beta * kldivergence:  0.18679\n",
      "batch accuracy: 90.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34474\n",
      "kldivergence:   1604.63\n",
      "variational_beta * kldivergence:  0.16046\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.28308\n",
      "kldivergence:   1510.48\n",
      "variational_beta * kldivergence:  0.15105\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34500\n",
      "kldivergence:   1876.32\n",
      "variational_beta * kldivergence:  0.18763\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33514\n",
      "kldivergence:   1579.85\n",
      "variational_beta * kldivergence:  0.15799\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.38941\n",
      "kldivergence:   1830.88\n",
      "variational_beta * kldivergence:  0.18309\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32954\n",
      "kldivergence:   1559.59\n",
      "variational_beta * kldivergence:  0.15596\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.41034\n",
      "kldivergence:   1813.04\n",
      "variational_beta * kldivergence:  0.18130\n",
      "batch accuracy: 86.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35602\n",
      "kldivergence:   1748.64\n",
      "variational_beta * kldivergence:  0.17486\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32789\n",
      "kldivergence:   1785.23\n",
      "variational_beta * kldivergence:  0.17852\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37534\n",
      "kldivergence:   1832.12\n",
      "variational_beta * kldivergence:  0.18321\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.24563\n",
      "kldivergence:   1595.73\n",
      "variational_beta * kldivergence:  0.15957\n",
      "batch accuracy: 91.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32261\n",
      "kldivergence:   1572.07\n",
      "variational_beta * kldivergence:  0.15721\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29936\n",
      "kldivergence:   1597.72\n",
      "variational_beta * kldivergence:  0.15977\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.38896\n",
      "kldivergence:   1788.87\n",
      "variational_beta * kldivergence:  0.17889\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34579\n",
      "kldivergence:   1812.23\n",
      "variational_beta * kldivergence:  0.18122\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31864\n",
      "kldivergence:   1480.73\n",
      "variational_beta * kldivergence:  0.14807\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33782\n",
      "kldivergence:   1665.34\n",
      "variational_beta * kldivergence:  0.16653\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34212\n",
      "kldivergence:   1663.91\n",
      "variational_beta * kldivergence:  0.16639\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35948\n",
      "kldivergence:   1745.09\n",
      "variational_beta * kldivergence:  0.17451\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37086\n",
      "kldivergence:   1712.90\n",
      "variational_beta * kldivergence:  0.17129\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31162\n",
      "kldivergence:   1877.16\n",
      "variational_beta * kldivergence:  0.18772\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33672\n",
      "kldivergence:   1833.07\n",
      "variational_beta * kldivergence:  0.18331\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36125\n",
      "kldivergence:   1922.74\n",
      "variational_beta * kldivergence:  0.19227\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33547\n",
      "kldivergence:   1917.87\n",
      "variational_beta * kldivergence:  0.19179\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32163\n",
      "kldivergence:   1853.73\n",
      "variational_beta * kldivergence:  0.18537\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34207\n",
      "kldivergence:   1998.92\n",
      "variational_beta * kldivergence:  0.19989\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36385\n",
      "kldivergence:   1953.01\n",
      "variational_beta * kldivergence:  0.19530\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.38155\n",
      "kldivergence:   2240.54\n",
      "variational_beta * kldivergence:  0.22405\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31328\n",
      "kldivergence:   1683.15\n",
      "variational_beta * kldivergence:  0.16831\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32172\n",
      "kldivergence:   1754.68\n",
      "variational_beta * kldivergence:  0.17547\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.26233\n",
      "kldivergence:   1536.35\n",
      "variational_beta * kldivergence:  0.15364\n",
      "batch accuracy: 91.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30125\n",
      "kldivergence:   1654.16\n",
      "variational_beta * kldivergence:  0.16542\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33643\n",
      "kldivergence:   1620.53\n",
      "variational_beta * kldivergence:  0.16205\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36607\n",
      "kldivergence:   1962.54\n",
      "variational_beta * kldivergence:  0.19625\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.38005\n",
      "kldivergence:   1818.38\n",
      "variational_beta * kldivergence:  0.18184\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33166\n",
      "kldivergence:   1841.73\n",
      "variational_beta * kldivergence:  0.18417\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32842\n",
      "kldivergence:   1831.27\n",
      "variational_beta * kldivergence:  0.18313\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30207\n",
      "kldivergence:   1685.13\n",
      "variational_beta * kldivergence:  0.16851\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36824\n",
      "kldivergence:   1745.49\n",
      "variational_beta * kldivergence:  0.17455\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37982\n",
      "kldivergence:   2055.72\n",
      "variational_beta * kldivergence:  0.20557\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31179\n",
      "kldivergence:   1749.55\n",
      "variational_beta * kldivergence:  0.17496\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36903\n",
      "kldivergence:   2016.95\n",
      "variational_beta * kldivergence:  0.20169\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34728\n",
      "kldivergence:   1991.59\n",
      "variational_beta * kldivergence:  0.19916\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37096\n",
      "kldivergence:   1900.93\n",
      "variational_beta * kldivergence:  0.19009\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31920\n",
      "kldivergence:   1764.60\n",
      "variational_beta * kldivergence:  0.17646\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37613\n",
      "kldivergence:   2083.30\n",
      "variational_beta * kldivergence:  0.20833\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37387\n",
      "kldivergence:   1906.00\n",
      "variational_beta * kldivergence:  0.19060\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31909\n",
      "kldivergence:   1847.88\n",
      "variational_beta * kldivergence:  0.18479\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29073\n",
      "kldivergence:   1714.34\n",
      "variational_beta * kldivergence:  0.17143\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35409\n",
      "kldivergence:   2154.45\n",
      "variational_beta * kldivergence:  0.21545\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.27235\n",
      "kldivergence:   1753.14\n",
      "variational_beta * kldivergence:  0.17531\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32015\n",
      "kldivergence:   1843.24\n",
      "variational_beta * kldivergence:  0.18432\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36273\n",
      "kldivergence:   1957.07\n",
      "variational_beta * kldivergence:  0.19571\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36094\n",
      "kldivergence:   1925.16\n",
      "variational_beta * kldivergence:  0.19252\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30339\n",
      "kldivergence:   1588.53\n",
      "variational_beta * kldivergence:  0.15885\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29463\n",
      "kldivergence:   1725.58\n",
      "variational_beta * kldivergence:  0.17256\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37489\n",
      "kldivergence:   1834.80\n",
      "variational_beta * kldivergence:  0.18348\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33065\n",
      "kldivergence:   1807.13\n",
      "variational_beta * kldivergence:  0.18071\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34288\n",
      "kldivergence:   1877.30\n",
      "variational_beta * kldivergence:  0.18773\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31679\n",
      "kldivergence:   1925.12\n",
      "variational_beta * kldivergence:  0.19251\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34052\n",
      "kldivergence:   1994.18\n",
      "variational_beta * kldivergence:  0.19942\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.39134\n",
      "kldivergence:   1983.88\n",
      "variational_beta * kldivergence:  0.19839\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.40365\n",
      "kldivergence:   1856.33\n",
      "variational_beta * kldivergence:  0.18563\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33498\n",
      "kldivergence:   1860.47\n",
      "variational_beta * kldivergence:  0.18605\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36432\n",
      "kldivergence:   1802.61\n",
      "variational_beta * kldivergence:  0.18026\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36645\n",
      "kldivergence:   1822.68\n",
      "variational_beta * kldivergence:  0.18227\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31711\n",
      "kldivergence:   1916.90\n",
      "variational_beta * kldivergence:  0.19169\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36307\n",
      "kldivergence:   1715.79\n",
      "variational_beta * kldivergence:  0.17158\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34654\n",
      "kldivergence:   1973.28\n",
      "variational_beta * kldivergence:  0.19733\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32934\n",
      "kldivergence:   1762.94\n",
      "variational_beta * kldivergence:  0.17629\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31385\n",
      "kldivergence:   1802.79\n",
      "variational_beta * kldivergence:  0.18028\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.28779\n",
      "kldivergence:   1743.86\n",
      "variational_beta * kldivergence:  0.17439\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32764\n",
      "kldivergence:   1740.16\n",
      "variational_beta * kldivergence:  0.17402\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33554\n",
      "kldivergence:   1885.19\n",
      "variational_beta * kldivergence:  0.18852\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34740\n",
      "kldivergence:   1790.67\n",
      "variational_beta * kldivergence:  0.17907\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37873\n",
      "kldivergence:   2018.27\n",
      "variational_beta * kldivergence:  0.20183\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33502\n",
      "kldivergence:   1950.64\n",
      "variational_beta * kldivergence:  0.19506\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32740\n",
      "kldivergence:   1952.51\n",
      "variational_beta * kldivergence:  0.19525\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35237\n",
      "kldivergence:   1847.83\n",
      "variational_beta * kldivergence:  0.18478\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35267\n",
      "kldivergence:   1963.12\n",
      "variational_beta * kldivergence:  0.19631\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35218\n",
      "kldivergence:   2059.57\n",
      "variational_beta * kldivergence:  0.20596\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.41442\n",
      "kldivergence:   2156.56\n",
      "variational_beta * kldivergence:  0.21566\n",
      "batch accuracy: 86.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34609\n",
      "kldivergence:   1912.43\n",
      "variational_beta * kldivergence:  0.19124\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.38345\n",
      "kldivergence:   2191.02\n",
      "variational_beta * kldivergence:  0.21910\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33615\n",
      "kldivergence:   2039.77\n",
      "variational_beta * kldivergence:  0.20398\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37660\n",
      "kldivergence:   2119.54\n",
      "variational_beta * kldivergence:  0.21195\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37522\n",
      "kldivergence:   1773.36\n",
      "variational_beta * kldivergence:  0.17734\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32956\n",
      "kldivergence:   1765.62\n",
      "variational_beta * kldivergence:  0.17656\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31603\n",
      "kldivergence:   1735.76\n",
      "variational_beta * kldivergence:  0.17358\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37663\n",
      "kldivergence:   1926.08\n",
      "variational_beta * kldivergence:  0.19261\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33576\n",
      "kldivergence:   1908.36\n",
      "variational_beta * kldivergence:  0.19084\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34701\n",
      "kldivergence:   1921.32\n",
      "variational_beta * kldivergence:  0.19213\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31219\n",
      "kldivergence:   1916.74\n",
      "variational_beta * kldivergence:  0.19167\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30671\n",
      "kldivergence:   1585.65\n",
      "variational_beta * kldivergence:  0.15856\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32796\n",
      "kldivergence:   1878.81\n",
      "variational_beta * kldivergence:  0.18788\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.38843\n",
      "kldivergence:   1799.06\n",
      "variational_beta * kldivergence:  0.17991\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31596\n",
      "kldivergence:   1703.84\n",
      "variational_beta * kldivergence:  0.17038\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32826\n",
      "kldivergence:   1664.60\n",
      "variational_beta * kldivergence:  0.16646\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37463\n",
      "kldivergence:   1953.41\n",
      "variational_beta * kldivergence:  0.19534\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35684\n",
      "kldivergence:   1670.98\n",
      "variational_beta * kldivergence:  0.16710\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33661\n",
      "kldivergence:   1788.69\n",
      "variational_beta * kldivergence:  0.17887\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34768\n",
      "kldivergence:   1645.39\n",
      "variational_beta * kldivergence:  0.16454\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34151\n",
      "kldivergence:   1785.56\n",
      "variational_beta * kldivergence:  0.17856\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29155\n",
      "kldivergence:   1707.80\n",
      "variational_beta * kldivergence:  0.17078\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34105\n",
      "kldivergence:   1837.97\n",
      "variational_beta * kldivergence:  0.18380\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.28734\n",
      "kldivergence:   1889.21\n",
      "variational_beta * kldivergence:  0.18892\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30299\n",
      "kldivergence:   2193.00\n",
      "variational_beta * kldivergence:  0.21930\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33193\n",
      "kldivergence:   1792.64\n",
      "variational_beta * kldivergence:  0.17926\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.38859\n",
      "kldivergence:   1840.51\n",
      "variational_beta * kldivergence:  0.18405\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30024\n",
      "kldivergence:   1854.64\n",
      "variational_beta * kldivergence:  0.18546\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33840\n",
      "kldivergence:   2263.68\n",
      "variational_beta * kldivergence:  0.22637\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37710\n",
      "kldivergence:   2026.03\n",
      "variational_beta * kldivergence:  0.20260\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.27587\n",
      "kldivergence:   1545.72\n",
      "variational_beta * kldivergence:  0.15457\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30138\n",
      "kldivergence:   1615.17\n",
      "variational_beta * kldivergence:  0.16152\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36731\n",
      "kldivergence:   1937.50\n",
      "variational_beta * kldivergence:  0.19375\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32308\n",
      "kldivergence:   1633.84\n",
      "variational_beta * kldivergence:  0.16338\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31790\n",
      "kldivergence:   1556.54\n",
      "variational_beta * kldivergence:  0.15565\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31010\n",
      "kldivergence:   1539.51\n",
      "variational_beta * kldivergence:  0.15395\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.38257\n",
      "kldivergence:   1767.57\n",
      "variational_beta * kldivergence:  0.17676\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33554\n",
      "kldivergence:   1620.40\n",
      "variational_beta * kldivergence:  0.16204\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31999\n",
      "kldivergence:   1768.25\n",
      "variational_beta * kldivergence:  0.17683\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35283\n",
      "kldivergence:   1623.81\n",
      "variational_beta * kldivergence:  0.16238\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.28605\n",
      "kldivergence:   1564.83\n",
      "variational_beta * kldivergence:  0.15648\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29000\n",
      "kldivergence:   1545.87\n",
      "variational_beta * kldivergence:  0.15459\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35378\n",
      "kldivergence:   1663.24\n",
      "variational_beta * kldivergence:  0.16632\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32028\n",
      "kldivergence:   1564.38\n",
      "variational_beta * kldivergence:  0.15644\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32573\n",
      "kldivergence:   1560.70\n",
      "variational_beta * kldivergence:  0.15607\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37302\n",
      "kldivergence:   1894.32\n",
      "variational_beta * kldivergence:  0.18943\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.39786\n",
      "kldivergence:   1774.79\n",
      "variational_beta * kldivergence:  0.17748\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31783\n",
      "kldivergence:   1880.29\n",
      "variational_beta * kldivergence:  0.18803\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30728\n",
      "kldivergence:   1642.24\n",
      "variational_beta * kldivergence:  0.16422\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36413\n",
      "kldivergence:   1810.13\n",
      "variational_beta * kldivergence:  0.18101\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31141\n",
      "kldivergence:   1663.53\n",
      "variational_beta * kldivergence:  0.16635\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.40260\n",
      "kldivergence:   1902.81\n",
      "variational_beta * kldivergence:  0.19028\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30036\n",
      "kldivergence:   1920.33\n",
      "variational_beta * kldivergence:  0.19203\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35303\n",
      "kldivergence:   2008.44\n",
      "variational_beta * kldivergence:  0.20084\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33528\n",
      "kldivergence:   1650.91\n",
      "variational_beta * kldivergence:  0.16509\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34524\n",
      "kldivergence:   1801.78\n",
      "variational_beta * kldivergence:  0.18018\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34013\n",
      "kldivergence:   1772.40\n",
      "variational_beta * kldivergence:  0.17724\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32559\n",
      "kldivergence:   1623.52\n",
      "variational_beta * kldivergence:  0.16235\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36549\n",
      "kldivergence:   1644.34\n",
      "variational_beta * kldivergence:  0.16443\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33521\n",
      "kldivergence:   1756.24\n",
      "variational_beta * kldivergence:  0.17562\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32854\n",
      "kldivergence:   1807.71\n",
      "variational_beta * kldivergence:  0.18077\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36293\n",
      "kldivergence:   1730.98\n",
      "variational_beta * kldivergence:  0.17310\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32162\n",
      "kldivergence:   1916.66\n",
      "variational_beta * kldivergence:  0.19167\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34935\n",
      "kldivergence:   1701.83\n",
      "variational_beta * kldivergence:  0.17018\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32145\n",
      "kldivergence:   1772.67\n",
      "variational_beta * kldivergence:  0.17727\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31437\n",
      "kldivergence:   1772.94\n",
      "variational_beta * kldivergence:  0.17729\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29943\n",
      "kldivergence:   1669.84\n",
      "variational_beta * kldivergence:  0.16698\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35816\n",
      "kldivergence:   1891.10\n",
      "variational_beta * kldivergence:  0.18911\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31691\n",
      "kldivergence:   1611.94\n",
      "variational_beta * kldivergence:  0.16119\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34229\n",
      "kldivergence:   1718.41\n",
      "variational_beta * kldivergence:  0.17184\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32111\n",
      "kldivergence:   1571.14\n",
      "variational_beta * kldivergence:  0.15711\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34160\n",
      "kldivergence:   1790.25\n",
      "variational_beta * kldivergence:  0.17903\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33975\n",
      "kldivergence:   1645.96\n",
      "variational_beta * kldivergence:  0.16460\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31955\n",
      "kldivergence:   1729.87\n",
      "variational_beta * kldivergence:  0.17299\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31626\n",
      "kldivergence:   1810.35\n",
      "variational_beta * kldivergence:  0.18103\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33562\n",
      "kldivergence:   1699.60\n",
      "variational_beta * kldivergence:  0.16996\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35853\n",
      "kldivergence:   1657.15\n",
      "variational_beta * kldivergence:  0.16572\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32651\n",
      "kldivergence:   1715.86\n",
      "variational_beta * kldivergence:  0.17159\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34148\n",
      "kldivergence:   1720.33\n",
      "variational_beta * kldivergence:  0.17203\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33855\n",
      "kldivergence:   2135.00\n",
      "variational_beta * kldivergence:  0.21350\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36589\n",
      "kldivergence:   1716.16\n",
      "variational_beta * kldivergence:  0.17162\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29841\n",
      "kldivergence:   1544.60\n",
      "variational_beta * kldivergence:  0.15446\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30685\n",
      "kldivergence:   1629.09\n",
      "variational_beta * kldivergence:  0.16291\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34190\n",
      "kldivergence:   2100.78\n",
      "variational_beta * kldivergence:  0.21008\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31897\n",
      "kldivergence:   1450.23\n",
      "variational_beta * kldivergence:  0.14502\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36573\n",
      "kldivergence:   2030.38\n",
      "variational_beta * kldivergence:  0.20304\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35824\n",
      "kldivergence:   1873.44\n",
      "variational_beta * kldivergence:  0.18734\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33341\n",
      "kldivergence:   1703.49\n",
      "variational_beta * kldivergence:  0.17035\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31580\n",
      "kldivergence:   1871.54\n",
      "variational_beta * kldivergence:  0.18715\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36325\n",
      "kldivergence:   1655.24\n",
      "variational_beta * kldivergence:  0.16552\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36285\n",
      "kldivergence:   1599.32\n",
      "variational_beta * kldivergence:  0.15993\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37908\n",
      "kldivergence:   1622.31\n",
      "variational_beta * kldivergence:  0.16223\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36846\n",
      "kldivergence:   1870.45\n",
      "variational_beta * kldivergence:  0.18704\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33185\n",
      "kldivergence:   1937.85\n",
      "variational_beta * kldivergence:  0.19378\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31463\n",
      "kldivergence:   1931.36\n",
      "variational_beta * kldivergence:  0.19314\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35407\n",
      "kldivergence:   1733.20\n",
      "variational_beta * kldivergence:  0.17332\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36819\n",
      "kldivergence:   1805.22\n",
      "variational_beta * kldivergence:  0.18052\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34190\n",
      "kldivergence:   1842.64\n",
      "variational_beta * kldivergence:  0.18426\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33171\n",
      "kldivergence:   1886.00\n",
      "variational_beta * kldivergence:  0.18860\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33466\n",
      "kldivergence:   1743.60\n",
      "variational_beta * kldivergence:  0.17436\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.36014\n",
      "kldivergence:   1903.42\n",
      "variational_beta * kldivergence:  0.19034\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.31543\n",
      "kldivergence:   1610.67\n",
      "variational_beta * kldivergence:  0.16107\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33277\n",
      "kldivergence:   1654.59\n",
      "variational_beta * kldivergence:  0.16546\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33082\n",
      "kldivergence:   1984.58\n",
      "variational_beta * kldivergence:  0.19846\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35633\n",
      "kldivergence:   1786.60\n",
      "variational_beta * kldivergence:  0.17866\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33841\n",
      "kldivergence:   1869.80\n",
      "variational_beta * kldivergence:  0.18698\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33828\n",
      "kldivergence:   1843.75\n",
      "variational_beta * kldivergence:  0.18437\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34694\n",
      "kldivergence:   1898.70\n",
      "variational_beta * kldivergence:  0.18987\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34033\n",
      "kldivergence:   1653.07\n",
      "variational_beta * kldivergence:  0.16531\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34168\n",
      "kldivergence:   2040.63\n",
      "variational_beta * kldivergence:  0.20406\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33345\n",
      "kldivergence:   1554.64\n",
      "variational_beta * kldivergence:  0.15546\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33791\n",
      "kldivergence:   1816.80\n",
      "variational_beta * kldivergence:  0.18168\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.41481\n",
      "kldivergence:   1763.86\n",
      "variational_beta * kldivergence:  0.17639\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34603\n",
      "kldivergence:   2001.08\n",
      "variational_beta * kldivergence:  0.20011\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37097\n",
      "kldivergence:   1721.75\n",
      "variational_beta * kldivergence:  0.17218\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33735\n",
      "kldivergence:   1549.10\n",
      "variational_beta * kldivergence:  0.15491\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35783\n",
      "kldivergence:   1907.88\n",
      "variational_beta * kldivergence:  0.19079\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.39497\n",
      "kldivergence:   1891.70\n",
      "variational_beta * kldivergence:  0.18917\n",
      "batch accuracy: 86.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.29299\n",
      "kldivergence:   1774.10\n",
      "variational_beta * kldivergence:  0.17741\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34776\n",
      "kldivergence:   1765.76\n",
      "variational_beta * kldivergence:  0.17658\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33046\n",
      "kldivergence:   1629.02\n",
      "variational_beta * kldivergence:  0.16290\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.33890\n",
      "kldivergence:   1953.81\n",
      "variational_beta * kldivergence:  0.19538\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34841\n",
      "kldivergence:   1823.37\n",
      "variational_beta * kldivergence:  0.18234\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.40264\n",
      "kldivergence:   1877.23\n",
      "variational_beta * kldivergence:  0.18772\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30605\n",
      "kldivergence:   1615.17\n",
      "variational_beta * kldivergence:  0.16152\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.43848\n",
      "kldivergence:   1983.23\n",
      "variational_beta * kldivergence:  0.19832\n",
      "batch accuracy: 85.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30437\n",
      "kldivergence:   1569.83\n",
      "variational_beta * kldivergence:  0.15698\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.26729\n",
      "kldivergence:   1878.27\n",
      "variational_beta * kldivergence:  0.18783\n",
      "batch accuracy: 90.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.35346\n",
      "kldivergence:   1774.19\n",
      "variational_beta * kldivergence:  0.17742\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.34947\n",
      "kldivergence:   1710.49\n",
      "variational_beta * kldivergence:  0.17105\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.30943\n",
      "kldivergence:   1764.50\n",
      "variational_beta * kldivergence:  0.17645\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.37602\n",
      "kldivergence:   1821.71\n",
      "variational_beta * kldivergence:  0.18217\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #4\n",
      "reconstruction loss: 0.32581\n",
      "kldivergence:   1768.35\n",
      "variational_beta * kldivergence:  0.17684\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.40366\n",
      "kldivergence:   1595.49\n",
      "variational_beta * kldivergence:  0.15955\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.43994\n",
      "kldivergence:   1649.89\n",
      "variational_beta * kldivergence:  0.16499\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.49770\n",
      "kldivergence:   1662.07\n",
      "variational_beta * kldivergence:  0.16621\n",
      "batch accuracy: 84.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.41002\n",
      "kldivergence:   1606.65\n",
      "variational_beta * kldivergence:  0.16067\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.44799\n",
      "kldivergence:   1728.17\n",
      "variational_beta * kldivergence:  0.17282\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.46031\n",
      "kldivergence:   1694.93\n",
      "variational_beta * kldivergence:  0.16949\n",
      "batch accuracy: 86.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.43322\n",
      "kldivergence:   1646.94\n",
      "variational_beta * kldivergence:  0.16469\n",
      "batch accuracy: 86.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.48435\n",
      "kldivergence:   1839.30\n",
      "variational_beta * kldivergence:  0.18393\n",
      "batch accuracy: 84.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.47078\n",
      "kldivergence:   1740.75\n",
      "variational_beta * kldivergence:  0.17408\n",
      "batch accuracy: 85.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.47471\n",
      "kldivergence:   1684.46\n",
      "variational_beta * kldivergence:  0.16845\n",
      "batch accuracy: 84.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.48476\n",
      "kldivergence:   1683.98\n",
      "variational_beta * kldivergence:  0.16840\n",
      "batch accuracy: 86.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.49815\n",
      "kldivergence:   1720.09\n",
      "variational_beta * kldivergence:  0.17201\n",
      "batch accuracy: 84.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.44974\n",
      "kldivergence:   1714.42\n",
      "variational_beta * kldivergence:  0.17144\n",
      "batch accuracy: 86.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.51759\n",
      "kldivergence:   1873.94\n",
      "variational_beta * kldivergence:  0.18739\n",
      "batch accuracy: 83.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.45104\n",
      "kldivergence:   1606.77\n",
      "variational_beta * kldivergence:  0.16068\n",
      "batch accuracy: 85.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.44652\n",
      "kldivergence:   1653.54\n",
      "variational_beta * kldivergence:  0.16535\n",
      "batch accuracy: 86.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.43994\n",
      "kldivergence:   1702.63\n",
      "variational_beta * kldivergence:  0.17026\n",
      "batch accuracy: 86.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.37921\n",
      "kldivergence:   1496.39\n",
      "variational_beta * kldivergence:  0.14964\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.39558\n",
      "kldivergence:   1618.88\n",
      "variational_beta * kldivergence:  0.16189\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.45179\n",
      "kldivergence:   1780.62\n",
      "variational_beta * kldivergence:  0.17806\n",
      "batch accuracy: 86.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.43773\n",
      "kldivergence:   1660.67\n",
      "variational_beta * kldivergence:  0.16607\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.44762\n",
      "kldivergence:   1725.48\n",
      "variational_beta * kldivergence:  0.17255\n",
      "batch accuracy: 85.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.45038\n",
      "kldivergence:   1745.51\n",
      "variational_beta * kldivergence:  0.17455\n",
      "batch accuracy: 85.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.42068\n",
      "kldivergence:   1657.84\n",
      "variational_beta * kldivergence:  0.16578\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.47811\n",
      "kldivergence:   1806.15\n",
      "variational_beta * kldivergence:  0.18062\n",
      "batch accuracy: 84.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.45306\n",
      "kldivergence:   1834.99\n",
      "variational_beta * kldivergence:  0.18350\n",
      "batch accuracy: 85.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.48567\n",
      "kldivergence:   1647.34\n",
      "variational_beta * kldivergence:  0.16473\n",
      "batch accuracy: 85.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.42348\n",
      "kldivergence:   1763.70\n",
      "variational_beta * kldivergence:  0.17637\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.55687\n",
      "kldivergence:   1830.27\n",
      "variational_beta * kldivergence:  0.18303\n",
      "batch accuracy: 83.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.47236\n",
      "kldivergence:   1765.58\n",
      "variational_beta * kldivergence:  0.17656\n",
      "batch accuracy: 85.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.37147\n",
      "kldivergence:   1647.16\n",
      "variational_beta * kldivergence:  0.16472\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.51657\n",
      "kldivergence:   1838.57\n",
      "variational_beta * kldivergence:  0.18386\n",
      "batch accuracy: 84.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.46059\n",
      "kldivergence:   1716.01\n",
      "variational_beta * kldivergence:  0.17160\n",
      "batch accuracy: 85.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.48343\n",
      "kldivergence:   1704.38\n",
      "variational_beta * kldivergence:  0.17044\n",
      "batch accuracy: 85.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.43520\n",
      "kldivergence:   1646.04\n",
      "variational_beta * kldivergence:  0.16460\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.37593\n",
      "kldivergence:   1632.25\n",
      "variational_beta * kldivergence:  0.16323\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.48344\n",
      "kldivergence:   1700.59\n",
      "variational_beta * kldivergence:  0.17006\n",
      "batch accuracy: 85.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.44456\n",
      "kldivergence:   1645.96\n",
      "variational_beta * kldivergence:  0.16460\n",
      "batch accuracy: 86.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.38771\n",
      "kldivergence:   1727.96\n",
      "variational_beta * kldivergence:  0.17280\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.53664\n",
      "kldivergence:   1882.76\n",
      "variational_beta * kldivergence:  0.18828\n",
      "batch accuracy: 83.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.44980\n",
      "kldivergence:   1732.08\n",
      "variational_beta * kldivergence:  0.17321\n",
      "batch accuracy: 86.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.42889\n",
      "kldivergence:   1569.86\n",
      "variational_beta * kldivergence:  0.15699\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.52271\n",
      "kldivergence:   1872.09\n",
      "variational_beta * kldivergence:  0.18721\n",
      "batch accuracy: 84.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.38701\n",
      "kldivergence:   1658.53\n",
      "variational_beta * kldivergence:  0.16585\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.46076\n",
      "kldivergence:   1761.19\n",
      "variational_beta * kldivergence:  0.17612\n",
      "batch accuracy: 85.62\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.51214\n",
      "kldivergence:   1696.38\n",
      "variational_beta * kldivergence:  0.16964\n",
      "batch accuracy: 84.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.50029\n",
      "kldivergence:   1713.51\n",
      "variational_beta * kldivergence:  0.17135\n",
      "batch accuracy: 84.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.45084\n",
      "kldivergence:   1651.19\n",
      "variational_beta * kldivergence:  0.16512\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.48740\n",
      "kldivergence:   1782.97\n",
      "variational_beta * kldivergence:  0.17830\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.57135\n",
      "kldivergence:   1846.59\n",
      "variational_beta * kldivergence:  0.18466\n",
      "batch accuracy: 82.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.44912\n",
      "kldivergence:   1731.19\n",
      "variational_beta * kldivergence:  0.17312\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.43170\n",
      "kldivergence:   1634.03\n",
      "variational_beta * kldivergence:  0.16340\n",
      "batch accuracy: 86.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.48763\n",
      "kldivergence:   1758.96\n",
      "variational_beta * kldivergence:  0.17590\n",
      "batch accuracy: 85.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.36878\n",
      "kldivergence:   1579.64\n",
      "variational_beta * kldivergence:  0.15796\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.42987\n",
      "kldivergence:   1653.12\n",
      "variational_beta * kldivergence:  0.16531\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.47473\n",
      "kldivergence:   1659.78\n",
      "variational_beta * kldivergence:  0.16598\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.41300\n",
      "kldivergence:   1609.24\n",
      "variational_beta * kldivergence:  0.16092\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.35292\n",
      "kldivergence:   1470.59\n",
      "variational_beta * kldivergence:  0.14706\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.50439\n",
      "kldivergence:   1767.01\n",
      "variational_beta * kldivergence:  0.17670\n",
      "batch accuracy: 84.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.47802\n",
      "kldivergence:   1738.45\n",
      "variational_beta * kldivergence:  0.17385\n",
      "batch accuracy: 85.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.35792\n",
      "kldivergence:   1532.58\n",
      "variational_beta * kldivergence:  0.15326\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #4\n",
      "reconstruction loss: 0.51562\n",
      "kldivergence:   1914.57\n",
      "variational_beta * kldivergence:  0.19146\n",
      "batch accuracy: 83.42\n",
      "\n",
      "\n",
      "epoch # 4 : train loss is [193.72312328916206] and validation loss is [0.10474429922601007] \n",
      "Epoch [5 / 150] average reconstruction error: 0.522165\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37588\n",
      "kldivergence:   2001.96\n",
      "variational_beta * kldivergence:  0.20020\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34032\n",
      "kldivergence:   1710.60\n",
      "variational_beta * kldivergence:  0.17106\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37243\n",
      "kldivergence:   2040.47\n",
      "variational_beta * kldivergence:  0.20405\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33843\n",
      "kldivergence:   2139.62\n",
      "variational_beta * kldivergence:  0.21396\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30647\n",
      "kldivergence:   1999.02\n",
      "variational_beta * kldivergence:  0.19990\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36847\n",
      "kldivergence:   1756.15\n",
      "variational_beta * kldivergence:  0.17562\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29716\n",
      "kldivergence:   1789.28\n",
      "variational_beta * kldivergence:  0.17893\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30579\n",
      "kldivergence:   1874.36\n",
      "variational_beta * kldivergence:  0.18744\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36403\n",
      "kldivergence:   1949.13\n",
      "variational_beta * kldivergence:  0.19491\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33613\n",
      "kldivergence:   1868.48\n",
      "variational_beta * kldivergence:  0.18685\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31441\n",
      "kldivergence:   1641.69\n",
      "variational_beta * kldivergence:  0.16417\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34005\n",
      "kldivergence:   1821.71\n",
      "variational_beta * kldivergence:  0.18217\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34310\n",
      "kldivergence:   1782.16\n",
      "variational_beta * kldivergence:  0.17822\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35428\n",
      "kldivergence:   1798.30\n",
      "variational_beta * kldivergence:  0.17983\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29687\n",
      "kldivergence:   1821.45\n",
      "variational_beta * kldivergence:  0.18214\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32234\n",
      "kldivergence:   1710.51\n",
      "variational_beta * kldivergence:  0.17105\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36826\n",
      "kldivergence:   1854.47\n",
      "variational_beta * kldivergence:  0.18545\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37029\n",
      "kldivergence:   1734.17\n",
      "variational_beta * kldivergence:  0.17342\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38142\n",
      "kldivergence:   1992.18\n",
      "variational_beta * kldivergence:  0.19922\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33288\n",
      "kldivergence:   1730.57\n",
      "variational_beta * kldivergence:  0.17306\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29934\n",
      "kldivergence:   1801.82\n",
      "variational_beta * kldivergence:  0.18018\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34562\n",
      "kldivergence:   1815.95\n",
      "variational_beta * kldivergence:  0.18160\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31355\n",
      "kldivergence:   1683.90\n",
      "variational_beta * kldivergence:  0.16839\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29337\n",
      "kldivergence:   1860.85\n",
      "variational_beta * kldivergence:  0.18608\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32963\n",
      "kldivergence:   1929.86\n",
      "variational_beta * kldivergence:  0.19299\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32989\n",
      "kldivergence:   1624.33\n",
      "variational_beta * kldivergence:  0.16243\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.40140\n",
      "kldivergence:   1838.25\n",
      "variational_beta * kldivergence:  0.18383\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37488\n",
      "kldivergence:   1655.18\n",
      "variational_beta * kldivergence:  0.16552\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31198\n",
      "kldivergence:   1485.49\n",
      "variational_beta * kldivergence:  0.14855\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30208\n",
      "kldivergence:   1499.80\n",
      "variational_beta * kldivergence:  0.14998\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35023\n",
      "kldivergence:   1862.35\n",
      "variational_beta * kldivergence:  0.18624\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31947\n",
      "kldivergence:   1883.51\n",
      "variational_beta * kldivergence:  0.18835\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36648\n",
      "kldivergence:   1801.29\n",
      "variational_beta * kldivergence:  0.18013\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34069\n",
      "kldivergence:   1717.85\n",
      "variational_beta * kldivergence:  0.17179\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29551\n",
      "kldivergence:   1885.94\n",
      "variational_beta * kldivergence:  0.18859\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35775\n",
      "kldivergence:   1779.40\n",
      "variational_beta * kldivergence:  0.17794\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.40719\n",
      "kldivergence:   1964.24\n",
      "variational_beta * kldivergence:  0.19642\n",
      "batch accuracy: 86.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35925\n",
      "kldivergence:   2114.61\n",
      "variational_beta * kldivergence:  0.21146\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35413\n",
      "kldivergence:   1737.32\n",
      "variational_beta * kldivergence:  0.17373\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30857\n",
      "kldivergence:   1495.52\n",
      "variational_beta * kldivergence:  0.14955\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33782\n",
      "kldivergence:   1599.90\n",
      "variational_beta * kldivergence:  0.15999\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30583\n",
      "kldivergence:   1845.78\n",
      "variational_beta * kldivergence:  0.18458\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36781\n",
      "kldivergence:   1958.43\n",
      "variational_beta * kldivergence:  0.19584\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35740\n",
      "kldivergence:   2005.54\n",
      "variational_beta * kldivergence:  0.20055\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35472\n",
      "kldivergence:   1903.03\n",
      "variational_beta * kldivergence:  0.19030\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32941\n",
      "kldivergence:   2138.80\n",
      "variational_beta * kldivergence:  0.21388\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34074\n",
      "kldivergence:   1772.51\n",
      "variational_beta * kldivergence:  0.17725\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30937\n",
      "kldivergence:   1972.75\n",
      "variational_beta * kldivergence:  0.19727\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32127\n",
      "kldivergence:   1912.85\n",
      "variational_beta * kldivergence:  0.19128\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39002\n",
      "kldivergence:   1855.42\n",
      "variational_beta * kldivergence:  0.18554\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28916\n",
      "kldivergence:   1532.33\n",
      "variational_beta * kldivergence:  0.15323\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33536\n",
      "kldivergence:   1742.05\n",
      "variational_beta * kldivergence:  0.17420\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.27216\n",
      "kldivergence:   1837.11\n",
      "variational_beta * kldivergence:  0.18371\n",
      "batch accuracy: 90.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30661\n",
      "kldivergence:   1687.83\n",
      "variational_beta * kldivergence:  0.16878\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34824\n",
      "kldivergence:   1585.75\n",
      "variational_beta * kldivergence:  0.15858\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34531\n",
      "kldivergence:   1950.46\n",
      "variational_beta * kldivergence:  0.19505\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35393\n",
      "kldivergence:   1760.63\n",
      "variational_beta * kldivergence:  0.17606\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36321\n",
      "kldivergence:   1900.85\n",
      "variational_beta * kldivergence:  0.19008\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31965\n",
      "kldivergence:   1488.69\n",
      "variational_beta * kldivergence:  0.14887\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39004\n",
      "kldivergence:   1639.79\n",
      "variational_beta * kldivergence:  0.16398\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30782\n",
      "kldivergence:   1877.35\n",
      "variational_beta * kldivergence:  0.18773\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32377\n",
      "kldivergence:   1762.55\n",
      "variational_beta * kldivergence:  0.17625\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32704\n",
      "kldivergence:   1646.45\n",
      "variational_beta * kldivergence:  0.16465\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.42066\n",
      "kldivergence:   1800.62\n",
      "variational_beta * kldivergence:  0.18006\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34262\n",
      "kldivergence:   1680.77\n",
      "variational_beta * kldivergence:  0.16808\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35303\n",
      "kldivergence:   1932.65\n",
      "variational_beta * kldivergence:  0.19327\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30143\n",
      "kldivergence:   1522.99\n",
      "variational_beta * kldivergence:  0.15230\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36903\n",
      "kldivergence:   1804.02\n",
      "variational_beta * kldivergence:  0.18040\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31604\n",
      "kldivergence:   1614.04\n",
      "variational_beta * kldivergence:  0.16140\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31607\n",
      "kldivergence:   1642.21\n",
      "variational_beta * kldivergence:  0.16422\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38148\n",
      "kldivergence:   1875.88\n",
      "variational_beta * kldivergence:  0.18759\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.27582\n",
      "kldivergence:   1950.94\n",
      "variational_beta * kldivergence:  0.19509\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30966\n",
      "kldivergence:   1947.03\n",
      "variational_beta * kldivergence:  0.19470\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31613\n",
      "kldivergence:   1683.25\n",
      "variational_beta * kldivergence:  0.16833\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29681\n",
      "kldivergence:   2062.68\n",
      "variational_beta * kldivergence:  0.20627\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34558\n",
      "kldivergence:   1788.15\n",
      "variational_beta * kldivergence:  0.17882\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31205\n",
      "kldivergence:   1624.42\n",
      "variational_beta * kldivergence:  0.16244\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29405\n",
      "kldivergence:   1684.81\n",
      "variational_beta * kldivergence:  0.16848\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34543\n",
      "kldivergence:   1892.46\n",
      "variational_beta * kldivergence:  0.18925\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36296\n",
      "kldivergence:   2100.82\n",
      "variational_beta * kldivergence:  0.21008\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32879\n",
      "kldivergence:   1595.60\n",
      "variational_beta * kldivergence:  0.15956\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34196\n",
      "kldivergence:   1916.62\n",
      "variational_beta * kldivergence:  0.19166\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29611\n",
      "kldivergence:   1683.07\n",
      "variational_beta * kldivergence:  0.16831\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34833\n",
      "kldivergence:   1808.38\n",
      "variational_beta * kldivergence:  0.18084\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30367\n",
      "kldivergence:   1771.94\n",
      "variational_beta * kldivergence:  0.17719\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29086\n",
      "kldivergence:   1915.72\n",
      "variational_beta * kldivergence:  0.19157\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29264\n",
      "kldivergence:   1576.26\n",
      "variational_beta * kldivergence:  0.15763\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33660\n",
      "kldivergence:   1749.35\n",
      "variational_beta * kldivergence:  0.17493\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34868\n",
      "kldivergence:   1760.33\n",
      "variational_beta * kldivergence:  0.17603\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31754\n",
      "kldivergence:   1591.46\n",
      "variational_beta * kldivergence:  0.15915\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35407\n",
      "kldivergence:   1692.04\n",
      "variational_beta * kldivergence:  0.16920\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32927\n",
      "kldivergence:   1695.59\n",
      "variational_beta * kldivergence:  0.16956\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37101\n",
      "kldivergence:   1995.25\n",
      "variational_beta * kldivergence:  0.19952\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36970\n",
      "kldivergence:   1793.74\n",
      "variational_beta * kldivergence:  0.17937\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33622\n",
      "kldivergence:   1727.62\n",
      "variational_beta * kldivergence:  0.17276\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31448\n",
      "kldivergence:   1707.45\n",
      "variational_beta * kldivergence:  0.17075\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33940\n",
      "kldivergence:   1800.89\n",
      "variational_beta * kldivergence:  0.18009\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38219\n",
      "kldivergence:   1877.71\n",
      "variational_beta * kldivergence:  0.18777\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34954\n",
      "kldivergence:   1501.20\n",
      "variational_beta * kldivergence:  0.15012\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30547\n",
      "kldivergence:   1780.51\n",
      "variational_beta * kldivergence:  0.17805\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31122\n",
      "kldivergence:   2145.90\n",
      "variational_beta * kldivergence:  0.21459\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28038\n",
      "kldivergence:   1518.87\n",
      "variational_beta * kldivergence:  0.15189\n",
      "batch accuracy: 90.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34762\n",
      "kldivergence:   1792.30\n",
      "variational_beta * kldivergence:  0.17923\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37238\n",
      "kldivergence:   1646.45\n",
      "variational_beta * kldivergence:  0.16464\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32565\n",
      "kldivergence:   1764.22\n",
      "variational_beta * kldivergence:  0.17642\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32118\n",
      "kldivergence:   1802.77\n",
      "variational_beta * kldivergence:  0.18028\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33633\n",
      "kldivergence:   1785.42\n",
      "variational_beta * kldivergence:  0.17854\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39329\n",
      "kldivergence:   2047.62\n",
      "variational_beta * kldivergence:  0.20476\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39673\n",
      "kldivergence:   1900.19\n",
      "variational_beta * kldivergence:  0.19002\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33283\n",
      "kldivergence:   1782.23\n",
      "variational_beta * kldivergence:  0.17822\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29705\n",
      "kldivergence:   1682.14\n",
      "variational_beta * kldivergence:  0.16821\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38575\n",
      "kldivergence:   2002.05\n",
      "variational_beta * kldivergence:  0.20020\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34304\n",
      "kldivergence:   2156.98\n",
      "variational_beta * kldivergence:  0.21570\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.26859\n",
      "kldivergence:   1584.81\n",
      "variational_beta * kldivergence:  0.15848\n",
      "batch accuracy: 90.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35256\n",
      "kldivergence:   1680.70\n",
      "variational_beta * kldivergence:  0.16807\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32139\n",
      "kldivergence:   1531.31\n",
      "variational_beta * kldivergence:  0.15313\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28476\n",
      "kldivergence:   1604.95\n",
      "variational_beta * kldivergence:  0.16049\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32998\n",
      "kldivergence:   1882.38\n",
      "variational_beta * kldivergence:  0.18824\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28748\n",
      "kldivergence:   1785.60\n",
      "variational_beta * kldivergence:  0.17856\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35639\n",
      "kldivergence:   1901.19\n",
      "variational_beta * kldivergence:  0.19012\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36309\n",
      "kldivergence:   1841.80\n",
      "variational_beta * kldivergence:  0.18418\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35079\n",
      "kldivergence:   1763.78\n",
      "variational_beta * kldivergence:  0.17638\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35749\n",
      "kldivergence:   1616.78\n",
      "variational_beta * kldivergence:  0.16168\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39592\n",
      "kldivergence:   1849.94\n",
      "variational_beta * kldivergence:  0.18499\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33039\n",
      "kldivergence:   1791.25\n",
      "variational_beta * kldivergence:  0.17912\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36760\n",
      "kldivergence:   1928.43\n",
      "variational_beta * kldivergence:  0.19284\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30417\n",
      "kldivergence:   1877.98\n",
      "variational_beta * kldivergence:  0.18780\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33441\n",
      "kldivergence:   1784.94\n",
      "variational_beta * kldivergence:  0.17849\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35160\n",
      "kldivergence:   1894.35\n",
      "variational_beta * kldivergence:  0.18943\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33710\n",
      "kldivergence:   1695.31\n",
      "variational_beta * kldivergence:  0.16953\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31807\n",
      "kldivergence:   2686.83\n",
      "variational_beta * kldivergence:  0.26868\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32966\n",
      "kldivergence:   1791.79\n",
      "variational_beta * kldivergence:  0.17918\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34589\n",
      "kldivergence:   1971.03\n",
      "variational_beta * kldivergence:  0.19710\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37846\n",
      "kldivergence:   2147.17\n",
      "variational_beta * kldivergence:  0.21472\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29770\n",
      "kldivergence:   1668.19\n",
      "variational_beta * kldivergence:  0.16682\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28525\n",
      "kldivergence:   1764.04\n",
      "variational_beta * kldivergence:  0.17640\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36457\n",
      "kldivergence:   2622.01\n",
      "variational_beta * kldivergence:  0.26220\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34229\n",
      "kldivergence:   1902.04\n",
      "variational_beta * kldivergence:  0.19020\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38947\n",
      "kldivergence:   1758.55\n",
      "variational_beta * kldivergence:  0.17585\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33148\n",
      "kldivergence:   1730.28\n",
      "variational_beta * kldivergence:  0.17303\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30527\n",
      "kldivergence:   1572.00\n",
      "variational_beta * kldivergence:  0.15720\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37681\n",
      "kldivergence:   1677.38\n",
      "variational_beta * kldivergence:  0.16774\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36318\n",
      "kldivergence:   1713.48\n",
      "variational_beta * kldivergence:  0.17135\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32229\n",
      "kldivergence:   1478.19\n",
      "variational_beta * kldivergence:  0.14782\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28291\n",
      "kldivergence:   1850.55\n",
      "variational_beta * kldivergence:  0.18505\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.41830\n",
      "kldivergence:   2072.39\n",
      "variational_beta * kldivergence:  0.20724\n",
      "batch accuracy: 85.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33775\n",
      "kldivergence:   1657.69\n",
      "variational_beta * kldivergence:  0.16577\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34682\n",
      "kldivergence:   1644.01\n",
      "variational_beta * kldivergence:  0.16440\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33688\n",
      "kldivergence:   1720.46\n",
      "variational_beta * kldivergence:  0.17205\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32995\n",
      "kldivergence:   1520.10\n",
      "variational_beta * kldivergence:  0.15201\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34267\n",
      "kldivergence:   1658.59\n",
      "variational_beta * kldivergence:  0.16586\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33155\n",
      "kldivergence:   1619.46\n",
      "variational_beta * kldivergence:  0.16195\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.40328\n",
      "kldivergence:   2029.41\n",
      "variational_beta * kldivergence:  0.20294\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38210\n",
      "kldivergence:   1831.87\n",
      "variational_beta * kldivergence:  0.18319\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35239\n",
      "kldivergence:   1628.53\n",
      "variational_beta * kldivergence:  0.16285\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35534\n",
      "kldivergence:   1680.17\n",
      "variational_beta * kldivergence:  0.16802\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31733\n",
      "kldivergence:   1772.50\n",
      "variational_beta * kldivergence:  0.17725\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39631\n",
      "kldivergence:   2006.06\n",
      "variational_beta * kldivergence:  0.20061\n",
      "batch accuracy: 86.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35040\n",
      "kldivergence:   1898.88\n",
      "variational_beta * kldivergence:  0.18989\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34619\n",
      "kldivergence:   1738.80\n",
      "variational_beta * kldivergence:  0.17388\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29767\n",
      "kldivergence:   1641.76\n",
      "variational_beta * kldivergence:  0.16418\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37361\n",
      "kldivergence:   1630.94\n",
      "variational_beta * kldivergence:  0.16309\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30988\n",
      "kldivergence:   1536.17\n",
      "variational_beta * kldivergence:  0.15362\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37984\n",
      "kldivergence:   1792.01\n",
      "variational_beta * kldivergence:  0.17920\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32431\n",
      "kldivergence:   1640.91\n",
      "variational_beta * kldivergence:  0.16409\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36092\n",
      "kldivergence:   1736.53\n",
      "variational_beta * kldivergence:  0.17365\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32316\n",
      "kldivergence:   1664.78\n",
      "variational_beta * kldivergence:  0.16648\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33145\n",
      "kldivergence:   2298.01\n",
      "variational_beta * kldivergence:  0.22980\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34306\n",
      "kldivergence:   1964.76\n",
      "variational_beta * kldivergence:  0.19648\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31191\n",
      "kldivergence:   1789.65\n",
      "variational_beta * kldivergence:  0.17897\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33465\n",
      "kldivergence:   2038.83\n",
      "variational_beta * kldivergence:  0.20388\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28751\n",
      "kldivergence:   1722.11\n",
      "variational_beta * kldivergence:  0.17221\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34802\n",
      "kldivergence:   2147.12\n",
      "variational_beta * kldivergence:  0.21471\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37346\n",
      "kldivergence:   1816.66\n",
      "variational_beta * kldivergence:  0.18167\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32550\n",
      "kldivergence:   1548.61\n",
      "variational_beta * kldivergence:  0.15486\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34834\n",
      "kldivergence:   1664.47\n",
      "variational_beta * kldivergence:  0.16645\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37718\n",
      "kldivergence:   1864.08\n",
      "variational_beta * kldivergence:  0.18641\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31902\n",
      "kldivergence:   1725.64\n",
      "variational_beta * kldivergence:  0.17256\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32803\n",
      "kldivergence:   1652.51\n",
      "variational_beta * kldivergence:  0.16525\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34673\n",
      "kldivergence:   1671.57\n",
      "variational_beta * kldivergence:  0.16716\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33020\n",
      "kldivergence:   1690.64\n",
      "variational_beta * kldivergence:  0.16906\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36339\n",
      "kldivergence:   1702.77\n",
      "variational_beta * kldivergence:  0.17028\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33527\n",
      "kldivergence:   1712.24\n",
      "variational_beta * kldivergence:  0.17122\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32936\n",
      "kldivergence:   1827.38\n",
      "variational_beta * kldivergence:  0.18274\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35337\n",
      "kldivergence:   1888.59\n",
      "variational_beta * kldivergence:  0.18886\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28753\n",
      "kldivergence:   1606.05\n",
      "variational_beta * kldivergence:  0.16061\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34377\n",
      "kldivergence:   1819.95\n",
      "variational_beta * kldivergence:  0.18200\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36522\n",
      "kldivergence:   1934.59\n",
      "variational_beta * kldivergence:  0.19346\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30769\n",
      "kldivergence:   1745.61\n",
      "variational_beta * kldivergence:  0.17456\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35536\n",
      "kldivergence:   1601.61\n",
      "variational_beta * kldivergence:  0.16016\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39643\n",
      "kldivergence:   2183.03\n",
      "variational_beta * kldivergence:  0.21830\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33968\n",
      "kldivergence:   1807.35\n",
      "variational_beta * kldivergence:  0.18074\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38321\n",
      "kldivergence:   2151.64\n",
      "variational_beta * kldivergence:  0.21516\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31783\n",
      "kldivergence:   1727.25\n",
      "variational_beta * kldivergence:  0.17272\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31589\n",
      "kldivergence:   1674.78\n",
      "variational_beta * kldivergence:  0.16748\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34417\n",
      "kldivergence:   2105.56\n",
      "variational_beta * kldivergence:  0.21056\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32205\n",
      "kldivergence:   1920.56\n",
      "variational_beta * kldivergence:  0.19206\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28001\n",
      "kldivergence:   1835.30\n",
      "variational_beta * kldivergence:  0.18353\n",
      "batch accuracy: 90.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37100\n",
      "kldivergence:   1801.29\n",
      "variational_beta * kldivergence:  0.18013\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36627\n",
      "kldivergence:   1919.26\n",
      "variational_beta * kldivergence:  0.19193\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.27236\n",
      "kldivergence:   1854.04\n",
      "variational_beta * kldivergence:  0.18540\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28687\n",
      "kldivergence:   1508.36\n",
      "variational_beta * kldivergence:  0.15084\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38676\n",
      "kldivergence:   1780.53\n",
      "variational_beta * kldivergence:  0.17805\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35929\n",
      "kldivergence:   2044.82\n",
      "variational_beta * kldivergence:  0.20448\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31755\n",
      "kldivergence:   1777.77\n",
      "variational_beta * kldivergence:  0.17778\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33341\n",
      "kldivergence:   2048.52\n",
      "variational_beta * kldivergence:  0.20485\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34824\n",
      "kldivergence:   1898.82\n",
      "variational_beta * kldivergence:  0.18988\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32798\n",
      "kldivergence:   1776.55\n",
      "variational_beta * kldivergence:  0.17765\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32343\n",
      "kldivergence:   1804.30\n",
      "variational_beta * kldivergence:  0.18043\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33345\n",
      "kldivergence:   1673.55\n",
      "variational_beta * kldivergence:  0.16735\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36353\n",
      "kldivergence:   1919.51\n",
      "variational_beta * kldivergence:  0.19195\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.41344\n",
      "kldivergence:   2001.62\n",
      "variational_beta * kldivergence:  0.20016\n",
      "batch accuracy: 85.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33102\n",
      "kldivergence:   1805.98\n",
      "variational_beta * kldivergence:  0.18060\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33794\n",
      "kldivergence:   1857.61\n",
      "variational_beta * kldivergence:  0.18576\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29875\n",
      "kldivergence:   1665.82\n",
      "variational_beta * kldivergence:  0.16658\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36528\n",
      "kldivergence:   1928.17\n",
      "variational_beta * kldivergence:  0.19282\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35002\n",
      "kldivergence:   1774.79\n",
      "variational_beta * kldivergence:  0.17748\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31195\n",
      "kldivergence:   1698.99\n",
      "variational_beta * kldivergence:  0.16990\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38709\n",
      "kldivergence:   1866.54\n",
      "variational_beta * kldivergence:  0.18665\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33220\n",
      "kldivergence:   1805.01\n",
      "variational_beta * kldivergence:  0.18050\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30963\n",
      "kldivergence:   1931.88\n",
      "variational_beta * kldivergence:  0.19319\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37033\n",
      "kldivergence:   1681.35\n",
      "variational_beta * kldivergence:  0.16814\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37604\n",
      "kldivergence:   1749.14\n",
      "variational_beta * kldivergence:  0.17491\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34114\n",
      "kldivergence:   1819.39\n",
      "variational_beta * kldivergence:  0.18194\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35838\n",
      "kldivergence:   1734.55\n",
      "variational_beta * kldivergence:  0.17345\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35523\n",
      "kldivergence:   1756.35\n",
      "variational_beta * kldivergence:  0.17563\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31546\n",
      "kldivergence:   1684.18\n",
      "variational_beta * kldivergence:  0.16842\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37290\n",
      "kldivergence:   1605.63\n",
      "variational_beta * kldivergence:  0.16056\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36107\n",
      "kldivergence:   1717.89\n",
      "variational_beta * kldivergence:  0.17179\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31988\n",
      "kldivergence:   1685.82\n",
      "variational_beta * kldivergence:  0.16858\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36424\n",
      "kldivergence:   1562.70\n",
      "variational_beta * kldivergence:  0.15627\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36490\n",
      "kldivergence:   1665.49\n",
      "variational_beta * kldivergence:  0.16655\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38504\n",
      "kldivergence:   1712.05\n",
      "variational_beta * kldivergence:  0.17121\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31347\n",
      "kldivergence:   1637.29\n",
      "variational_beta * kldivergence:  0.16373\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38101\n",
      "kldivergence:   1887.87\n",
      "variational_beta * kldivergence:  0.18879\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38668\n",
      "kldivergence:   1797.85\n",
      "variational_beta * kldivergence:  0.17978\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33948\n",
      "kldivergence:   1954.50\n",
      "variational_beta * kldivergence:  0.19545\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32558\n",
      "kldivergence:   1777.37\n",
      "variational_beta * kldivergence:  0.17774\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36180\n",
      "kldivergence:   2021.68\n",
      "variational_beta * kldivergence:  0.20217\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32428\n",
      "kldivergence:   1494.43\n",
      "variational_beta * kldivergence:  0.14944\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36888\n",
      "kldivergence:   1730.62\n",
      "variational_beta * kldivergence:  0.17306\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29737\n",
      "kldivergence:   1746.84\n",
      "variational_beta * kldivergence:  0.17468\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35423\n",
      "kldivergence:   1734.02\n",
      "variational_beta * kldivergence:  0.17340\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36615\n",
      "kldivergence:   1758.65\n",
      "variational_beta * kldivergence:  0.17587\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34372\n",
      "kldivergence:   1724.56\n",
      "variational_beta * kldivergence:  0.17246\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38194\n",
      "kldivergence:   1733.65\n",
      "variational_beta * kldivergence:  0.17337\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37869\n",
      "kldivergence:   1745.03\n",
      "variational_beta * kldivergence:  0.17450\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33886\n",
      "kldivergence:   1724.05\n",
      "variational_beta * kldivergence:  0.17240\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33069\n",
      "kldivergence:   1845.47\n",
      "variational_beta * kldivergence:  0.18455\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36263\n",
      "kldivergence:   1717.79\n",
      "variational_beta * kldivergence:  0.17178\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34279\n",
      "kldivergence:   1747.31\n",
      "variational_beta * kldivergence:  0.17473\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30844\n",
      "kldivergence:   1743.25\n",
      "variational_beta * kldivergence:  0.17432\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37453\n",
      "kldivergence:   1725.91\n",
      "variational_beta * kldivergence:  0.17259\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31137\n",
      "kldivergence:   1845.21\n",
      "variational_beta * kldivergence:  0.18452\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32616\n",
      "kldivergence:   1852.81\n",
      "variational_beta * kldivergence:  0.18528\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35275\n",
      "kldivergence:   1933.76\n",
      "variational_beta * kldivergence:  0.19338\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30333\n",
      "kldivergence:   1595.37\n",
      "variational_beta * kldivergence:  0.15954\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31954\n",
      "kldivergence:   1548.78\n",
      "variational_beta * kldivergence:  0.15488\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.26886\n",
      "kldivergence:   1711.74\n",
      "variational_beta * kldivergence:  0.17117\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30843\n",
      "kldivergence:   1706.76\n",
      "variational_beta * kldivergence:  0.17068\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32906\n",
      "kldivergence:   1684.86\n",
      "variational_beta * kldivergence:  0.16849\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32649\n",
      "kldivergence:   1689.54\n",
      "variational_beta * kldivergence:  0.16895\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31738\n",
      "kldivergence:   1766.04\n",
      "variational_beta * kldivergence:  0.17660\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35822\n",
      "kldivergence:   1790.25\n",
      "variational_beta * kldivergence:  0.17902\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38314\n",
      "kldivergence:   1830.97\n",
      "variational_beta * kldivergence:  0.18310\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31592\n",
      "kldivergence:   1883.03\n",
      "variational_beta * kldivergence:  0.18830\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34200\n",
      "kldivergence:   1722.22\n",
      "variational_beta * kldivergence:  0.17222\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34728\n",
      "kldivergence:   1642.47\n",
      "variational_beta * kldivergence:  0.16425\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31977\n",
      "kldivergence:   1774.86\n",
      "variational_beta * kldivergence:  0.17749\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37241\n",
      "kldivergence:   1661.57\n",
      "variational_beta * kldivergence:  0.16616\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32619\n",
      "kldivergence:   1842.74\n",
      "variational_beta * kldivergence:  0.18427\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37068\n",
      "kldivergence:   1915.13\n",
      "variational_beta * kldivergence:  0.19151\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35041\n",
      "kldivergence:   1718.27\n",
      "variational_beta * kldivergence:  0.17183\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29279\n",
      "kldivergence:   1734.31\n",
      "variational_beta * kldivergence:  0.17343\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37309\n",
      "kldivergence:   1809.25\n",
      "variational_beta * kldivergence:  0.18092\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.26673\n",
      "kldivergence:   1495.44\n",
      "variational_beta * kldivergence:  0.14954\n",
      "batch accuracy: 90.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36931\n",
      "kldivergence:   1977.93\n",
      "variational_beta * kldivergence:  0.19779\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39607\n",
      "kldivergence:   2115.89\n",
      "variational_beta * kldivergence:  0.21159\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34638\n",
      "kldivergence:   1666.03\n",
      "variational_beta * kldivergence:  0.16660\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36538\n",
      "kldivergence:   1597.20\n",
      "variational_beta * kldivergence:  0.15972\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32672\n",
      "kldivergence:   1634.81\n",
      "variational_beta * kldivergence:  0.16348\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33766\n",
      "kldivergence:   1651.21\n",
      "variational_beta * kldivergence:  0.16512\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38285\n",
      "kldivergence:   1838.26\n",
      "variational_beta * kldivergence:  0.18383\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33271\n",
      "kldivergence:   1527.43\n",
      "variational_beta * kldivergence:  0.15274\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34285\n",
      "kldivergence:   1940.98\n",
      "variational_beta * kldivergence:  0.19410\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32744\n",
      "kldivergence:   1756.49\n",
      "variational_beta * kldivergence:  0.17565\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36697\n",
      "kldivergence:   1853.27\n",
      "variational_beta * kldivergence:  0.18533\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35313\n",
      "kldivergence:   1796.33\n",
      "variational_beta * kldivergence:  0.17963\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31411\n",
      "kldivergence:   1862.96\n",
      "variational_beta * kldivergence:  0.18630\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32196\n",
      "kldivergence:   1989.46\n",
      "variational_beta * kldivergence:  0.19895\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32572\n",
      "kldivergence:   1929.76\n",
      "variational_beta * kldivergence:  0.19298\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.29864\n",
      "kldivergence:   1825.67\n",
      "variational_beta * kldivergence:  0.18257\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30315\n",
      "kldivergence:   2363.14\n",
      "variational_beta * kldivergence:  0.23631\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31898\n",
      "kldivergence:   1752.71\n",
      "variational_beta * kldivergence:  0.17527\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31331\n",
      "kldivergence:   1823.32\n",
      "variational_beta * kldivergence:  0.18233\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31299\n",
      "kldivergence:   1619.76\n",
      "variational_beta * kldivergence:  0.16198\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34283\n",
      "kldivergence:   1836.92\n",
      "variational_beta * kldivergence:  0.18369\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36196\n",
      "kldivergence:   1939.05\n",
      "variational_beta * kldivergence:  0.19390\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32731\n",
      "kldivergence:   1720.90\n",
      "variational_beta * kldivergence:  0.17209\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38461\n",
      "kldivergence:   1961.01\n",
      "variational_beta * kldivergence:  0.19610\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36813\n",
      "kldivergence:   2088.34\n",
      "variational_beta * kldivergence:  0.20883\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33749\n",
      "kldivergence:   1589.87\n",
      "variational_beta * kldivergence:  0.15899\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36181\n",
      "kldivergence:   1724.07\n",
      "variational_beta * kldivergence:  0.17241\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36756\n",
      "kldivergence:   1756.19\n",
      "variational_beta * kldivergence:  0.17562\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35203\n",
      "kldivergence:   1724.36\n",
      "variational_beta * kldivergence:  0.17244\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35118\n",
      "kldivergence:   1726.17\n",
      "variational_beta * kldivergence:  0.17262\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31220\n",
      "kldivergence:   1733.63\n",
      "variational_beta * kldivergence:  0.17336\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31197\n",
      "kldivergence:   1637.07\n",
      "variational_beta * kldivergence:  0.16371\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39218\n",
      "kldivergence:   1923.91\n",
      "variational_beta * kldivergence:  0.19239\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.40292\n",
      "kldivergence:   1822.63\n",
      "variational_beta * kldivergence:  0.18226\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35220\n",
      "kldivergence:   1703.98\n",
      "variational_beta * kldivergence:  0.17040\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.26496\n",
      "kldivergence:   1653.61\n",
      "variational_beta * kldivergence:  0.16536\n",
      "batch accuracy: 91.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31491\n",
      "kldivergence:   1959.04\n",
      "variational_beta * kldivergence:  0.19590\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35538\n",
      "kldivergence:   1659.48\n",
      "variational_beta * kldivergence:  0.16595\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39777\n",
      "kldivergence:   1951.00\n",
      "variational_beta * kldivergence:  0.19510\n",
      "batch accuracy: 86.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35748\n",
      "kldivergence:   1693.54\n",
      "variational_beta * kldivergence:  0.16935\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37425\n",
      "kldivergence:   1925.92\n",
      "variational_beta * kldivergence:  0.19259\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34403\n",
      "kldivergence:   1627.36\n",
      "variational_beta * kldivergence:  0.16274\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31229\n",
      "kldivergence:   1487.10\n",
      "variational_beta * kldivergence:  0.14871\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31242\n",
      "kldivergence:   1599.75\n",
      "variational_beta * kldivergence:  0.15998\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34589\n",
      "kldivergence:   1553.80\n",
      "variational_beta * kldivergence:  0.15538\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32482\n",
      "kldivergence:   1716.87\n",
      "variational_beta * kldivergence:  0.17169\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38580\n",
      "kldivergence:   1898.00\n",
      "variational_beta * kldivergence:  0.18980\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34292\n",
      "kldivergence:   1599.37\n",
      "variational_beta * kldivergence:  0.15994\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32333\n",
      "kldivergence:   1673.96\n",
      "variational_beta * kldivergence:  0.16740\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35539\n",
      "kldivergence:   1611.02\n",
      "variational_beta * kldivergence:  0.16110\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35083\n",
      "kldivergence:   1603.62\n",
      "variational_beta * kldivergence:  0.16036\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31261\n",
      "kldivergence:   1691.80\n",
      "variational_beta * kldivergence:  0.16918\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34202\n",
      "kldivergence:   1633.89\n",
      "variational_beta * kldivergence:  0.16339\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33827\n",
      "kldivergence:   1742.47\n",
      "variational_beta * kldivergence:  0.17425\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39606\n",
      "kldivergence:   1789.27\n",
      "variational_beta * kldivergence:  0.17893\n",
      "batch accuracy: 86.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31064\n",
      "kldivergence:   1776.15\n",
      "variational_beta * kldivergence:  0.17761\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34877\n",
      "kldivergence:   1962.46\n",
      "variational_beta * kldivergence:  0.19625\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31825\n",
      "kldivergence:   1666.87\n",
      "variational_beta * kldivergence:  0.16669\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36838\n",
      "kldivergence:   1822.11\n",
      "variational_beta * kldivergence:  0.18221\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37156\n",
      "kldivergence:   1730.14\n",
      "variational_beta * kldivergence:  0.17301\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34635\n",
      "kldivergence:   1969.37\n",
      "variational_beta * kldivergence:  0.19694\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36595\n",
      "kldivergence:   2044.80\n",
      "variational_beta * kldivergence:  0.20448\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31628\n",
      "kldivergence:   1791.01\n",
      "variational_beta * kldivergence:  0.17910\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37343\n",
      "kldivergence:   1955.81\n",
      "variational_beta * kldivergence:  0.19558\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32213\n",
      "kldivergence:   2116.81\n",
      "variational_beta * kldivergence:  0.21168\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32808\n",
      "kldivergence:   1574.02\n",
      "variational_beta * kldivergence:  0.15740\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33225\n",
      "kldivergence:   1730.71\n",
      "variational_beta * kldivergence:  0.17307\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28407\n",
      "kldivergence:   1870.58\n",
      "variational_beta * kldivergence:  0.18706\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33666\n",
      "kldivergence:   1798.26\n",
      "variational_beta * kldivergence:  0.17983\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.27044\n",
      "kldivergence:   1450.34\n",
      "variational_beta * kldivergence:  0.14503\n",
      "batch accuracy: 90.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36373\n",
      "kldivergence:   1789.83\n",
      "variational_beta * kldivergence:  0.17898\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31544\n",
      "kldivergence:   1516.92\n",
      "variational_beta * kldivergence:  0.15169\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32294\n",
      "kldivergence:   1653.15\n",
      "variational_beta * kldivergence:  0.16532\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33763\n",
      "kldivergence:   1746.19\n",
      "variational_beta * kldivergence:  0.17462\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34726\n",
      "kldivergence:   1754.07\n",
      "variational_beta * kldivergence:  0.17541\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.28263\n",
      "kldivergence:   1422.78\n",
      "variational_beta * kldivergence:  0.14228\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35907\n",
      "kldivergence:   1811.58\n",
      "variational_beta * kldivergence:  0.18116\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.27717\n",
      "kldivergence:   1783.89\n",
      "variational_beta * kldivergence:  0.17839\n",
      "batch accuracy: 91.08\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.30643\n",
      "kldivergence:   1734.02\n",
      "variational_beta * kldivergence:  0.17340\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.31391\n",
      "kldivergence:   1613.17\n",
      "variational_beta * kldivergence:  0.16132\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.32815\n",
      "kldivergence:   1548.96\n",
      "variational_beta * kldivergence:  0.15490\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34504\n",
      "kldivergence:   1834.43\n",
      "variational_beta * kldivergence:  0.18344\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35467\n",
      "kldivergence:   1691.23\n",
      "variational_beta * kldivergence:  0.16912\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33016\n",
      "kldivergence:   1599.34\n",
      "variational_beta * kldivergence:  0.15993\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.38972\n",
      "kldivergence:   1835.90\n",
      "variational_beta * kldivergence:  0.18359\n",
      "batch accuracy: 87.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35012\n",
      "kldivergence:   1729.30\n",
      "variational_beta * kldivergence:  0.17293\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33619\n",
      "kldivergence:   1541.58\n",
      "variational_beta * kldivergence:  0.15416\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36279\n",
      "kldivergence:   1652.26\n",
      "variational_beta * kldivergence:  0.16523\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.35938\n",
      "kldivergence:   1749.74\n",
      "variational_beta * kldivergence:  0.17497\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.39230\n",
      "kldivergence:   2040.10\n",
      "variational_beta * kldivergence:  0.20401\n",
      "batch accuracy: 86.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34619\n",
      "kldivergence:   1749.85\n",
      "variational_beta * kldivergence:  0.17498\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.37776\n",
      "kldivergence:   2122.32\n",
      "variational_beta * kldivergence:  0.21223\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.33977\n",
      "kldivergence:   1711.34\n",
      "variational_beta * kldivergence:  0.17113\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.36002\n",
      "kldivergence:   1692.57\n",
      "variational_beta * kldivergence:  0.16926\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #5\n",
      "reconstruction loss: 0.34687\n",
      "kldivergence:   1775.77\n",
      "variational_beta * kldivergence:  0.17758\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.43677\n",
      "kldivergence:   1878.01\n",
      "variational_beta * kldivergence:  0.18780\n",
      "batch accuracy: 86.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.36607\n",
      "kldivergence:   1556.48\n",
      "variational_beta * kldivergence:  0.15565\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.45165\n",
      "kldivergence:   1602.32\n",
      "variational_beta * kldivergence:  0.16023\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.56317\n",
      "kldivergence:   1998.21\n",
      "variational_beta * kldivergence:  0.19982\n",
      "batch accuracy: 82.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.53840\n",
      "kldivergence:   1776.43\n",
      "variational_beta * kldivergence:  0.17764\n",
      "batch accuracy: 84.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.47835\n",
      "kldivergence:   1734.58\n",
      "variational_beta * kldivergence:  0.17346\n",
      "batch accuracy: 85.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.40737\n",
      "kldivergence:   1558.98\n",
      "variational_beta * kldivergence:  0.15590\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.47562\n",
      "kldivergence:   1847.94\n",
      "variational_beta * kldivergence:  0.18479\n",
      "batch accuracy: 85.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.49439\n",
      "kldivergence:   1732.27\n",
      "variational_beta * kldivergence:  0.17323\n",
      "batch accuracy: 84.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.46237\n",
      "kldivergence:   1769.54\n",
      "variational_beta * kldivergence:  0.17695\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.50857\n",
      "kldivergence:   1774.73\n",
      "variational_beta * kldivergence:  0.17747\n",
      "batch accuracy: 84.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.53134\n",
      "kldivergence:   1981.90\n",
      "variational_beta * kldivergence:  0.19819\n",
      "batch accuracy: 84.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.46320\n",
      "kldivergence:   1740.81\n",
      "variational_beta * kldivergence:  0.17408\n",
      "batch accuracy: 85.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.50332\n",
      "kldivergence:   1827.03\n",
      "variational_beta * kldivergence:  0.18270\n",
      "batch accuracy: 83.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.49522\n",
      "kldivergence:   1737.48\n",
      "variational_beta * kldivergence:  0.17375\n",
      "batch accuracy: 84.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.44090\n",
      "kldivergence:   1654.07\n",
      "variational_beta * kldivergence:  0.16541\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.46667\n",
      "kldivergence:   1776.05\n",
      "variational_beta * kldivergence:  0.17761\n",
      "batch accuracy: 85.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.49334\n",
      "kldivergence:   1711.54\n",
      "variational_beta * kldivergence:  0.17115\n",
      "batch accuracy: 84.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.40888\n",
      "kldivergence:   1598.92\n",
      "variational_beta * kldivergence:  0.15989\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.40507\n",
      "kldivergence:   1666.33\n",
      "variational_beta * kldivergence:  0.16663\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.43946\n",
      "kldivergence:   1714.08\n",
      "variational_beta * kldivergence:  0.17141\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.45204\n",
      "kldivergence:   1851.83\n",
      "variational_beta * kldivergence:  0.18518\n",
      "batch accuracy: 85.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.35332\n",
      "kldivergence:   1576.41\n",
      "variational_beta * kldivergence:  0.15764\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.47405\n",
      "kldivergence:   1586.36\n",
      "variational_beta * kldivergence:  0.15864\n",
      "batch accuracy: 85.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.43394\n",
      "kldivergence:   1705.13\n",
      "variational_beta * kldivergence:  0.17051\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.49197\n",
      "kldivergence:   1761.12\n",
      "variational_beta * kldivergence:  0.17611\n",
      "batch accuracy: 84.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.41128\n",
      "kldivergence:   1676.12\n",
      "variational_beta * kldivergence:  0.16761\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.44861\n",
      "kldivergence:   1773.28\n",
      "variational_beta * kldivergence:  0.17733\n",
      "batch accuracy: 86.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.41349\n",
      "kldivergence:   1658.00\n",
      "variational_beta * kldivergence:  0.16580\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.40548\n",
      "kldivergence:   1657.85\n",
      "variational_beta * kldivergence:  0.16578\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.45932\n",
      "kldivergence:   1746.81\n",
      "variational_beta * kldivergence:  0.17468\n",
      "batch accuracy: 85.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.35932\n",
      "kldivergence:   1588.22\n",
      "variational_beta * kldivergence:  0.15882\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.50381\n",
      "kldivergence:   1777.28\n",
      "variational_beta * kldivergence:  0.17773\n",
      "batch accuracy: 84.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.45621\n",
      "kldivergence:   1728.08\n",
      "variational_beta * kldivergence:  0.17281\n",
      "batch accuracy: 85.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.46280\n",
      "kldivergence:   1824.56\n",
      "variational_beta * kldivergence:  0.18246\n",
      "batch accuracy: 85.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.39461\n",
      "kldivergence:   1646.28\n",
      "variational_beta * kldivergence:  0.16463\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.40206\n",
      "kldivergence:   1762.51\n",
      "variational_beta * kldivergence:  0.17625\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.40723\n",
      "kldivergence:   1710.45\n",
      "variational_beta * kldivergence:  0.17105\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.49214\n",
      "kldivergence:   1803.95\n",
      "variational_beta * kldivergence:  0.18040\n",
      "batch accuracy: 85.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.46005\n",
      "kldivergence:   1767.86\n",
      "variational_beta * kldivergence:  0.17679\n",
      "batch accuracy: 86.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.50106\n",
      "kldivergence:   1885.71\n",
      "variational_beta * kldivergence:  0.18857\n",
      "batch accuracy: 84.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.43933\n",
      "kldivergence:   1792.80\n",
      "variational_beta * kldivergence:  0.17928\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.41106\n",
      "kldivergence:   1697.82\n",
      "variational_beta * kldivergence:  0.16978\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.45967\n",
      "kldivergence:   1732.49\n",
      "variational_beta * kldivergence:  0.17325\n",
      "batch accuracy: 86.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.43193\n",
      "kldivergence:   1636.34\n",
      "variational_beta * kldivergence:  0.16363\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.49642\n",
      "kldivergence:   1789.28\n",
      "variational_beta * kldivergence:  0.17893\n",
      "batch accuracy: 84.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.39722\n",
      "kldivergence:   1643.07\n",
      "variational_beta * kldivergence:  0.16431\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.46768\n",
      "kldivergence:   1735.53\n",
      "variational_beta * kldivergence:  0.17355\n",
      "batch accuracy: 85.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.40001\n",
      "kldivergence:   1684.08\n",
      "variational_beta * kldivergence:  0.16841\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.37507\n",
      "kldivergence:   1545.58\n",
      "variational_beta * kldivergence:  0.15456\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.40995\n",
      "kldivergence:   1744.97\n",
      "variational_beta * kldivergence:  0.17450\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.54709\n",
      "kldivergence:   1849.64\n",
      "variational_beta * kldivergence:  0.18496\n",
      "batch accuracy: 83.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.42126\n",
      "kldivergence:   1669.46\n",
      "variational_beta * kldivergence:  0.16695\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.38109\n",
      "kldivergence:   1580.93\n",
      "variational_beta * kldivergence:  0.15809\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.46622\n",
      "kldivergence:   1644.74\n",
      "variational_beta * kldivergence:  0.16447\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.41173\n",
      "kldivergence:   1749.98\n",
      "variational_beta * kldivergence:  0.17500\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.44153\n",
      "kldivergence:   1783.37\n",
      "variational_beta * kldivergence:  0.17834\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.49827\n",
      "kldivergence:   1735.94\n",
      "variational_beta * kldivergence:  0.17359\n",
      "batch accuracy: 85.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.37989\n",
      "kldivergence:   1564.74\n",
      "variational_beta * kldivergence:  0.15647\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.46046\n",
      "kldivergence:   1719.34\n",
      "variational_beta * kldivergence:  0.17193\n",
      "batch accuracy: 86.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.46352\n",
      "kldivergence:   1631.82\n",
      "variational_beta * kldivergence:  0.16318\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #5\n",
      "reconstruction loss: 0.40044\n",
      "kldivergence:   1588.39\n",
      "variational_beta * kldivergence:  0.15884\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "epoch # 5 : train loss is [192.85251565845778] and validation loss is [0.1038870597356226] \n",
      "Epoch [6 / 150] average reconstruction error: 0.519818\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37434\n",
      "kldivergence:   1966.80\n",
      "variational_beta * kldivergence:  0.19668\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35158\n",
      "kldivergence:   1847.25\n",
      "variational_beta * kldivergence:  0.18473\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.28947\n",
      "kldivergence:   1619.28\n",
      "variational_beta * kldivergence:  0.16193\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33044\n",
      "kldivergence:   1661.57\n",
      "variational_beta * kldivergence:  0.16616\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.42410\n",
      "kldivergence:   2267.69\n",
      "variational_beta * kldivergence:  0.22677\n",
      "batch accuracy: 85.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35560\n",
      "kldivergence:   1575.38\n",
      "variational_beta * kldivergence:  0.15754\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36923\n",
      "kldivergence:   1674.65\n",
      "variational_beta * kldivergence:  0.16746\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31518\n",
      "kldivergence:   1642.29\n",
      "variational_beta * kldivergence:  0.16423\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36353\n",
      "kldivergence:   2123.59\n",
      "variational_beta * kldivergence:  0.21236\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34013\n",
      "kldivergence:   1822.27\n",
      "variational_beta * kldivergence:  0.18223\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34746\n",
      "kldivergence:   1861.16\n",
      "variational_beta * kldivergence:  0.18612\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31038\n",
      "kldivergence:   1829.43\n",
      "variational_beta * kldivergence:  0.18294\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32689\n",
      "kldivergence:   1658.37\n",
      "variational_beta * kldivergence:  0.16584\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36754\n",
      "kldivergence:   1849.35\n",
      "variational_beta * kldivergence:  0.18494\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31959\n",
      "kldivergence:   1752.39\n",
      "variational_beta * kldivergence:  0.17524\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32470\n",
      "kldivergence:   1695.52\n",
      "variational_beta * kldivergence:  0.16955\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29546\n",
      "kldivergence:   1659.86\n",
      "variational_beta * kldivergence:  0.16599\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32281\n",
      "kldivergence:   1810.51\n",
      "variational_beta * kldivergence:  0.18105\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32616\n",
      "kldivergence:   1674.25\n",
      "variational_beta * kldivergence:  0.16743\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33375\n",
      "kldivergence:   1693.26\n",
      "variational_beta * kldivergence:  0.16933\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31537\n",
      "kldivergence:   2122.07\n",
      "variational_beta * kldivergence:  0.21221\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32700\n",
      "kldivergence:   1801.76\n",
      "variational_beta * kldivergence:  0.18018\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35219\n",
      "kldivergence:   1696.39\n",
      "variational_beta * kldivergence:  0.16964\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32513\n",
      "kldivergence:   1627.34\n",
      "variational_beta * kldivergence:  0.16273\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31729\n",
      "kldivergence:   1716.84\n",
      "variational_beta * kldivergence:  0.17168\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29916\n",
      "kldivergence:   1650.31\n",
      "variational_beta * kldivergence:  0.16503\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32053\n",
      "kldivergence:   1493.55\n",
      "variational_beta * kldivergence:  0.14935\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35612\n",
      "kldivergence:   1910.00\n",
      "variational_beta * kldivergence:  0.19100\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.39983\n",
      "kldivergence:   1816.04\n",
      "variational_beta * kldivergence:  0.18160\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32188\n",
      "kldivergence:   1644.22\n",
      "variational_beta * kldivergence:  0.16442\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29280\n",
      "kldivergence:   1869.47\n",
      "variational_beta * kldivergence:  0.18695\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34641\n",
      "kldivergence:   1745.68\n",
      "variational_beta * kldivergence:  0.17457\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34885\n",
      "kldivergence:   1502.02\n",
      "variational_beta * kldivergence:  0.15020\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32720\n",
      "kldivergence:   1808.31\n",
      "variational_beta * kldivergence:  0.18083\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36696\n",
      "kldivergence:   1619.04\n",
      "variational_beta * kldivergence:  0.16190\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34805\n",
      "kldivergence:   1563.25\n",
      "variational_beta * kldivergence:  0.15633\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.27748\n",
      "kldivergence:   1455.72\n",
      "variational_beta * kldivergence:  0.14557\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36243\n",
      "kldivergence:   1953.21\n",
      "variational_beta * kldivergence:  0.19532\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.27890\n",
      "kldivergence:   1459.80\n",
      "variational_beta * kldivergence:  0.14598\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34317\n",
      "kldivergence:   1681.83\n",
      "variational_beta * kldivergence:  0.16818\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37978\n",
      "kldivergence:   1901.52\n",
      "variational_beta * kldivergence:  0.19015\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35138\n",
      "kldivergence:   1879.10\n",
      "variational_beta * kldivergence:  0.18791\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32352\n",
      "kldivergence:   1873.07\n",
      "variational_beta * kldivergence:  0.18731\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33220\n",
      "kldivergence:   1456.34\n",
      "variational_beta * kldivergence:  0.14563\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33682\n",
      "kldivergence:   1705.44\n",
      "variational_beta * kldivergence:  0.17054\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34419\n",
      "kldivergence:   1698.63\n",
      "variational_beta * kldivergence:  0.16986\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33451\n",
      "kldivergence:   1714.75\n",
      "variational_beta * kldivergence:  0.17148\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31506\n",
      "kldivergence:   1782.25\n",
      "variational_beta * kldivergence:  0.17823\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33459\n",
      "kldivergence:   1764.74\n",
      "variational_beta * kldivergence:  0.17647\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35242\n",
      "kldivergence:   1757.86\n",
      "variational_beta * kldivergence:  0.17579\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35191\n",
      "kldivergence:   1890.97\n",
      "variational_beta * kldivergence:  0.18910\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34499\n",
      "kldivergence:   1945.63\n",
      "variational_beta * kldivergence:  0.19456\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32812\n",
      "kldivergence:   1491.31\n",
      "variational_beta * kldivergence:  0.14913\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36377\n",
      "kldivergence:   1842.17\n",
      "variational_beta * kldivergence:  0.18422\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32334\n",
      "kldivergence:   1588.19\n",
      "variational_beta * kldivergence:  0.15882\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35652\n",
      "kldivergence:   1843.39\n",
      "variational_beta * kldivergence:  0.18434\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36985\n",
      "kldivergence:   1641.95\n",
      "variational_beta * kldivergence:  0.16419\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36011\n",
      "kldivergence:   1616.86\n",
      "variational_beta * kldivergence:  0.16169\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36254\n",
      "kldivergence:   2072.39\n",
      "variational_beta * kldivergence:  0.20724\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29157\n",
      "kldivergence:   1882.01\n",
      "variational_beta * kldivergence:  0.18820\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35430\n",
      "kldivergence:   1818.56\n",
      "variational_beta * kldivergence:  0.18186\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37154\n",
      "kldivergence:   1708.21\n",
      "variational_beta * kldivergence:  0.17082\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33101\n",
      "kldivergence:   1748.79\n",
      "variational_beta * kldivergence:  0.17488\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36722\n",
      "kldivergence:   1780.26\n",
      "variational_beta * kldivergence:  0.17803\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37347\n",
      "kldivergence:   2010.14\n",
      "variational_beta * kldivergence:  0.20101\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.28075\n",
      "kldivergence:   1437.20\n",
      "variational_beta * kldivergence:  0.14372\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30905\n",
      "kldivergence:   1723.13\n",
      "variational_beta * kldivergence:  0.17231\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32236\n",
      "kldivergence:   1859.36\n",
      "variational_beta * kldivergence:  0.18594\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.44448\n",
      "kldivergence:   2146.39\n",
      "variational_beta * kldivergence:  0.21464\n",
      "batch accuracy: 85.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32894\n",
      "kldivergence:   1789.21\n",
      "variational_beta * kldivergence:  0.17892\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33139\n",
      "kldivergence:   1864.33\n",
      "variational_beta * kldivergence:  0.18643\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34149\n",
      "kldivergence:   1728.57\n",
      "variational_beta * kldivergence:  0.17286\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30549\n",
      "kldivergence:   1685.90\n",
      "variational_beta * kldivergence:  0.16859\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35812\n",
      "kldivergence:   1731.09\n",
      "variational_beta * kldivergence:  0.17311\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.40737\n",
      "kldivergence:   2101.76\n",
      "variational_beta * kldivergence:  0.21018\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31604\n",
      "kldivergence:   1945.54\n",
      "variational_beta * kldivergence:  0.19455\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31542\n",
      "kldivergence:   1669.18\n",
      "variational_beta * kldivergence:  0.16692\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31805\n",
      "kldivergence:   1680.08\n",
      "variational_beta * kldivergence:  0.16801\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.28790\n",
      "kldivergence:   1886.79\n",
      "variational_beta * kldivergence:  0.18868\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36712\n",
      "kldivergence:   2159.25\n",
      "variational_beta * kldivergence:  0.21593\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30731\n",
      "kldivergence:   1871.49\n",
      "variational_beta * kldivergence:  0.18715\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.26882\n",
      "kldivergence:   1830.86\n",
      "variational_beta * kldivergence:  0.18309\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34911\n",
      "kldivergence:   2004.20\n",
      "variational_beta * kldivergence:  0.20042\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35101\n",
      "kldivergence:   1898.17\n",
      "variational_beta * kldivergence:  0.18982\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35270\n",
      "kldivergence:   1737.69\n",
      "variational_beta * kldivergence:  0.17377\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36072\n",
      "kldivergence:   1889.87\n",
      "variational_beta * kldivergence:  0.18899\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.27904\n",
      "kldivergence:   1638.29\n",
      "variational_beta * kldivergence:  0.16383\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29268\n",
      "kldivergence:   1559.97\n",
      "variational_beta * kldivergence:  0.15600\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35774\n",
      "kldivergence:   1865.30\n",
      "variational_beta * kldivergence:  0.18653\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35987\n",
      "kldivergence:   1762.75\n",
      "variational_beta * kldivergence:  0.17627\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37398\n",
      "kldivergence:   1747.43\n",
      "variational_beta * kldivergence:  0.17474\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29022\n",
      "kldivergence:   1554.49\n",
      "variational_beta * kldivergence:  0.15545\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37512\n",
      "kldivergence:   1930.10\n",
      "variational_beta * kldivergence:  0.19301\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.27900\n",
      "kldivergence:   1596.48\n",
      "variational_beta * kldivergence:  0.15965\n",
      "batch accuracy: 90.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31971\n",
      "kldivergence:   1634.33\n",
      "variational_beta * kldivergence:  0.16343\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33646\n",
      "kldivergence:   1927.96\n",
      "variational_beta * kldivergence:  0.19280\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38656\n",
      "kldivergence:   2070.78\n",
      "variational_beta * kldivergence:  0.20708\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35703\n",
      "kldivergence:   1697.25\n",
      "variational_beta * kldivergence:  0.16973\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32011\n",
      "kldivergence:   1833.11\n",
      "variational_beta * kldivergence:  0.18331\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33447\n",
      "kldivergence:   1874.81\n",
      "variational_beta * kldivergence:  0.18748\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38062\n",
      "kldivergence:   1758.25\n",
      "variational_beta * kldivergence:  0.17582\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34637\n",
      "kldivergence:   1584.71\n",
      "variational_beta * kldivergence:  0.15847\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31475\n",
      "kldivergence:   1664.35\n",
      "variational_beta * kldivergence:  0.16644\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36023\n",
      "kldivergence:   1741.65\n",
      "variational_beta * kldivergence:  0.17417\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35366\n",
      "kldivergence:   1627.07\n",
      "variational_beta * kldivergence:  0.16271\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29256\n",
      "kldivergence:   1784.66\n",
      "variational_beta * kldivergence:  0.17847\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35457\n",
      "kldivergence:   1796.99\n",
      "variational_beta * kldivergence:  0.17970\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36358\n",
      "kldivergence:   1674.88\n",
      "variational_beta * kldivergence:  0.16749\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34201\n",
      "kldivergence:   1726.04\n",
      "variational_beta * kldivergence:  0.17260\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36992\n",
      "kldivergence:   2068.82\n",
      "variational_beta * kldivergence:  0.20688\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37385\n",
      "kldivergence:   1606.12\n",
      "variational_beta * kldivergence:  0.16061\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33873\n",
      "kldivergence:   1752.61\n",
      "variational_beta * kldivergence:  0.17526\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.28947\n",
      "kldivergence:   1762.66\n",
      "variational_beta * kldivergence:  0.17627\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.42837\n",
      "kldivergence:   1966.33\n",
      "variational_beta * kldivergence:  0.19663\n",
      "batch accuracy: 86.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32505\n",
      "kldivergence:   1513.83\n",
      "variational_beta * kldivergence:  0.15138\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32039\n",
      "kldivergence:   1959.26\n",
      "variational_beta * kldivergence:  0.19593\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35149\n",
      "kldivergence:   1736.63\n",
      "variational_beta * kldivergence:  0.17366\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36397\n",
      "kldivergence:   1856.53\n",
      "variational_beta * kldivergence:  0.18565\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33154\n",
      "kldivergence:   1913.85\n",
      "variational_beta * kldivergence:  0.19138\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35611\n",
      "kldivergence:   1766.45\n",
      "variational_beta * kldivergence:  0.17665\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37026\n",
      "kldivergence:   1780.98\n",
      "variational_beta * kldivergence:  0.17810\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35729\n",
      "kldivergence:   1747.64\n",
      "variational_beta * kldivergence:  0.17476\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30938\n",
      "kldivergence:   1702.06\n",
      "variational_beta * kldivergence:  0.17021\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36797\n",
      "kldivergence:   2040.75\n",
      "variational_beta * kldivergence:  0.20408\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31906\n",
      "kldivergence:   1642.60\n",
      "variational_beta * kldivergence:  0.16426\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38058\n",
      "kldivergence:   1625.02\n",
      "variational_beta * kldivergence:  0.16250\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37193\n",
      "kldivergence:   1696.06\n",
      "variational_beta * kldivergence:  0.16961\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34842\n",
      "kldivergence:   1801.57\n",
      "variational_beta * kldivergence:  0.18016\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.40054\n",
      "kldivergence:   1881.59\n",
      "variational_beta * kldivergence:  0.18816\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34568\n",
      "kldivergence:   1751.37\n",
      "variational_beta * kldivergence:  0.17514\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.25126\n",
      "kldivergence:   1439.22\n",
      "variational_beta * kldivergence:  0.14392\n",
      "batch accuracy: 91.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34306\n",
      "kldivergence:   1692.40\n",
      "variational_beta * kldivergence:  0.16924\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33772\n",
      "kldivergence:   1722.38\n",
      "variational_beta * kldivergence:  0.17224\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32444\n",
      "kldivergence:   1719.95\n",
      "variational_beta * kldivergence:  0.17199\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30022\n",
      "kldivergence:   1727.80\n",
      "variational_beta * kldivergence:  0.17278\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.28655\n",
      "kldivergence:   1844.46\n",
      "variational_beta * kldivergence:  0.18445\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30790\n",
      "kldivergence:   1770.62\n",
      "variational_beta * kldivergence:  0.17706\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35126\n",
      "kldivergence:   1664.84\n",
      "variational_beta * kldivergence:  0.16648\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33695\n",
      "kldivergence:   1823.72\n",
      "variational_beta * kldivergence:  0.18237\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35055\n",
      "kldivergence:   1753.55\n",
      "variational_beta * kldivergence:  0.17535\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31787\n",
      "kldivergence:   2056.68\n",
      "variational_beta * kldivergence:  0.20567\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32750\n",
      "kldivergence:   1760.92\n",
      "variational_beta * kldivergence:  0.17609\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33803\n",
      "kldivergence:   1719.94\n",
      "variational_beta * kldivergence:  0.17199\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32115\n",
      "kldivergence:   1651.51\n",
      "variational_beta * kldivergence:  0.16515\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32576\n",
      "kldivergence:   1697.49\n",
      "variational_beta * kldivergence:  0.16975\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30848\n",
      "kldivergence:   1819.94\n",
      "variational_beta * kldivergence:  0.18199\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36864\n",
      "kldivergence:   1910.28\n",
      "variational_beta * kldivergence:  0.19103\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30561\n",
      "kldivergence:   1624.72\n",
      "variational_beta * kldivergence:  0.16247\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34278\n",
      "kldivergence:   1740.35\n",
      "variational_beta * kldivergence:  0.17403\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.28257\n",
      "kldivergence:   1852.15\n",
      "variational_beta * kldivergence:  0.18522\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34804\n",
      "kldivergence:   1808.16\n",
      "variational_beta * kldivergence:  0.18082\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33687\n",
      "kldivergence:   1591.71\n",
      "variational_beta * kldivergence:  0.15917\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32287\n",
      "kldivergence:   1836.82\n",
      "variational_beta * kldivergence:  0.18368\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34968\n",
      "kldivergence:   1694.80\n",
      "variational_beta * kldivergence:  0.16948\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36545\n",
      "kldivergence:   1822.46\n",
      "variational_beta * kldivergence:  0.18225\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31636\n",
      "kldivergence:   1765.47\n",
      "variational_beta * kldivergence:  0.17655\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34505\n",
      "kldivergence:   1892.08\n",
      "variational_beta * kldivergence:  0.18921\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34566\n",
      "kldivergence:   1888.54\n",
      "variational_beta * kldivergence:  0.18885\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35202\n",
      "kldivergence:   1682.05\n",
      "variational_beta * kldivergence:  0.16820\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.27812\n",
      "kldivergence:   1773.69\n",
      "variational_beta * kldivergence:  0.17737\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38748\n",
      "kldivergence:   1722.86\n",
      "variational_beta * kldivergence:  0.17229\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31235\n",
      "kldivergence:   1995.12\n",
      "variational_beta * kldivergence:  0.19951\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37691\n",
      "kldivergence:   1714.70\n",
      "variational_beta * kldivergence:  0.17147\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33187\n",
      "kldivergence:   1755.37\n",
      "variational_beta * kldivergence:  0.17554\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34962\n",
      "kldivergence:   1747.60\n",
      "variational_beta * kldivergence:  0.17476\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34792\n",
      "kldivergence:   1735.82\n",
      "variational_beta * kldivergence:  0.17358\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29661\n",
      "kldivergence:   1740.96\n",
      "variational_beta * kldivergence:  0.17410\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.42025\n",
      "kldivergence:   2177.42\n",
      "variational_beta * kldivergence:  0.21774\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33905\n",
      "kldivergence:   1657.40\n",
      "variational_beta * kldivergence:  0.16574\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34215\n",
      "kldivergence:   1837.40\n",
      "variational_beta * kldivergence:  0.18374\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34969\n",
      "kldivergence:   1757.78\n",
      "variational_beta * kldivergence:  0.17578\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36401\n",
      "kldivergence:   1970.14\n",
      "variational_beta * kldivergence:  0.19701\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34599\n",
      "kldivergence:   1824.87\n",
      "variational_beta * kldivergence:  0.18249\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33723\n",
      "kldivergence:   1568.32\n",
      "variational_beta * kldivergence:  0.15683\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.28237\n",
      "kldivergence:   1742.87\n",
      "variational_beta * kldivergence:  0.17429\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33507\n",
      "kldivergence:   1793.75\n",
      "variational_beta * kldivergence:  0.17937\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33539\n",
      "kldivergence:   1887.52\n",
      "variational_beta * kldivergence:  0.18875\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37267\n",
      "kldivergence:   1807.21\n",
      "variational_beta * kldivergence:  0.18072\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.42153\n",
      "kldivergence:   1920.38\n",
      "variational_beta * kldivergence:  0.19204\n",
      "batch accuracy: 86.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32736\n",
      "kldivergence:   1807.14\n",
      "variational_beta * kldivergence:  0.18071\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34738\n",
      "kldivergence:   1981.00\n",
      "variational_beta * kldivergence:  0.19810\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30882\n",
      "kldivergence:   1903.18\n",
      "variational_beta * kldivergence:  0.19032\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33072\n",
      "kldivergence:   1873.65\n",
      "variational_beta * kldivergence:  0.18736\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32565\n",
      "kldivergence:   2100.82\n",
      "variational_beta * kldivergence:  0.21008\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35923\n",
      "kldivergence:   1714.96\n",
      "variational_beta * kldivergence:  0.17150\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31851\n",
      "kldivergence:   1786.94\n",
      "variational_beta * kldivergence:  0.17869\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33370\n",
      "kldivergence:   1767.97\n",
      "variational_beta * kldivergence:  0.17680\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38088\n",
      "kldivergence:   1966.80\n",
      "variational_beta * kldivergence:  0.19668\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35619\n",
      "kldivergence:   1811.35\n",
      "variational_beta * kldivergence:  0.18114\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35510\n",
      "kldivergence:   1762.75\n",
      "variational_beta * kldivergence:  0.17628\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33030\n",
      "kldivergence:   1958.06\n",
      "variational_beta * kldivergence:  0.19581\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33620\n",
      "kldivergence:   1788.52\n",
      "variational_beta * kldivergence:  0.17885\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34587\n",
      "kldivergence:   1848.45\n",
      "variational_beta * kldivergence:  0.18485\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30731\n",
      "kldivergence:   1709.92\n",
      "variational_beta * kldivergence:  0.17099\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32213\n",
      "kldivergence:   2086.71\n",
      "variational_beta * kldivergence:  0.20867\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30054\n",
      "kldivergence:   1713.68\n",
      "variational_beta * kldivergence:  0.17137\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34964\n",
      "kldivergence:   1710.90\n",
      "variational_beta * kldivergence:  0.17109\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33773\n",
      "kldivergence:   1683.54\n",
      "variational_beta * kldivergence:  0.16835\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30454\n",
      "kldivergence:   1688.98\n",
      "variational_beta * kldivergence:  0.16890\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31981\n",
      "kldivergence:   1726.54\n",
      "variational_beta * kldivergence:  0.17265\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32205\n",
      "kldivergence:   1516.33\n",
      "variational_beta * kldivergence:  0.15163\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32069\n",
      "kldivergence:   1456.05\n",
      "variational_beta * kldivergence:  0.14561\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35152\n",
      "kldivergence:   1688.59\n",
      "variational_beta * kldivergence:  0.16886\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34721\n",
      "kldivergence:   1773.55\n",
      "variational_beta * kldivergence:  0.17736\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30384\n",
      "kldivergence:   1773.91\n",
      "variational_beta * kldivergence:  0.17739\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32912\n",
      "kldivergence:   1569.89\n",
      "variational_beta * kldivergence:  0.15699\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35319\n",
      "kldivergence:   1686.61\n",
      "variational_beta * kldivergence:  0.16866\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32288\n",
      "kldivergence:   1695.93\n",
      "variational_beta * kldivergence:  0.16959\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37400\n",
      "kldivergence:   1768.29\n",
      "variational_beta * kldivergence:  0.17683\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38857\n",
      "kldivergence:   1753.68\n",
      "variational_beta * kldivergence:  0.17537\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38907\n",
      "kldivergence:   1622.09\n",
      "variational_beta * kldivergence:  0.16221\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33576\n",
      "kldivergence:   1812.19\n",
      "variational_beta * kldivergence:  0.18122\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33102\n",
      "kldivergence:   1568.54\n",
      "variational_beta * kldivergence:  0.15685\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37236\n",
      "kldivergence:   1983.35\n",
      "variational_beta * kldivergence:  0.19833\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29755\n",
      "kldivergence:   1693.61\n",
      "variational_beta * kldivergence:  0.16936\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38921\n",
      "kldivergence:   1700.68\n",
      "variational_beta * kldivergence:  0.17007\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36639\n",
      "kldivergence:   1910.81\n",
      "variational_beta * kldivergence:  0.19108\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32964\n",
      "kldivergence:   1633.78\n",
      "variational_beta * kldivergence:  0.16338\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36786\n",
      "kldivergence:   2002.50\n",
      "variational_beta * kldivergence:  0.20025\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36044\n",
      "kldivergence:   2146.31\n",
      "variational_beta * kldivergence:  0.21463\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34554\n",
      "kldivergence:   1805.43\n",
      "variational_beta * kldivergence:  0.18054\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33858\n",
      "kldivergence:   1833.05\n",
      "variational_beta * kldivergence:  0.18331\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30428\n",
      "kldivergence:   1765.73\n",
      "variational_beta * kldivergence:  0.17657\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35256\n",
      "kldivergence:   1924.36\n",
      "variational_beta * kldivergence:  0.19244\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29819\n",
      "kldivergence:   1819.18\n",
      "variational_beta * kldivergence:  0.18192\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.40713\n",
      "kldivergence:   2012.32\n",
      "variational_beta * kldivergence:  0.20123\n",
      "batch accuracy: 86.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33468\n",
      "kldivergence:   1550.86\n",
      "variational_beta * kldivergence:  0.15509\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31655\n",
      "kldivergence:   1807.45\n",
      "variational_beta * kldivergence:  0.18074\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.28257\n",
      "kldivergence:   1440.26\n",
      "variational_beta * kldivergence:  0.14403\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35708\n",
      "kldivergence:   1857.67\n",
      "variational_beta * kldivergence:  0.18577\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32603\n",
      "kldivergence:   1612.93\n",
      "variational_beta * kldivergence:  0.16129\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34606\n",
      "kldivergence:   1820.58\n",
      "variational_beta * kldivergence:  0.18206\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30440\n",
      "kldivergence:   1667.28\n",
      "variational_beta * kldivergence:  0.16673\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.39450\n",
      "kldivergence:   1865.25\n",
      "variational_beta * kldivergence:  0.18653\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33440\n",
      "kldivergence:   1897.14\n",
      "variational_beta * kldivergence:  0.18971\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30597\n",
      "kldivergence:   1548.48\n",
      "variational_beta * kldivergence:  0.15485\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31079\n",
      "kldivergence:   1628.51\n",
      "variational_beta * kldivergence:  0.16285\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35982\n",
      "kldivergence:   1688.72\n",
      "variational_beta * kldivergence:  0.16887\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35039\n",
      "kldivergence:   1936.69\n",
      "variational_beta * kldivergence:  0.19367\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32784\n",
      "kldivergence:   1739.06\n",
      "variational_beta * kldivergence:  0.17391\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31415\n",
      "kldivergence:   1506.92\n",
      "variational_beta * kldivergence:  0.15069\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32248\n",
      "kldivergence:   1792.09\n",
      "variational_beta * kldivergence:  0.17921\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34260\n",
      "kldivergence:   1944.84\n",
      "variational_beta * kldivergence:  0.19448\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29934\n",
      "kldivergence:   1578.51\n",
      "variational_beta * kldivergence:  0.15785\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30808\n",
      "kldivergence:   1674.02\n",
      "variational_beta * kldivergence:  0.16740\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35980\n",
      "kldivergence:   1581.63\n",
      "variational_beta * kldivergence:  0.15816\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34621\n",
      "kldivergence:   1786.35\n",
      "variational_beta * kldivergence:  0.17863\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33102\n",
      "kldivergence:   1562.81\n",
      "variational_beta * kldivergence:  0.15628\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.39003\n",
      "kldivergence:   1678.02\n",
      "variational_beta * kldivergence:  0.16780\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35603\n",
      "kldivergence:   1682.22\n",
      "variational_beta * kldivergence:  0.16822\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34871\n",
      "kldivergence:   1867.81\n",
      "variational_beta * kldivergence:  0.18678\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33270\n",
      "kldivergence:   1725.35\n",
      "variational_beta * kldivergence:  0.17253\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33796\n",
      "kldivergence:   1769.97\n",
      "variational_beta * kldivergence:  0.17700\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35149\n",
      "kldivergence:   1549.20\n",
      "variational_beta * kldivergence:  0.15492\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38506\n",
      "kldivergence:   1745.24\n",
      "variational_beta * kldivergence:  0.17452\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.40239\n",
      "kldivergence:   1964.29\n",
      "variational_beta * kldivergence:  0.19643\n",
      "batch accuracy: 86.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36231\n",
      "kldivergence:   1926.07\n",
      "variational_beta * kldivergence:  0.19261\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32617\n",
      "kldivergence:   1727.10\n",
      "variational_beta * kldivergence:  0.17271\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.28476\n",
      "kldivergence:   1629.53\n",
      "variational_beta * kldivergence:  0.16295\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29909\n",
      "kldivergence:   1782.34\n",
      "variational_beta * kldivergence:  0.17823\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35201\n",
      "kldivergence:   1831.61\n",
      "variational_beta * kldivergence:  0.18316\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35651\n",
      "kldivergence:   2196.06\n",
      "variational_beta * kldivergence:  0.21961\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33631\n",
      "kldivergence:   2185.19\n",
      "variational_beta * kldivergence:  0.21852\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38820\n",
      "kldivergence:   2078.54\n",
      "variational_beta * kldivergence:  0.20785\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37991\n",
      "kldivergence:   2004.92\n",
      "variational_beta * kldivergence:  0.20049\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36799\n",
      "kldivergence:   1767.72\n",
      "variational_beta * kldivergence:  0.17677\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31763\n",
      "kldivergence:   1747.85\n",
      "variational_beta * kldivergence:  0.17478\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.27473\n",
      "kldivergence:   1710.55\n",
      "variational_beta * kldivergence:  0.17106\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38832\n",
      "kldivergence:   1815.07\n",
      "variational_beta * kldivergence:  0.18151\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34318\n",
      "kldivergence:   1771.86\n",
      "variational_beta * kldivergence:  0.17719\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36251\n",
      "kldivergence:   1774.18\n",
      "variational_beta * kldivergence:  0.17742\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35619\n",
      "kldivergence:   1595.21\n",
      "variational_beta * kldivergence:  0.15952\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37429\n",
      "kldivergence:   1773.44\n",
      "variational_beta * kldivergence:  0.17734\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37216\n",
      "kldivergence:   1578.67\n",
      "variational_beta * kldivergence:  0.15787\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33449\n",
      "kldivergence:   1672.77\n",
      "variational_beta * kldivergence:  0.16728\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33798\n",
      "kldivergence:   1674.21\n",
      "variational_beta * kldivergence:  0.16742\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30824\n",
      "kldivergence:   1544.92\n",
      "variational_beta * kldivergence:  0.15449\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37566\n",
      "kldivergence:   1779.27\n",
      "variational_beta * kldivergence:  0.17793\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34461\n",
      "kldivergence:   1771.75\n",
      "variational_beta * kldivergence:  0.17718\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32652\n",
      "kldivergence:   1840.23\n",
      "variational_beta * kldivergence:  0.18402\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36979\n",
      "kldivergence:   1748.65\n",
      "variational_beta * kldivergence:  0.17487\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38031\n",
      "kldivergence:   1703.14\n",
      "variational_beta * kldivergence:  0.17031\n",
      "batch accuracy: 86.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36917\n",
      "kldivergence:   1990.53\n",
      "variational_beta * kldivergence:  0.19905\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29702\n",
      "kldivergence:   1736.62\n",
      "variational_beta * kldivergence:  0.17366\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35518\n",
      "kldivergence:   2066.77\n",
      "variational_beta * kldivergence:  0.20668\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35321\n",
      "kldivergence:   1539.46\n",
      "variational_beta * kldivergence:  0.15395\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34707\n",
      "kldivergence:   1671.76\n",
      "variational_beta * kldivergence:  0.16718\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33129\n",
      "kldivergence:   1664.87\n",
      "variational_beta * kldivergence:  0.16649\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33987\n",
      "kldivergence:   1907.88\n",
      "variational_beta * kldivergence:  0.19079\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34515\n",
      "kldivergence:   1785.74\n",
      "variational_beta * kldivergence:  0.17857\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30990\n",
      "kldivergence:   1656.35\n",
      "variational_beta * kldivergence:  0.16564\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38524\n",
      "kldivergence:   2050.17\n",
      "variational_beta * kldivergence:  0.20502\n",
      "batch accuracy: 86.52\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32820\n",
      "kldivergence:   1631.33\n",
      "variational_beta * kldivergence:  0.16313\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35116\n",
      "kldivergence:   1654.28\n",
      "variational_beta * kldivergence:  0.16543\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33137\n",
      "kldivergence:   1793.68\n",
      "variational_beta * kldivergence:  0.17937\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33939\n",
      "kldivergence:   1690.62\n",
      "variational_beta * kldivergence:  0.16906\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32748\n",
      "kldivergence:   1726.79\n",
      "variational_beta * kldivergence:  0.17268\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32702\n",
      "kldivergence:   1695.62\n",
      "variational_beta * kldivergence:  0.16956\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29601\n",
      "kldivergence:   1622.15\n",
      "variational_beta * kldivergence:  0.16221\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34419\n",
      "kldivergence:   1764.35\n",
      "variational_beta * kldivergence:  0.17643\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38487\n",
      "kldivergence:   1822.16\n",
      "variational_beta * kldivergence:  0.18222\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.41195\n",
      "kldivergence:   1899.60\n",
      "variational_beta * kldivergence:  0.18996\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35521\n",
      "kldivergence:   1770.82\n",
      "variational_beta * kldivergence:  0.17708\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.42698\n",
      "kldivergence:   1770.57\n",
      "variational_beta * kldivergence:  0.17706\n",
      "batch accuracy: 85.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32111\n",
      "kldivergence:   1731.95\n",
      "variational_beta * kldivergence:  0.17319\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36662\n",
      "kldivergence:   1878.42\n",
      "variational_beta * kldivergence:  0.18784\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.39978\n",
      "kldivergence:   1793.87\n",
      "variational_beta * kldivergence:  0.17939\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33678\n",
      "kldivergence:   1603.14\n",
      "variational_beta * kldivergence:  0.16031\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34987\n",
      "kldivergence:   1538.91\n",
      "variational_beta * kldivergence:  0.15389\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36548\n",
      "kldivergence:   1735.08\n",
      "variational_beta * kldivergence:  0.17351\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35649\n",
      "kldivergence:   1747.79\n",
      "variational_beta * kldivergence:  0.17478\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32029\n",
      "kldivergence:   1935.22\n",
      "variational_beta * kldivergence:  0.19352\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32283\n",
      "kldivergence:   1679.58\n",
      "variational_beta * kldivergence:  0.16796\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31832\n",
      "kldivergence:   1643.76\n",
      "variational_beta * kldivergence:  0.16438\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30493\n",
      "kldivergence:   1557.87\n",
      "variational_beta * kldivergence:  0.15579\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33749\n",
      "kldivergence:   1717.43\n",
      "variational_beta * kldivergence:  0.17174\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31986\n",
      "kldivergence:   1656.62\n",
      "variational_beta * kldivergence:  0.16566\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.41840\n",
      "kldivergence:   2015.35\n",
      "variational_beta * kldivergence:  0.20154\n",
      "batch accuracy: 85.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31825\n",
      "kldivergence:   1598.14\n",
      "variational_beta * kldivergence:  0.15981\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32522\n",
      "kldivergence:   1705.36\n",
      "variational_beta * kldivergence:  0.17054\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33016\n",
      "kldivergence:   1793.65\n",
      "variational_beta * kldivergence:  0.17936\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31734\n",
      "kldivergence:   1777.01\n",
      "variational_beta * kldivergence:  0.17770\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36222\n",
      "kldivergence:   1789.81\n",
      "variational_beta * kldivergence:  0.17898\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31796\n",
      "kldivergence:   1725.77\n",
      "variational_beta * kldivergence:  0.17258\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34308\n",
      "kldivergence:   1775.36\n",
      "variational_beta * kldivergence:  0.17754\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35247\n",
      "kldivergence:   2070.87\n",
      "variational_beta * kldivergence:  0.20709\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30165\n",
      "kldivergence:   1737.43\n",
      "variational_beta * kldivergence:  0.17374\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34772\n",
      "kldivergence:   1909.43\n",
      "variational_beta * kldivergence:  0.19094\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31023\n",
      "kldivergence:   1647.43\n",
      "variational_beta * kldivergence:  0.16474\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34703\n",
      "kldivergence:   1845.11\n",
      "variational_beta * kldivergence:  0.18451\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34537\n",
      "kldivergence:   1846.95\n",
      "variational_beta * kldivergence:  0.18470\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29531\n",
      "kldivergence:   1594.38\n",
      "variational_beta * kldivergence:  0.15944\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32917\n",
      "kldivergence:   1785.01\n",
      "variational_beta * kldivergence:  0.17850\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30059\n",
      "kldivergence:   1669.78\n",
      "variational_beta * kldivergence:  0.16698\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34221\n",
      "kldivergence:   1946.69\n",
      "variational_beta * kldivergence:  0.19467\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36979\n",
      "kldivergence:   1914.13\n",
      "variational_beta * kldivergence:  0.19141\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35997\n",
      "kldivergence:   1890.39\n",
      "variational_beta * kldivergence:  0.18904\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29477\n",
      "kldivergence:   1651.63\n",
      "variational_beta * kldivergence:  0.16516\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.27978\n",
      "kldivergence:   1581.25\n",
      "variational_beta * kldivergence:  0.15812\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.31114\n",
      "kldivergence:   1706.22\n",
      "variational_beta * kldivergence:  0.17062\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29523\n",
      "kldivergence:   1542.51\n",
      "variational_beta * kldivergence:  0.15425\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30844\n",
      "kldivergence:   1921.99\n",
      "variational_beta * kldivergence:  0.19220\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34227\n",
      "kldivergence:   1728.81\n",
      "variational_beta * kldivergence:  0.17288\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33344\n",
      "kldivergence:   1664.58\n",
      "variational_beta * kldivergence:  0.16646\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37045\n",
      "kldivergence:   1766.79\n",
      "variational_beta * kldivergence:  0.17668\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33973\n",
      "kldivergence:   1842.84\n",
      "variational_beta * kldivergence:  0.18428\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29390\n",
      "kldivergence:   1512.91\n",
      "variational_beta * kldivergence:  0.15129\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30299\n",
      "kldivergence:   1558.53\n",
      "variational_beta * kldivergence:  0.15585\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.30266\n",
      "kldivergence:   1562.77\n",
      "variational_beta * kldivergence:  0.15628\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35190\n",
      "kldivergence:   1491.90\n",
      "variational_beta * kldivergence:  0.14919\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.29248\n",
      "kldivergence:   1700.67\n",
      "variational_beta * kldivergence:  0.17007\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32989\n",
      "kldivergence:   1653.51\n",
      "variational_beta * kldivergence:  0.16535\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33737\n",
      "kldivergence:   1696.32\n",
      "variational_beta * kldivergence:  0.16963\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37194\n",
      "kldivergence:   1709.60\n",
      "variational_beta * kldivergence:  0.17096\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32715\n",
      "kldivergence:   1633.71\n",
      "variational_beta * kldivergence:  0.16337\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33809\n",
      "kldivergence:   1586.75\n",
      "variational_beta * kldivergence:  0.15868\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37463\n",
      "kldivergence:   1734.22\n",
      "variational_beta * kldivergence:  0.17342\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36764\n",
      "kldivergence:   1997.98\n",
      "variational_beta * kldivergence:  0.19980\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33563\n",
      "kldivergence:   1516.96\n",
      "variational_beta * kldivergence:  0.15170\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37077\n",
      "kldivergence:   1567.85\n",
      "variational_beta * kldivergence:  0.15679\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36373\n",
      "kldivergence:   1580.34\n",
      "variational_beta * kldivergence:  0.15803\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.34402\n",
      "kldivergence:   1685.52\n",
      "variational_beta * kldivergence:  0.16855\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.33410\n",
      "kldivergence:   1678.63\n",
      "variational_beta * kldivergence:  0.16786\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.36378\n",
      "kldivergence:   1654.74\n",
      "variational_beta * kldivergence:  0.16547\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32226\n",
      "kldivergence:   1917.36\n",
      "variational_beta * kldivergence:  0.19174\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.35328\n",
      "kldivergence:   2106.90\n",
      "variational_beta * kldivergence:  0.21069\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.37602\n",
      "kldivergence:   1579.26\n",
      "variational_beta * kldivergence:  0.15793\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.38955\n",
      "kldivergence:   2170.53\n",
      "variational_beta * kldivergence:  0.21705\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32924\n",
      "kldivergence:   1660.20\n",
      "variational_beta * kldivergence:  0.16602\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.26805\n",
      "kldivergence:   1379.00\n",
      "variational_beta * kldivergence:  0.13790\n",
      "batch accuracy: 91.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #6\n",
      "reconstruction loss: 0.32677\n",
      "kldivergence:   1573.74\n",
      "variational_beta * kldivergence:  0.15737\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.43658\n",
      "kldivergence:   1592.27\n",
      "variational_beta * kldivergence:  0.15923\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.39497\n",
      "kldivergence:   1487.24\n",
      "variational_beta * kldivergence:  0.14872\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.41466\n",
      "kldivergence:   1628.70\n",
      "variational_beta * kldivergence:  0.16287\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.45213\n",
      "kldivergence:   1607.59\n",
      "variational_beta * kldivergence:  0.16076\n",
      "batch accuracy: 86.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.49047\n",
      "kldivergence:   1621.20\n",
      "variational_beta * kldivergence:  0.16212\n",
      "batch accuracy: 86.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.38740\n",
      "kldivergence:   1521.53\n",
      "variational_beta * kldivergence:  0.15215\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.54418\n",
      "kldivergence:   1711.45\n",
      "variational_beta * kldivergence:  0.17115\n",
      "batch accuracy: 83.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.49760\n",
      "kldivergence:   1623.07\n",
      "variational_beta * kldivergence:  0.16231\n",
      "batch accuracy: 85.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.43079\n",
      "kldivergence:   1579.64\n",
      "variational_beta * kldivergence:  0.15796\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.51092\n",
      "kldivergence:   1643.58\n",
      "variational_beta * kldivergence:  0.16436\n",
      "batch accuracy: 85.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.43916\n",
      "kldivergence:   1602.09\n",
      "variational_beta * kldivergence:  0.16021\n",
      "batch accuracy: 86.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.44962\n",
      "kldivergence:   1524.54\n",
      "variational_beta * kldivergence:  0.15245\n",
      "batch accuracy: 86.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.48368\n",
      "kldivergence:   1766.04\n",
      "variational_beta * kldivergence:  0.17660\n",
      "batch accuracy: 85.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.48207\n",
      "kldivergence:   1623.94\n",
      "variational_beta * kldivergence:  0.16239\n",
      "batch accuracy: 85.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.44681\n",
      "kldivergence:   1636.34\n",
      "variational_beta * kldivergence:  0.16363\n",
      "batch accuracy: 85.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.41238\n",
      "kldivergence:   1530.77\n",
      "variational_beta * kldivergence:  0.15308\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.53606\n",
      "kldivergence:   1723.70\n",
      "variational_beta * kldivergence:  0.17237\n",
      "batch accuracy: 83.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.41311\n",
      "kldivergence:   1610.42\n",
      "variational_beta * kldivergence:  0.16104\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.43666\n",
      "kldivergence:   1576.45\n",
      "variational_beta * kldivergence:  0.15764\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.42570\n",
      "kldivergence:   1606.29\n",
      "variational_beta * kldivergence:  0.16063\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.48765\n",
      "kldivergence:   1621.39\n",
      "variational_beta * kldivergence:  0.16214\n",
      "batch accuracy: 84.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.43528\n",
      "kldivergence:   1612.60\n",
      "variational_beta * kldivergence:  0.16126\n",
      "batch accuracy: 86.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.46556\n",
      "kldivergence:   1678.36\n",
      "variational_beta * kldivergence:  0.16784\n",
      "batch accuracy: 85.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.43423\n",
      "kldivergence:   1722.72\n",
      "variational_beta * kldivergence:  0.17227\n",
      "batch accuracy: 86.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.42870\n",
      "kldivergence:   1604.93\n",
      "variational_beta * kldivergence:  0.16049\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.41948\n",
      "kldivergence:   1584.08\n",
      "variational_beta * kldivergence:  0.15841\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.42846\n",
      "kldivergence:   1504.09\n",
      "variational_beta * kldivergence:  0.15041\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.41306\n",
      "kldivergence:   1490.62\n",
      "variational_beta * kldivergence:  0.14906\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.47252\n",
      "kldivergence:   1675.61\n",
      "variational_beta * kldivergence:  0.16756\n",
      "batch accuracy: 85.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.43059\n",
      "kldivergence:   1536.01\n",
      "variational_beta * kldivergence:  0.15360\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.48612\n",
      "kldivergence:   1555.97\n",
      "variational_beta * kldivergence:  0.15560\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.40333\n",
      "kldivergence:   1629.75\n",
      "variational_beta * kldivergence:  0.16297\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.49238\n",
      "kldivergence:   1649.57\n",
      "variational_beta * kldivergence:  0.16496\n",
      "batch accuracy: 84.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.44645\n",
      "kldivergence:   1642.02\n",
      "variational_beta * kldivergence:  0.16420\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.42542\n",
      "kldivergence:   1534.12\n",
      "variational_beta * kldivergence:  0.15341\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.50552\n",
      "kldivergence:   1824.86\n",
      "variational_beta * kldivergence:  0.18249\n",
      "batch accuracy: 84.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.46529\n",
      "kldivergence:   1663.84\n",
      "variational_beta * kldivergence:  0.16638\n",
      "batch accuracy: 85.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.51215\n",
      "kldivergence:   1671.44\n",
      "variational_beta * kldivergence:  0.16714\n",
      "batch accuracy: 84.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.43508\n",
      "kldivergence:   1613.05\n",
      "variational_beta * kldivergence:  0.16130\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.37441\n",
      "kldivergence:   1472.96\n",
      "variational_beta * kldivergence:  0.14730\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.42585\n",
      "kldivergence:   1559.64\n",
      "variational_beta * kldivergence:  0.15596\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.47528\n",
      "kldivergence:   1677.91\n",
      "variational_beta * kldivergence:  0.16779\n",
      "batch accuracy: 85.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.49176\n",
      "kldivergence:   1620.12\n",
      "variational_beta * kldivergence:  0.16201\n",
      "batch accuracy: 85.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.53629\n",
      "kldivergence:   1696.30\n",
      "variational_beta * kldivergence:  0.16963\n",
      "batch accuracy: 84.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.54583\n",
      "kldivergence:   1716.74\n",
      "variational_beta * kldivergence:  0.17167\n",
      "batch accuracy: 83.24\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.49805\n",
      "kldivergence:   1700.86\n",
      "variational_beta * kldivergence:  0.17009\n",
      "batch accuracy: 85.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.38638\n",
      "kldivergence:   1454.97\n",
      "variational_beta * kldivergence:  0.14550\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.46521\n",
      "kldivergence:   1737.00\n",
      "variational_beta * kldivergence:  0.17370\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.44455\n",
      "kldivergence:   1664.16\n",
      "variational_beta * kldivergence:  0.16642\n",
      "batch accuracy: 85.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.46495\n",
      "kldivergence:   1740.10\n",
      "variational_beta * kldivergence:  0.17401\n",
      "batch accuracy: 85.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.48621\n",
      "kldivergence:   1645.84\n",
      "variational_beta * kldivergence:  0.16458\n",
      "batch accuracy: 85.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.47008\n",
      "kldivergence:   1766.97\n",
      "variational_beta * kldivergence:  0.17670\n",
      "batch accuracy: 85.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.43343\n",
      "kldivergence:   1661.50\n",
      "variational_beta * kldivergence:  0.16615\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.49196\n",
      "kldivergence:   1600.04\n",
      "variational_beta * kldivergence:  0.16000\n",
      "batch accuracy: 85.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.45096\n",
      "kldivergence:   1561.40\n",
      "variational_beta * kldivergence:  0.15614\n",
      "batch accuracy: 86.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.41514\n",
      "kldivergence:   1565.51\n",
      "variational_beta * kldivergence:  0.15655\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.47360\n",
      "kldivergence:   1555.45\n",
      "variational_beta * kldivergence:  0.15555\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.50713\n",
      "kldivergence:   1776.40\n",
      "variational_beta * kldivergence:  0.17764\n",
      "batch accuracy: 84.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.45364\n",
      "kldivergence:   1510.26\n",
      "variational_beta * kldivergence:  0.15103\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.55983\n",
      "kldivergence:   1732.19\n",
      "variational_beta * kldivergence:  0.17322\n",
      "batch accuracy: 83.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.50549\n",
      "kldivergence:   1767.01\n",
      "variational_beta * kldivergence:  0.17670\n",
      "batch accuracy: 84.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #6\n",
      "reconstruction loss: 0.39113\n",
      "kldivergence:   1517.46\n",
      "variational_beta * kldivergence:  0.15175\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "epoch # 6 : train loss is [192.03974777875328] and validation loss is [0.10403366031685118] \n",
      "saved samples\n",
      "Epoch [7 / 150] average reconstruction error: 0.517627\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39475\n",
      "kldivergence:   1645.52\n",
      "variational_beta * kldivergence:  0.16455\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31814\n",
      "kldivergence:   1689.59\n",
      "variational_beta * kldivergence:  0.16896\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30760\n",
      "kldivergence:   1696.89\n",
      "variational_beta * kldivergence:  0.16969\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37097\n",
      "kldivergence:   1617.33\n",
      "variational_beta * kldivergence:  0.16173\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33393\n",
      "kldivergence:   1882.07\n",
      "variational_beta * kldivergence:  0.18821\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34087\n",
      "kldivergence:   1807.48\n",
      "variational_beta * kldivergence:  0.18075\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31532\n",
      "kldivergence:   1831.56\n",
      "variational_beta * kldivergence:  0.18316\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33063\n",
      "kldivergence:   1839.28\n",
      "variational_beta * kldivergence:  0.18393\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35477\n",
      "kldivergence:   1899.67\n",
      "variational_beta * kldivergence:  0.18997\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30124\n",
      "kldivergence:   1614.69\n",
      "variational_beta * kldivergence:  0.16147\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33646\n",
      "kldivergence:   1918.37\n",
      "variational_beta * kldivergence:  0.19184\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29306\n",
      "kldivergence:   2141.99\n",
      "variational_beta * kldivergence:  0.21420\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31493\n",
      "kldivergence:   1767.38\n",
      "variational_beta * kldivergence:  0.17674\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29588\n",
      "kldivergence:   1774.33\n",
      "variational_beta * kldivergence:  0.17743\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.41073\n",
      "kldivergence:   2010.06\n",
      "variational_beta * kldivergence:  0.20101\n",
      "batch accuracy: 85.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.28580\n",
      "kldivergence:   1693.82\n",
      "variational_beta * kldivergence:  0.16938\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32028\n",
      "kldivergence:   2211.62\n",
      "variational_beta * kldivergence:  0.22116\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31796\n",
      "kldivergence:   1654.14\n",
      "variational_beta * kldivergence:  0.16541\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30779\n",
      "kldivergence:   1671.30\n",
      "variational_beta * kldivergence:  0.16713\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35959\n",
      "kldivergence:   1780.37\n",
      "variational_beta * kldivergence:  0.17804\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38952\n",
      "kldivergence:   1854.86\n",
      "variational_beta * kldivergence:  0.18549\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.27856\n",
      "kldivergence:   1928.24\n",
      "variational_beta * kldivergence:  0.19282\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33260\n",
      "kldivergence:   1766.06\n",
      "variational_beta * kldivergence:  0.17661\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31930\n",
      "kldivergence:   1690.69\n",
      "variational_beta * kldivergence:  0.16907\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32615\n",
      "kldivergence:   1501.05\n",
      "variational_beta * kldivergence:  0.15011\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35555\n",
      "kldivergence:   1688.06\n",
      "variational_beta * kldivergence:  0.16881\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33350\n",
      "kldivergence:   1716.71\n",
      "variational_beta * kldivergence:  0.17167\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35439\n",
      "kldivergence:   1572.40\n",
      "variational_beta * kldivergence:  0.15724\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30593\n",
      "kldivergence:   1596.47\n",
      "variational_beta * kldivergence:  0.15965\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36159\n",
      "kldivergence:   1781.95\n",
      "variational_beta * kldivergence:  0.17820\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34205\n",
      "kldivergence:   1973.71\n",
      "variational_beta * kldivergence:  0.19737\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33400\n",
      "kldivergence:   1783.69\n",
      "variational_beta * kldivergence:  0.17837\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35491\n",
      "kldivergence:   1985.16\n",
      "variational_beta * kldivergence:  0.19852\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34960\n",
      "kldivergence:   1755.10\n",
      "variational_beta * kldivergence:  0.17551\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29317\n",
      "kldivergence:   1761.09\n",
      "variational_beta * kldivergence:  0.17611\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34873\n",
      "kldivergence:   1852.63\n",
      "variational_beta * kldivergence:  0.18526\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30649\n",
      "kldivergence:   1800.46\n",
      "variational_beta * kldivergence:  0.18005\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36074\n",
      "kldivergence:   1682.96\n",
      "variational_beta * kldivergence:  0.16830\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29244\n",
      "kldivergence:   1712.72\n",
      "variational_beta * kldivergence:  0.17127\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33842\n",
      "kldivergence:   1627.75\n",
      "variational_beta * kldivergence:  0.16278\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33123\n",
      "kldivergence:   1720.22\n",
      "variational_beta * kldivergence:  0.17202\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29195\n",
      "kldivergence:   1667.89\n",
      "variational_beta * kldivergence:  0.16679\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35285\n",
      "kldivergence:   1930.88\n",
      "variational_beta * kldivergence:  0.19309\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33350\n",
      "kldivergence:   1802.07\n",
      "variational_beta * kldivergence:  0.18021\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36084\n",
      "kldivergence:   1780.18\n",
      "variational_beta * kldivergence:  0.17802\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36162\n",
      "kldivergence:   1729.32\n",
      "variational_beta * kldivergence:  0.17293\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31845\n",
      "kldivergence:   1717.30\n",
      "variational_beta * kldivergence:  0.17173\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32438\n",
      "kldivergence:   1677.84\n",
      "variational_beta * kldivergence:  0.16778\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37983\n",
      "kldivergence:   1764.55\n",
      "variational_beta * kldivergence:  0.17645\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34168\n",
      "kldivergence:   1504.33\n",
      "variational_beta * kldivergence:  0.15043\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.26375\n",
      "kldivergence:   1688.04\n",
      "variational_beta * kldivergence:  0.16880\n",
      "batch accuracy: 91.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37811\n",
      "kldivergence:   2038.05\n",
      "variational_beta * kldivergence:  0.20381\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39514\n",
      "kldivergence:   1931.67\n",
      "variational_beta * kldivergence:  0.19317\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32252\n",
      "kldivergence:   1838.98\n",
      "variational_beta * kldivergence:  0.18390\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30687\n",
      "kldivergence:   1592.12\n",
      "variational_beta * kldivergence:  0.15921\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30091\n",
      "kldivergence:   1682.11\n",
      "variational_beta * kldivergence:  0.16821\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37049\n",
      "kldivergence:   1821.74\n",
      "variational_beta * kldivergence:  0.18217\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34327\n",
      "kldivergence:   1674.97\n",
      "variational_beta * kldivergence:  0.16750\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36751\n",
      "kldivergence:   1860.79\n",
      "variational_beta * kldivergence:  0.18608\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38097\n",
      "kldivergence:   1669.56\n",
      "variational_beta * kldivergence:  0.16696\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33693\n",
      "kldivergence:   1693.53\n",
      "variational_beta * kldivergence:  0.16935\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32241\n",
      "kldivergence:   1462.86\n",
      "variational_beta * kldivergence:  0.14629\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34553\n",
      "kldivergence:   1421.69\n",
      "variational_beta * kldivergence:  0.14217\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.40353\n",
      "kldivergence:   1827.82\n",
      "variational_beta * kldivergence:  0.18278\n",
      "batch accuracy: 86.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35529\n",
      "kldivergence:   1568.36\n",
      "variational_beta * kldivergence:  0.15684\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39016\n",
      "kldivergence:   1811.24\n",
      "variational_beta * kldivergence:  0.18112\n",
      "batch accuracy: 86.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29186\n",
      "kldivergence:   1530.89\n",
      "variational_beta * kldivergence:  0.15309\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36608\n",
      "kldivergence:   1772.40\n",
      "variational_beta * kldivergence:  0.17724\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33478\n",
      "kldivergence:   1668.62\n",
      "variational_beta * kldivergence:  0.16686\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36494\n",
      "kldivergence:   1692.68\n",
      "variational_beta * kldivergence:  0.16927\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34442\n",
      "kldivergence:   1854.24\n",
      "variational_beta * kldivergence:  0.18542\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29800\n",
      "kldivergence:   1504.99\n",
      "variational_beta * kldivergence:  0.15050\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29520\n",
      "kldivergence:   1600.70\n",
      "variational_beta * kldivergence:  0.16007\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30784\n",
      "kldivergence:   1682.83\n",
      "variational_beta * kldivergence:  0.16828\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32571\n",
      "kldivergence:   1810.40\n",
      "variational_beta * kldivergence:  0.18104\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37218\n",
      "kldivergence:   1660.01\n",
      "variational_beta * kldivergence:  0.16600\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31325\n",
      "kldivergence:   1909.41\n",
      "variational_beta * kldivergence:  0.19094\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39315\n",
      "kldivergence:   1841.01\n",
      "variational_beta * kldivergence:  0.18410\n",
      "batch accuracy: 86.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34892\n",
      "kldivergence:   1609.18\n",
      "variational_beta * kldivergence:  0.16092\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31144\n",
      "kldivergence:   2260.10\n",
      "variational_beta * kldivergence:  0.22601\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32735\n",
      "kldivergence:   1606.03\n",
      "variational_beta * kldivergence:  0.16060\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38978\n",
      "kldivergence:   1888.23\n",
      "variational_beta * kldivergence:  0.18882\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33626\n",
      "kldivergence:   1771.34\n",
      "variational_beta * kldivergence:  0.17713\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32347\n",
      "kldivergence:   1722.75\n",
      "variational_beta * kldivergence:  0.17228\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31230\n",
      "kldivergence:   1611.25\n",
      "variational_beta * kldivergence:  0.16112\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35679\n",
      "kldivergence:   2116.16\n",
      "variational_beta * kldivergence:  0.21162\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35006\n",
      "kldivergence:   1780.31\n",
      "variational_beta * kldivergence:  0.17803\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30325\n",
      "kldivergence:   1644.27\n",
      "variational_beta * kldivergence:  0.16443\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29677\n",
      "kldivergence:   1643.65\n",
      "variational_beta * kldivergence:  0.16437\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33878\n",
      "kldivergence:   1642.14\n",
      "variational_beta * kldivergence:  0.16421\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31781\n",
      "kldivergence:   2000.12\n",
      "variational_beta * kldivergence:  0.20001\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32919\n",
      "kldivergence:   1901.96\n",
      "variational_beta * kldivergence:  0.19020\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34663\n",
      "kldivergence:   1695.13\n",
      "variational_beta * kldivergence:  0.16951\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34411\n",
      "kldivergence:   1739.19\n",
      "variational_beta * kldivergence:  0.17392\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32806\n",
      "kldivergence:   1612.78\n",
      "variational_beta * kldivergence:  0.16128\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.41603\n",
      "kldivergence:   1854.14\n",
      "variational_beta * kldivergence:  0.18541\n",
      "batch accuracy: 85.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34664\n",
      "kldivergence:   2010.22\n",
      "variational_beta * kldivergence:  0.20102\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.27862\n",
      "kldivergence:   1866.23\n",
      "variational_beta * kldivergence:  0.18662\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35784\n",
      "kldivergence:   1735.75\n",
      "variational_beta * kldivergence:  0.17358\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32880\n",
      "kldivergence:   1692.18\n",
      "variational_beta * kldivergence:  0.16922\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37983\n",
      "kldivergence:   1918.40\n",
      "variational_beta * kldivergence:  0.19184\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33444\n",
      "kldivergence:   1611.83\n",
      "variational_beta * kldivergence:  0.16118\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30828\n",
      "kldivergence:   1609.97\n",
      "variational_beta * kldivergence:  0.16100\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34059\n",
      "kldivergence:   1701.05\n",
      "variational_beta * kldivergence:  0.17010\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.27224\n",
      "kldivergence:   1583.90\n",
      "variational_beta * kldivergence:  0.15839\n",
      "batch accuracy: 90.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36777\n",
      "kldivergence:   2010.60\n",
      "variational_beta * kldivergence:  0.20106\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31066\n",
      "kldivergence:   1712.24\n",
      "variational_beta * kldivergence:  0.17122\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39831\n",
      "kldivergence:   1881.35\n",
      "variational_beta * kldivergence:  0.18813\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36945\n",
      "kldivergence:   1840.84\n",
      "variational_beta * kldivergence:  0.18408\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38345\n",
      "kldivergence:   1883.80\n",
      "variational_beta * kldivergence:  0.18838\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.40043\n",
      "kldivergence:   2024.38\n",
      "variational_beta * kldivergence:  0.20244\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29949\n",
      "kldivergence:   1695.36\n",
      "variational_beta * kldivergence:  0.16954\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35134\n",
      "kldivergence:   1794.66\n",
      "variational_beta * kldivergence:  0.17947\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37210\n",
      "kldivergence:   1945.95\n",
      "variational_beta * kldivergence:  0.19460\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31502\n",
      "kldivergence:   1641.19\n",
      "variational_beta * kldivergence:  0.16412\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39208\n",
      "kldivergence:   1881.29\n",
      "variational_beta * kldivergence:  0.18813\n",
      "batch accuracy: 86.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29550\n",
      "kldivergence:   1765.88\n",
      "variational_beta * kldivergence:  0.17659\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39567\n",
      "kldivergence:   1898.27\n",
      "variational_beta * kldivergence:  0.18983\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35477\n",
      "kldivergence:   1757.61\n",
      "variational_beta * kldivergence:  0.17576\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30363\n",
      "kldivergence:   1818.11\n",
      "variational_beta * kldivergence:  0.18181\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32628\n",
      "kldivergence:   1720.42\n",
      "variational_beta * kldivergence:  0.17204\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37688\n",
      "kldivergence:   1650.15\n",
      "variational_beta * kldivergence:  0.16501\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32039\n",
      "kldivergence:   1911.49\n",
      "variational_beta * kldivergence:  0.19115\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34492\n",
      "kldivergence:   1643.74\n",
      "variational_beta * kldivergence:  0.16437\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30998\n",
      "kldivergence:   1538.50\n",
      "variational_beta * kldivergence:  0.15385\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.40405\n",
      "kldivergence:   2043.71\n",
      "variational_beta * kldivergence:  0.20437\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33333\n",
      "kldivergence:   1973.63\n",
      "variational_beta * kldivergence:  0.19736\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35693\n",
      "kldivergence:   1922.86\n",
      "variational_beta * kldivergence:  0.19229\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36064\n",
      "kldivergence:   1884.39\n",
      "variational_beta * kldivergence:  0.18844\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33316\n",
      "kldivergence:   1693.87\n",
      "variational_beta * kldivergence:  0.16939\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37738\n",
      "kldivergence:   1729.01\n",
      "variational_beta * kldivergence:  0.17290\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29150\n",
      "kldivergence:   1768.48\n",
      "variational_beta * kldivergence:  0.17685\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34514\n",
      "kldivergence:   1634.78\n",
      "variational_beta * kldivergence:  0.16348\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32397\n",
      "kldivergence:   1514.25\n",
      "variational_beta * kldivergence:  0.15143\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32754\n",
      "kldivergence:   1873.32\n",
      "variational_beta * kldivergence:  0.18733\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35706\n",
      "kldivergence:   1472.99\n",
      "variational_beta * kldivergence:  0.14730\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32899\n",
      "kldivergence:   1752.99\n",
      "variational_beta * kldivergence:  0.17530\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36255\n",
      "kldivergence:   1756.94\n",
      "variational_beta * kldivergence:  0.17569\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38862\n",
      "kldivergence:   1919.65\n",
      "variational_beta * kldivergence:  0.19196\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31738\n",
      "kldivergence:   1725.99\n",
      "variational_beta * kldivergence:  0.17260\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35157\n",
      "kldivergence:   1728.14\n",
      "variational_beta * kldivergence:  0.17281\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37070\n",
      "kldivergence:   2064.32\n",
      "variational_beta * kldivergence:  0.20643\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32309\n",
      "kldivergence:   1569.17\n",
      "variational_beta * kldivergence:  0.15692\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33451\n",
      "kldivergence:   1780.75\n",
      "variational_beta * kldivergence:  0.17808\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35021\n",
      "kldivergence:   1700.03\n",
      "variational_beta * kldivergence:  0.17000\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29644\n",
      "kldivergence:   1606.43\n",
      "variational_beta * kldivergence:  0.16064\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37448\n",
      "kldivergence:   1899.83\n",
      "variational_beta * kldivergence:  0.18998\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34437\n",
      "kldivergence:   1787.00\n",
      "variational_beta * kldivergence:  0.17870\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35586\n",
      "kldivergence:   1898.91\n",
      "variational_beta * kldivergence:  0.18989\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38160\n",
      "kldivergence:   1640.34\n",
      "variational_beta * kldivergence:  0.16403\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32228\n",
      "kldivergence:   1696.13\n",
      "variational_beta * kldivergence:  0.16961\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30109\n",
      "kldivergence:   1455.98\n",
      "variational_beta * kldivergence:  0.14560\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34537\n",
      "kldivergence:   1851.91\n",
      "variational_beta * kldivergence:  0.18519\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35670\n",
      "kldivergence:   1810.38\n",
      "variational_beta * kldivergence:  0.18104\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36839\n",
      "kldivergence:   1715.47\n",
      "variational_beta * kldivergence:  0.17155\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29255\n",
      "kldivergence:   1729.41\n",
      "variational_beta * kldivergence:  0.17294\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34115\n",
      "kldivergence:   1673.69\n",
      "variational_beta * kldivergence:  0.16737\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31208\n",
      "kldivergence:   1461.78\n",
      "variational_beta * kldivergence:  0.14618\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.41262\n",
      "kldivergence:   1639.43\n",
      "variational_beta * kldivergence:  0.16394\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29978\n",
      "kldivergence:   1560.05\n",
      "variational_beta * kldivergence:  0.15600\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.25795\n",
      "kldivergence:   1555.99\n",
      "variational_beta * kldivergence:  0.15560\n",
      "batch accuracy: 91.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29351\n",
      "kldivergence:   1571.47\n",
      "variational_beta * kldivergence:  0.15715\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35972\n",
      "kldivergence:   1833.39\n",
      "variational_beta * kldivergence:  0.18334\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30109\n",
      "kldivergence:   1462.93\n",
      "variational_beta * kldivergence:  0.14629\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34418\n",
      "kldivergence:   1804.24\n",
      "variational_beta * kldivergence:  0.18042\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35447\n",
      "kldivergence:   1876.71\n",
      "variational_beta * kldivergence:  0.18767\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34393\n",
      "kldivergence:   1724.49\n",
      "variational_beta * kldivergence:  0.17245\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30913\n",
      "kldivergence:   1872.10\n",
      "variational_beta * kldivergence:  0.18721\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.42940\n",
      "kldivergence:   2147.02\n",
      "variational_beta * kldivergence:  0.21470\n",
      "batch accuracy: 85.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31547\n",
      "kldivergence:   1617.70\n",
      "variational_beta * kldivergence:  0.16177\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30705\n",
      "kldivergence:   1521.93\n",
      "variational_beta * kldivergence:  0.15219\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36931\n",
      "kldivergence:   1617.85\n",
      "variational_beta * kldivergence:  0.16178\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35344\n",
      "kldivergence:   1625.05\n",
      "variational_beta * kldivergence:  0.16251\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31220\n",
      "kldivergence:   2093.78\n",
      "variational_beta * kldivergence:  0.20938\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30502\n",
      "kldivergence:   1516.30\n",
      "variational_beta * kldivergence:  0.15163\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37997\n",
      "kldivergence:   1788.66\n",
      "variational_beta * kldivergence:  0.17887\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35033\n",
      "kldivergence:   1760.18\n",
      "variational_beta * kldivergence:  0.17602\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31988\n",
      "kldivergence:   1549.19\n",
      "variational_beta * kldivergence:  0.15492\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32750\n",
      "kldivergence:   1649.05\n",
      "variational_beta * kldivergence:  0.16490\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31802\n",
      "kldivergence:   1581.20\n",
      "variational_beta * kldivergence:  0.15812\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33478\n",
      "kldivergence:   1580.54\n",
      "variational_beta * kldivergence:  0.15805\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34281\n",
      "kldivergence:   1571.23\n",
      "variational_beta * kldivergence:  0.15712\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30401\n",
      "kldivergence:   1651.02\n",
      "variational_beta * kldivergence:  0.16510\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33600\n",
      "kldivergence:   1630.51\n",
      "variational_beta * kldivergence:  0.16305\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33333\n",
      "kldivergence:   1549.68\n",
      "variational_beta * kldivergence:  0.15497\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33969\n",
      "kldivergence:   1872.55\n",
      "variational_beta * kldivergence:  0.18726\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32546\n",
      "kldivergence:   1636.72\n",
      "variational_beta * kldivergence:  0.16367\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.41103\n",
      "kldivergence:   1776.82\n",
      "variational_beta * kldivergence:  0.17768\n",
      "batch accuracy: 85.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34377\n",
      "kldivergence:   1680.89\n",
      "variational_beta * kldivergence:  0.16809\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39893\n",
      "kldivergence:   1736.32\n",
      "variational_beta * kldivergence:  0.17363\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36454\n",
      "kldivergence:   1708.32\n",
      "variational_beta * kldivergence:  0.17083\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33571\n",
      "kldivergence:   1666.17\n",
      "variational_beta * kldivergence:  0.16662\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31301\n",
      "kldivergence:   1612.75\n",
      "variational_beta * kldivergence:  0.16127\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36947\n",
      "kldivergence:   1716.13\n",
      "variational_beta * kldivergence:  0.17161\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39061\n",
      "kldivergence:   1793.27\n",
      "variational_beta * kldivergence:  0.17933\n",
      "batch accuracy: 86.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37433\n",
      "kldivergence:   1780.03\n",
      "variational_beta * kldivergence:  0.17800\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36983\n",
      "kldivergence:   1732.02\n",
      "variational_beta * kldivergence:  0.17320\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31135\n",
      "kldivergence:   1551.38\n",
      "variational_beta * kldivergence:  0.15514\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30700\n",
      "kldivergence:   1762.29\n",
      "variational_beta * kldivergence:  0.17623\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38091\n",
      "kldivergence:   1785.15\n",
      "variational_beta * kldivergence:  0.17851\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29752\n",
      "kldivergence:   1863.47\n",
      "variational_beta * kldivergence:  0.18635\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37241\n",
      "kldivergence:   1794.33\n",
      "variational_beta * kldivergence:  0.17943\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33071\n",
      "kldivergence:   1557.83\n",
      "variational_beta * kldivergence:  0.15578\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36590\n",
      "kldivergence:   1582.11\n",
      "variational_beta * kldivergence:  0.15821\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32365\n",
      "kldivergence:   1736.66\n",
      "variational_beta * kldivergence:  0.17367\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34514\n",
      "kldivergence:   1744.24\n",
      "variational_beta * kldivergence:  0.17442\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31830\n",
      "kldivergence:   1789.18\n",
      "variational_beta * kldivergence:  0.17892\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34185\n",
      "kldivergence:   2021.98\n",
      "variational_beta * kldivergence:  0.20220\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35494\n",
      "kldivergence:   1641.01\n",
      "variational_beta * kldivergence:  0.16410\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30008\n",
      "kldivergence:   1738.47\n",
      "variational_beta * kldivergence:  0.17385\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31323\n",
      "kldivergence:   1676.02\n",
      "variational_beta * kldivergence:  0.16760\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31597\n",
      "kldivergence:   1917.56\n",
      "variational_beta * kldivergence:  0.19176\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38736\n",
      "kldivergence:   2064.17\n",
      "variational_beta * kldivergence:  0.20642\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36450\n",
      "kldivergence:   1737.87\n",
      "variational_beta * kldivergence:  0.17379\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36102\n",
      "kldivergence:   1694.80\n",
      "variational_beta * kldivergence:  0.16948\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34380\n",
      "kldivergence:   1614.63\n",
      "variational_beta * kldivergence:  0.16146\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31085\n",
      "kldivergence:   1687.59\n",
      "variational_beta * kldivergence:  0.16876\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38297\n",
      "kldivergence:   1784.16\n",
      "variational_beta * kldivergence:  0.17842\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35495\n",
      "kldivergence:   1839.00\n",
      "variational_beta * kldivergence:  0.18390\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31396\n",
      "kldivergence:   1792.08\n",
      "variational_beta * kldivergence:  0.17921\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29798\n",
      "kldivergence:   1676.17\n",
      "variational_beta * kldivergence:  0.16762\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35939\n",
      "kldivergence:   1843.44\n",
      "variational_beta * kldivergence:  0.18434\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31527\n",
      "kldivergence:   1738.47\n",
      "variational_beta * kldivergence:  0.17385\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29736\n",
      "kldivergence:   1405.20\n",
      "variational_beta * kldivergence:  0.14052\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35594\n",
      "kldivergence:   1771.47\n",
      "variational_beta * kldivergence:  0.17715\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35284\n",
      "kldivergence:   1712.59\n",
      "variational_beta * kldivergence:  0.17126\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35424\n",
      "kldivergence:   1961.17\n",
      "variational_beta * kldivergence:  0.19612\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34754\n",
      "kldivergence:   1848.45\n",
      "variational_beta * kldivergence:  0.18484\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36318\n",
      "kldivergence:   1817.86\n",
      "variational_beta * kldivergence:  0.18179\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33344\n",
      "kldivergence:   1563.15\n",
      "variational_beta * kldivergence:  0.15631\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31638\n",
      "kldivergence:   1778.75\n",
      "variational_beta * kldivergence:  0.17787\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34657\n",
      "kldivergence:   1718.95\n",
      "variational_beta * kldivergence:  0.17190\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32492\n",
      "kldivergence:   1719.68\n",
      "variational_beta * kldivergence:  0.17197\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35939\n",
      "kldivergence:   1909.71\n",
      "variational_beta * kldivergence:  0.19097\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33083\n",
      "kldivergence:   2155.76\n",
      "variational_beta * kldivergence:  0.21558\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.28307\n",
      "kldivergence:   1711.50\n",
      "variational_beta * kldivergence:  0.17115\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31912\n",
      "kldivergence:   1811.63\n",
      "variational_beta * kldivergence:  0.18116\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34278\n",
      "kldivergence:   1946.02\n",
      "variational_beta * kldivergence:  0.19460\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30704\n",
      "kldivergence:   1678.08\n",
      "variational_beta * kldivergence:  0.16781\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31182\n",
      "kldivergence:   2086.40\n",
      "variational_beta * kldivergence:  0.20864\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37280\n",
      "kldivergence:   1889.13\n",
      "variational_beta * kldivergence:  0.18891\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35394\n",
      "kldivergence:   1788.83\n",
      "variational_beta * kldivergence:  0.17888\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30301\n",
      "kldivergence:   1710.33\n",
      "variational_beta * kldivergence:  0.17103\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37093\n",
      "kldivergence:   1900.91\n",
      "variational_beta * kldivergence:  0.19009\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35053\n",
      "kldivergence:   1872.68\n",
      "variational_beta * kldivergence:  0.18727\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36519\n",
      "kldivergence:   1907.71\n",
      "variational_beta * kldivergence:  0.19077\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34430\n",
      "kldivergence:   1852.17\n",
      "variational_beta * kldivergence:  0.18522\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33787\n",
      "kldivergence:   1864.67\n",
      "variational_beta * kldivergence:  0.18647\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33737\n",
      "kldivergence:   1575.85\n",
      "variational_beta * kldivergence:  0.15759\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34605\n",
      "kldivergence:   1842.00\n",
      "variational_beta * kldivergence:  0.18420\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34531\n",
      "kldivergence:   1768.38\n",
      "variational_beta * kldivergence:  0.17684\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34917\n",
      "kldivergence:   1577.86\n",
      "variational_beta * kldivergence:  0.15779\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35559\n",
      "kldivergence:   1528.19\n",
      "variational_beta * kldivergence:  0.15282\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32192\n",
      "kldivergence:   1962.71\n",
      "variational_beta * kldivergence:  0.19627\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35487\n",
      "kldivergence:   1649.79\n",
      "variational_beta * kldivergence:  0.16498\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32507\n",
      "kldivergence:   1745.53\n",
      "variational_beta * kldivergence:  0.17455\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37012\n",
      "kldivergence:   1880.12\n",
      "variational_beta * kldivergence:  0.18801\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36089\n",
      "kldivergence:   1781.64\n",
      "variational_beta * kldivergence:  0.17816\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32014\n",
      "kldivergence:   1705.45\n",
      "variational_beta * kldivergence:  0.17054\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33093\n",
      "kldivergence:   1560.50\n",
      "variational_beta * kldivergence:  0.15605\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31630\n",
      "kldivergence:   1885.85\n",
      "variational_beta * kldivergence:  0.18858\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33944\n",
      "kldivergence:   1751.13\n",
      "variational_beta * kldivergence:  0.17511\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36693\n",
      "kldivergence:   1611.96\n",
      "variational_beta * kldivergence:  0.16120\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30389\n",
      "kldivergence:   2043.10\n",
      "variational_beta * kldivergence:  0.20431\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32848\n",
      "kldivergence:   1610.00\n",
      "variational_beta * kldivergence:  0.16100\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35063\n",
      "kldivergence:   1927.37\n",
      "variational_beta * kldivergence:  0.19274\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29135\n",
      "kldivergence:   1630.84\n",
      "variational_beta * kldivergence:  0.16308\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31954\n",
      "kldivergence:   1789.88\n",
      "variational_beta * kldivergence:  0.17899\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37427\n",
      "kldivergence:   1751.19\n",
      "variational_beta * kldivergence:  0.17512\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35154\n",
      "kldivergence:   1920.53\n",
      "variational_beta * kldivergence:  0.19205\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.28649\n",
      "kldivergence:   1931.25\n",
      "variational_beta * kldivergence:  0.19313\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30834\n",
      "kldivergence:   2041.80\n",
      "variational_beta * kldivergence:  0.20418\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30870\n",
      "kldivergence:   1662.01\n",
      "variational_beta * kldivergence:  0.16620\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34147\n",
      "kldivergence:   1663.12\n",
      "variational_beta * kldivergence:  0.16631\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29582\n",
      "kldivergence:   1568.94\n",
      "variational_beta * kldivergence:  0.15689\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33980\n",
      "kldivergence:   1621.00\n",
      "variational_beta * kldivergence:  0.16210\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38080\n",
      "kldivergence:   1770.63\n",
      "variational_beta * kldivergence:  0.17706\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38578\n",
      "kldivergence:   1642.18\n",
      "variational_beta * kldivergence:  0.16422\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30754\n",
      "kldivergence:   1750.24\n",
      "variational_beta * kldivergence:  0.17502\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34206\n",
      "kldivergence:   1851.82\n",
      "variational_beta * kldivergence:  0.18518\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36180\n",
      "kldivergence:   1968.09\n",
      "variational_beta * kldivergence:  0.19681\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33615\n",
      "kldivergence:   1766.81\n",
      "variational_beta * kldivergence:  0.17668\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32942\n",
      "kldivergence:   1734.07\n",
      "variational_beta * kldivergence:  0.17341\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35041\n",
      "kldivergence:   1935.38\n",
      "variational_beta * kldivergence:  0.19354\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33572\n",
      "kldivergence:   1782.52\n",
      "variational_beta * kldivergence:  0.17825\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30480\n",
      "kldivergence:   1680.49\n",
      "variational_beta * kldivergence:  0.16805\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31454\n",
      "kldivergence:   1707.81\n",
      "variational_beta * kldivergence:  0.17078\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36304\n",
      "kldivergence:   1809.02\n",
      "variational_beta * kldivergence:  0.18090\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35122\n",
      "kldivergence:   1723.84\n",
      "variational_beta * kldivergence:  0.17238\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33392\n",
      "kldivergence:   1938.03\n",
      "variational_beta * kldivergence:  0.19380\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33088\n",
      "kldivergence:   1655.03\n",
      "variational_beta * kldivergence:  0.16550\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31427\n",
      "kldivergence:   1694.04\n",
      "variational_beta * kldivergence:  0.16940\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32593\n",
      "kldivergence:   1483.55\n",
      "variational_beta * kldivergence:  0.14836\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34549\n",
      "kldivergence:   1773.65\n",
      "variational_beta * kldivergence:  0.17736\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35466\n",
      "kldivergence:   1712.00\n",
      "variational_beta * kldivergence:  0.17120\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33367\n",
      "kldivergence:   1528.58\n",
      "variational_beta * kldivergence:  0.15286\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30677\n",
      "kldivergence:   1701.46\n",
      "variational_beta * kldivergence:  0.17015\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34675\n",
      "kldivergence:   1470.03\n",
      "variational_beta * kldivergence:  0.14700\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31263\n",
      "kldivergence:   1470.83\n",
      "variational_beta * kldivergence:  0.14708\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35463\n",
      "kldivergence:   1870.15\n",
      "variational_beta * kldivergence:  0.18702\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36146\n",
      "kldivergence:   1715.54\n",
      "variational_beta * kldivergence:  0.17155\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.28551\n",
      "kldivergence:   1469.96\n",
      "variational_beta * kldivergence:  0.14700\n",
      "batch accuracy: 90.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35386\n",
      "kldivergence:   1591.86\n",
      "variational_beta * kldivergence:  0.15919\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39700\n",
      "kldivergence:   1817.35\n",
      "variational_beta * kldivergence:  0.18174\n",
      "batch accuracy: 86.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34055\n",
      "kldivergence:   1776.06\n",
      "variational_beta * kldivergence:  0.17761\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36247\n",
      "kldivergence:   1799.55\n",
      "variational_beta * kldivergence:  0.17995\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32044\n",
      "kldivergence:   1741.63\n",
      "variational_beta * kldivergence:  0.17416\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38734\n",
      "kldivergence:   1758.08\n",
      "variational_beta * kldivergence:  0.17581\n",
      "batch accuracy: 86.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36799\n",
      "kldivergence:   2004.27\n",
      "variational_beta * kldivergence:  0.20043\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.27061\n",
      "kldivergence:   1583.15\n",
      "variational_beta * kldivergence:  0.15831\n",
      "batch accuracy: 90.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30123\n",
      "kldivergence:   1846.39\n",
      "variational_beta * kldivergence:  0.18464\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34064\n",
      "kldivergence:   1755.00\n",
      "variational_beta * kldivergence:  0.17550\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30153\n",
      "kldivergence:   1769.81\n",
      "variational_beta * kldivergence:  0.17698\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33092\n",
      "kldivergence:   1645.82\n",
      "variational_beta * kldivergence:  0.16458\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38891\n",
      "kldivergence:   1747.45\n",
      "variational_beta * kldivergence:  0.17474\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39819\n",
      "kldivergence:   1780.54\n",
      "variational_beta * kldivergence:  0.17805\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39202\n",
      "kldivergence:   1783.66\n",
      "variational_beta * kldivergence:  0.17837\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37448\n",
      "kldivergence:   1937.87\n",
      "variational_beta * kldivergence:  0.19379\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29535\n",
      "kldivergence:   1790.23\n",
      "variational_beta * kldivergence:  0.17902\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30561\n",
      "kldivergence:   1590.05\n",
      "variational_beta * kldivergence:  0.15900\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33771\n",
      "kldivergence:   1694.62\n",
      "variational_beta * kldivergence:  0.16946\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31079\n",
      "kldivergence:   1573.87\n",
      "variational_beta * kldivergence:  0.15739\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35390\n",
      "kldivergence:   1625.98\n",
      "variational_beta * kldivergence:  0.16260\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36897\n",
      "kldivergence:   1771.51\n",
      "variational_beta * kldivergence:  0.17715\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.39612\n",
      "kldivergence:   1825.15\n",
      "variational_beta * kldivergence:  0.18251\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38170\n",
      "kldivergence:   1634.37\n",
      "variational_beta * kldivergence:  0.16344\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36905\n",
      "kldivergence:   1867.02\n",
      "variational_beta * kldivergence:  0.18670\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32314\n",
      "kldivergence:   1605.11\n",
      "variational_beta * kldivergence:  0.16051\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33098\n",
      "kldivergence:   1723.88\n",
      "variational_beta * kldivergence:  0.17239\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29615\n",
      "kldivergence:   1646.77\n",
      "variational_beta * kldivergence:  0.16468\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35719\n",
      "kldivergence:   1954.79\n",
      "variational_beta * kldivergence:  0.19548\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36589\n",
      "kldivergence:   1867.81\n",
      "variational_beta * kldivergence:  0.18678\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36978\n",
      "kldivergence:   1950.60\n",
      "variational_beta * kldivergence:  0.19506\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34535\n",
      "kldivergence:   1929.58\n",
      "variational_beta * kldivergence:  0.19296\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31581\n",
      "kldivergence:   1922.79\n",
      "variational_beta * kldivergence:  0.19228\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36404\n",
      "kldivergence:   1804.20\n",
      "variational_beta * kldivergence:  0.18042\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.27488\n",
      "kldivergence:   1682.78\n",
      "variational_beta * kldivergence:  0.16828\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34001\n",
      "kldivergence:   1594.19\n",
      "variational_beta * kldivergence:  0.15942\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29911\n",
      "kldivergence:   1779.83\n",
      "variational_beta * kldivergence:  0.17798\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32619\n",
      "kldivergence:   1688.64\n",
      "variational_beta * kldivergence:  0.16886\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32011\n",
      "kldivergence:   1674.58\n",
      "variational_beta * kldivergence:  0.16746\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33903\n",
      "kldivergence:   1894.81\n",
      "variational_beta * kldivergence:  0.18948\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32463\n",
      "kldivergence:   1611.19\n",
      "variational_beta * kldivergence:  0.16112\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30901\n",
      "kldivergence:   1703.02\n",
      "variational_beta * kldivergence:  0.17030\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32093\n",
      "kldivergence:   1883.71\n",
      "variational_beta * kldivergence:  0.18837\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38189\n",
      "kldivergence:   1833.23\n",
      "variational_beta * kldivergence:  0.18332\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34874\n",
      "kldivergence:   2083.49\n",
      "variational_beta * kldivergence:  0.20835\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29629\n",
      "kldivergence:   1748.43\n",
      "variational_beta * kldivergence:  0.17484\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.38180\n",
      "kldivergence:   2027.32\n",
      "variational_beta * kldivergence:  0.20273\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34077\n",
      "kldivergence:   1687.22\n",
      "variational_beta * kldivergence:  0.16872\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.41166\n",
      "kldivergence:   1883.56\n",
      "variational_beta * kldivergence:  0.18836\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32198\n",
      "kldivergence:   1965.96\n",
      "variational_beta * kldivergence:  0.19660\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37189\n",
      "kldivergence:   1748.60\n",
      "variational_beta * kldivergence:  0.17486\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.29648\n",
      "kldivergence:   1620.95\n",
      "variational_beta * kldivergence:  0.16209\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34861\n",
      "kldivergence:   1683.97\n",
      "variational_beta * kldivergence:  0.16840\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30401\n",
      "kldivergence:   1699.62\n",
      "variational_beta * kldivergence:  0.16996\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34210\n",
      "kldivergence:   1885.73\n",
      "variational_beta * kldivergence:  0.18857\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36784\n",
      "kldivergence:   2045.15\n",
      "variational_beta * kldivergence:  0.20451\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32351\n",
      "kldivergence:   1475.46\n",
      "variational_beta * kldivergence:  0.14755\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.36383\n",
      "kldivergence:   1957.00\n",
      "variational_beta * kldivergence:  0.19570\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34829\n",
      "kldivergence:   1806.30\n",
      "variational_beta * kldivergence:  0.18063\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.33257\n",
      "kldivergence:   1815.88\n",
      "variational_beta * kldivergence:  0.18159\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37029\n",
      "kldivergence:   1748.57\n",
      "variational_beta * kldivergence:  0.17486\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35551\n",
      "kldivergence:   2120.21\n",
      "variational_beta * kldivergence:  0.21202\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.37981\n",
      "kldivergence:   2006.37\n",
      "variational_beta * kldivergence:  0.20064\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.34475\n",
      "kldivergence:   1598.41\n",
      "variational_beta * kldivergence:  0.15984\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.31538\n",
      "kldivergence:   1491.95\n",
      "variational_beta * kldivergence:  0.14920\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.32630\n",
      "kldivergence:   1797.86\n",
      "variational_beta * kldivergence:  0.17979\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.30556\n",
      "kldivergence:   1455.97\n",
      "variational_beta * kldivergence:  0.14560\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35676\n",
      "kldivergence:   1690.53\n",
      "variational_beta * kldivergence:  0.16905\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #7\n",
      "reconstruction loss: 0.35928\n",
      "kldivergence:   1630.76\n",
      "variational_beta * kldivergence:  0.16308\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.40085\n",
      "kldivergence:   1483.84\n",
      "variational_beta * kldivergence:  0.14838\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.46388\n",
      "kldivergence:   1666.10\n",
      "variational_beta * kldivergence:  0.16661\n",
      "batch accuracy: 85.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.54523\n",
      "kldivergence:   1679.30\n",
      "variational_beta * kldivergence:  0.16793\n",
      "batch accuracy: 82.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.53608\n",
      "kldivergence:   1695.36\n",
      "variational_beta * kldivergence:  0.16954\n",
      "batch accuracy: 83.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.45922\n",
      "kldivergence:   1538.88\n",
      "variational_beta * kldivergence:  0.15389\n",
      "batch accuracy: 86.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.65587\n",
      "kldivergence:   1777.09\n",
      "variational_beta * kldivergence:  0.17771\n",
      "batch accuracy: 81.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.45836\n",
      "kldivergence:   1745.90\n",
      "variational_beta * kldivergence:  0.17459\n",
      "batch accuracy: 85.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.55354\n",
      "kldivergence:   1783.13\n",
      "variational_beta * kldivergence:  0.17831\n",
      "batch accuracy: 83.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.42541\n",
      "kldivergence:   1550.48\n",
      "variational_beta * kldivergence:  0.15505\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.39232\n",
      "kldivergence:   1611.68\n",
      "variational_beta * kldivergence:  0.16117\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.41251\n",
      "kldivergence:   1569.50\n",
      "variational_beta * kldivergence:  0.15695\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.38546\n",
      "kldivergence:   1559.96\n",
      "variational_beta * kldivergence:  0.15600\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.42943\n",
      "kldivergence:   1626.59\n",
      "variational_beta * kldivergence:  0.16266\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.42081\n",
      "kldivergence:   1592.36\n",
      "variational_beta * kldivergence:  0.15924\n",
      "batch accuracy: 86.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.50545\n",
      "kldivergence:   1631.22\n",
      "variational_beta * kldivergence:  0.16312\n",
      "batch accuracy: 85.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.45116\n",
      "kldivergence:   1775.38\n",
      "variational_beta * kldivergence:  0.17754\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.48488\n",
      "kldivergence:   1544.60\n",
      "variational_beta * kldivergence:  0.15446\n",
      "batch accuracy: 85.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.37886\n",
      "kldivergence:   1587.57\n",
      "variational_beta * kldivergence:  0.15876\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.40287\n",
      "kldivergence:   1509.57\n",
      "variational_beta * kldivergence:  0.15096\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.45046\n",
      "kldivergence:   1518.55\n",
      "variational_beta * kldivergence:  0.15186\n",
      "batch accuracy: 86.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.45817\n",
      "kldivergence:   1508.83\n",
      "variational_beta * kldivergence:  0.15088\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.49142\n",
      "kldivergence:   1606.41\n",
      "variational_beta * kldivergence:  0.16064\n",
      "batch accuracy: 85.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.39506\n",
      "kldivergence:   1534.45\n",
      "variational_beta * kldivergence:  0.15345\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.42228\n",
      "kldivergence:   1588.47\n",
      "variational_beta * kldivergence:  0.15885\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.45811\n",
      "kldivergence:   1665.64\n",
      "variational_beta * kldivergence:  0.16656\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.46185\n",
      "kldivergence:   1559.77\n",
      "variational_beta * kldivergence:  0.15598\n",
      "batch accuracy: 85.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.44652\n",
      "kldivergence:   1614.23\n",
      "variational_beta * kldivergence:  0.16142\n",
      "batch accuracy: 86.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.40848\n",
      "kldivergence:   1486.43\n",
      "variational_beta * kldivergence:  0.14864\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.48236\n",
      "kldivergence:   1704.86\n",
      "variational_beta * kldivergence:  0.17049\n",
      "batch accuracy: 84.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.49868\n",
      "kldivergence:   1594.61\n",
      "variational_beta * kldivergence:  0.15946\n",
      "batch accuracy: 85.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.41495\n",
      "kldivergence:   1507.84\n",
      "variational_beta * kldivergence:  0.15078\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.52763\n",
      "kldivergence:   1738.77\n",
      "variational_beta * kldivergence:  0.17388\n",
      "batch accuracy: 84.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.48047\n",
      "kldivergence:   1615.54\n",
      "variational_beta * kldivergence:  0.16155\n",
      "batch accuracy: 85.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.42952\n",
      "kldivergence:   1532.38\n",
      "variational_beta * kldivergence:  0.15324\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.39500\n",
      "kldivergence:   1525.60\n",
      "variational_beta * kldivergence:  0.15256\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.40022\n",
      "kldivergence:   1506.23\n",
      "variational_beta * kldivergence:  0.15062\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.42453\n",
      "kldivergence:   1568.73\n",
      "variational_beta * kldivergence:  0.15687\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.42543\n",
      "kldivergence:   1548.11\n",
      "variational_beta * kldivergence:  0.15481\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.43084\n",
      "kldivergence:   1640.23\n",
      "variational_beta * kldivergence:  0.16402\n",
      "batch accuracy: 86.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.49929\n",
      "kldivergence:   1635.88\n",
      "variational_beta * kldivergence:  0.16359\n",
      "batch accuracy: 84.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.56981\n",
      "kldivergence:   1744.43\n",
      "variational_beta * kldivergence:  0.17444\n",
      "batch accuracy: 82.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.35462\n",
      "kldivergence:   1415.10\n",
      "variational_beta * kldivergence:  0.14151\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.48361\n",
      "kldivergence:   1672.79\n",
      "variational_beta * kldivergence:  0.16728\n",
      "batch accuracy: 85.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.42126\n",
      "kldivergence:   1725.61\n",
      "variational_beta * kldivergence:  0.17256\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.47250\n",
      "kldivergence:   1726.33\n",
      "variational_beta * kldivergence:  0.17263\n",
      "batch accuracy: 85.82\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.47390\n",
      "kldivergence:   1653.53\n",
      "variational_beta * kldivergence:  0.16535\n",
      "batch accuracy: 85.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.51292\n",
      "kldivergence:   1650.21\n",
      "variational_beta * kldivergence:  0.16502\n",
      "batch accuracy: 83.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.47678\n",
      "kldivergence:   1679.58\n",
      "variational_beta * kldivergence:  0.16796\n",
      "batch accuracy: 85.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.53647\n",
      "kldivergence:   1658.67\n",
      "variational_beta * kldivergence:  0.16587\n",
      "batch accuracy: 84.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.47539\n",
      "kldivergence:   1588.42\n",
      "variational_beta * kldivergence:  0.15884\n",
      "batch accuracy: 85.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.43017\n",
      "kldivergence:   1706.78\n",
      "variational_beta * kldivergence:  0.17068\n",
      "batch accuracy: 85.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.49570\n",
      "kldivergence:   1674.36\n",
      "variational_beta * kldivergence:  0.16744\n",
      "batch accuracy: 85.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.46068\n",
      "kldivergence:   1627.91\n",
      "variational_beta * kldivergence:  0.16279\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.49524\n",
      "kldivergence:   1583.09\n",
      "variational_beta * kldivergence:  0.15831\n",
      "batch accuracy: 84.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.52608\n",
      "kldivergence:   1676.68\n",
      "variational_beta * kldivergence:  0.16767\n",
      "batch accuracy: 83.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.41712\n",
      "kldivergence:   1569.36\n",
      "variational_beta * kldivergence:  0.15694\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.48732\n",
      "kldivergence:   1564.05\n",
      "variational_beta * kldivergence:  0.15641\n",
      "batch accuracy: 85.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.51688\n",
      "kldivergence:   1692.33\n",
      "variational_beta * kldivergence:  0.16923\n",
      "batch accuracy: 84.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.44318\n",
      "kldivergence:   1549.72\n",
      "variational_beta * kldivergence:  0.15497\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.48742\n",
      "kldivergence:   1583.81\n",
      "variational_beta * kldivergence:  0.15838\n",
      "batch accuracy: 86.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.51090\n",
      "kldivergence:   1588.40\n",
      "variational_beta * kldivergence:  0.15884\n",
      "batch accuracy: 84.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #7\n",
      "reconstruction loss: 0.42856\n",
      "kldivergence:   1529.87\n",
      "variational_beta * kldivergence:  0.15299\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "epoch # 7 : train loss is [191.5770672500406] and validation loss is [0.10442878312987562] \n",
      "Epoch [8 / 150] average reconstruction error: 0.516380\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30569\n",
      "kldivergence:   1700.76\n",
      "variational_beta * kldivergence:  0.17008\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33861\n",
      "kldivergence:   1737.93\n",
      "variational_beta * kldivergence:  0.17379\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35508\n",
      "kldivergence:   1601.89\n",
      "variational_beta * kldivergence:  0.16019\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36686\n",
      "kldivergence:   1740.85\n",
      "variational_beta * kldivergence:  0.17409\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31403\n",
      "kldivergence:   1550.66\n",
      "variational_beta * kldivergence:  0.15507\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34682\n",
      "kldivergence:   1761.47\n",
      "variational_beta * kldivergence:  0.17615\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35245\n",
      "kldivergence:   1587.64\n",
      "variational_beta * kldivergence:  0.15876\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29935\n",
      "kldivergence:   1663.47\n",
      "variational_beta * kldivergence:  0.16635\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33574\n",
      "kldivergence:   1907.63\n",
      "variational_beta * kldivergence:  0.19076\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32322\n",
      "kldivergence:   1618.00\n",
      "variational_beta * kldivergence:  0.16180\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36666\n",
      "kldivergence:   1887.28\n",
      "variational_beta * kldivergence:  0.18873\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32637\n",
      "kldivergence:   1540.71\n",
      "variational_beta * kldivergence:  0.15407\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33522\n",
      "kldivergence:   1861.25\n",
      "variational_beta * kldivergence:  0.18612\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38824\n",
      "kldivergence:   1841.06\n",
      "variational_beta * kldivergence:  0.18411\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35739\n",
      "kldivergence:   1818.40\n",
      "variational_beta * kldivergence:  0.18184\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35558\n",
      "kldivergence:   1857.05\n",
      "variational_beta * kldivergence:  0.18571\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31154\n",
      "kldivergence:   1638.45\n",
      "variational_beta * kldivergence:  0.16384\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31760\n",
      "kldivergence:   1525.44\n",
      "variational_beta * kldivergence:  0.15254\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29452\n",
      "kldivergence:   1564.57\n",
      "variational_beta * kldivergence:  0.15646\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.27399\n",
      "kldivergence:   1683.98\n",
      "variational_beta * kldivergence:  0.16840\n",
      "batch accuracy: 90.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30309\n",
      "kldivergence:   1589.06\n",
      "variational_beta * kldivergence:  0.15891\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36455\n",
      "kldivergence:   1627.01\n",
      "variational_beta * kldivergence:  0.16270\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34189\n",
      "kldivergence:   1407.90\n",
      "variational_beta * kldivergence:  0.14079\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.28907\n",
      "kldivergence:   1672.70\n",
      "variational_beta * kldivergence:  0.16727\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29691\n",
      "kldivergence:   1624.06\n",
      "variational_beta * kldivergence:  0.16241\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34982\n",
      "kldivergence:   1747.34\n",
      "variational_beta * kldivergence:  0.17473\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34880\n",
      "kldivergence:   1952.80\n",
      "variational_beta * kldivergence:  0.19528\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34049\n",
      "kldivergence:   1613.02\n",
      "variational_beta * kldivergence:  0.16130\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39812\n",
      "kldivergence:   1927.83\n",
      "variational_beta * kldivergence:  0.19278\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34072\n",
      "kldivergence:   1590.32\n",
      "variational_beta * kldivergence:  0.15903\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34186\n",
      "kldivergence:   1965.25\n",
      "variational_beta * kldivergence:  0.19653\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32866\n",
      "kldivergence:   1569.62\n",
      "variational_beta * kldivergence:  0.15696\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35344\n",
      "kldivergence:   1878.54\n",
      "variational_beta * kldivergence:  0.18785\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30875\n",
      "kldivergence:   1492.50\n",
      "variational_beta * kldivergence:  0.14925\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37107\n",
      "kldivergence:   1749.80\n",
      "variational_beta * kldivergence:  0.17498\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38558\n",
      "kldivergence:   1655.38\n",
      "variational_beta * kldivergence:  0.16554\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33060\n",
      "kldivergence:   1774.93\n",
      "variational_beta * kldivergence:  0.17749\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35956\n",
      "kldivergence:   1683.16\n",
      "variational_beta * kldivergence:  0.16832\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36858\n",
      "kldivergence:   1714.25\n",
      "variational_beta * kldivergence:  0.17142\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30509\n",
      "kldivergence:   1422.02\n",
      "variational_beta * kldivergence:  0.14220\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.28010\n",
      "kldivergence:   1470.27\n",
      "variational_beta * kldivergence:  0.14703\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30509\n",
      "kldivergence:   1731.40\n",
      "variational_beta * kldivergence:  0.17314\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32183\n",
      "kldivergence:   2088.99\n",
      "variational_beta * kldivergence:  0.20890\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34456\n",
      "kldivergence:   1691.81\n",
      "variational_beta * kldivergence:  0.16918\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39765\n",
      "kldivergence:   1869.00\n",
      "variational_beta * kldivergence:  0.18690\n",
      "batch accuracy: 86.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32472\n",
      "kldivergence:   1773.47\n",
      "variational_beta * kldivergence:  0.17735\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32280\n",
      "kldivergence:   1476.20\n",
      "variational_beta * kldivergence:  0.14762\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34937\n",
      "kldivergence:   1906.79\n",
      "variational_beta * kldivergence:  0.19068\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35692\n",
      "kldivergence:   1846.37\n",
      "variational_beta * kldivergence:  0.18464\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34434\n",
      "kldivergence:   1913.21\n",
      "variational_beta * kldivergence:  0.19132\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33481\n",
      "kldivergence:   1631.57\n",
      "variational_beta * kldivergence:  0.16316\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37960\n",
      "kldivergence:   1907.44\n",
      "variational_beta * kldivergence:  0.19074\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39358\n",
      "kldivergence:   1779.99\n",
      "variational_beta * kldivergence:  0.17800\n",
      "batch accuracy: 86.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32853\n",
      "kldivergence:   1872.34\n",
      "variational_beta * kldivergence:  0.18723\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29940\n",
      "kldivergence:   1800.50\n",
      "variational_beta * kldivergence:  0.18005\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29487\n",
      "kldivergence:   1804.63\n",
      "variational_beta * kldivergence:  0.18046\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37236\n",
      "kldivergence:   1904.94\n",
      "variational_beta * kldivergence:  0.19049\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34610\n",
      "kldivergence:   1578.07\n",
      "variational_beta * kldivergence:  0.15781\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35001\n",
      "kldivergence:   1841.06\n",
      "variational_beta * kldivergence:  0.18411\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38371\n",
      "kldivergence:   1931.48\n",
      "variational_beta * kldivergence:  0.19315\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34339\n",
      "kldivergence:   1727.41\n",
      "variational_beta * kldivergence:  0.17274\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32542\n",
      "kldivergence:   1643.47\n",
      "variational_beta * kldivergence:  0.16435\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35847\n",
      "kldivergence:   1606.56\n",
      "variational_beta * kldivergence:  0.16066\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29930\n",
      "kldivergence:   1632.05\n",
      "variational_beta * kldivergence:  0.16320\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37650\n",
      "kldivergence:   2038.19\n",
      "variational_beta * kldivergence:  0.20382\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36740\n",
      "kldivergence:   1917.89\n",
      "variational_beta * kldivergence:  0.19179\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31775\n",
      "kldivergence:   1709.80\n",
      "variational_beta * kldivergence:  0.17098\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36177\n",
      "kldivergence:   1848.72\n",
      "variational_beta * kldivergence:  0.18487\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30897\n",
      "kldivergence:   1664.54\n",
      "variational_beta * kldivergence:  0.16645\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33956\n",
      "kldivergence:   1696.71\n",
      "variational_beta * kldivergence:  0.16967\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33395\n",
      "kldivergence:   1946.58\n",
      "variational_beta * kldivergence:  0.19466\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39954\n",
      "kldivergence:   1700.21\n",
      "variational_beta * kldivergence:  0.17002\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33662\n",
      "kldivergence:   1777.89\n",
      "variational_beta * kldivergence:  0.17779\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39320\n",
      "kldivergence:   1587.61\n",
      "variational_beta * kldivergence:  0.15876\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31165\n",
      "kldivergence:   1513.89\n",
      "variational_beta * kldivergence:  0.15139\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31996\n",
      "kldivergence:   1806.91\n",
      "variational_beta * kldivergence:  0.18069\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29673\n",
      "kldivergence:   1540.09\n",
      "variational_beta * kldivergence:  0.15401\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.40432\n",
      "kldivergence:   1670.11\n",
      "variational_beta * kldivergence:  0.16701\n",
      "batch accuracy: 86.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38002\n",
      "kldivergence:   1702.53\n",
      "variational_beta * kldivergence:  0.17025\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38461\n",
      "kldivergence:   1726.66\n",
      "variational_beta * kldivergence:  0.17267\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32862\n",
      "kldivergence:   1771.00\n",
      "variational_beta * kldivergence:  0.17710\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38064\n",
      "kldivergence:   1749.04\n",
      "variational_beta * kldivergence:  0.17490\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34551\n",
      "kldivergence:   1659.96\n",
      "variational_beta * kldivergence:  0.16600\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36997\n",
      "kldivergence:   1782.52\n",
      "variational_beta * kldivergence:  0.17825\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32806\n",
      "kldivergence:   1721.49\n",
      "variational_beta * kldivergence:  0.17215\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29489\n",
      "kldivergence:   1743.90\n",
      "variational_beta * kldivergence:  0.17439\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30212\n",
      "kldivergence:   1475.56\n",
      "variational_beta * kldivergence:  0.14756\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35371\n",
      "kldivergence:   1688.50\n",
      "variational_beta * kldivergence:  0.16885\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35876\n",
      "kldivergence:   1796.48\n",
      "variational_beta * kldivergence:  0.17965\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29502\n",
      "kldivergence:   1631.76\n",
      "variational_beta * kldivergence:  0.16318\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30781\n",
      "kldivergence:   1755.93\n",
      "variational_beta * kldivergence:  0.17559\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30241\n",
      "kldivergence:   1738.60\n",
      "variational_beta * kldivergence:  0.17386\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.40220\n",
      "kldivergence:   1913.28\n",
      "variational_beta * kldivergence:  0.19133\n",
      "batch accuracy: 86.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35906\n",
      "kldivergence:   1759.38\n",
      "variational_beta * kldivergence:  0.17594\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30965\n",
      "kldivergence:   1744.47\n",
      "variational_beta * kldivergence:  0.17445\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31786\n",
      "kldivergence:   1976.76\n",
      "variational_beta * kldivergence:  0.19768\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39675\n",
      "kldivergence:   1761.66\n",
      "variational_beta * kldivergence:  0.17617\n",
      "batch accuracy: 86.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31956\n",
      "kldivergence:   1773.50\n",
      "variational_beta * kldivergence:  0.17735\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29770\n",
      "kldivergence:   1825.22\n",
      "variational_beta * kldivergence:  0.18252\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36736\n",
      "kldivergence:   1835.19\n",
      "variational_beta * kldivergence:  0.18352\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31992\n",
      "kldivergence:   1778.44\n",
      "variational_beta * kldivergence:  0.17784\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30785\n",
      "kldivergence:   1531.40\n",
      "variational_beta * kldivergence:  0.15314\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32375\n",
      "kldivergence:   1699.02\n",
      "variational_beta * kldivergence:  0.16990\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34628\n",
      "kldivergence:   1722.27\n",
      "variational_beta * kldivergence:  0.17223\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37122\n",
      "kldivergence:   1719.55\n",
      "variational_beta * kldivergence:  0.17195\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29264\n",
      "kldivergence:   1762.51\n",
      "variational_beta * kldivergence:  0.17625\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34056\n",
      "kldivergence:   1706.26\n",
      "variational_beta * kldivergence:  0.17063\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37463\n",
      "kldivergence:   1729.14\n",
      "variational_beta * kldivergence:  0.17291\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32413\n",
      "kldivergence:   1647.11\n",
      "variational_beta * kldivergence:  0.16471\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33068\n",
      "kldivergence:   1593.53\n",
      "variational_beta * kldivergence:  0.15935\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32771\n",
      "kldivergence:   1764.73\n",
      "variational_beta * kldivergence:  0.17647\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38503\n",
      "kldivergence:   1748.51\n",
      "variational_beta * kldivergence:  0.17485\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37503\n",
      "kldivergence:   2030.45\n",
      "variational_beta * kldivergence:  0.20304\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35022\n",
      "kldivergence:   1629.03\n",
      "variational_beta * kldivergence:  0.16290\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33929\n",
      "kldivergence:   1889.45\n",
      "variational_beta * kldivergence:  0.18894\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32193\n",
      "kldivergence:   1513.09\n",
      "variational_beta * kldivergence:  0.15131\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30358\n",
      "kldivergence:   1726.02\n",
      "variational_beta * kldivergence:  0.17260\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31588\n",
      "kldivergence:   1849.06\n",
      "variational_beta * kldivergence:  0.18491\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34016\n",
      "kldivergence:   1596.66\n",
      "variational_beta * kldivergence:  0.15967\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30340\n",
      "kldivergence:   1637.93\n",
      "variational_beta * kldivergence:  0.16379\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31705\n",
      "kldivergence:   1544.98\n",
      "variational_beta * kldivergence:  0.15450\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33817\n",
      "kldivergence:   1723.55\n",
      "variational_beta * kldivergence:  0.17235\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34437\n",
      "kldivergence:   1836.10\n",
      "variational_beta * kldivergence:  0.18361\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38233\n",
      "kldivergence:   1747.30\n",
      "variational_beta * kldivergence:  0.17473\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.28283\n",
      "kldivergence:   1524.21\n",
      "variational_beta * kldivergence:  0.15242\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.40591\n",
      "kldivergence:   1940.87\n",
      "variational_beta * kldivergence:  0.19409\n",
      "batch accuracy: 86.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30567\n",
      "kldivergence:   1692.40\n",
      "variational_beta * kldivergence:  0.16924\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.27859\n",
      "kldivergence:   1480.17\n",
      "variational_beta * kldivergence:  0.14802\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35179\n",
      "kldivergence:   1776.98\n",
      "variational_beta * kldivergence:  0.17770\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33044\n",
      "kldivergence:   1862.42\n",
      "variational_beta * kldivergence:  0.18624\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31671\n",
      "kldivergence:   1781.09\n",
      "variational_beta * kldivergence:  0.17811\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33486\n",
      "kldivergence:   1754.73\n",
      "variational_beta * kldivergence:  0.17547\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35198\n",
      "kldivergence:   1854.49\n",
      "variational_beta * kldivergence:  0.18545\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32428\n",
      "kldivergence:   1524.84\n",
      "variational_beta * kldivergence:  0.15248\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33405\n",
      "kldivergence:   1798.19\n",
      "variational_beta * kldivergence:  0.17982\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29585\n",
      "kldivergence:   1585.28\n",
      "variational_beta * kldivergence:  0.15853\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34477\n",
      "kldivergence:   1684.49\n",
      "variational_beta * kldivergence:  0.16845\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31420\n",
      "kldivergence:   1830.17\n",
      "variational_beta * kldivergence:  0.18302\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33491\n",
      "kldivergence:   1529.73\n",
      "variational_beta * kldivergence:  0.15297\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34731\n",
      "kldivergence:   1529.58\n",
      "variational_beta * kldivergence:  0.15296\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33592\n",
      "kldivergence:   1743.76\n",
      "variational_beta * kldivergence:  0.17438\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35524\n",
      "kldivergence:   2014.89\n",
      "variational_beta * kldivergence:  0.20149\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32250\n",
      "kldivergence:   1454.18\n",
      "variational_beta * kldivergence:  0.14542\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31936\n",
      "kldivergence:   1838.08\n",
      "variational_beta * kldivergence:  0.18381\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33944\n",
      "kldivergence:   1599.93\n",
      "variational_beta * kldivergence:  0.15999\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38075\n",
      "kldivergence:   1944.92\n",
      "variational_beta * kldivergence:  0.19449\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35188\n",
      "kldivergence:   2145.87\n",
      "variational_beta * kldivergence:  0.21459\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36038\n",
      "kldivergence:   1762.58\n",
      "variational_beta * kldivergence:  0.17626\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36764\n",
      "kldivergence:   1757.91\n",
      "variational_beta * kldivergence:  0.17579\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39341\n",
      "kldivergence:   1787.44\n",
      "variational_beta * kldivergence:  0.17874\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32625\n",
      "kldivergence:   1555.46\n",
      "variational_beta * kldivergence:  0.15555\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.40736\n",
      "kldivergence:   1850.81\n",
      "variational_beta * kldivergence:  0.18508\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39915\n",
      "kldivergence:   2147.14\n",
      "variational_beta * kldivergence:  0.21471\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29957\n",
      "kldivergence:   1615.67\n",
      "variational_beta * kldivergence:  0.16157\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36312\n",
      "kldivergence:   1525.52\n",
      "variational_beta * kldivergence:  0.15255\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36122\n",
      "kldivergence:   1719.82\n",
      "variational_beta * kldivergence:  0.17198\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.41369\n",
      "kldivergence:   1820.45\n",
      "variational_beta * kldivergence:  0.18205\n",
      "batch accuracy: 86.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33254\n",
      "kldivergence:   1742.62\n",
      "variational_beta * kldivergence:  0.17426\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35154\n",
      "kldivergence:   1942.26\n",
      "variational_beta * kldivergence:  0.19423\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.27954\n",
      "kldivergence:   1545.29\n",
      "variational_beta * kldivergence:  0.15453\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34580\n",
      "kldivergence:   1633.37\n",
      "variational_beta * kldivergence:  0.16334\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37950\n",
      "kldivergence:   1751.82\n",
      "variational_beta * kldivergence:  0.17518\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34960\n",
      "kldivergence:   1722.49\n",
      "variational_beta * kldivergence:  0.17225\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36024\n",
      "kldivergence:   1744.27\n",
      "variational_beta * kldivergence:  0.17443\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37819\n",
      "kldivergence:   1768.55\n",
      "variational_beta * kldivergence:  0.17685\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.28290\n",
      "kldivergence:   1642.34\n",
      "variational_beta * kldivergence:  0.16423\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29685\n",
      "kldivergence:   1956.74\n",
      "variational_beta * kldivergence:  0.19567\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32096\n",
      "kldivergence:   1785.73\n",
      "variational_beta * kldivergence:  0.17857\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34099\n",
      "kldivergence:   1578.92\n",
      "variational_beta * kldivergence:  0.15789\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36766\n",
      "kldivergence:   1827.32\n",
      "variational_beta * kldivergence:  0.18273\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32665\n",
      "kldivergence:   1646.78\n",
      "variational_beta * kldivergence:  0.16468\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29473\n",
      "kldivergence:   2031.20\n",
      "variational_beta * kldivergence:  0.20312\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31780\n",
      "kldivergence:   1467.82\n",
      "variational_beta * kldivergence:  0.14678\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31443\n",
      "kldivergence:   1693.61\n",
      "variational_beta * kldivergence:  0.16936\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33067\n",
      "kldivergence:   1738.00\n",
      "variational_beta * kldivergence:  0.17380\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33465\n",
      "kldivergence:   1681.10\n",
      "variational_beta * kldivergence:  0.16811\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34101\n",
      "kldivergence:   1780.79\n",
      "variational_beta * kldivergence:  0.17808\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36957\n",
      "kldivergence:   2002.61\n",
      "variational_beta * kldivergence:  0.20026\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32877\n",
      "kldivergence:   1585.19\n",
      "variational_beta * kldivergence:  0.15852\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34922\n",
      "kldivergence:   1721.71\n",
      "variational_beta * kldivergence:  0.17217\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34006\n",
      "kldivergence:   1734.63\n",
      "variational_beta * kldivergence:  0.17346\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31500\n",
      "kldivergence:   1785.64\n",
      "variational_beta * kldivergence:  0.17856\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33027\n",
      "kldivergence:   2129.00\n",
      "variational_beta * kldivergence:  0.21290\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33862\n",
      "kldivergence:   2044.15\n",
      "variational_beta * kldivergence:  0.20441\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33060\n",
      "kldivergence:   1691.40\n",
      "variational_beta * kldivergence:  0.16914\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36147\n",
      "kldivergence:   1636.93\n",
      "variational_beta * kldivergence:  0.16369\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35931\n",
      "kldivergence:   1571.84\n",
      "variational_beta * kldivergence:  0.15718\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36897\n",
      "kldivergence:   1808.63\n",
      "variational_beta * kldivergence:  0.18086\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31829\n",
      "kldivergence:   1628.36\n",
      "variational_beta * kldivergence:  0.16284\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33278\n",
      "kldivergence:   1655.17\n",
      "variational_beta * kldivergence:  0.16552\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33964\n",
      "kldivergence:   1913.59\n",
      "variational_beta * kldivergence:  0.19136\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34360\n",
      "kldivergence:   1570.93\n",
      "variational_beta * kldivergence:  0.15709\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35232\n",
      "kldivergence:   1653.83\n",
      "variational_beta * kldivergence:  0.16538\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31258\n",
      "kldivergence:   1648.46\n",
      "variational_beta * kldivergence:  0.16485\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35391\n",
      "kldivergence:   1618.55\n",
      "variational_beta * kldivergence:  0.16186\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33686\n",
      "kldivergence:   1876.83\n",
      "variational_beta * kldivergence:  0.18768\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34078\n",
      "kldivergence:   1552.23\n",
      "variational_beta * kldivergence:  0.15522\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29253\n",
      "kldivergence:   1483.07\n",
      "variational_beta * kldivergence:  0.14831\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33743\n",
      "kldivergence:   1645.83\n",
      "variational_beta * kldivergence:  0.16458\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.28197\n",
      "kldivergence:   1608.98\n",
      "variational_beta * kldivergence:  0.16090\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35233\n",
      "kldivergence:   1725.41\n",
      "variational_beta * kldivergence:  0.17254\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30776\n",
      "kldivergence:   1641.40\n",
      "variational_beta * kldivergence:  0.16414\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35200\n",
      "kldivergence:   1702.75\n",
      "variational_beta * kldivergence:  0.17027\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37752\n",
      "kldivergence:   1815.65\n",
      "variational_beta * kldivergence:  0.18156\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35840\n",
      "kldivergence:   1732.35\n",
      "variational_beta * kldivergence:  0.17324\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34529\n",
      "kldivergence:   1678.58\n",
      "variational_beta * kldivergence:  0.16786\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33043\n",
      "kldivergence:   1612.37\n",
      "variational_beta * kldivergence:  0.16124\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35300\n",
      "kldivergence:   1810.90\n",
      "variational_beta * kldivergence:  0.18109\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31567\n",
      "kldivergence:   1950.52\n",
      "variational_beta * kldivergence:  0.19505\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32540\n",
      "kldivergence:   1790.73\n",
      "variational_beta * kldivergence:  0.17907\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34961\n",
      "kldivergence:   1783.68\n",
      "variational_beta * kldivergence:  0.17837\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34499\n",
      "kldivergence:   1818.07\n",
      "variational_beta * kldivergence:  0.18181\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37066\n",
      "kldivergence:   1868.08\n",
      "variational_beta * kldivergence:  0.18681\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33290\n",
      "kldivergence:   1998.74\n",
      "variational_beta * kldivergence:  0.19987\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31432\n",
      "kldivergence:   1707.17\n",
      "variational_beta * kldivergence:  0.17072\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31908\n",
      "kldivergence:   1815.78\n",
      "variational_beta * kldivergence:  0.18158\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35871\n",
      "kldivergence:   1941.85\n",
      "variational_beta * kldivergence:  0.19418\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34405\n",
      "kldivergence:   1911.32\n",
      "variational_beta * kldivergence:  0.19113\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34816\n",
      "kldivergence:   1768.61\n",
      "variational_beta * kldivergence:  0.17686\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29764\n",
      "kldivergence:   2182.42\n",
      "variational_beta * kldivergence:  0.21824\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.27649\n",
      "kldivergence:   1641.92\n",
      "variational_beta * kldivergence:  0.16419\n",
      "batch accuracy: 90.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.40493\n",
      "kldivergence:   1869.60\n",
      "variational_beta * kldivergence:  0.18696\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34506\n",
      "kldivergence:   1833.49\n",
      "variational_beta * kldivergence:  0.18335\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36162\n",
      "kldivergence:   1990.87\n",
      "variational_beta * kldivergence:  0.19909\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33787\n",
      "kldivergence:   1718.26\n",
      "variational_beta * kldivergence:  0.17183\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36984\n",
      "kldivergence:   1880.96\n",
      "variational_beta * kldivergence:  0.18810\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31722\n",
      "kldivergence:   1504.80\n",
      "variational_beta * kldivergence:  0.15048\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34706\n",
      "kldivergence:   1622.48\n",
      "variational_beta * kldivergence:  0.16225\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32334\n",
      "kldivergence:   1731.93\n",
      "variational_beta * kldivergence:  0.17319\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35895\n",
      "kldivergence:   1865.51\n",
      "variational_beta * kldivergence:  0.18655\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38901\n",
      "kldivergence:   1867.50\n",
      "variational_beta * kldivergence:  0.18675\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32054\n",
      "kldivergence:   1914.51\n",
      "variational_beta * kldivergence:  0.19145\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32482\n",
      "kldivergence:   1737.58\n",
      "variational_beta * kldivergence:  0.17376\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33815\n",
      "kldivergence:   1627.94\n",
      "variational_beta * kldivergence:  0.16279\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33860\n",
      "kldivergence:   1726.76\n",
      "variational_beta * kldivergence:  0.17268\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35292\n",
      "kldivergence:   1670.39\n",
      "variational_beta * kldivergence:  0.16704\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34131\n",
      "kldivergence:   1893.61\n",
      "variational_beta * kldivergence:  0.18936\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32139\n",
      "kldivergence:   1602.44\n",
      "variational_beta * kldivergence:  0.16024\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33735\n",
      "kldivergence:   1684.33\n",
      "variational_beta * kldivergence:  0.16843\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34529\n",
      "kldivergence:   1523.86\n",
      "variational_beta * kldivergence:  0.15239\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38710\n",
      "kldivergence:   1673.62\n",
      "variational_beta * kldivergence:  0.16736\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33440\n",
      "kldivergence:   1669.20\n",
      "variational_beta * kldivergence:  0.16692\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33067\n",
      "kldivergence:   1865.91\n",
      "variational_beta * kldivergence:  0.18659\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36360\n",
      "kldivergence:   1715.94\n",
      "variational_beta * kldivergence:  0.17159\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31555\n",
      "kldivergence:   2453.45\n",
      "variational_beta * kldivergence:  0.24534\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32752\n",
      "kldivergence:   2079.64\n",
      "variational_beta * kldivergence:  0.20796\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30753\n",
      "kldivergence:   1525.83\n",
      "variational_beta * kldivergence:  0.15258\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37527\n",
      "kldivergence:   1674.92\n",
      "variational_beta * kldivergence:  0.16749\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34560\n",
      "kldivergence:   1794.49\n",
      "variational_beta * kldivergence:  0.17945\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33380\n",
      "kldivergence:   1857.02\n",
      "variational_beta * kldivergence:  0.18570\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35555\n",
      "kldivergence:   1761.06\n",
      "variational_beta * kldivergence:  0.17611\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33200\n",
      "kldivergence:   1850.76\n",
      "variational_beta * kldivergence:  0.18508\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.28801\n",
      "kldivergence:   1541.89\n",
      "variational_beta * kldivergence:  0.15419\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37486\n",
      "kldivergence:   1841.75\n",
      "variational_beta * kldivergence:  0.18418\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36266\n",
      "kldivergence:   1761.94\n",
      "variational_beta * kldivergence:  0.17619\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33629\n",
      "kldivergence:   1691.72\n",
      "variational_beta * kldivergence:  0.16917\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35645\n",
      "kldivergence:   1842.61\n",
      "variational_beta * kldivergence:  0.18426\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.27938\n",
      "kldivergence:   1778.07\n",
      "variational_beta * kldivergence:  0.17781\n",
      "batch accuracy: 90.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32422\n",
      "kldivergence:   1681.74\n",
      "variational_beta * kldivergence:  0.16817\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39845\n",
      "kldivergence:   1884.15\n",
      "variational_beta * kldivergence:  0.18841\n",
      "batch accuracy: 86.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38413\n",
      "kldivergence:   1795.86\n",
      "variational_beta * kldivergence:  0.17959\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33209\n",
      "kldivergence:   1745.63\n",
      "variational_beta * kldivergence:  0.17456\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36259\n",
      "kldivergence:   1556.56\n",
      "variational_beta * kldivergence:  0.15566\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.26200\n",
      "kldivergence:   1487.33\n",
      "variational_beta * kldivergence:  0.14873\n",
      "batch accuracy: 91.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35813\n",
      "kldivergence:   1611.43\n",
      "variational_beta * kldivergence:  0.16114\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30455\n",
      "kldivergence:   1600.56\n",
      "variational_beta * kldivergence:  0.16006\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36253\n",
      "kldivergence:   1602.10\n",
      "variational_beta * kldivergence:  0.16021\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34110\n",
      "kldivergence:   1621.02\n",
      "variational_beta * kldivergence:  0.16210\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36733\n",
      "kldivergence:   1616.22\n",
      "variational_beta * kldivergence:  0.16162\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34961\n",
      "kldivergence:   1733.49\n",
      "variational_beta * kldivergence:  0.17335\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33764\n",
      "kldivergence:   1614.26\n",
      "variational_beta * kldivergence:  0.16143\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31467\n",
      "kldivergence:   1622.18\n",
      "variational_beta * kldivergence:  0.16222\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37619\n",
      "kldivergence:   1760.02\n",
      "variational_beta * kldivergence:  0.17600\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30714\n",
      "kldivergence:   1590.53\n",
      "variational_beta * kldivergence:  0.15905\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30960\n",
      "kldivergence:   1559.02\n",
      "variational_beta * kldivergence:  0.15590\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30765\n",
      "kldivergence:   1629.53\n",
      "variational_beta * kldivergence:  0.16295\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.27314\n",
      "kldivergence:   1626.88\n",
      "variational_beta * kldivergence:  0.16269\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.40220\n",
      "kldivergence:   2089.99\n",
      "variational_beta * kldivergence:  0.20900\n",
      "batch accuracy: 86.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36360\n",
      "kldivergence:   1764.15\n",
      "variational_beta * kldivergence:  0.17642\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33589\n",
      "kldivergence:   1648.44\n",
      "variational_beta * kldivergence:  0.16484\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38397\n",
      "kldivergence:   1640.35\n",
      "variational_beta * kldivergence:  0.16404\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37927\n",
      "kldivergence:   1623.07\n",
      "variational_beta * kldivergence:  0.16231\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35378\n",
      "kldivergence:   1726.56\n",
      "variational_beta * kldivergence:  0.17266\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33567\n",
      "kldivergence:   1451.58\n",
      "variational_beta * kldivergence:  0.14516\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36630\n",
      "kldivergence:   1706.16\n",
      "variational_beta * kldivergence:  0.17062\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33512\n",
      "kldivergence:   1602.49\n",
      "variational_beta * kldivergence:  0.16025\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33858\n",
      "kldivergence:   1721.71\n",
      "variational_beta * kldivergence:  0.17217\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33747\n",
      "kldivergence:   1628.52\n",
      "variational_beta * kldivergence:  0.16285\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33417\n",
      "kldivergence:   1729.32\n",
      "variational_beta * kldivergence:  0.17293\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32826\n",
      "kldivergence:   1658.91\n",
      "variational_beta * kldivergence:  0.16589\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31701\n",
      "kldivergence:   1629.97\n",
      "variational_beta * kldivergence:  0.16300\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36109\n",
      "kldivergence:   1805.87\n",
      "variational_beta * kldivergence:  0.18059\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32479\n",
      "kldivergence:   1843.35\n",
      "variational_beta * kldivergence:  0.18433\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32400\n",
      "kldivergence:   1814.62\n",
      "variational_beta * kldivergence:  0.18146\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32468\n",
      "kldivergence:   2304.07\n",
      "variational_beta * kldivergence:  0.23041\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38005\n",
      "kldivergence:   1808.74\n",
      "variational_beta * kldivergence:  0.18087\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31948\n",
      "kldivergence:   1759.66\n",
      "variational_beta * kldivergence:  0.17597\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36151\n",
      "kldivergence:   2063.30\n",
      "variational_beta * kldivergence:  0.20633\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37852\n",
      "kldivergence:   1948.41\n",
      "variational_beta * kldivergence:  0.19484\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32752\n",
      "kldivergence:   1719.09\n",
      "variational_beta * kldivergence:  0.17191\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30891\n",
      "kldivergence:   1629.79\n",
      "variational_beta * kldivergence:  0.16298\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32708\n",
      "kldivergence:   1643.08\n",
      "variational_beta * kldivergence:  0.16431\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34852\n",
      "kldivergence:   1912.66\n",
      "variational_beta * kldivergence:  0.19127\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35199\n",
      "kldivergence:   1670.98\n",
      "variational_beta * kldivergence:  0.16710\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32663\n",
      "kldivergence:   1882.87\n",
      "variational_beta * kldivergence:  0.18829\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35171\n",
      "kldivergence:   1617.03\n",
      "variational_beta * kldivergence:  0.16170\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30416\n",
      "kldivergence:   1610.93\n",
      "variational_beta * kldivergence:  0.16109\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37559\n",
      "kldivergence:   1628.60\n",
      "variational_beta * kldivergence:  0.16286\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31369\n",
      "kldivergence:   1615.86\n",
      "variational_beta * kldivergence:  0.16159\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.42764\n",
      "kldivergence:   1765.47\n",
      "variational_beta * kldivergence:  0.17655\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39174\n",
      "kldivergence:   1647.77\n",
      "variational_beta * kldivergence:  0.16478\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36171\n",
      "kldivergence:   1569.27\n",
      "variational_beta * kldivergence:  0.15693\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35074\n",
      "kldivergence:   1485.16\n",
      "variational_beta * kldivergence:  0.14852\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34533\n",
      "kldivergence:   1911.29\n",
      "variational_beta * kldivergence:  0.19113\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32658\n",
      "kldivergence:   1588.58\n",
      "variational_beta * kldivergence:  0.15886\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31257\n",
      "kldivergence:   1528.09\n",
      "variational_beta * kldivergence:  0.15281\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31273\n",
      "kldivergence:   1610.92\n",
      "variational_beta * kldivergence:  0.16109\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31434\n",
      "kldivergence:   1572.91\n",
      "variational_beta * kldivergence:  0.15729\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35556\n",
      "kldivergence:   1802.45\n",
      "variational_beta * kldivergence:  0.18025\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35827\n",
      "kldivergence:   1955.50\n",
      "variational_beta * kldivergence:  0.19555\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29660\n",
      "kldivergence:   1790.52\n",
      "variational_beta * kldivergence:  0.17905\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38188\n",
      "kldivergence:   1843.35\n",
      "variational_beta * kldivergence:  0.18434\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31243\n",
      "kldivergence:   2099.89\n",
      "variational_beta * kldivergence:  0.20999\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36270\n",
      "kldivergence:   1735.89\n",
      "variational_beta * kldivergence:  0.17359\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33348\n",
      "kldivergence:   1747.85\n",
      "variational_beta * kldivergence:  0.17478\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36608\n",
      "kldivergence:   1945.01\n",
      "variational_beta * kldivergence:  0.19450\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33986\n",
      "kldivergence:   1940.98\n",
      "variational_beta * kldivergence:  0.19410\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32773\n",
      "kldivergence:   1874.61\n",
      "variational_beta * kldivergence:  0.18746\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38957\n",
      "kldivergence:   1778.99\n",
      "variational_beta * kldivergence:  0.17790\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37143\n",
      "kldivergence:   1981.95\n",
      "variational_beta * kldivergence:  0.19819\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33449\n",
      "kldivergence:   1762.96\n",
      "variational_beta * kldivergence:  0.17630\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30933\n",
      "kldivergence:   1630.80\n",
      "variational_beta * kldivergence:  0.16308\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36226\n",
      "kldivergence:   1761.10\n",
      "variational_beta * kldivergence:  0.17611\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35054\n",
      "kldivergence:   1864.70\n",
      "variational_beta * kldivergence:  0.18647\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37064\n",
      "kldivergence:   1856.57\n",
      "variational_beta * kldivergence:  0.18566\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34307\n",
      "kldivergence:   1788.60\n",
      "variational_beta * kldivergence:  0.17886\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34360\n",
      "kldivergence:   1687.78\n",
      "variational_beta * kldivergence:  0.16878\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33016\n",
      "kldivergence:   1819.98\n",
      "variational_beta * kldivergence:  0.18200\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39650\n",
      "kldivergence:   1822.59\n",
      "variational_beta * kldivergence:  0.18226\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31029\n",
      "kldivergence:   1656.16\n",
      "variational_beta * kldivergence:  0.16562\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34934\n",
      "kldivergence:   1711.75\n",
      "variational_beta * kldivergence:  0.17117\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31228\n",
      "kldivergence:   1647.99\n",
      "variational_beta * kldivergence:  0.16480\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34406\n",
      "kldivergence:   1775.75\n",
      "variational_beta * kldivergence:  0.17757\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33443\n",
      "kldivergence:   1517.48\n",
      "variational_beta * kldivergence:  0.15175\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33987\n",
      "kldivergence:   1614.67\n",
      "variational_beta * kldivergence:  0.16147\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.29029\n",
      "kldivergence:   1692.08\n",
      "variational_beta * kldivergence:  0.16921\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31106\n",
      "kldivergence:   1753.92\n",
      "variational_beta * kldivergence:  0.17539\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30651\n",
      "kldivergence:   1586.67\n",
      "variational_beta * kldivergence:  0.15867\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34737\n",
      "kldivergence:   1586.61\n",
      "variational_beta * kldivergence:  0.15866\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32848\n",
      "kldivergence:   1887.20\n",
      "variational_beta * kldivergence:  0.18872\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35323\n",
      "kldivergence:   1679.93\n",
      "variational_beta * kldivergence:  0.16799\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34330\n",
      "kldivergence:   1598.01\n",
      "variational_beta * kldivergence:  0.15980\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37517\n",
      "kldivergence:   1830.44\n",
      "variational_beta * kldivergence:  0.18304\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.31983\n",
      "kldivergence:   1455.95\n",
      "variational_beta * kldivergence:  0.14559\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32793\n",
      "kldivergence:   1640.30\n",
      "variational_beta * kldivergence:  0.16403\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34944\n",
      "kldivergence:   1817.99\n",
      "variational_beta * kldivergence:  0.18180\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30725\n",
      "kldivergence:   1861.17\n",
      "variational_beta * kldivergence:  0.18612\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32603\n",
      "kldivergence:   1571.60\n",
      "variational_beta * kldivergence:  0.15716\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.36264\n",
      "kldivergence:   2209.97\n",
      "variational_beta * kldivergence:  0.22100\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.37224\n",
      "kldivergence:   1910.71\n",
      "variational_beta * kldivergence:  0.19107\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.30840\n",
      "kldivergence:   1581.03\n",
      "variational_beta * kldivergence:  0.15810\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35015\n",
      "kldivergence:   1884.67\n",
      "variational_beta * kldivergence:  0.18847\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.39058\n",
      "kldivergence:   1797.45\n",
      "variational_beta * kldivergence:  0.17974\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32923\n",
      "kldivergence:   1663.82\n",
      "variational_beta * kldivergence:  0.16638\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38144\n",
      "kldivergence:   1774.67\n",
      "variational_beta * kldivergence:  0.17747\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.35042\n",
      "kldivergence:   1641.26\n",
      "variational_beta * kldivergence:  0.16413\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33073\n",
      "kldivergence:   1617.98\n",
      "variational_beta * kldivergence:  0.16180\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.38238\n",
      "kldivergence:   1674.91\n",
      "variational_beta * kldivergence:  0.16749\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.34399\n",
      "kldivergence:   1515.21\n",
      "variational_beta * kldivergence:  0.15152\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.33286\n",
      "kldivergence:   1525.80\n",
      "variational_beta * kldivergence:  0.15258\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #8\n",
      "reconstruction loss: 0.32797\n",
      "kldivergence:   1735.90\n",
      "variational_beta * kldivergence:  0.17359\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.39955\n",
      "kldivergence:   1549.55\n",
      "variational_beta * kldivergence:  0.15496\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.36077\n",
      "kldivergence:   1482.56\n",
      "variational_beta * kldivergence:  0.14826\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.39528\n",
      "kldivergence:   1573.66\n",
      "variational_beta * kldivergence:  0.15737\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.48614\n",
      "kldivergence:   1626.25\n",
      "variational_beta * kldivergence:  0.16263\n",
      "batch accuracy: 84.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.46376\n",
      "kldivergence:   1571.71\n",
      "variational_beta * kldivergence:  0.15717\n",
      "batch accuracy: 85.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.55104\n",
      "kldivergence:   1686.02\n",
      "variational_beta * kldivergence:  0.16860\n",
      "batch accuracy: 83.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.45226\n",
      "kldivergence:   1575.45\n",
      "variational_beta * kldivergence:  0.15754\n",
      "batch accuracy: 86.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.47836\n",
      "kldivergence:   1681.01\n",
      "variational_beta * kldivergence:  0.16810\n",
      "batch accuracy: 85.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.51635\n",
      "kldivergence:   1632.20\n",
      "variational_beta * kldivergence:  0.16322\n",
      "batch accuracy: 84.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.44427\n",
      "kldivergence:   1606.00\n",
      "variational_beta * kldivergence:  0.16060\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.41225\n",
      "kldivergence:   1612.16\n",
      "variational_beta * kldivergence:  0.16122\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.41704\n",
      "kldivergence:   1575.07\n",
      "variational_beta * kldivergence:  0.15751\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.48200\n",
      "kldivergence:   1687.44\n",
      "variational_beta * kldivergence:  0.16874\n",
      "batch accuracy: 85.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.40692\n",
      "kldivergence:   1585.68\n",
      "variational_beta * kldivergence:  0.15857\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.46670\n",
      "kldivergence:   1604.25\n",
      "variational_beta * kldivergence:  0.16042\n",
      "batch accuracy: 85.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.55263\n",
      "kldivergence:   1670.13\n",
      "variational_beta * kldivergence:  0.16701\n",
      "batch accuracy: 83.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.46740\n",
      "kldivergence:   1585.92\n",
      "variational_beta * kldivergence:  0.15859\n",
      "batch accuracy: 85.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.48399\n",
      "kldivergence:   1648.67\n",
      "variational_beta * kldivergence:  0.16487\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.42444\n",
      "kldivergence:   1513.61\n",
      "variational_beta * kldivergence:  0.15136\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.42610\n",
      "kldivergence:   1561.23\n",
      "variational_beta * kldivergence:  0.15612\n",
      "batch accuracy: 86.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.48056\n",
      "kldivergence:   1563.71\n",
      "variational_beta * kldivergence:  0.15637\n",
      "batch accuracy: 85.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.40083\n",
      "kldivergence:   1567.42\n",
      "variational_beta * kldivergence:  0.15674\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.44881\n",
      "kldivergence:   1598.37\n",
      "variational_beta * kldivergence:  0.15984\n",
      "batch accuracy: 86.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.41814\n",
      "kldivergence:   1500.04\n",
      "variational_beta * kldivergence:  0.15000\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.51004\n",
      "kldivergence:   1778.32\n",
      "variational_beta * kldivergence:  0.17783\n",
      "batch accuracy: 84.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.53856\n",
      "kldivergence:   1699.31\n",
      "variational_beta * kldivergence:  0.16993\n",
      "batch accuracy: 84.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.53114\n",
      "kldivergence:   1661.07\n",
      "variational_beta * kldivergence:  0.16611\n",
      "batch accuracy: 84.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.40750\n",
      "kldivergence:   1476.91\n",
      "variational_beta * kldivergence:  0.14769\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.57560\n",
      "kldivergence:   1724.27\n",
      "variational_beta * kldivergence:  0.17243\n",
      "batch accuracy: 83.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.56879\n",
      "kldivergence:   1710.04\n",
      "variational_beta * kldivergence:  0.17100\n",
      "batch accuracy: 82.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.45257\n",
      "kldivergence:   1579.11\n",
      "variational_beta * kldivergence:  0.15791\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.49600\n",
      "kldivergence:   1590.17\n",
      "variational_beta * kldivergence:  0.15902\n",
      "batch accuracy: 84.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.53036\n",
      "kldivergence:   1737.45\n",
      "variational_beta * kldivergence:  0.17375\n",
      "batch accuracy: 83.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.42862\n",
      "kldivergence:   1529.15\n",
      "variational_beta * kldivergence:  0.15291\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.44749\n",
      "kldivergence:   1786.67\n",
      "variational_beta * kldivergence:  0.17867\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.47484\n",
      "kldivergence:   1603.12\n",
      "variational_beta * kldivergence:  0.16031\n",
      "batch accuracy: 85.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.57271\n",
      "kldivergence:   1730.90\n",
      "variational_beta * kldivergence:  0.17309\n",
      "batch accuracy: 82.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.48877\n",
      "kldivergence:   1650.37\n",
      "variational_beta * kldivergence:  0.16504\n",
      "batch accuracy: 85.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.54940\n",
      "kldivergence:   1728.39\n",
      "variational_beta * kldivergence:  0.17284\n",
      "batch accuracy: 83.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.40337\n",
      "kldivergence:   1518.45\n",
      "variational_beta * kldivergence:  0.15184\n",
      "batch accuracy: 86.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.40814\n",
      "kldivergence:   1648.53\n",
      "variational_beta * kldivergence:  0.16485\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.46426\n",
      "kldivergence:   1665.20\n",
      "variational_beta * kldivergence:  0.16652\n",
      "batch accuracy: 85.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.39427\n",
      "kldivergence:   1541.85\n",
      "variational_beta * kldivergence:  0.15418\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.43469\n",
      "kldivergence:   1486.88\n",
      "variational_beta * kldivergence:  0.14869\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.53847\n",
      "kldivergence:   1688.47\n",
      "variational_beta * kldivergence:  0.16885\n",
      "batch accuracy: 83.14\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.44862\n",
      "kldivergence:   1629.24\n",
      "variational_beta * kldivergence:  0.16292\n",
      "batch accuracy: 85.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.37848\n",
      "kldivergence:   1614.90\n",
      "variational_beta * kldivergence:  0.16149\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.44297\n",
      "kldivergence:   1508.70\n",
      "variational_beta * kldivergence:  0.15087\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.55539\n",
      "kldivergence:   1768.56\n",
      "variational_beta * kldivergence:  0.17686\n",
      "batch accuracy: 83.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.48075\n",
      "kldivergence:   1591.31\n",
      "variational_beta * kldivergence:  0.15913\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.45028\n",
      "kldivergence:   1609.36\n",
      "variational_beta * kldivergence:  0.16094\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.53934\n",
      "kldivergence:   1732.12\n",
      "variational_beta * kldivergence:  0.17321\n",
      "batch accuracy: 82.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.42774\n",
      "kldivergence:   1603.23\n",
      "variational_beta * kldivergence:  0.16032\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.40911\n",
      "kldivergence:   1498.47\n",
      "variational_beta * kldivergence:  0.14985\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.33742\n",
      "kldivergence:   1419.74\n",
      "variational_beta * kldivergence:  0.14197\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.41705\n",
      "kldivergence:   1505.27\n",
      "variational_beta * kldivergence:  0.15053\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.41888\n",
      "kldivergence:   1516.41\n",
      "variational_beta * kldivergence:  0.15164\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.39186\n",
      "kldivergence:   1506.55\n",
      "variational_beta * kldivergence:  0.15066\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.44529\n",
      "kldivergence:   1579.75\n",
      "variational_beta * kldivergence:  0.15798\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.39896\n",
      "kldivergence:   1538.75\n",
      "variational_beta * kldivergence:  0.15387\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.55011\n",
      "kldivergence:   1842.27\n",
      "variational_beta * kldivergence:  0.18423\n",
      "batch accuracy: 82.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #8\n",
      "reconstruction loss: 0.46956\n",
      "kldivergence:   1599.45\n",
      "variational_beta * kldivergence:  0.15994\n",
      "batch accuracy: 86.01\n",
      "\n",
      "\n",
      "epoch # 8 : train loss is [191.2424169029991] and validation loss is [0.10432107618092641] \n",
      "Epoch [9 / 150] average reconstruction error: 0.515478\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33359\n",
      "kldivergence:   1714.28\n",
      "variational_beta * kldivergence:  0.17143\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32793\n",
      "kldivergence:   1594.39\n",
      "variational_beta * kldivergence:  0.15944\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32467\n",
      "kldivergence:   1817.59\n",
      "variational_beta * kldivergence:  0.18176\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.39892\n",
      "kldivergence:   1765.48\n",
      "variational_beta * kldivergence:  0.17655\n",
      "batch accuracy: 86.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30765\n",
      "kldivergence:   1898.75\n",
      "variational_beta * kldivergence:  0.18988\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34183\n",
      "kldivergence:   1845.42\n",
      "variational_beta * kldivergence:  0.18454\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32527\n",
      "kldivergence:   1912.66\n",
      "variational_beta * kldivergence:  0.19127\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35606\n",
      "kldivergence:   1885.77\n",
      "variational_beta * kldivergence:  0.18858\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.42914\n",
      "kldivergence:   2154.43\n",
      "variational_beta * kldivergence:  0.21544\n",
      "batch accuracy: 85.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34042\n",
      "kldivergence:   1727.92\n",
      "variational_beta * kldivergence:  0.17279\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35576\n",
      "kldivergence:   1844.76\n",
      "variational_beta * kldivergence:  0.18448\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30202\n",
      "kldivergence:   1614.41\n",
      "variational_beta * kldivergence:  0.16144\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35342\n",
      "kldivergence:   1692.18\n",
      "variational_beta * kldivergence:  0.16922\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37206\n",
      "kldivergence:   1802.84\n",
      "variational_beta * kldivergence:  0.18028\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34138\n",
      "kldivergence:   1884.22\n",
      "variational_beta * kldivergence:  0.18842\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33881\n",
      "kldivergence:   1795.44\n",
      "variational_beta * kldivergence:  0.17954\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30710\n",
      "kldivergence:   1901.75\n",
      "variational_beta * kldivergence:  0.19018\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37809\n",
      "kldivergence:   2006.80\n",
      "variational_beta * kldivergence:  0.20068\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32333\n",
      "kldivergence:   1655.62\n",
      "variational_beta * kldivergence:  0.16556\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32746\n",
      "kldivergence:   1600.88\n",
      "variational_beta * kldivergence:  0.16009\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34835\n",
      "kldivergence:   1646.72\n",
      "variational_beta * kldivergence:  0.16467\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37642\n",
      "kldivergence:   1844.25\n",
      "variational_beta * kldivergence:  0.18443\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37898\n",
      "kldivergence:   1754.71\n",
      "variational_beta * kldivergence:  0.17547\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.28611\n",
      "kldivergence:   1700.65\n",
      "variational_beta * kldivergence:  0.17007\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.39378\n",
      "kldivergence:   2063.37\n",
      "variational_beta * kldivergence:  0.20634\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34894\n",
      "kldivergence:   1703.77\n",
      "variational_beta * kldivergence:  0.17038\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35245\n",
      "kldivergence:   1651.75\n",
      "variational_beta * kldivergence:  0.16518\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35740\n",
      "kldivergence:   1856.07\n",
      "variational_beta * kldivergence:  0.18561\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33454\n",
      "kldivergence:   1675.62\n",
      "variational_beta * kldivergence:  0.16756\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33155\n",
      "kldivergence:   1781.83\n",
      "variational_beta * kldivergence:  0.17818\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29582\n",
      "kldivergence:   1502.47\n",
      "variational_beta * kldivergence:  0.15025\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33948\n",
      "kldivergence:   1724.41\n",
      "variational_beta * kldivergence:  0.17244\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33150\n",
      "kldivergence:   1634.86\n",
      "variational_beta * kldivergence:  0.16349\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35040\n",
      "kldivergence:   1796.75\n",
      "variational_beta * kldivergence:  0.17967\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34231\n",
      "kldivergence:   1722.01\n",
      "variational_beta * kldivergence:  0.17220\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.27961\n",
      "kldivergence:   1527.41\n",
      "variational_beta * kldivergence:  0.15274\n",
      "batch accuracy: 90.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.40040\n",
      "kldivergence:   1969.21\n",
      "variational_beta * kldivergence:  0.19692\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33967\n",
      "kldivergence:   1791.46\n",
      "variational_beta * kldivergence:  0.17915\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37441\n",
      "kldivergence:   1758.28\n",
      "variational_beta * kldivergence:  0.17583\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35342\n",
      "kldivergence:   1783.96\n",
      "variational_beta * kldivergence:  0.17840\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31806\n",
      "kldivergence:   1772.82\n",
      "variational_beta * kldivergence:  0.17728\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31540\n",
      "kldivergence:   1602.01\n",
      "variational_beta * kldivergence:  0.16020\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34843\n",
      "kldivergence:   1599.24\n",
      "variational_beta * kldivergence:  0.15992\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31124\n",
      "kldivergence:   1773.39\n",
      "variational_beta * kldivergence:  0.17734\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33938\n",
      "kldivergence:   1803.68\n",
      "variational_beta * kldivergence:  0.18037\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30647\n",
      "kldivergence:   1507.01\n",
      "variational_beta * kldivergence:  0.15070\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34849\n",
      "kldivergence:   1692.00\n",
      "variational_beta * kldivergence:  0.16920\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.40970\n",
      "kldivergence:   1834.08\n",
      "variational_beta * kldivergence:  0.18341\n",
      "batch accuracy: 85.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34040\n",
      "kldivergence:   1772.82\n",
      "variational_beta * kldivergence:  0.17728\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.27584\n",
      "kldivergence:   1698.75\n",
      "variational_beta * kldivergence:  0.16987\n",
      "batch accuracy: 90.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29148\n",
      "kldivergence:   1414.45\n",
      "variational_beta * kldivergence:  0.14144\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30161\n",
      "kldivergence:   1703.76\n",
      "variational_beta * kldivergence:  0.17038\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36399\n",
      "kldivergence:   1695.18\n",
      "variational_beta * kldivergence:  0.16952\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37682\n",
      "kldivergence:   1875.27\n",
      "variational_beta * kldivergence:  0.18753\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33684\n",
      "kldivergence:   1700.21\n",
      "variational_beta * kldivergence:  0.17002\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31144\n",
      "kldivergence:   1543.91\n",
      "variational_beta * kldivergence:  0.15439\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35149\n",
      "kldivergence:   1739.30\n",
      "variational_beta * kldivergence:  0.17393\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34191\n",
      "kldivergence:   1832.19\n",
      "variational_beta * kldivergence:  0.18322\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30938\n",
      "kldivergence:   1841.98\n",
      "variational_beta * kldivergence:  0.18420\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.38468\n",
      "kldivergence:   1878.05\n",
      "variational_beta * kldivergence:  0.18781\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36918\n",
      "kldivergence:   1877.01\n",
      "variational_beta * kldivergence:  0.18770\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31644\n",
      "kldivergence:   1781.36\n",
      "variational_beta * kldivergence:  0.17814\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34119\n",
      "kldivergence:   1578.00\n",
      "variational_beta * kldivergence:  0.15780\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35238\n",
      "kldivergence:   1530.79\n",
      "variational_beta * kldivergence:  0.15308\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34605\n",
      "kldivergence:   1675.59\n",
      "variational_beta * kldivergence:  0.16756\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37247\n",
      "kldivergence:   1896.67\n",
      "variational_beta * kldivergence:  0.18967\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33143\n",
      "kldivergence:   1640.76\n",
      "variational_beta * kldivergence:  0.16408\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34466\n",
      "kldivergence:   1786.96\n",
      "variational_beta * kldivergence:  0.17870\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36260\n",
      "kldivergence:   1789.33\n",
      "variational_beta * kldivergence:  0.17893\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29379\n",
      "kldivergence:   1804.31\n",
      "variational_beta * kldivergence:  0.18043\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35846\n",
      "kldivergence:   1736.80\n",
      "variational_beta * kldivergence:  0.17368\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.38282\n",
      "kldivergence:   2031.66\n",
      "variational_beta * kldivergence:  0.20317\n",
      "batch accuracy: 87.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37081\n",
      "kldivergence:   1853.48\n",
      "variational_beta * kldivergence:  0.18535\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33543\n",
      "kldivergence:   1777.18\n",
      "variational_beta * kldivergence:  0.17772\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35341\n",
      "kldivergence:   1783.27\n",
      "variational_beta * kldivergence:  0.17833\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31390\n",
      "kldivergence:   1783.26\n",
      "variational_beta * kldivergence:  0.17833\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30351\n",
      "kldivergence:   1758.48\n",
      "variational_beta * kldivergence:  0.17585\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34238\n",
      "kldivergence:   1983.60\n",
      "variational_beta * kldivergence:  0.19836\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37470\n",
      "kldivergence:   1799.74\n",
      "variational_beta * kldivergence:  0.17997\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34252\n",
      "kldivergence:   1849.22\n",
      "variational_beta * kldivergence:  0.18492\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34548\n",
      "kldivergence:   1771.26\n",
      "variational_beta * kldivergence:  0.17713\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29712\n",
      "kldivergence:   1563.80\n",
      "variational_beta * kldivergence:  0.15638\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37556\n",
      "kldivergence:   1972.01\n",
      "variational_beta * kldivergence:  0.19720\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36140\n",
      "kldivergence:   2021.47\n",
      "variational_beta * kldivergence:  0.20215\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31710\n",
      "kldivergence:   1942.78\n",
      "variational_beta * kldivergence:  0.19428\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33038\n",
      "kldivergence:   1758.48\n",
      "variational_beta * kldivergence:  0.17585\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.40536\n",
      "kldivergence:   1694.12\n",
      "variational_beta * kldivergence:  0.16941\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34565\n",
      "kldivergence:   1921.19\n",
      "variational_beta * kldivergence:  0.19212\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29864\n",
      "kldivergence:   1531.63\n",
      "variational_beta * kldivergence:  0.15316\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31892\n",
      "kldivergence:   1671.94\n",
      "variational_beta * kldivergence:  0.16719\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35265\n",
      "kldivergence:   1587.58\n",
      "variational_beta * kldivergence:  0.15876\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34125\n",
      "kldivergence:   1608.12\n",
      "variational_beta * kldivergence:  0.16081\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29662\n",
      "kldivergence:   1616.14\n",
      "variational_beta * kldivergence:  0.16161\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34615\n",
      "kldivergence:   1537.03\n",
      "variational_beta * kldivergence:  0.15370\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31917\n",
      "kldivergence:   1914.45\n",
      "variational_beta * kldivergence:  0.19145\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33552\n",
      "kldivergence:   1642.01\n",
      "variational_beta * kldivergence:  0.16420\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32691\n",
      "kldivergence:   1757.10\n",
      "variational_beta * kldivergence:  0.17571\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30325\n",
      "kldivergence:   1599.26\n",
      "variational_beta * kldivergence:  0.15993\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.40253\n",
      "kldivergence:   1759.69\n",
      "variational_beta * kldivergence:  0.17597\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32252\n",
      "kldivergence:   1720.21\n",
      "variational_beta * kldivergence:  0.17202\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36717\n",
      "kldivergence:   1685.56\n",
      "variational_beta * kldivergence:  0.16856\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35076\n",
      "kldivergence:   1680.10\n",
      "variational_beta * kldivergence:  0.16801\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34702\n",
      "kldivergence:   1648.96\n",
      "variational_beta * kldivergence:  0.16490\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30620\n",
      "kldivergence:   1681.18\n",
      "variational_beta * kldivergence:  0.16812\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37887\n",
      "kldivergence:   1727.23\n",
      "variational_beta * kldivergence:  0.17272\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30647\n",
      "kldivergence:   1483.72\n",
      "variational_beta * kldivergence:  0.14837\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.39815\n",
      "kldivergence:   1638.99\n",
      "variational_beta * kldivergence:  0.16390\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36299\n",
      "kldivergence:   1799.02\n",
      "variational_beta * kldivergence:  0.17990\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32374\n",
      "kldivergence:   1594.41\n",
      "variational_beta * kldivergence:  0.15944\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37384\n",
      "kldivergence:   1729.29\n",
      "variational_beta * kldivergence:  0.17293\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32511\n",
      "kldivergence:   1591.95\n",
      "variational_beta * kldivergence:  0.15920\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34758\n",
      "kldivergence:   1703.19\n",
      "variational_beta * kldivergence:  0.17032\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33113\n",
      "kldivergence:   1739.66\n",
      "variational_beta * kldivergence:  0.17397\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35877\n",
      "kldivergence:   1849.03\n",
      "variational_beta * kldivergence:  0.18490\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30901\n",
      "kldivergence:   1738.02\n",
      "variational_beta * kldivergence:  0.17380\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30777\n",
      "kldivergence:   1623.93\n",
      "variational_beta * kldivergence:  0.16239\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37010\n",
      "kldivergence:   1802.38\n",
      "variational_beta * kldivergence:  0.18024\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32892\n",
      "kldivergence:   1679.84\n",
      "variational_beta * kldivergence:  0.16798\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.39587\n",
      "kldivergence:   1906.83\n",
      "variational_beta * kldivergence:  0.19068\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33807\n",
      "kldivergence:   1936.39\n",
      "variational_beta * kldivergence:  0.19364\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30074\n",
      "kldivergence:   1998.23\n",
      "variational_beta * kldivergence:  0.19982\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34227\n",
      "kldivergence:   1822.82\n",
      "variational_beta * kldivergence:  0.18228\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.39095\n",
      "kldivergence:   1808.60\n",
      "variational_beta * kldivergence:  0.18086\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32462\n",
      "kldivergence:   1735.34\n",
      "variational_beta * kldivergence:  0.17353\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30393\n",
      "kldivergence:   1590.19\n",
      "variational_beta * kldivergence:  0.15902\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37564\n",
      "kldivergence:   1856.77\n",
      "variational_beta * kldivergence:  0.18568\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31360\n",
      "kldivergence:   1518.70\n",
      "variational_beta * kldivergence:  0.15187\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.38840\n",
      "kldivergence:   2035.05\n",
      "variational_beta * kldivergence:  0.20350\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33767\n",
      "kldivergence:   1791.53\n",
      "variational_beta * kldivergence:  0.17915\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36189\n",
      "kldivergence:   1694.09\n",
      "variational_beta * kldivergence:  0.16941\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30366\n",
      "kldivergence:   1709.15\n",
      "variational_beta * kldivergence:  0.17092\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33776\n",
      "kldivergence:   1766.16\n",
      "variational_beta * kldivergence:  0.17662\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37562\n",
      "kldivergence:   1898.86\n",
      "variational_beta * kldivergence:  0.18989\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31184\n",
      "kldivergence:   1660.25\n",
      "variational_beta * kldivergence:  0.16603\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32011\n",
      "kldivergence:   1641.74\n",
      "variational_beta * kldivergence:  0.16417\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.39839\n",
      "kldivergence:   2090.42\n",
      "variational_beta * kldivergence:  0.20904\n",
      "batch accuracy: 86.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33470\n",
      "kldivergence:   1911.41\n",
      "variational_beta * kldivergence:  0.19114\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34248\n",
      "kldivergence:   1639.30\n",
      "variational_beta * kldivergence:  0.16393\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34318\n",
      "kldivergence:   2012.20\n",
      "variational_beta * kldivergence:  0.20122\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.41296\n",
      "kldivergence:   1947.87\n",
      "variational_beta * kldivergence:  0.19479\n",
      "batch accuracy: 86.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31761\n",
      "kldivergence:   1517.20\n",
      "variational_beta * kldivergence:  0.15172\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31972\n",
      "kldivergence:   1613.77\n",
      "variational_beta * kldivergence:  0.16138\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.28494\n",
      "kldivergence:   1978.56\n",
      "variational_beta * kldivergence:  0.19786\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32523\n",
      "kldivergence:   1866.32\n",
      "variational_beta * kldivergence:  0.18663\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35420\n",
      "kldivergence:   1608.65\n",
      "variational_beta * kldivergence:  0.16087\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32652\n",
      "kldivergence:   1481.81\n",
      "variational_beta * kldivergence:  0.14818\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36732\n",
      "kldivergence:   1589.17\n",
      "variational_beta * kldivergence:  0.15892\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36916\n",
      "kldivergence:   1437.13\n",
      "variational_beta * kldivergence:  0.14371\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35789\n",
      "kldivergence:   1531.03\n",
      "variational_beta * kldivergence:  0.15310\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34822\n",
      "kldivergence:   1668.53\n",
      "variational_beta * kldivergence:  0.16685\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36870\n",
      "kldivergence:   1789.70\n",
      "variational_beta * kldivergence:  0.17897\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30940\n",
      "kldivergence:   1629.16\n",
      "variational_beta * kldivergence:  0.16292\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37877\n",
      "kldivergence:   1721.50\n",
      "variational_beta * kldivergence:  0.17215\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33053\n",
      "kldivergence:   1585.92\n",
      "variational_beta * kldivergence:  0.15859\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.40604\n",
      "kldivergence:   2016.27\n",
      "variational_beta * kldivergence:  0.20163\n",
      "batch accuracy: 86.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36968\n",
      "kldivergence:   1840.28\n",
      "variational_beta * kldivergence:  0.18403\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31655\n",
      "kldivergence:   1457.03\n",
      "variational_beta * kldivergence:  0.14570\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.38334\n",
      "kldivergence:   1664.36\n",
      "variational_beta * kldivergence:  0.16644\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31498\n",
      "kldivergence:   1673.33\n",
      "variational_beta * kldivergence:  0.16733\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32780\n",
      "kldivergence:   1596.43\n",
      "variational_beta * kldivergence:  0.15964\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32647\n",
      "kldivergence:   1757.31\n",
      "variational_beta * kldivergence:  0.17573\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32533\n",
      "kldivergence:   1610.53\n",
      "variational_beta * kldivergence:  0.16105\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.41281\n",
      "kldivergence:   1767.50\n",
      "variational_beta * kldivergence:  0.17675\n",
      "batch accuracy: 86.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.24243\n",
      "kldivergence:   1476.07\n",
      "variational_beta * kldivergence:  0.14761\n",
      "batch accuracy: 92.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.28995\n",
      "kldivergence:   1923.07\n",
      "variational_beta * kldivergence:  0.19231\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34264\n",
      "kldivergence:   1824.31\n",
      "variational_beta * kldivergence:  0.18243\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32242\n",
      "kldivergence:   1924.39\n",
      "variational_beta * kldivergence:  0.19244\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35964\n",
      "kldivergence:   1555.89\n",
      "variational_beta * kldivergence:  0.15559\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34146\n",
      "kldivergence:   1830.50\n",
      "variational_beta * kldivergence:  0.18305\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.26240\n",
      "kldivergence:   1561.77\n",
      "variational_beta * kldivergence:  0.15618\n",
      "batch accuracy: 91.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35098\n",
      "kldivergence:   1659.06\n",
      "variational_beta * kldivergence:  0.16591\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32449\n",
      "kldivergence:   2016.09\n",
      "variational_beta * kldivergence:  0.20161\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37869\n",
      "kldivergence:   1900.66\n",
      "variational_beta * kldivergence:  0.19007\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33830\n",
      "kldivergence:   1616.80\n",
      "variational_beta * kldivergence:  0.16168\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32537\n",
      "kldivergence:   1909.67\n",
      "variational_beta * kldivergence:  0.19097\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29841\n",
      "kldivergence:   1786.08\n",
      "variational_beta * kldivergence:  0.17861\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35473\n",
      "kldivergence:   1700.94\n",
      "variational_beta * kldivergence:  0.17009\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.38437\n",
      "kldivergence:   1949.88\n",
      "variational_beta * kldivergence:  0.19499\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.27448\n",
      "kldivergence:   1565.30\n",
      "variational_beta * kldivergence:  0.15653\n",
      "batch accuracy: 90.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35637\n",
      "kldivergence:   1870.02\n",
      "variational_beta * kldivergence:  0.18700\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37122\n",
      "kldivergence:   1954.72\n",
      "variational_beta * kldivergence:  0.19547\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34052\n",
      "kldivergence:   1738.67\n",
      "variational_beta * kldivergence:  0.17387\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33774\n",
      "kldivergence:   1774.89\n",
      "variational_beta * kldivergence:  0.17749\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33333\n",
      "kldivergence:   1709.40\n",
      "variational_beta * kldivergence:  0.17094\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36342\n",
      "kldivergence:   1861.41\n",
      "variational_beta * kldivergence:  0.18614\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30435\n",
      "kldivergence:   1467.65\n",
      "variational_beta * kldivergence:  0.14677\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30902\n",
      "kldivergence:   1632.94\n",
      "variational_beta * kldivergence:  0.16329\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37646\n",
      "kldivergence:   1698.20\n",
      "variational_beta * kldivergence:  0.16982\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.24672\n",
      "kldivergence:   1622.73\n",
      "variational_beta * kldivergence:  0.16227\n",
      "batch accuracy: 92.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32712\n",
      "kldivergence:   1405.83\n",
      "variational_beta * kldivergence:  0.14058\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36705\n",
      "kldivergence:   2031.35\n",
      "variational_beta * kldivergence:  0.20313\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29923\n",
      "kldivergence:   1660.65\n",
      "variational_beta * kldivergence:  0.16607\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.38741\n",
      "kldivergence:   1751.91\n",
      "variational_beta * kldivergence:  0.17519\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35483\n",
      "kldivergence:   1539.98\n",
      "variational_beta * kldivergence:  0.15400\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30150\n",
      "kldivergence:   1620.16\n",
      "variational_beta * kldivergence:  0.16202\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.38619\n",
      "kldivergence:   1539.97\n",
      "variational_beta * kldivergence:  0.15400\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35538\n",
      "kldivergence:   1713.44\n",
      "variational_beta * kldivergence:  0.17134\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35740\n",
      "kldivergence:   1846.49\n",
      "variational_beta * kldivergence:  0.18465\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30608\n",
      "kldivergence:   1765.28\n",
      "variational_beta * kldivergence:  0.17653\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35783\n",
      "kldivergence:   1517.70\n",
      "variational_beta * kldivergence:  0.15177\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34756\n",
      "kldivergence:   1465.33\n",
      "variational_beta * kldivergence:  0.14653\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.39136\n",
      "kldivergence:   1651.51\n",
      "variational_beta * kldivergence:  0.16515\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35358\n",
      "kldivergence:   1559.64\n",
      "variational_beta * kldivergence:  0.15596\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33755\n",
      "kldivergence:   1574.97\n",
      "variational_beta * kldivergence:  0.15750\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36261\n",
      "kldivergence:   1703.73\n",
      "variational_beta * kldivergence:  0.17037\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32289\n",
      "kldivergence:   1722.15\n",
      "variational_beta * kldivergence:  0.17222\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.28811\n",
      "kldivergence:   1505.95\n",
      "variational_beta * kldivergence:  0.15059\n",
      "batch accuracy: 90.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31543\n",
      "kldivergence:   1659.66\n",
      "variational_beta * kldivergence:  0.16597\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.32846\n",
      "kldivergence:   1921.09\n",
      "variational_beta * kldivergence:  0.19211\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34749\n",
      "kldivergence:   1823.03\n",
      "variational_beta * kldivergence:  0.18230\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36758\n",
      "kldivergence:   1893.82\n",
      "variational_beta * kldivergence:  0.18938\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36173\n",
      "kldivergence:   1649.22\n",
      "variational_beta * kldivergence:  0.16492\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34744\n",
      "kldivergence:   1697.41\n",
      "variational_beta * kldivergence:  0.16974\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30397\n",
      "kldivergence:   1521.43\n",
      "variational_beta * kldivergence:  0.15214\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36034\n",
      "kldivergence:   1773.96\n",
      "variational_beta * kldivergence:  0.17740\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34151\n",
      "kldivergence:   1769.10\n",
      "variational_beta * kldivergence:  0.17691\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36975\n",
      "kldivergence:   1882.29\n",
      "variational_beta * kldivergence:  0.18823\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33234\n",
      "kldivergence:   1719.96\n",
      "variational_beta * kldivergence:  0.17200\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34221\n",
      "kldivergence:   1757.26\n",
      "variational_beta * kldivergence:  0.17573\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35927\n",
      "kldivergence:   1811.62\n",
      "variational_beta * kldivergence:  0.18116\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34178\n",
      "kldivergence:   1726.85\n",
      "variational_beta * kldivergence:  0.17268\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.38599\n",
      "kldivergence:   2087.32\n",
      "variational_beta * kldivergence:  0.20873\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29821\n",
      "kldivergence:   1986.77\n",
      "variational_beta * kldivergence:  0.19868\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30118\n",
      "kldivergence:   1737.46\n",
      "variational_beta * kldivergence:  0.17375\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31561\n",
      "kldivergence:   1780.19\n",
      "variational_beta * kldivergence:  0.17802\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36628\n",
      "kldivergence:   1788.41\n",
      "variational_beta * kldivergence:  0.17884\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.28261\n",
      "kldivergence:   1794.88\n",
      "variational_beta * kldivergence:  0.17949\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.28660\n",
      "kldivergence:   1584.57\n",
      "variational_beta * kldivergence:  0.15846\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36568\n",
      "kldivergence:   1944.43\n",
      "variational_beta * kldivergence:  0.19444\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33659\n",
      "kldivergence:   1687.22\n",
      "variational_beta * kldivergence:  0.16872\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.34324\n",
      "kldivergence:   1681.83\n",
      "variational_beta * kldivergence:  0.16818\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29858\n",
      "kldivergence:   1613.09\n",
      "variational_beta * kldivergence:  0.16131\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36498\n",
      "kldivergence:   2159.10\n",
      "variational_beta * kldivergence:  0.21591\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30317\n",
      "kldivergence:   1646.87\n",
      "variational_beta * kldivergence:  0.16469\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31155\n",
      "kldivergence:   1785.12\n",
      "variational_beta * kldivergence:  0.17851\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37162\n",
      "kldivergence:   1752.46\n",
      "variational_beta * kldivergence:  0.17525\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.30096\n",
      "kldivergence:   1675.97\n",
      "variational_beta * kldivergence:  0.16760\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.33692\n",
      "kldivergence:   1944.73\n",
      "variational_beta * kldivergence:  0.19447\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.38509\n",
      "kldivergence:   1966.56\n",
      "variational_beta * kldivergence:  0.19666\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.29549\n",
      "kldivergence:   1667.55\n",
      "variational_beta * kldivergence:  0.16675\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.28818\n",
      "kldivergence:   1679.20\n",
      "variational_beta * kldivergence:  0.16792\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.36242\n",
      "kldivergence:   1622.28\n",
      "variational_beta * kldivergence:  0.16223\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37465\n",
      "kldivergence:   1955.11\n",
      "variational_beta * kldivergence:  0.19551\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.38788\n",
      "kldivergence:   1774.84\n",
      "variational_beta * kldivergence:  0.17748\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35463\n",
      "kldivergence:   1524.29\n",
      "variational_beta * kldivergence:  0.15243\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37495\n",
      "kldivergence:   1954.99\n",
      "variational_beta * kldivergence:  0.19550\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.31327\n",
      "kldivergence:   1958.08\n",
      "variational_beta * kldivergence:  0.19581\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.39295\n",
      "kldivergence:   1727.74\n",
      "variational_beta * kldivergence:  0.17277\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.35757\n",
      "kldivergence:   1890.08\n",
      "variational_beta * kldivergence:  0.18901\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #9\n",
      "reconstruction loss: 0.37606\n",
      "kldivergence:   1676.56\n",
      "variational_beta * kldivergence:  0.16766\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33652\n",
      "kldivergence:   1471.55\n",
      "variational_beta * kldivergence:  0.14715\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31057\n",
      "kldivergence:   1824.48\n",
      "variational_beta * kldivergence:  0.18245\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34330\n",
      "kldivergence:   1656.34\n",
      "variational_beta * kldivergence:  0.16563\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30033\n",
      "kldivergence:   1363.23\n",
      "variational_beta * kldivergence:  0.13632\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38578\n",
      "kldivergence:   1673.59\n",
      "variational_beta * kldivergence:  0.16736\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34979\n",
      "kldivergence:   1486.39\n",
      "variational_beta * kldivergence:  0.14864\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35866\n",
      "kldivergence:   1498.45\n",
      "variational_beta * kldivergence:  0.14984\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37496\n",
      "kldivergence:   1531.83\n",
      "variational_beta * kldivergence:  0.15318\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31490\n",
      "kldivergence:   1527.85\n",
      "variational_beta * kldivergence:  0.15279\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.27076\n",
      "kldivergence:   1418.95\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 90.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33567\n",
      "kldivergence:   1729.82\n",
      "variational_beta * kldivergence:  0.17298\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.39043\n",
      "kldivergence:   1622.64\n",
      "variational_beta * kldivergence:  0.16226\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30580\n",
      "kldivergence:   1626.98\n",
      "variational_beta * kldivergence:  0.16270\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.28030\n",
      "kldivergence:   1511.10\n",
      "variational_beta * kldivergence:  0.15111\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34214\n",
      "kldivergence:   1709.55\n",
      "variational_beta * kldivergence:  0.17096\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36436\n",
      "kldivergence:   1717.44\n",
      "variational_beta * kldivergence:  0.17174\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.40236\n",
      "kldivergence:   1795.15\n",
      "variational_beta * kldivergence:  0.17952\n",
      "batch accuracy: 86.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34104\n",
      "kldivergence:   1787.41\n",
      "variational_beta * kldivergence:  0.17874\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34148\n",
      "kldivergence:   1699.00\n",
      "variational_beta * kldivergence:  0.16990\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33854\n",
      "kldivergence:   1350.30\n",
      "variational_beta * kldivergence:  0.13503\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35500\n",
      "kldivergence:   1774.62\n",
      "variational_beta * kldivergence:  0.17746\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32745\n",
      "kldivergence:   1608.83\n",
      "variational_beta * kldivergence:  0.16088\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35188\n",
      "kldivergence:   1550.54\n",
      "variational_beta * kldivergence:  0.15505\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37967\n",
      "kldivergence:   1688.19\n",
      "variational_beta * kldivergence:  0.16882\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38267\n",
      "kldivergence:   1761.46\n",
      "variational_beta * kldivergence:  0.17615\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.39170\n",
      "kldivergence:   1593.00\n",
      "variational_beta * kldivergence:  0.15930\n",
      "batch accuracy: 86.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34766\n",
      "kldivergence:   1714.24\n",
      "variational_beta * kldivergence:  0.17142\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30473\n",
      "kldivergence:   1522.11\n",
      "variational_beta * kldivergence:  0.15221\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.40787\n",
      "kldivergence:   1708.55\n",
      "variational_beta * kldivergence:  0.17085\n",
      "batch accuracy: 86.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.27206\n",
      "kldivergence:   1637.44\n",
      "variational_beta * kldivergence:  0.16374\n",
      "batch accuracy: 91.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32261\n",
      "kldivergence:   1506.07\n",
      "variational_beta * kldivergence:  0.15061\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33132\n",
      "kldivergence:   1534.18\n",
      "variational_beta * kldivergence:  0.15342\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.28094\n",
      "kldivergence:   1555.29\n",
      "variational_beta * kldivergence:  0.15553\n",
      "batch accuracy: 90.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31261\n",
      "kldivergence:   1632.70\n",
      "variational_beta * kldivergence:  0.16327\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36391\n",
      "kldivergence:   1841.88\n",
      "variational_beta * kldivergence:  0.18419\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37594\n",
      "kldivergence:   1811.71\n",
      "variational_beta * kldivergence:  0.18117\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30690\n",
      "kldivergence:   1640.70\n",
      "variational_beta * kldivergence:  0.16407\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37078\n",
      "kldivergence:   1721.60\n",
      "variational_beta * kldivergence:  0.17216\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31723\n",
      "kldivergence:   1719.06\n",
      "variational_beta * kldivergence:  0.17191\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37971\n",
      "kldivergence:   1759.44\n",
      "variational_beta * kldivergence:  0.17594\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37515\n",
      "kldivergence:   1608.57\n",
      "variational_beta * kldivergence:  0.16086\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.27712\n",
      "kldivergence:   1566.94\n",
      "variational_beta * kldivergence:  0.15669\n",
      "batch accuracy: 90.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38218\n",
      "kldivergence:   1767.30\n",
      "variational_beta * kldivergence:  0.17673\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31116\n",
      "kldivergence:   1606.25\n",
      "variational_beta * kldivergence:  0.16062\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33380\n",
      "kldivergence:   1912.17\n",
      "variational_beta * kldivergence:  0.19122\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35363\n",
      "kldivergence:   2081.52\n",
      "variational_beta * kldivergence:  0.20815\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37887\n",
      "kldivergence:   1701.64\n",
      "variational_beta * kldivergence:  0.17016\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35203\n",
      "kldivergence:   1866.75\n",
      "variational_beta * kldivergence:  0.18668\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38578\n",
      "kldivergence:   1840.19\n",
      "variational_beta * kldivergence:  0.18402\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35744\n",
      "kldivergence:   1878.66\n",
      "variational_beta * kldivergence:  0.18787\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31265\n",
      "kldivergence:   1479.88\n",
      "variational_beta * kldivergence:  0.14799\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31063\n",
      "kldivergence:   1673.84\n",
      "variational_beta * kldivergence:  0.16738\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32029\n",
      "kldivergence:   1790.79\n",
      "variational_beta * kldivergence:  0.17908\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34518\n",
      "kldivergence:   1513.34\n",
      "variational_beta * kldivergence:  0.15133\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33553\n",
      "kldivergence:   1480.62\n",
      "variational_beta * kldivergence:  0.14806\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31846\n",
      "kldivergence:   1576.31\n",
      "variational_beta * kldivergence:  0.15763\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32939\n",
      "kldivergence:   1634.12\n",
      "variational_beta * kldivergence:  0.16341\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33312\n",
      "kldivergence:   1868.44\n",
      "variational_beta * kldivergence:  0.18684\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30751\n",
      "kldivergence:   1541.57\n",
      "variational_beta * kldivergence:  0.15416\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33261\n",
      "kldivergence:   1494.59\n",
      "variational_beta * kldivergence:  0.14946\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35341\n",
      "kldivergence:   1744.27\n",
      "variational_beta * kldivergence:  0.17443\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31752\n",
      "kldivergence:   1552.41\n",
      "variational_beta * kldivergence:  0.15524\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35108\n",
      "kldivergence:   1866.33\n",
      "variational_beta * kldivergence:  0.18663\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36601\n",
      "kldivergence:   1795.16\n",
      "variational_beta * kldivergence:  0.17952\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31425\n",
      "kldivergence:   2187.49\n",
      "variational_beta * kldivergence:  0.21875\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33479\n",
      "kldivergence:   1521.64\n",
      "variational_beta * kldivergence:  0.15216\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34291\n",
      "kldivergence:   1819.97\n",
      "variational_beta * kldivergence:  0.18200\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30688\n",
      "kldivergence:   1632.61\n",
      "variational_beta * kldivergence:  0.16326\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36771\n",
      "kldivergence:   1681.28\n",
      "variational_beta * kldivergence:  0.16813\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37538\n",
      "kldivergence:   1563.79\n",
      "variational_beta * kldivergence:  0.15638\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30167\n",
      "kldivergence:   1482.09\n",
      "variational_beta * kldivergence:  0.14821\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34157\n",
      "kldivergence:   1634.02\n",
      "variational_beta * kldivergence:  0.16340\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35920\n",
      "kldivergence:   1731.96\n",
      "variational_beta * kldivergence:  0.17320\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31423\n",
      "kldivergence:   1738.90\n",
      "variational_beta * kldivergence:  0.17389\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34706\n",
      "kldivergence:   1707.97\n",
      "variational_beta * kldivergence:  0.17080\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38419\n",
      "kldivergence:   1656.54\n",
      "variational_beta * kldivergence:  0.16565\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35483\n",
      "kldivergence:   1629.07\n",
      "variational_beta * kldivergence:  0.16291\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34153\n",
      "kldivergence:   1676.59\n",
      "variational_beta * kldivergence:  0.16766\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.29063\n",
      "kldivergence:   1580.59\n",
      "variational_beta * kldivergence:  0.15806\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.29659\n",
      "kldivergence:   1586.57\n",
      "variational_beta * kldivergence:  0.15866\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.42480\n",
      "kldivergence:   1690.25\n",
      "variational_beta * kldivergence:  0.16903\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30061\n",
      "kldivergence:   1412.14\n",
      "variational_beta * kldivergence:  0.14121\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37383\n",
      "kldivergence:   1725.40\n",
      "variational_beta * kldivergence:  0.17254\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33909\n",
      "kldivergence:   1730.54\n",
      "variational_beta * kldivergence:  0.17305\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32765\n",
      "kldivergence:   1600.05\n",
      "variational_beta * kldivergence:  0.16001\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38618\n",
      "kldivergence:   1641.17\n",
      "variational_beta * kldivergence:  0.16412\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32442\n",
      "kldivergence:   1559.99\n",
      "variational_beta * kldivergence:  0.15600\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31265\n",
      "kldivergence:   1515.97\n",
      "variational_beta * kldivergence:  0.15160\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34046\n",
      "kldivergence:   1449.25\n",
      "variational_beta * kldivergence:  0.14493\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31805\n",
      "kldivergence:   1545.34\n",
      "variational_beta * kldivergence:  0.15453\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33908\n",
      "kldivergence:   1544.47\n",
      "variational_beta * kldivergence:  0.15445\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33914\n",
      "kldivergence:   1672.77\n",
      "variational_beta * kldivergence:  0.16728\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38992\n",
      "kldivergence:   1698.75\n",
      "variational_beta * kldivergence:  0.16987\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31954\n",
      "kldivergence:   1822.77\n",
      "variational_beta * kldivergence:  0.18228\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30131\n",
      "kldivergence:   1629.12\n",
      "variational_beta * kldivergence:  0.16291\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35680\n",
      "kldivergence:   1505.67\n",
      "variational_beta * kldivergence:  0.15057\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34213\n",
      "kldivergence:   1573.18\n",
      "variational_beta * kldivergence:  0.15732\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32634\n",
      "kldivergence:   1565.97\n",
      "variational_beta * kldivergence:  0.15660\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30416\n",
      "kldivergence:   1522.53\n",
      "variational_beta * kldivergence:  0.15225\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33471\n",
      "kldivergence:   1634.54\n",
      "variational_beta * kldivergence:  0.16345\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35748\n",
      "kldivergence:   1659.54\n",
      "variational_beta * kldivergence:  0.16595\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31016\n",
      "kldivergence:   1811.51\n",
      "variational_beta * kldivergence:  0.18115\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32300\n",
      "kldivergence:   1422.26\n",
      "variational_beta * kldivergence:  0.14223\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35020\n",
      "kldivergence:   1701.27\n",
      "variational_beta * kldivergence:  0.17013\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38193\n",
      "kldivergence:   1815.16\n",
      "variational_beta * kldivergence:  0.18152\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34365\n",
      "kldivergence:   1629.24\n",
      "variational_beta * kldivergence:  0.16292\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.39236\n",
      "kldivergence:   1897.36\n",
      "variational_beta * kldivergence:  0.18974\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31675\n",
      "kldivergence:   1431.62\n",
      "variational_beta * kldivergence:  0.14316\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.26633\n",
      "kldivergence:   1698.74\n",
      "variational_beta * kldivergence:  0.16987\n",
      "batch accuracy: 91.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33097\n",
      "kldivergence:   1632.38\n",
      "variational_beta * kldivergence:  0.16324\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34538\n",
      "kldivergence:   1805.23\n",
      "variational_beta * kldivergence:  0.18052\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37535\n",
      "kldivergence:   1903.94\n",
      "variational_beta * kldivergence:  0.19039\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32908\n",
      "kldivergence:   1568.94\n",
      "variational_beta * kldivergence:  0.15689\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30889\n",
      "kldivergence:   1679.99\n",
      "variational_beta * kldivergence:  0.16800\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31281\n",
      "kldivergence:   1677.62\n",
      "variational_beta * kldivergence:  0.16776\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30989\n",
      "kldivergence:   1557.36\n",
      "variational_beta * kldivergence:  0.15574\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33939\n",
      "kldivergence:   1647.17\n",
      "variational_beta * kldivergence:  0.16472\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30760\n",
      "kldivergence:   1570.74\n",
      "variational_beta * kldivergence:  0.15707\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32284\n",
      "kldivergence:   1707.17\n",
      "variational_beta * kldivergence:  0.17072\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32050\n",
      "kldivergence:   1746.68\n",
      "variational_beta * kldivergence:  0.17467\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33230\n",
      "kldivergence:   1607.73\n",
      "variational_beta * kldivergence:  0.16077\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34580\n",
      "kldivergence:   1786.64\n",
      "variational_beta * kldivergence:  0.17866\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36310\n",
      "kldivergence:   1586.26\n",
      "variational_beta * kldivergence:  0.15863\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33125\n",
      "kldivergence:   1639.43\n",
      "variational_beta * kldivergence:  0.16394\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35412\n",
      "kldivergence:   1727.63\n",
      "variational_beta * kldivergence:  0.17276\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.42694\n",
      "kldivergence:   1731.88\n",
      "variational_beta * kldivergence:  0.17319\n",
      "batch accuracy: 85.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.28671\n",
      "kldivergence:   1717.45\n",
      "variational_beta * kldivergence:  0.17175\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30589\n",
      "kldivergence:   1526.20\n",
      "variational_beta * kldivergence:  0.15262\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35536\n",
      "kldivergence:   1664.82\n",
      "variational_beta * kldivergence:  0.16648\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35720\n",
      "kldivergence:   1612.63\n",
      "variational_beta * kldivergence:  0.16126\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.39627\n",
      "kldivergence:   1675.91\n",
      "variational_beta * kldivergence:  0.16759\n",
      "batch accuracy: 86.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38326\n",
      "kldivergence:   1454.50\n",
      "variational_beta * kldivergence:  0.14545\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33732\n",
      "kldivergence:   1632.34\n",
      "variational_beta * kldivergence:  0.16323\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32918\n",
      "kldivergence:   1688.64\n",
      "variational_beta * kldivergence:  0.16886\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34642\n",
      "kldivergence:   1511.69\n",
      "variational_beta * kldivergence:  0.15117\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35489\n",
      "kldivergence:   1787.03\n",
      "variational_beta * kldivergence:  0.17870\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34162\n",
      "kldivergence:   1702.42\n",
      "variational_beta * kldivergence:  0.17024\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37742\n",
      "kldivergence:   1783.76\n",
      "variational_beta * kldivergence:  0.17838\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30527\n",
      "kldivergence:   1598.93\n",
      "variational_beta * kldivergence:  0.15989\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36040\n",
      "kldivergence:   1803.96\n",
      "variational_beta * kldivergence:  0.18040\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30961\n",
      "kldivergence:   1751.93\n",
      "variational_beta * kldivergence:  0.17519\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35439\n",
      "kldivergence:   1718.91\n",
      "variational_beta * kldivergence:  0.17189\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36461\n",
      "kldivergence:   1755.84\n",
      "variational_beta * kldivergence:  0.17558\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37038\n",
      "kldivergence:   1670.74\n",
      "variational_beta * kldivergence:  0.16707\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36541\n",
      "kldivergence:   1729.81\n",
      "variational_beta * kldivergence:  0.17298\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31405\n",
      "kldivergence:   1529.55\n",
      "variational_beta * kldivergence:  0.15296\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.28537\n",
      "kldivergence:   1930.00\n",
      "variational_beta * kldivergence:  0.19300\n",
      "batch accuracy: 90.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33886\n",
      "kldivergence:   1820.37\n",
      "variational_beta * kldivergence:  0.18204\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34395\n",
      "kldivergence:   1776.34\n",
      "variational_beta * kldivergence:  0.17763\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.35494\n",
      "kldivergence:   1752.23\n",
      "variational_beta * kldivergence:  0.17522\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38859\n",
      "kldivergence:   1913.63\n",
      "variational_beta * kldivergence:  0.19136\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34060\n",
      "kldivergence:   1866.64\n",
      "variational_beta * kldivergence:  0.18666\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31303\n",
      "kldivergence:   1651.34\n",
      "variational_beta * kldivergence:  0.16513\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32918\n",
      "kldivergence:   1541.24\n",
      "variational_beta * kldivergence:  0.15412\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.31854\n",
      "kldivergence:   1621.94\n",
      "variational_beta * kldivergence:  0.16219\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30279\n",
      "kldivergence:   1563.49\n",
      "variational_beta * kldivergence:  0.15635\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34000\n",
      "kldivergence:   1682.72\n",
      "variational_beta * kldivergence:  0.16827\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33550\n",
      "kldivergence:   1805.58\n",
      "variational_beta * kldivergence:  0.18056\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32544\n",
      "kldivergence:   2080.29\n",
      "variational_beta * kldivergence:  0.20803\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30874\n",
      "kldivergence:   1571.20\n",
      "variational_beta * kldivergence:  0.15712\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.27501\n",
      "kldivergence:   1560.57\n",
      "variational_beta * kldivergence:  0.15606\n",
      "batch accuracy: 90.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34150\n",
      "kldivergence:   1446.95\n",
      "variational_beta * kldivergence:  0.14469\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36370\n",
      "kldivergence:   1485.99\n",
      "variational_beta * kldivergence:  0.14860\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.33553\n",
      "kldivergence:   1571.15\n",
      "variational_beta * kldivergence:  0.15711\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32152\n",
      "kldivergence:   1582.87\n",
      "variational_beta * kldivergence:  0.15829\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38302\n",
      "kldivergence:   1990.52\n",
      "variational_beta * kldivergence:  0.19905\n",
      "batch accuracy: 86.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34912\n",
      "kldivergence:   1556.24\n",
      "variational_beta * kldivergence:  0.15562\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.32224\n",
      "kldivergence:   1555.18\n",
      "variational_beta * kldivergence:  0.15552\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36258\n",
      "kldivergence:   1667.10\n",
      "variational_beta * kldivergence:  0.16671\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.30965\n",
      "kldivergence:   1735.49\n",
      "variational_beta * kldivergence:  0.17355\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.40959\n",
      "kldivergence:   1782.79\n",
      "variational_beta * kldivergence:  0.17828\n",
      "batch accuracy: 86.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.38003\n",
      "kldivergence:   1755.23\n",
      "variational_beta * kldivergence:  0.17552\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.27868\n",
      "kldivergence:   1594.19\n",
      "variational_beta * kldivergence:  0.15942\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.28801\n",
      "kldivergence:   1503.12\n",
      "variational_beta * kldivergence:  0.15031\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36621\n",
      "kldivergence:   1613.00\n",
      "variational_beta * kldivergence:  0.16130\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.34071\n",
      "kldivergence:   1747.35\n",
      "variational_beta * kldivergence:  0.17474\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.37968\n",
      "kldivergence:   1820.04\n",
      "variational_beta * kldivergence:  0.18200\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.36043\n",
      "kldivergence:   1430.31\n",
      "variational_beta * kldivergence:  0.14303\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #18\n",
      "reconstruction loss: 0.25852\n",
      "kldivergence:   1526.81\n",
      "variational_beta * kldivergence:  0.15268\n",
      "batch accuracy: 91.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.43807\n",
      "kldivergence:   1471.62\n",
      "variational_beta * kldivergence:  0.14716\n",
      "batch accuracy: 86.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.48480\n",
      "kldivergence:   1586.48\n",
      "variational_beta * kldivergence:  0.15865\n",
      "batch accuracy: 85.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.45992\n",
      "kldivergence:   1550.71\n",
      "variational_beta * kldivergence:  0.15507\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.46691\n",
      "kldivergence:   1668.35\n",
      "variational_beta * kldivergence:  0.16684\n",
      "batch accuracy: 85.57\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.40899\n",
      "kldivergence:   1402.03\n",
      "variational_beta * kldivergence:  0.14020\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.40228\n",
      "kldivergence:   1410.44\n",
      "variational_beta * kldivergence:  0.14104\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.42087\n",
      "kldivergence:   1500.63\n",
      "variational_beta * kldivergence:  0.15006\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.49912\n",
      "kldivergence:   1694.90\n",
      "variational_beta * kldivergence:  0.16949\n",
      "batch accuracy: 84.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.50933\n",
      "kldivergence:   1656.68\n",
      "variational_beta * kldivergence:  0.16567\n",
      "batch accuracy: 85.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.47947\n",
      "kldivergence:   1593.49\n",
      "variational_beta * kldivergence:  0.15935\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.61099\n",
      "kldivergence:   1695.29\n",
      "variational_beta * kldivergence:  0.16953\n",
      "batch accuracy: 82.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.46770\n",
      "kldivergence:   1595.14\n",
      "variational_beta * kldivergence:  0.15951\n",
      "batch accuracy: 85.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.53131\n",
      "kldivergence:   1722.64\n",
      "variational_beta * kldivergence:  0.17226\n",
      "batch accuracy: 83.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.41668\n",
      "kldivergence:   1381.09\n",
      "variational_beta * kldivergence:  0.13811\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.42674\n",
      "kldivergence:   1490.00\n",
      "variational_beta * kldivergence:  0.14900\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.41550\n",
      "kldivergence:   1497.64\n",
      "variational_beta * kldivergence:  0.14976\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.50409\n",
      "kldivergence:   1568.15\n",
      "variational_beta * kldivergence:  0.15682\n",
      "batch accuracy: 84.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.37828\n",
      "kldivergence:   1411.15\n",
      "variational_beta * kldivergence:  0.14112\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.43938\n",
      "kldivergence:   1451.73\n",
      "variational_beta * kldivergence:  0.14517\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.43628\n",
      "kldivergence:   1535.48\n",
      "variational_beta * kldivergence:  0.15355\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.52940\n",
      "kldivergence:   1568.90\n",
      "variational_beta * kldivergence:  0.15689\n",
      "batch accuracy: 84.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.49784\n",
      "kldivergence:   1661.98\n",
      "variational_beta * kldivergence:  0.16620\n",
      "batch accuracy: 84.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.46229\n",
      "kldivergence:   1579.43\n",
      "variational_beta * kldivergence:  0.15794\n",
      "batch accuracy: 85.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.51918\n",
      "kldivergence:   1683.24\n",
      "variational_beta * kldivergence:  0.16832\n",
      "batch accuracy: 84.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.47031\n",
      "kldivergence:   1568.36\n",
      "variational_beta * kldivergence:  0.15684\n",
      "batch accuracy: 85.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.47955\n",
      "kldivergence:   1555.33\n",
      "variational_beta * kldivergence:  0.15553\n",
      "batch accuracy: 85.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.38066\n",
      "kldivergence:   1539.75\n",
      "variational_beta * kldivergence:  0.15397\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.58231\n",
      "kldivergence:   1614.08\n",
      "variational_beta * kldivergence:  0.16141\n",
      "batch accuracy: 83.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.38454\n",
      "kldivergence:   1410.02\n",
      "variational_beta * kldivergence:  0.14100\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.42427\n",
      "kldivergence:   1530.92\n",
      "variational_beta * kldivergence:  0.15309\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.45204\n",
      "kldivergence:   1440.06\n",
      "variational_beta * kldivergence:  0.14401\n",
      "batch accuracy: 86.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.46710\n",
      "kldivergence:   1596.28\n",
      "variational_beta * kldivergence:  0.15963\n",
      "batch accuracy: 84.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.44547\n",
      "kldivergence:   1626.03\n",
      "variational_beta * kldivergence:  0.16260\n",
      "batch accuracy: 86.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.54585\n",
      "kldivergence:   1673.77\n",
      "variational_beta * kldivergence:  0.16738\n",
      "batch accuracy: 83.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.44624\n",
      "kldivergence:   1442.61\n",
      "variational_beta * kldivergence:  0.14426\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.39573\n",
      "kldivergence:   1426.78\n",
      "variational_beta * kldivergence:  0.14268\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.45380\n",
      "kldivergence:   1534.33\n",
      "variational_beta * kldivergence:  0.15343\n",
      "batch accuracy: 85.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.48578\n",
      "kldivergence:   1588.03\n",
      "variational_beta * kldivergence:  0.15880\n",
      "batch accuracy: 84.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.43169\n",
      "kldivergence:   1439.29\n",
      "variational_beta * kldivergence:  0.14393\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.55248\n",
      "kldivergence:   1734.37\n",
      "variational_beta * kldivergence:  0.17344\n",
      "batch accuracy: 82.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.47831\n",
      "kldivergence:   1649.46\n",
      "variational_beta * kldivergence:  0.16495\n",
      "batch accuracy: 85.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.45704\n",
      "kldivergence:   1677.51\n",
      "variational_beta * kldivergence:  0.16775\n",
      "batch accuracy: 85.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.36303\n",
      "kldivergence:   1376.43\n",
      "variational_beta * kldivergence:  0.13764\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.44157\n",
      "kldivergence:   1536.35\n",
      "variational_beta * kldivergence:  0.15364\n",
      "batch accuracy: 86.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.41020\n",
      "kldivergence:   1450.45\n",
      "variational_beta * kldivergence:  0.14505\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.39439\n",
      "kldivergence:   1487.61\n",
      "variational_beta * kldivergence:  0.14876\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.43692\n",
      "kldivergence:   1471.25\n",
      "variational_beta * kldivergence:  0.14713\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.41202\n",
      "kldivergence:   1520.19\n",
      "variational_beta * kldivergence:  0.15202\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.49073\n",
      "kldivergence:   1653.64\n",
      "variational_beta * kldivergence:  0.16536\n",
      "batch accuracy: 85.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.57711\n",
      "kldivergence:   1658.76\n",
      "variational_beta * kldivergence:  0.16588\n",
      "batch accuracy: 82.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.44285\n",
      "kldivergence:   1512.11\n",
      "variational_beta * kldivergence:  0.15121\n",
      "batch accuracy: 86.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.51650\n",
      "kldivergence:   1547.65\n",
      "variational_beta * kldivergence:  0.15477\n",
      "batch accuracy: 83.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.50657\n",
      "kldivergence:   1539.27\n",
      "variational_beta * kldivergence:  0.15393\n",
      "batch accuracy: 84.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.44486\n",
      "kldivergence:   1465.56\n",
      "variational_beta * kldivergence:  0.14656\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.48071\n",
      "kldivergence:   1553.54\n",
      "variational_beta * kldivergence:  0.15535\n",
      "batch accuracy: 84.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.42404\n",
      "kldivergence:   1601.34\n",
      "variational_beta * kldivergence:  0.16013\n",
      "batch accuracy: 86.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.40895\n",
      "kldivergence:   1501.93\n",
      "variational_beta * kldivergence:  0.15019\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.41528\n",
      "kldivergence:   1498.90\n",
      "variational_beta * kldivergence:  0.14989\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.47821\n",
      "kldivergence:   1661.70\n",
      "variational_beta * kldivergence:  0.16617\n",
      "batch accuracy: 84.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.47849\n",
      "kldivergence:   1592.71\n",
      "variational_beta * kldivergence:  0.15927\n",
      "batch accuracy: 84.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.43431\n",
      "kldivergence:   1476.58\n",
      "variational_beta * kldivergence:  0.14766\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #18\n",
      "reconstruction loss: 0.36390\n",
      "kldivergence:   1284.42\n",
      "variational_beta * kldivergence:  0.12844\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "epoch # 18 : train loss is [187.23334145441135] and validation loss is [0.10281199749562177] \n",
      "saved samples\n",
      "Epoch [19 / 150] average reconstruction error: 0.504672\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36880\n",
      "kldivergence:   1503.69\n",
      "variational_beta * kldivergence:  0.15037\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34319\n",
      "kldivergence:   1716.95\n",
      "variational_beta * kldivergence:  0.17170\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34736\n",
      "kldivergence:   1603.96\n",
      "variational_beta * kldivergence:  0.16040\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39678\n",
      "kldivergence:   1602.44\n",
      "variational_beta * kldivergence:  0.16024\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33580\n",
      "kldivergence:   1596.20\n",
      "variational_beta * kldivergence:  0.15962\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32565\n",
      "kldivergence:   1655.12\n",
      "variational_beta * kldivergence:  0.16551\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34503\n",
      "kldivergence:   1612.18\n",
      "variational_beta * kldivergence:  0.16122\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36925\n",
      "kldivergence:   1619.85\n",
      "variational_beta * kldivergence:  0.16199\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29050\n",
      "kldivergence:   1800.14\n",
      "variational_beta * kldivergence:  0.18001\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33934\n",
      "kldivergence:   1800.26\n",
      "variational_beta * kldivergence:  0.18003\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34667\n",
      "kldivergence:   1684.92\n",
      "variational_beta * kldivergence:  0.16849\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32512\n",
      "kldivergence:   1493.90\n",
      "variational_beta * kldivergence:  0.14939\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37846\n",
      "kldivergence:   1768.78\n",
      "variational_beta * kldivergence:  0.17688\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36205\n",
      "kldivergence:   1590.21\n",
      "variational_beta * kldivergence:  0.15902\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31471\n",
      "kldivergence:   1913.47\n",
      "variational_beta * kldivergence:  0.19135\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30764\n",
      "kldivergence:   1726.82\n",
      "variational_beta * kldivergence:  0.17268\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31121\n",
      "kldivergence:   1458.45\n",
      "variational_beta * kldivergence:  0.14584\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35447\n",
      "kldivergence:   1525.22\n",
      "variational_beta * kldivergence:  0.15252\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33783\n",
      "kldivergence:   1630.50\n",
      "variational_beta * kldivergence:  0.16305\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37116\n",
      "kldivergence:   1746.68\n",
      "variational_beta * kldivergence:  0.17467\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39265\n",
      "kldivergence:   1785.22\n",
      "variational_beta * kldivergence:  0.17852\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35195\n",
      "kldivergence:   1638.16\n",
      "variational_beta * kldivergence:  0.16382\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30778\n",
      "kldivergence:   1418.12\n",
      "variational_beta * kldivergence:  0.14181\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37137\n",
      "kldivergence:   1797.17\n",
      "variational_beta * kldivergence:  0.17972\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34705\n",
      "kldivergence:   1757.74\n",
      "variational_beta * kldivergence:  0.17577\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34411\n",
      "kldivergence:   1857.46\n",
      "variational_beta * kldivergence:  0.18575\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33093\n",
      "kldivergence:   1628.33\n",
      "variational_beta * kldivergence:  0.16283\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39129\n",
      "kldivergence:   1766.73\n",
      "variational_beta * kldivergence:  0.17667\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39230\n",
      "kldivergence:   1979.71\n",
      "variational_beta * kldivergence:  0.19797\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30413\n",
      "kldivergence:   1704.77\n",
      "variational_beta * kldivergence:  0.17048\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34197\n",
      "kldivergence:   1616.59\n",
      "variational_beta * kldivergence:  0.16166\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33560\n",
      "kldivergence:   1813.72\n",
      "variational_beta * kldivergence:  0.18137\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36535\n",
      "kldivergence:   2137.80\n",
      "variational_beta * kldivergence:  0.21378\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33148\n",
      "kldivergence:   1575.77\n",
      "variational_beta * kldivergence:  0.15758\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.38651\n",
      "kldivergence:   1646.70\n",
      "variational_beta * kldivergence:  0.16467\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33724\n",
      "kldivergence:   1673.64\n",
      "variational_beta * kldivergence:  0.16736\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32662\n",
      "kldivergence:   1428.35\n",
      "variational_beta * kldivergence:  0.14283\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34699\n",
      "kldivergence:   1536.88\n",
      "variational_beta * kldivergence:  0.15369\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36081\n",
      "kldivergence:   1554.78\n",
      "variational_beta * kldivergence:  0.15548\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32496\n",
      "kldivergence:   1549.94\n",
      "variational_beta * kldivergence:  0.15499\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32875\n",
      "kldivergence:   1534.54\n",
      "variational_beta * kldivergence:  0.15345\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34178\n",
      "kldivergence:   1594.01\n",
      "variational_beta * kldivergence:  0.15940\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37940\n",
      "kldivergence:   1677.46\n",
      "variational_beta * kldivergence:  0.16775\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.38539\n",
      "kldivergence:   1844.25\n",
      "variational_beta * kldivergence:  0.18442\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34123\n",
      "kldivergence:   1585.27\n",
      "variational_beta * kldivergence:  0.15853\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30494\n",
      "kldivergence:   1667.42\n",
      "variational_beta * kldivergence:  0.16674\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33279\n",
      "kldivergence:   1534.51\n",
      "variational_beta * kldivergence:  0.15345\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32447\n",
      "kldivergence:   1846.39\n",
      "variational_beta * kldivergence:  0.18464\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28213\n",
      "kldivergence:   1608.82\n",
      "variational_beta * kldivergence:  0.16088\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35274\n",
      "kldivergence:   1626.60\n",
      "variational_beta * kldivergence:  0.16266\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31917\n",
      "kldivergence:   1487.96\n",
      "variational_beta * kldivergence:  0.14880\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36250\n",
      "kldivergence:   1916.93\n",
      "variational_beta * kldivergence:  0.19169\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31085\n",
      "kldivergence:   1475.01\n",
      "variational_beta * kldivergence:  0.14750\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33280\n",
      "kldivergence:   1622.91\n",
      "variational_beta * kldivergence:  0.16229\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.27469\n",
      "kldivergence:   1364.87\n",
      "variational_beta * kldivergence:  0.13649\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37466\n",
      "kldivergence:   1584.61\n",
      "variational_beta * kldivergence:  0.15846\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32683\n",
      "kldivergence:   1569.41\n",
      "variational_beta * kldivergence:  0.15694\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30421\n",
      "kldivergence:   1718.84\n",
      "variational_beta * kldivergence:  0.17188\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35193\n",
      "kldivergence:   1669.84\n",
      "variational_beta * kldivergence:  0.16698\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34824\n",
      "kldivergence:   1632.52\n",
      "variational_beta * kldivergence:  0.16325\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34874\n",
      "kldivergence:   1738.36\n",
      "variational_beta * kldivergence:  0.17384\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36618\n",
      "kldivergence:   1663.17\n",
      "variational_beta * kldivergence:  0.16632\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33285\n",
      "kldivergence:   1564.36\n",
      "variational_beta * kldivergence:  0.15644\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32234\n",
      "kldivergence:   1817.37\n",
      "variational_beta * kldivergence:  0.18174\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34031\n",
      "kldivergence:   1766.08\n",
      "variational_beta * kldivergence:  0.17661\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32049\n",
      "kldivergence:   1335.08\n",
      "variational_beta * kldivergence:  0.13351\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29335\n",
      "kldivergence:   1451.43\n",
      "variational_beta * kldivergence:  0.14514\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35475\n",
      "kldivergence:   1824.63\n",
      "variational_beta * kldivergence:  0.18246\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31867\n",
      "kldivergence:   1430.59\n",
      "variational_beta * kldivergence:  0.14306\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32290\n",
      "kldivergence:   1536.36\n",
      "variational_beta * kldivergence:  0.15364\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31146\n",
      "kldivergence:   1794.19\n",
      "variational_beta * kldivergence:  0.17942\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30302\n",
      "kldivergence:   1661.79\n",
      "variational_beta * kldivergence:  0.16618\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34507\n",
      "kldivergence:   1635.01\n",
      "variational_beta * kldivergence:  0.16350\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36520\n",
      "kldivergence:   1630.55\n",
      "variational_beta * kldivergence:  0.16305\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32824\n",
      "kldivergence:   1729.91\n",
      "variational_beta * kldivergence:  0.17299\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34957\n",
      "kldivergence:   1752.57\n",
      "variational_beta * kldivergence:  0.17526\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33165\n",
      "kldivergence:   1742.75\n",
      "variational_beta * kldivergence:  0.17428\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32006\n",
      "kldivergence:   1645.84\n",
      "variational_beta * kldivergence:  0.16458\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30612\n",
      "kldivergence:   1499.99\n",
      "variational_beta * kldivergence:  0.15000\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36273\n",
      "kldivergence:   1656.79\n",
      "variational_beta * kldivergence:  0.16568\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33908\n",
      "kldivergence:   1914.31\n",
      "variational_beta * kldivergence:  0.19143\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33229\n",
      "kldivergence:   1748.26\n",
      "variational_beta * kldivergence:  0.17483\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29970\n",
      "kldivergence:   1922.25\n",
      "variational_beta * kldivergence:  0.19223\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32021\n",
      "kldivergence:   1407.14\n",
      "variational_beta * kldivergence:  0.14071\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33804\n",
      "kldivergence:   1592.38\n",
      "variational_beta * kldivergence:  0.15924\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29467\n",
      "kldivergence:   1448.87\n",
      "variational_beta * kldivergence:  0.14489\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36785\n",
      "kldivergence:   1482.44\n",
      "variational_beta * kldivergence:  0.14824\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33798\n",
      "kldivergence:   1616.63\n",
      "variational_beta * kldivergence:  0.16166\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32897\n",
      "kldivergence:   1605.34\n",
      "variational_beta * kldivergence:  0.16053\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31782\n",
      "kldivergence:   1610.80\n",
      "variational_beta * kldivergence:  0.16108\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31778\n",
      "kldivergence:   1579.66\n",
      "variational_beta * kldivergence:  0.15797\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29229\n",
      "kldivergence:   1464.81\n",
      "variational_beta * kldivergence:  0.14648\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28264\n",
      "kldivergence:   1347.92\n",
      "variational_beta * kldivergence:  0.13479\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34570\n",
      "kldivergence:   1690.34\n",
      "variational_beta * kldivergence:  0.16903\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34461\n",
      "kldivergence:   1711.30\n",
      "variational_beta * kldivergence:  0.17113\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36256\n",
      "kldivergence:   1604.40\n",
      "variational_beta * kldivergence:  0.16044\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30287\n",
      "kldivergence:   1468.33\n",
      "variational_beta * kldivergence:  0.14683\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34660\n",
      "kldivergence:   1737.55\n",
      "variational_beta * kldivergence:  0.17375\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32865\n",
      "kldivergence:   1848.34\n",
      "variational_beta * kldivergence:  0.18483\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.40216\n",
      "kldivergence:   1620.21\n",
      "variational_beta * kldivergence:  0.16202\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32206\n",
      "kldivergence:   1574.63\n",
      "variational_beta * kldivergence:  0.15746\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30689\n",
      "kldivergence:   1470.51\n",
      "variational_beta * kldivergence:  0.14705\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33260\n",
      "kldivergence:   1780.72\n",
      "variational_beta * kldivergence:  0.17807\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37082\n",
      "kldivergence:   1725.75\n",
      "variational_beta * kldivergence:  0.17258\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35239\n",
      "kldivergence:   1672.07\n",
      "variational_beta * kldivergence:  0.16721\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34750\n",
      "kldivergence:   1735.32\n",
      "variational_beta * kldivergence:  0.17353\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.40421\n",
      "kldivergence:   1698.82\n",
      "variational_beta * kldivergence:  0.16988\n",
      "batch accuracy: 86.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34389\n",
      "kldivergence:   1632.05\n",
      "variational_beta * kldivergence:  0.16320\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33606\n",
      "kldivergence:   1781.06\n",
      "variational_beta * kldivergence:  0.17811\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37381\n",
      "kldivergence:   1825.15\n",
      "variational_beta * kldivergence:  0.18251\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34171\n",
      "kldivergence:   1650.44\n",
      "variational_beta * kldivergence:  0.16504\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34890\n",
      "kldivergence:   1586.35\n",
      "variational_beta * kldivergence:  0.15864\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28615\n",
      "kldivergence:   1404.71\n",
      "variational_beta * kldivergence:  0.14047\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34631\n",
      "kldivergence:   1694.37\n",
      "variational_beta * kldivergence:  0.16944\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30898\n",
      "kldivergence:   1539.88\n",
      "variational_beta * kldivergence:  0.15399\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31525\n",
      "kldivergence:   1600.71\n",
      "variational_beta * kldivergence:  0.16007\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32091\n",
      "kldivergence:   1350.51\n",
      "variational_beta * kldivergence:  0.13505\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31294\n",
      "kldivergence:   1605.37\n",
      "variational_beta * kldivergence:  0.16054\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39752\n",
      "kldivergence:   1778.28\n",
      "variational_beta * kldivergence:  0.17783\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31381\n",
      "kldivergence:   1774.27\n",
      "variational_beta * kldivergence:  0.17743\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34096\n",
      "kldivergence:   1843.58\n",
      "variational_beta * kldivergence:  0.18436\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30487\n",
      "kldivergence:   1594.18\n",
      "variational_beta * kldivergence:  0.15942\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36796\n",
      "kldivergence:   1639.05\n",
      "variational_beta * kldivergence:  0.16390\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35826\n",
      "kldivergence:   1572.23\n",
      "variational_beta * kldivergence:  0.15722\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28996\n",
      "kldivergence:   1491.27\n",
      "variational_beta * kldivergence:  0.14913\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34788\n",
      "kldivergence:   1578.91\n",
      "variational_beta * kldivergence:  0.15789\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35625\n",
      "kldivergence:   1763.43\n",
      "variational_beta * kldivergence:  0.17634\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29983\n",
      "kldivergence:   1624.62\n",
      "variational_beta * kldivergence:  0.16246\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37087\n",
      "kldivergence:   1794.77\n",
      "variational_beta * kldivergence:  0.17948\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33473\n",
      "kldivergence:   1768.11\n",
      "variational_beta * kldivergence:  0.17681\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37606\n",
      "kldivergence:   1764.75\n",
      "variational_beta * kldivergence:  0.17647\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33495\n",
      "kldivergence:   1696.41\n",
      "variational_beta * kldivergence:  0.16964\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34158\n",
      "kldivergence:   1814.46\n",
      "variational_beta * kldivergence:  0.18145\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28710\n",
      "kldivergence:   1713.45\n",
      "variational_beta * kldivergence:  0.17134\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31633\n",
      "kldivergence:   1704.08\n",
      "variational_beta * kldivergence:  0.17041\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30357\n",
      "kldivergence:   1728.58\n",
      "variational_beta * kldivergence:  0.17286\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33679\n",
      "kldivergence:   1669.86\n",
      "variational_beta * kldivergence:  0.16699\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32855\n",
      "kldivergence:   1674.50\n",
      "variational_beta * kldivergence:  0.16745\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30231\n",
      "kldivergence:   1761.65\n",
      "variational_beta * kldivergence:  0.17616\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.27525\n",
      "kldivergence:   1525.71\n",
      "variational_beta * kldivergence:  0.15257\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28542\n",
      "kldivergence:   1559.34\n",
      "variational_beta * kldivergence:  0.15593\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33238\n",
      "kldivergence:   1780.46\n",
      "variational_beta * kldivergence:  0.17805\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30151\n",
      "kldivergence:   1612.65\n",
      "variational_beta * kldivergence:  0.16127\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32443\n",
      "kldivergence:   1609.02\n",
      "variational_beta * kldivergence:  0.16090\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37487\n",
      "kldivergence:   1895.50\n",
      "variational_beta * kldivergence:  0.18955\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39423\n",
      "kldivergence:   1751.30\n",
      "variational_beta * kldivergence:  0.17513\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32494\n",
      "kldivergence:   1576.73\n",
      "variational_beta * kldivergence:  0.15767\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33407\n",
      "kldivergence:   1636.58\n",
      "variational_beta * kldivergence:  0.16366\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35179\n",
      "kldivergence:   1397.41\n",
      "variational_beta * kldivergence:  0.13974\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36570\n",
      "kldivergence:   1579.16\n",
      "variational_beta * kldivergence:  0.15792\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31082\n",
      "kldivergence:   1624.23\n",
      "variational_beta * kldivergence:  0.16242\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31992\n",
      "kldivergence:   1584.16\n",
      "variational_beta * kldivergence:  0.15842\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39078\n",
      "kldivergence:   1638.77\n",
      "variational_beta * kldivergence:  0.16388\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39134\n",
      "kldivergence:   1820.89\n",
      "variational_beta * kldivergence:  0.18209\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34109\n",
      "kldivergence:   1597.20\n",
      "variational_beta * kldivergence:  0.15972\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35344\n",
      "kldivergence:   1544.15\n",
      "variational_beta * kldivergence:  0.15441\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33513\n",
      "kldivergence:   1754.67\n",
      "variational_beta * kldivergence:  0.17547\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36309\n",
      "kldivergence:   1654.61\n",
      "variational_beta * kldivergence:  0.16546\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36005\n",
      "kldivergence:   1906.00\n",
      "variational_beta * kldivergence:  0.19060\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35406\n",
      "kldivergence:   1516.07\n",
      "variational_beta * kldivergence:  0.15161\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32029\n",
      "kldivergence:   1478.53\n",
      "variational_beta * kldivergence:  0.14785\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.38210\n",
      "kldivergence:   1695.52\n",
      "variational_beta * kldivergence:  0.16955\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30888\n",
      "kldivergence:   1527.54\n",
      "variational_beta * kldivergence:  0.15275\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36057\n",
      "kldivergence:   1784.22\n",
      "variational_beta * kldivergence:  0.17842\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34306\n",
      "kldivergence:   2039.87\n",
      "variational_beta * kldivergence:  0.20399\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33571\n",
      "kldivergence:   1575.30\n",
      "variational_beta * kldivergence:  0.15753\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34285\n",
      "kldivergence:   1826.61\n",
      "variational_beta * kldivergence:  0.18266\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30455\n",
      "kldivergence:   1722.48\n",
      "variational_beta * kldivergence:  0.17225\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.24824\n",
      "kldivergence:   1854.80\n",
      "variational_beta * kldivergence:  0.18548\n",
      "batch accuracy: 91.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33549\n",
      "kldivergence:   1723.97\n",
      "variational_beta * kldivergence:  0.17240\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29128\n",
      "kldivergence:   1712.60\n",
      "variational_beta * kldivergence:  0.17126\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30303\n",
      "kldivergence:   1544.65\n",
      "variational_beta * kldivergence:  0.15446\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35147\n",
      "kldivergence:   1573.59\n",
      "variational_beta * kldivergence:  0.15736\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34576\n",
      "kldivergence:   1626.54\n",
      "variational_beta * kldivergence:  0.16265\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31326\n",
      "kldivergence:   1750.83\n",
      "variational_beta * kldivergence:  0.17508\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32504\n",
      "kldivergence:   1545.82\n",
      "variational_beta * kldivergence:  0.15458\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37490\n",
      "kldivergence:   1501.73\n",
      "variational_beta * kldivergence:  0.15017\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35679\n",
      "kldivergence:   1601.05\n",
      "variational_beta * kldivergence:  0.16011\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34772\n",
      "kldivergence:   1543.35\n",
      "variational_beta * kldivergence:  0.15434\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33959\n",
      "kldivergence:   1720.64\n",
      "variational_beta * kldivergence:  0.17206\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.38429\n",
      "kldivergence:   2004.21\n",
      "variational_beta * kldivergence:  0.20042\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39553\n",
      "kldivergence:   2032.71\n",
      "variational_beta * kldivergence:  0.20327\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32844\n",
      "kldivergence:   1703.85\n",
      "variational_beta * kldivergence:  0.17038\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39120\n",
      "kldivergence:   1723.90\n",
      "variational_beta * kldivergence:  0.17239\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35881\n",
      "kldivergence:   1625.01\n",
      "variational_beta * kldivergence:  0.16250\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33060\n",
      "kldivergence:   1465.02\n",
      "variational_beta * kldivergence:  0.14650\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34176\n",
      "kldivergence:   1699.08\n",
      "variational_beta * kldivergence:  0.16991\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32480\n",
      "kldivergence:   1565.80\n",
      "variational_beta * kldivergence:  0.15658\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34036\n",
      "kldivergence:   1354.48\n",
      "variational_beta * kldivergence:  0.13545\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33300\n",
      "kldivergence:   1593.42\n",
      "variational_beta * kldivergence:  0.15934\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35252\n",
      "kldivergence:   1716.57\n",
      "variational_beta * kldivergence:  0.17166\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30589\n",
      "kldivergence:   1824.19\n",
      "variational_beta * kldivergence:  0.18242\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30654\n",
      "kldivergence:   1592.65\n",
      "variational_beta * kldivergence:  0.15926\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.41522\n",
      "kldivergence:   1560.16\n",
      "variational_beta * kldivergence:  0.15602\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35939\n",
      "kldivergence:   1735.93\n",
      "variational_beta * kldivergence:  0.17359\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34968\n",
      "kldivergence:   1618.35\n",
      "variational_beta * kldivergence:  0.16183\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34412\n",
      "kldivergence:   1827.31\n",
      "variational_beta * kldivergence:  0.18273\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39015\n",
      "kldivergence:   1854.42\n",
      "variational_beta * kldivergence:  0.18544\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32281\n",
      "kldivergence:   1740.64\n",
      "variational_beta * kldivergence:  0.17406\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33879\n",
      "kldivergence:   1522.95\n",
      "variational_beta * kldivergence:  0.15230\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37453\n",
      "kldivergence:   1611.31\n",
      "variational_beta * kldivergence:  0.16113\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31524\n",
      "kldivergence:   1605.88\n",
      "variational_beta * kldivergence:  0.16059\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32350\n",
      "kldivergence:   1659.82\n",
      "variational_beta * kldivergence:  0.16598\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33329\n",
      "kldivergence:   1771.43\n",
      "variational_beta * kldivergence:  0.17714\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.27328\n",
      "kldivergence:   1730.14\n",
      "variational_beta * kldivergence:  0.17301\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35557\n",
      "kldivergence:   1530.47\n",
      "variational_beta * kldivergence:  0.15305\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37269\n",
      "kldivergence:   1782.92\n",
      "variational_beta * kldivergence:  0.17829\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34201\n",
      "kldivergence:   1663.69\n",
      "variational_beta * kldivergence:  0.16637\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.40410\n",
      "kldivergence:   1695.59\n",
      "variational_beta * kldivergence:  0.16956\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29265\n",
      "kldivergence:   1549.04\n",
      "variational_beta * kldivergence:  0.15490\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32014\n",
      "kldivergence:   1709.01\n",
      "variational_beta * kldivergence:  0.17090\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32644\n",
      "kldivergence:   1727.63\n",
      "variational_beta * kldivergence:  0.17276\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37330\n",
      "kldivergence:   1540.25\n",
      "variational_beta * kldivergence:  0.15403\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.41856\n",
      "kldivergence:   2071.41\n",
      "variational_beta * kldivergence:  0.20714\n",
      "batch accuracy: 86.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36975\n",
      "kldivergence:   1659.45\n",
      "variational_beta * kldivergence:  0.16595\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.38739\n",
      "kldivergence:   1750.90\n",
      "variational_beta * kldivergence:  0.17509\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39279\n",
      "kldivergence:   1610.59\n",
      "variational_beta * kldivergence:  0.16106\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31147\n",
      "kldivergence:   1408.65\n",
      "variational_beta * kldivergence:  0.14086\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30389\n",
      "kldivergence:   1686.52\n",
      "variational_beta * kldivergence:  0.16865\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35154\n",
      "kldivergence:   1813.17\n",
      "variational_beta * kldivergence:  0.18132\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34068\n",
      "kldivergence:   1502.97\n",
      "variational_beta * kldivergence:  0.15030\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.26867\n",
      "kldivergence:   1740.82\n",
      "variational_beta * kldivergence:  0.17408\n",
      "batch accuracy: 91.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32521\n",
      "kldivergence:   1614.86\n",
      "variational_beta * kldivergence:  0.16149\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36180\n",
      "kldivergence:   1635.03\n",
      "variational_beta * kldivergence:  0.16350\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35107\n",
      "kldivergence:   1704.50\n",
      "variational_beta * kldivergence:  0.17045\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32068\n",
      "kldivergence:   1559.46\n",
      "variational_beta * kldivergence:  0.15595\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36554\n",
      "kldivergence:   1822.10\n",
      "variational_beta * kldivergence:  0.18221\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36789\n",
      "kldivergence:   1918.47\n",
      "variational_beta * kldivergence:  0.19185\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34143\n",
      "kldivergence:   1558.08\n",
      "variational_beta * kldivergence:  0.15581\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35419\n",
      "kldivergence:   1942.53\n",
      "variational_beta * kldivergence:  0.19425\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33236\n",
      "kldivergence:   1693.17\n",
      "variational_beta * kldivergence:  0.16932\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34389\n",
      "kldivergence:   1790.39\n",
      "variational_beta * kldivergence:  0.17904\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37272\n",
      "kldivergence:   2175.26\n",
      "variational_beta * kldivergence:  0.21753\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29744\n",
      "kldivergence:   1556.20\n",
      "variational_beta * kldivergence:  0.15562\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32282\n",
      "kldivergence:   1586.61\n",
      "variational_beta * kldivergence:  0.15866\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33618\n",
      "kldivergence:   1794.07\n",
      "variational_beta * kldivergence:  0.17941\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28295\n",
      "kldivergence:   1475.12\n",
      "variational_beta * kldivergence:  0.14751\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.40101\n",
      "kldivergence:   1783.92\n",
      "variational_beta * kldivergence:  0.17839\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35196\n",
      "kldivergence:   1719.47\n",
      "variational_beta * kldivergence:  0.17195\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31411\n",
      "kldivergence:   1670.09\n",
      "variational_beta * kldivergence:  0.16701\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37366\n",
      "kldivergence:   1826.97\n",
      "variational_beta * kldivergence:  0.18270\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33349\n",
      "kldivergence:   1802.28\n",
      "variational_beta * kldivergence:  0.18023\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29997\n",
      "kldivergence:   1611.43\n",
      "variational_beta * kldivergence:  0.16114\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33296\n",
      "kldivergence:   1608.07\n",
      "variational_beta * kldivergence:  0.16081\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35735\n",
      "kldivergence:   1692.67\n",
      "variational_beta * kldivergence:  0.16927\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32312\n",
      "kldivergence:   1607.32\n",
      "variational_beta * kldivergence:  0.16073\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32486\n",
      "kldivergence:   1612.69\n",
      "variational_beta * kldivergence:  0.16127\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31168\n",
      "kldivergence:   1400.83\n",
      "variational_beta * kldivergence:  0.14008\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33726\n",
      "kldivergence:   1583.42\n",
      "variational_beta * kldivergence:  0.15834\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32484\n",
      "kldivergence:   1494.77\n",
      "variational_beta * kldivergence:  0.14948\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.27570\n",
      "kldivergence:   1401.02\n",
      "variational_beta * kldivergence:  0.14010\n",
      "batch accuracy: 91.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36952\n",
      "kldivergence:   1817.36\n",
      "variational_beta * kldivergence:  0.18174\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.40539\n",
      "kldivergence:   1787.64\n",
      "variational_beta * kldivergence:  0.17876\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37531\n",
      "kldivergence:   1773.17\n",
      "variational_beta * kldivergence:  0.17732\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35989\n",
      "kldivergence:   1656.99\n",
      "variational_beta * kldivergence:  0.16570\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32170\n",
      "kldivergence:   1495.20\n",
      "variational_beta * kldivergence:  0.14952\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31747\n",
      "kldivergence:   1457.99\n",
      "variational_beta * kldivergence:  0.14580\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33450\n",
      "kldivergence:   1639.40\n",
      "variational_beta * kldivergence:  0.16394\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32590\n",
      "kldivergence:   1516.14\n",
      "variational_beta * kldivergence:  0.15161\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29916\n",
      "kldivergence:   1467.99\n",
      "variational_beta * kldivergence:  0.14680\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.38217\n",
      "kldivergence:   1799.63\n",
      "variational_beta * kldivergence:  0.17996\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.38478\n",
      "kldivergence:   1664.52\n",
      "variational_beta * kldivergence:  0.16645\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32684\n",
      "kldivergence:   1500.38\n",
      "variational_beta * kldivergence:  0.15004\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30202\n",
      "kldivergence:   1473.00\n",
      "variational_beta * kldivergence:  0.14730\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37725\n",
      "kldivergence:   1714.74\n",
      "variational_beta * kldivergence:  0.17147\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35699\n",
      "kldivergence:   1499.52\n",
      "variational_beta * kldivergence:  0.14995\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32325\n",
      "kldivergence:   1498.63\n",
      "variational_beta * kldivergence:  0.14986\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35571\n",
      "kldivergence:   1548.43\n",
      "variational_beta * kldivergence:  0.15484\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32079\n",
      "kldivergence:   1675.84\n",
      "variational_beta * kldivergence:  0.16758\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28795\n",
      "kldivergence:   1400.45\n",
      "variational_beta * kldivergence:  0.14004\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30037\n",
      "kldivergence:   1381.00\n",
      "variational_beta * kldivergence:  0.13810\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.39364\n",
      "kldivergence:   1624.29\n",
      "variational_beta * kldivergence:  0.16243\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28499\n",
      "kldivergence:   1452.41\n",
      "variational_beta * kldivergence:  0.14524\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36427\n",
      "kldivergence:   1742.37\n",
      "variational_beta * kldivergence:  0.17424\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31703\n",
      "kldivergence:   1442.58\n",
      "variational_beta * kldivergence:  0.14426\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32727\n",
      "kldivergence:   1566.65\n",
      "variational_beta * kldivergence:  0.15666\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31959\n",
      "kldivergence:   1670.96\n",
      "variational_beta * kldivergence:  0.16710\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31938\n",
      "kldivergence:   1780.23\n",
      "variational_beta * kldivergence:  0.17802\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34669\n",
      "kldivergence:   1621.09\n",
      "variational_beta * kldivergence:  0.16211\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33856\n",
      "kldivergence:   1371.41\n",
      "variational_beta * kldivergence:  0.13714\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37975\n",
      "kldivergence:   1778.45\n",
      "variational_beta * kldivergence:  0.17785\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31976\n",
      "kldivergence:   1545.53\n",
      "variational_beta * kldivergence:  0.15455\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37022\n",
      "kldivergence:   1969.43\n",
      "variational_beta * kldivergence:  0.19694\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37233\n",
      "kldivergence:   1665.38\n",
      "variational_beta * kldivergence:  0.16654\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34343\n",
      "kldivergence:   1737.29\n",
      "variational_beta * kldivergence:  0.17373\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28227\n",
      "kldivergence:   1824.73\n",
      "variational_beta * kldivergence:  0.18247\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34875\n",
      "kldivergence:   1490.44\n",
      "variational_beta * kldivergence:  0.14904\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29828\n",
      "kldivergence:   1609.87\n",
      "variational_beta * kldivergence:  0.16099\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35580\n",
      "kldivergence:   1625.27\n",
      "variational_beta * kldivergence:  0.16253\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33454\n",
      "kldivergence:   1554.97\n",
      "variational_beta * kldivergence:  0.15550\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33162\n",
      "kldivergence:   1630.61\n",
      "variational_beta * kldivergence:  0.16306\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36185\n",
      "kldivergence:   1922.80\n",
      "variational_beta * kldivergence:  0.19228\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37111\n",
      "kldivergence:   1710.49\n",
      "variational_beta * kldivergence:  0.17105\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.27048\n",
      "kldivergence:   1503.88\n",
      "variational_beta * kldivergence:  0.15039\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32943\n",
      "kldivergence:   1618.07\n",
      "variational_beta * kldivergence:  0.16181\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36684\n",
      "kldivergence:   1721.12\n",
      "variational_beta * kldivergence:  0.17211\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34707\n",
      "kldivergence:   1909.60\n",
      "variational_beta * kldivergence:  0.19096\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33977\n",
      "kldivergence:   1692.07\n",
      "variational_beta * kldivergence:  0.16921\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36604\n",
      "kldivergence:   1495.78\n",
      "variational_beta * kldivergence:  0.14958\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34293\n",
      "kldivergence:   1367.53\n",
      "variational_beta * kldivergence:  0.13675\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34487\n",
      "kldivergence:   1616.87\n",
      "variational_beta * kldivergence:  0.16169\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34980\n",
      "kldivergence:   1650.47\n",
      "variational_beta * kldivergence:  0.16505\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29975\n",
      "kldivergence:   1776.51\n",
      "variational_beta * kldivergence:  0.17765\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33790\n",
      "kldivergence:   1580.78\n",
      "variational_beta * kldivergence:  0.15808\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30570\n",
      "kldivergence:   1444.48\n",
      "variational_beta * kldivergence:  0.14445\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37947\n",
      "kldivergence:   1854.14\n",
      "variational_beta * kldivergence:  0.18541\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34094\n",
      "kldivergence:   1609.33\n",
      "variational_beta * kldivergence:  0.16093\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30575\n",
      "kldivergence:   1482.40\n",
      "variational_beta * kldivergence:  0.14824\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32374\n",
      "kldivergence:   1536.87\n",
      "variational_beta * kldivergence:  0.15369\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37476\n",
      "kldivergence:   1640.61\n",
      "variational_beta * kldivergence:  0.16406\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35821\n",
      "kldivergence:   1638.85\n",
      "variational_beta * kldivergence:  0.16388\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34976\n",
      "kldivergence:   1624.91\n",
      "variational_beta * kldivergence:  0.16249\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34673\n",
      "kldivergence:   1752.34\n",
      "variational_beta * kldivergence:  0.17523\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32326\n",
      "kldivergence:   1542.69\n",
      "variational_beta * kldivergence:  0.15427\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29688\n",
      "kldivergence:   1412.05\n",
      "variational_beta * kldivergence:  0.14120\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33020\n",
      "kldivergence:   1627.47\n",
      "variational_beta * kldivergence:  0.16275\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33927\n",
      "kldivergence:   1696.58\n",
      "variational_beta * kldivergence:  0.16966\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35413\n",
      "kldivergence:   1750.17\n",
      "variational_beta * kldivergence:  0.17502\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31931\n",
      "kldivergence:   1493.40\n",
      "variational_beta * kldivergence:  0.14934\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34801\n",
      "kldivergence:   1764.24\n",
      "variational_beta * kldivergence:  0.17642\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36861\n",
      "kldivergence:   1621.75\n",
      "variational_beta * kldivergence:  0.16217\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31095\n",
      "kldivergence:   1771.41\n",
      "variational_beta * kldivergence:  0.17714\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32264\n",
      "kldivergence:   1653.14\n",
      "variational_beta * kldivergence:  0.16531\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32342\n",
      "kldivergence:   1626.79\n",
      "variational_beta * kldivergence:  0.16268\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34908\n",
      "kldivergence:   1616.63\n",
      "variational_beta * kldivergence:  0.16166\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29098\n",
      "kldivergence:   1329.35\n",
      "variational_beta * kldivergence:  0.13293\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31561\n",
      "kldivergence:   1980.46\n",
      "variational_beta * kldivergence:  0.19805\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28662\n",
      "kldivergence:   1339.88\n",
      "variational_beta * kldivergence:  0.13399\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29109\n",
      "kldivergence:   1484.93\n",
      "variational_beta * kldivergence:  0.14849\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31345\n",
      "kldivergence:   1363.44\n",
      "variational_beta * kldivergence:  0.13634\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31986\n",
      "kldivergence:   1733.52\n",
      "variational_beta * kldivergence:  0.17335\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30418\n",
      "kldivergence:   1468.02\n",
      "variational_beta * kldivergence:  0.14680\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34909\n",
      "kldivergence:   1784.12\n",
      "variational_beta * kldivergence:  0.17841\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32718\n",
      "kldivergence:   1659.18\n",
      "variational_beta * kldivergence:  0.16592\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34030\n",
      "kldivergence:   1508.95\n",
      "variational_beta * kldivergence:  0.15090\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37085\n",
      "kldivergence:   1506.95\n",
      "variational_beta * kldivergence:  0.15069\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37609\n",
      "kldivergence:   1503.57\n",
      "variational_beta * kldivergence:  0.15036\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33542\n",
      "kldivergence:   1575.72\n",
      "variational_beta * kldivergence:  0.15757\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34160\n",
      "kldivergence:   1955.16\n",
      "variational_beta * kldivergence:  0.19552\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36326\n",
      "kldivergence:   1636.69\n",
      "variational_beta * kldivergence:  0.16367\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32827\n",
      "kldivergence:   1511.91\n",
      "variational_beta * kldivergence:  0.15119\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35583\n",
      "kldivergence:   1489.96\n",
      "variational_beta * kldivergence:  0.14900\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30511\n",
      "kldivergence:   1427.66\n",
      "variational_beta * kldivergence:  0.14277\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37014\n",
      "kldivergence:   1660.18\n",
      "variational_beta * kldivergence:  0.16602\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36080\n",
      "kldivergence:   1600.27\n",
      "variational_beta * kldivergence:  0.16003\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31939\n",
      "kldivergence:   1691.74\n",
      "variational_beta * kldivergence:  0.16917\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29675\n",
      "kldivergence:   1645.50\n",
      "variational_beta * kldivergence:  0.16455\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36441\n",
      "kldivergence:   1586.55\n",
      "variational_beta * kldivergence:  0.15865\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35860\n",
      "kldivergence:   1573.19\n",
      "variational_beta * kldivergence:  0.15732\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.29735\n",
      "kldivergence:   1361.25\n",
      "variational_beta * kldivergence:  0.13613\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36376\n",
      "kldivergence:   1629.30\n",
      "variational_beta * kldivergence:  0.16293\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36875\n",
      "kldivergence:   1588.64\n",
      "variational_beta * kldivergence:  0.15886\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32674\n",
      "kldivergence:   1470.10\n",
      "variational_beta * kldivergence:  0.14701\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.28307\n",
      "kldivergence:   1652.13\n",
      "variational_beta * kldivergence:  0.16521\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34630\n",
      "kldivergence:   1628.13\n",
      "variational_beta * kldivergence:  0.16281\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33761\n",
      "kldivergence:   1947.25\n",
      "variational_beta * kldivergence:  0.19472\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32231\n",
      "kldivergence:   1568.60\n",
      "variational_beta * kldivergence:  0.15686\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37948\n",
      "kldivergence:   1774.31\n",
      "variational_beta * kldivergence:  0.17743\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37379\n",
      "kldivergence:   1884.40\n",
      "variational_beta * kldivergence:  0.18844\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.37761\n",
      "kldivergence:   1659.22\n",
      "variational_beta * kldivergence:  0.16592\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34516\n",
      "kldivergence:   1665.76\n",
      "variational_beta * kldivergence:  0.16658\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.31615\n",
      "kldivergence:   1571.09\n",
      "variational_beta * kldivergence:  0.15711\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.36253\n",
      "kldivergence:   1494.07\n",
      "variational_beta * kldivergence:  0.14941\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34863\n",
      "kldivergence:   1662.74\n",
      "variational_beta * kldivergence:  0.16627\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35200\n",
      "kldivergence:   1620.61\n",
      "variational_beta * kldivergence:  0.16206\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.35675\n",
      "kldivergence:   1668.18\n",
      "variational_beta * kldivergence:  0.16682\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33319\n",
      "kldivergence:   1551.41\n",
      "variational_beta * kldivergence:  0.15514\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.34373\n",
      "kldivergence:   1640.19\n",
      "variational_beta * kldivergence:  0.16402\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.30609\n",
      "kldivergence:   1719.62\n",
      "variational_beta * kldivergence:  0.17196\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.33643\n",
      "kldivergence:   1712.96\n",
      "variational_beta * kldivergence:  0.17130\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #19\n",
      "reconstruction loss: 0.32826\n",
      "kldivergence:   1620.47\n",
      "variational_beta * kldivergence:  0.16205\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.41414\n",
      "kldivergence:   1463.17\n",
      "variational_beta * kldivergence:  0.14632\n",
      "batch accuracy: 86.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.44939\n",
      "kldivergence:   1504.38\n",
      "variational_beta * kldivergence:  0.15044\n",
      "batch accuracy: 86.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.46405\n",
      "kldivergence:   1578.53\n",
      "variational_beta * kldivergence:  0.15785\n",
      "batch accuracy: 86.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.50944\n",
      "kldivergence:   1601.51\n",
      "variational_beta * kldivergence:  0.16015\n",
      "batch accuracy: 84.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.35080\n",
      "kldivergence:   1418.95\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.48574\n",
      "kldivergence:   1674.98\n",
      "variational_beta * kldivergence:  0.16750\n",
      "batch accuracy: 85.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.49929\n",
      "kldivergence:   1607.10\n",
      "variational_beta * kldivergence:  0.16071\n",
      "batch accuracy: 83.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.53935\n",
      "kldivergence:   1674.60\n",
      "variational_beta * kldivergence:  0.16746\n",
      "batch accuracy: 83.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.46631\n",
      "kldivergence:   1546.36\n",
      "variational_beta * kldivergence:  0.15464\n",
      "batch accuracy: 85.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.43448\n",
      "kldivergence:   1583.11\n",
      "variational_beta * kldivergence:  0.15831\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.46563\n",
      "kldivergence:   1494.23\n",
      "variational_beta * kldivergence:  0.14942\n",
      "batch accuracy: 85.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.42038\n",
      "kldivergence:   1530.04\n",
      "variational_beta * kldivergence:  0.15300\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.52942\n",
      "kldivergence:   1594.97\n",
      "variational_beta * kldivergence:  0.15950\n",
      "batch accuracy: 84.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.46762\n",
      "kldivergence:   1599.08\n",
      "variational_beta * kldivergence:  0.15991\n",
      "batch accuracy: 84.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.51603\n",
      "kldivergence:   1634.39\n",
      "variational_beta * kldivergence:  0.16344\n",
      "batch accuracy: 84.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.47593\n",
      "kldivergence:   1628.31\n",
      "variational_beta * kldivergence:  0.16283\n",
      "batch accuracy: 85.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.47766\n",
      "kldivergence:   1554.65\n",
      "variational_beta * kldivergence:  0.15546\n",
      "batch accuracy: 85.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.46602\n",
      "kldivergence:   1519.01\n",
      "variational_beta * kldivergence:  0.15190\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.50221\n",
      "kldivergence:   1514.85\n",
      "variational_beta * kldivergence:  0.15148\n",
      "batch accuracy: 85.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.36838\n",
      "kldivergence:   1426.42\n",
      "variational_beta * kldivergence:  0.14264\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.48469\n",
      "kldivergence:   1572.65\n",
      "variational_beta * kldivergence:  0.15727\n",
      "batch accuracy: 85.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.44437\n",
      "kldivergence:   1570.66\n",
      "variational_beta * kldivergence:  0.15707\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.45780\n",
      "kldivergence:   1474.25\n",
      "variational_beta * kldivergence:  0.14742\n",
      "batch accuracy: 85.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.47250\n",
      "kldivergence:   1440.90\n",
      "variational_beta * kldivergence:  0.14409\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.44319\n",
      "kldivergence:   1456.50\n",
      "variational_beta * kldivergence:  0.14565\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.41248\n",
      "kldivergence:   1480.07\n",
      "variational_beta * kldivergence:  0.14801\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.40644\n",
      "kldivergence:   1486.04\n",
      "variational_beta * kldivergence:  0.14860\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.44356\n",
      "kldivergence:   1491.02\n",
      "variational_beta * kldivergence:  0.14910\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.46523\n",
      "kldivergence:   1654.62\n",
      "variational_beta * kldivergence:  0.16546\n",
      "batch accuracy: 85.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.50481\n",
      "kldivergence:   1554.61\n",
      "variational_beta * kldivergence:  0.15546\n",
      "batch accuracy: 85.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.46014\n",
      "kldivergence:   1605.79\n",
      "variational_beta * kldivergence:  0.16058\n",
      "batch accuracy: 85.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.46172\n",
      "kldivergence:   1534.22\n",
      "variational_beta * kldivergence:  0.15342\n",
      "batch accuracy: 85.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.38477\n",
      "kldivergence:   1450.68\n",
      "variational_beta * kldivergence:  0.14507\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.36376\n",
      "kldivergence:   1440.48\n",
      "variational_beta * kldivergence:  0.14405\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.44350\n",
      "kldivergence:   1526.67\n",
      "variational_beta * kldivergence:  0.15267\n",
      "batch accuracy: 86.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.44714\n",
      "kldivergence:   1563.29\n",
      "variational_beta * kldivergence:  0.15633\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.43051\n",
      "kldivergence:   1543.91\n",
      "variational_beta * kldivergence:  0.15439\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.42463\n",
      "kldivergence:   1390.45\n",
      "variational_beta * kldivergence:  0.13904\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.55507\n",
      "kldivergence:   1556.78\n",
      "variational_beta * kldivergence:  0.15568\n",
      "batch accuracy: 84.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.49902\n",
      "kldivergence:   1710.34\n",
      "variational_beta * kldivergence:  0.17103\n",
      "batch accuracy: 85.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.42711\n",
      "kldivergence:   1468.99\n",
      "variational_beta * kldivergence:  0.14690\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.55920\n",
      "kldivergence:   1745.33\n",
      "variational_beta * kldivergence:  0.17453\n",
      "batch accuracy: 82.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.43707\n",
      "kldivergence:   1438.34\n",
      "variational_beta * kldivergence:  0.14383\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.53287\n",
      "kldivergence:   1561.30\n",
      "variational_beta * kldivergence:  0.15613\n",
      "batch accuracy: 83.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.46758\n",
      "kldivergence:   1470.39\n",
      "variational_beta * kldivergence:  0.14704\n",
      "batch accuracy: 85.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.45738\n",
      "kldivergence:   1453.86\n",
      "variational_beta * kldivergence:  0.14539\n",
      "batch accuracy: 85.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.54392\n",
      "kldivergence:   1678.43\n",
      "variational_beta * kldivergence:  0.16784\n",
      "batch accuracy: 83.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.41155\n",
      "kldivergence:   1493.89\n",
      "variational_beta * kldivergence:  0.14939\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.48166\n",
      "kldivergence:   1557.67\n",
      "variational_beta * kldivergence:  0.15577\n",
      "batch accuracy: 84.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.40390\n",
      "kldivergence:   1388.61\n",
      "variational_beta * kldivergence:  0.13886\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.38330\n",
      "kldivergence:   1481.64\n",
      "variational_beta * kldivergence:  0.14816\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.47211\n",
      "kldivergence:   1609.99\n",
      "variational_beta * kldivergence:  0.16100\n",
      "batch accuracy: 86.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.47917\n",
      "kldivergence:   1744.70\n",
      "variational_beta * kldivergence:  0.17447\n",
      "batch accuracy: 84.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.47396\n",
      "kldivergence:   1574.47\n",
      "variational_beta * kldivergence:  0.15745\n",
      "batch accuracy: 85.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.40874\n",
      "kldivergence:   1556.66\n",
      "variational_beta * kldivergence:  0.15567\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.52252\n",
      "kldivergence:   1604.66\n",
      "variational_beta * kldivergence:  0.16047\n",
      "batch accuracy: 84.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.44879\n",
      "kldivergence:   1576.76\n",
      "variational_beta * kldivergence:  0.15768\n",
      "batch accuracy: 85.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.44131\n",
      "kldivergence:   1465.86\n",
      "variational_beta * kldivergence:  0.14659\n",
      "batch accuracy: 86.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.43858\n",
      "kldivergence:   1568.75\n",
      "variational_beta * kldivergence:  0.15687\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.39890\n",
      "kldivergence:   1530.43\n",
      "variational_beta * kldivergence:  0.15304\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.54070\n",
      "kldivergence:   1651.13\n",
      "variational_beta * kldivergence:  0.16511\n",
      "batch accuracy: 83.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #19\n",
      "reconstruction loss: 0.44283\n",
      "kldivergence:   1491.49\n",
      "variational_beta * kldivergence:  0.14915\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "epoch # 19 : train loss is [187.1868288806157] and validation loss is [0.10285755808613299] \n",
      "Epoch [20 / 150] average reconstruction error: 0.504547\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31316\n",
      "kldivergence:   1799.99\n",
      "variational_beta * kldivergence:  0.18000\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32657\n",
      "kldivergence:   1647.80\n",
      "variational_beta * kldivergence:  0.16478\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30053\n",
      "kldivergence:   1551.68\n",
      "variational_beta * kldivergence:  0.15517\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32052\n",
      "kldivergence:   1622.27\n",
      "variational_beta * kldivergence:  0.16223\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32122\n",
      "kldivergence:   1779.16\n",
      "variational_beta * kldivergence:  0.17792\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.28451\n",
      "kldivergence:   1730.39\n",
      "variational_beta * kldivergence:  0.17304\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37944\n",
      "kldivergence:   1833.58\n",
      "variational_beta * kldivergence:  0.18336\n",
      "batch accuracy: 86.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39000\n",
      "kldivergence:   1617.37\n",
      "variational_beta * kldivergence:  0.16174\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38498\n",
      "kldivergence:   1731.71\n",
      "variational_beta * kldivergence:  0.17317\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29607\n",
      "kldivergence:   1761.50\n",
      "variational_beta * kldivergence:  0.17615\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33589\n",
      "kldivergence:   1785.87\n",
      "variational_beta * kldivergence:  0.17859\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35412\n",
      "kldivergence:   1590.26\n",
      "variational_beta * kldivergence:  0.15903\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33013\n",
      "kldivergence:   1917.12\n",
      "variational_beta * kldivergence:  0.19171\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32983\n",
      "kldivergence:   1563.07\n",
      "variational_beta * kldivergence:  0.15631\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38038\n",
      "kldivergence:   1885.16\n",
      "variational_beta * kldivergence:  0.18852\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33269\n",
      "kldivergence:   1500.32\n",
      "variational_beta * kldivergence:  0.15003\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31699\n",
      "kldivergence:   1725.52\n",
      "variational_beta * kldivergence:  0.17255\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29720\n",
      "kldivergence:   1622.31\n",
      "variational_beta * kldivergence:  0.16223\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33697\n",
      "kldivergence:   1684.32\n",
      "variational_beta * kldivergence:  0.16843\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34101\n",
      "kldivergence:   1723.14\n",
      "variational_beta * kldivergence:  0.17231\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32315\n",
      "kldivergence:   1972.08\n",
      "variational_beta * kldivergence:  0.19721\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36078\n",
      "kldivergence:   1536.25\n",
      "variational_beta * kldivergence:  0.15362\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36531\n",
      "kldivergence:   1720.88\n",
      "variational_beta * kldivergence:  0.17209\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34461\n",
      "kldivergence:   1744.06\n",
      "variational_beta * kldivergence:  0.17441\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33856\n",
      "kldivergence:   1716.07\n",
      "variational_beta * kldivergence:  0.17161\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30664\n",
      "kldivergence:   1789.14\n",
      "variational_beta * kldivergence:  0.17891\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29362\n",
      "kldivergence:   1759.44\n",
      "variational_beta * kldivergence:  0.17594\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31611\n",
      "kldivergence:   1755.78\n",
      "variational_beta * kldivergence:  0.17558\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33327\n",
      "kldivergence:   1646.58\n",
      "variational_beta * kldivergence:  0.16466\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34490\n",
      "kldivergence:   1725.91\n",
      "variational_beta * kldivergence:  0.17259\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34453\n",
      "kldivergence:   1630.81\n",
      "variational_beta * kldivergence:  0.16308\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31616\n",
      "kldivergence:   1719.14\n",
      "variational_beta * kldivergence:  0.17191\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38354\n",
      "kldivergence:   1392.40\n",
      "variational_beta * kldivergence:  0.13924\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29298\n",
      "kldivergence:   1429.09\n",
      "variational_beta * kldivergence:  0.14291\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32051\n",
      "kldivergence:   1547.37\n",
      "variational_beta * kldivergence:  0.15474\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33449\n",
      "kldivergence:   1448.59\n",
      "variational_beta * kldivergence:  0.14486\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31278\n",
      "kldivergence:   1621.59\n",
      "variational_beta * kldivergence:  0.16216\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36308\n",
      "kldivergence:   1897.01\n",
      "variational_beta * kldivergence:  0.18970\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32516\n",
      "kldivergence:   1618.04\n",
      "variational_beta * kldivergence:  0.16180\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33021\n",
      "kldivergence:   1542.20\n",
      "variational_beta * kldivergence:  0.15422\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29839\n",
      "kldivergence:   1652.61\n",
      "variational_beta * kldivergence:  0.16526\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33683\n",
      "kldivergence:   1464.25\n",
      "variational_beta * kldivergence:  0.14642\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30292\n",
      "kldivergence:   1819.10\n",
      "variational_beta * kldivergence:  0.18191\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34026\n",
      "kldivergence:   1641.64\n",
      "variational_beta * kldivergence:  0.16416\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38742\n",
      "kldivergence:   1617.83\n",
      "variational_beta * kldivergence:  0.16178\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33193\n",
      "kldivergence:   1413.89\n",
      "variational_beta * kldivergence:  0.14139\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32266\n",
      "kldivergence:   1823.90\n",
      "variational_beta * kldivergence:  0.18239\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30520\n",
      "kldivergence:   1427.11\n",
      "variational_beta * kldivergence:  0.14271\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32172\n",
      "kldivergence:   1509.74\n",
      "variational_beta * kldivergence:  0.15097\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39142\n",
      "kldivergence:   1813.33\n",
      "variational_beta * kldivergence:  0.18133\n",
      "batch accuracy: 87.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33248\n",
      "kldivergence:   1737.81\n",
      "variational_beta * kldivergence:  0.17378\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33763\n",
      "kldivergence:   1776.86\n",
      "variational_beta * kldivergence:  0.17769\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35249\n",
      "kldivergence:   1676.81\n",
      "variational_beta * kldivergence:  0.16768\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31455\n",
      "kldivergence:   1628.95\n",
      "variational_beta * kldivergence:  0.16289\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36650\n",
      "kldivergence:   1646.44\n",
      "variational_beta * kldivergence:  0.16464\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.40951\n",
      "kldivergence:   1852.68\n",
      "variational_beta * kldivergence:  0.18527\n",
      "batch accuracy: 86.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37340\n",
      "kldivergence:   1722.51\n",
      "variational_beta * kldivergence:  0.17225\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35527\n",
      "kldivergence:   1823.83\n",
      "variational_beta * kldivergence:  0.18238\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31699\n",
      "kldivergence:   1487.22\n",
      "variational_beta * kldivergence:  0.14872\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34761\n",
      "kldivergence:   1731.90\n",
      "variational_beta * kldivergence:  0.17319\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36371\n",
      "kldivergence:   1741.87\n",
      "variational_beta * kldivergence:  0.17419\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33532\n",
      "kldivergence:   1712.63\n",
      "variational_beta * kldivergence:  0.17126\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37296\n",
      "kldivergence:   1544.95\n",
      "variational_beta * kldivergence:  0.15450\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.42069\n",
      "kldivergence:   1660.17\n",
      "variational_beta * kldivergence:  0.16602\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36616\n",
      "kldivergence:   2032.61\n",
      "variational_beta * kldivergence:  0.20326\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31214\n",
      "kldivergence:   1869.25\n",
      "variational_beta * kldivergence:  0.18693\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34544\n",
      "kldivergence:   1613.67\n",
      "variational_beta * kldivergence:  0.16137\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29776\n",
      "kldivergence:   1652.75\n",
      "variational_beta * kldivergence:  0.16528\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38215\n",
      "kldivergence:   1770.78\n",
      "variational_beta * kldivergence:  0.17708\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38414\n",
      "kldivergence:   1585.31\n",
      "variational_beta * kldivergence:  0.15853\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29153\n",
      "kldivergence:   1682.24\n",
      "variational_beta * kldivergence:  0.16822\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32685\n",
      "kldivergence:   1651.71\n",
      "variational_beta * kldivergence:  0.16517\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35206\n",
      "kldivergence:   1829.78\n",
      "variational_beta * kldivergence:  0.18298\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35312\n",
      "kldivergence:   1811.58\n",
      "variational_beta * kldivergence:  0.18116\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33400\n",
      "kldivergence:   1849.91\n",
      "variational_beta * kldivergence:  0.18499\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32963\n",
      "kldivergence:   1756.73\n",
      "variational_beta * kldivergence:  0.17567\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36289\n",
      "kldivergence:   2206.99\n",
      "variational_beta * kldivergence:  0.22070\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38039\n",
      "kldivergence:   1908.22\n",
      "variational_beta * kldivergence:  0.19082\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32738\n",
      "kldivergence:   1823.60\n",
      "variational_beta * kldivergence:  0.18236\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37349\n",
      "kldivergence:   1853.53\n",
      "variational_beta * kldivergence:  0.18535\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33050\n",
      "kldivergence:   1864.73\n",
      "variational_beta * kldivergence:  0.18647\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33795\n",
      "kldivergence:   1683.65\n",
      "variational_beta * kldivergence:  0.16836\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31645\n",
      "kldivergence:   1633.82\n",
      "variational_beta * kldivergence:  0.16338\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33857\n",
      "kldivergence:   1647.72\n",
      "variational_beta * kldivergence:  0.16477\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32229\n",
      "kldivergence:   1679.66\n",
      "variational_beta * kldivergence:  0.16797\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29658\n",
      "kldivergence:   1723.12\n",
      "variational_beta * kldivergence:  0.17231\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31243\n",
      "kldivergence:   1665.70\n",
      "variational_beta * kldivergence:  0.16657\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34180\n",
      "kldivergence:   1646.22\n",
      "variational_beta * kldivergence:  0.16462\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32591\n",
      "kldivergence:   1530.70\n",
      "variational_beta * kldivergence:  0.15307\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34838\n",
      "kldivergence:   1735.88\n",
      "variational_beta * kldivergence:  0.17359\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32139\n",
      "kldivergence:   1729.36\n",
      "variational_beta * kldivergence:  0.17294\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37511\n",
      "kldivergence:   1682.97\n",
      "variational_beta * kldivergence:  0.16830\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31730\n",
      "kldivergence:   1728.04\n",
      "variational_beta * kldivergence:  0.17280\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34683\n",
      "kldivergence:   1749.82\n",
      "variational_beta * kldivergence:  0.17498\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31678\n",
      "kldivergence:   1607.89\n",
      "variational_beta * kldivergence:  0.16079\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36888\n",
      "kldivergence:   1717.38\n",
      "variational_beta * kldivergence:  0.17174\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34610\n",
      "kldivergence:   1601.52\n",
      "variational_beta * kldivergence:  0.16015\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.27705\n",
      "kldivergence:   1871.39\n",
      "variational_beta * kldivergence:  0.18714\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31525\n",
      "kldivergence:   1617.52\n",
      "variational_beta * kldivergence:  0.16175\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.27117\n",
      "kldivergence:   1483.01\n",
      "variational_beta * kldivergence:  0.14830\n",
      "batch accuracy: 91.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33314\n",
      "kldivergence:   1586.10\n",
      "variational_beta * kldivergence:  0.15861\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.28324\n",
      "kldivergence:   1543.00\n",
      "variational_beta * kldivergence:  0.15430\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36277\n",
      "kldivergence:   1834.75\n",
      "variational_beta * kldivergence:  0.18348\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31752\n",
      "kldivergence:   1554.91\n",
      "variational_beta * kldivergence:  0.15549\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38526\n",
      "kldivergence:   1622.50\n",
      "variational_beta * kldivergence:  0.16225\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32281\n",
      "kldivergence:   1811.88\n",
      "variational_beta * kldivergence:  0.18119\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35412\n",
      "kldivergence:   1777.39\n",
      "variational_beta * kldivergence:  0.17774\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33554\n",
      "kldivergence:   1665.66\n",
      "variational_beta * kldivergence:  0.16657\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35121\n",
      "kldivergence:   1896.92\n",
      "variational_beta * kldivergence:  0.18969\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31605\n",
      "kldivergence:   1895.30\n",
      "variational_beta * kldivergence:  0.18953\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34870\n",
      "kldivergence:   1694.90\n",
      "variational_beta * kldivergence:  0.16949\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38909\n",
      "kldivergence:   1762.95\n",
      "variational_beta * kldivergence:  0.17630\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.40273\n",
      "kldivergence:   2009.61\n",
      "variational_beta * kldivergence:  0.20096\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32816\n",
      "kldivergence:   1605.29\n",
      "variational_beta * kldivergence:  0.16053\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35758\n",
      "kldivergence:   1532.04\n",
      "variational_beta * kldivergence:  0.15320\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32700\n",
      "kldivergence:   1887.08\n",
      "variational_beta * kldivergence:  0.18871\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33975\n",
      "kldivergence:   1935.77\n",
      "variational_beta * kldivergence:  0.19358\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.27772\n",
      "kldivergence:   1601.94\n",
      "variational_beta * kldivergence:  0.16019\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37693\n",
      "kldivergence:   1658.58\n",
      "variational_beta * kldivergence:  0.16586\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36169\n",
      "kldivergence:   1687.61\n",
      "variational_beta * kldivergence:  0.16876\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.26049\n",
      "kldivergence:   1387.67\n",
      "variational_beta * kldivergence:  0.13877\n",
      "batch accuracy: 91.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31167\n",
      "kldivergence:   2343.78\n",
      "variational_beta * kldivergence:  0.23438\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35757\n",
      "kldivergence:   1511.65\n",
      "variational_beta * kldivergence:  0.15117\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.40664\n",
      "kldivergence:   1753.00\n",
      "variational_beta * kldivergence:  0.17530\n",
      "batch accuracy: 86.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30273\n",
      "kldivergence:   1882.92\n",
      "variational_beta * kldivergence:  0.18829\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33352\n",
      "kldivergence:   1755.29\n",
      "variational_beta * kldivergence:  0.17553\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32760\n",
      "kldivergence:   1755.43\n",
      "variational_beta * kldivergence:  0.17554\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35275\n",
      "kldivergence:   1683.50\n",
      "variational_beta * kldivergence:  0.16835\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37736\n",
      "kldivergence:   1566.88\n",
      "variational_beta * kldivergence:  0.15669\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31202\n",
      "kldivergence:   1542.27\n",
      "variational_beta * kldivergence:  0.15423\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29183\n",
      "kldivergence:   1582.18\n",
      "variational_beta * kldivergence:  0.15822\n",
      "batch accuracy: 90.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.27478\n",
      "kldivergence:   1409.17\n",
      "variational_beta * kldivergence:  0.14092\n",
      "batch accuracy: 90.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39421\n",
      "kldivergence:   1555.37\n",
      "variational_beta * kldivergence:  0.15554\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34407\n",
      "kldivergence:   1665.10\n",
      "variational_beta * kldivergence:  0.16651\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35454\n",
      "kldivergence:   1468.40\n",
      "variational_beta * kldivergence:  0.14684\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.27548\n",
      "kldivergence:   1810.13\n",
      "variational_beta * kldivergence:  0.18101\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35460\n",
      "kldivergence:   1664.84\n",
      "variational_beta * kldivergence:  0.16648\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32609\n",
      "kldivergence:   1377.33\n",
      "variational_beta * kldivergence:  0.13773\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37094\n",
      "kldivergence:   1734.65\n",
      "variational_beta * kldivergence:  0.17347\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36812\n",
      "kldivergence:   1699.46\n",
      "variational_beta * kldivergence:  0.16995\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33801\n",
      "kldivergence:   1620.18\n",
      "variational_beta * kldivergence:  0.16202\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30103\n",
      "kldivergence:   1519.27\n",
      "variational_beta * kldivergence:  0.15193\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37930\n",
      "kldivergence:   1638.42\n",
      "variational_beta * kldivergence:  0.16384\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31828\n",
      "kldivergence:   1683.41\n",
      "variational_beta * kldivergence:  0.16834\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33936\n",
      "kldivergence:   1688.50\n",
      "variational_beta * kldivergence:  0.16885\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.28101\n",
      "kldivergence:   1482.96\n",
      "variational_beta * kldivergence:  0.14830\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32370\n",
      "kldivergence:   1564.91\n",
      "variational_beta * kldivergence:  0.15649\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38068\n",
      "kldivergence:   1626.02\n",
      "variational_beta * kldivergence:  0.16260\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31001\n",
      "kldivergence:   1337.34\n",
      "variational_beta * kldivergence:  0.13373\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35661\n",
      "kldivergence:   1689.55\n",
      "variational_beta * kldivergence:  0.16895\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32694\n",
      "kldivergence:   1728.51\n",
      "variational_beta * kldivergence:  0.17285\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.28012\n",
      "kldivergence:   1504.97\n",
      "variational_beta * kldivergence:  0.15050\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33315\n",
      "kldivergence:   1693.47\n",
      "variational_beta * kldivergence:  0.16935\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37201\n",
      "kldivergence:   1819.34\n",
      "variational_beta * kldivergence:  0.18193\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32196\n",
      "kldivergence:   1600.69\n",
      "variational_beta * kldivergence:  0.16007\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31707\n",
      "kldivergence:   1738.31\n",
      "variational_beta * kldivergence:  0.17383\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36576\n",
      "kldivergence:   1809.87\n",
      "variational_beta * kldivergence:  0.18099\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.44091\n",
      "kldivergence:   2264.56\n",
      "variational_beta * kldivergence:  0.22646\n",
      "batch accuracy: 85.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34744\n",
      "kldivergence:   1653.23\n",
      "variational_beta * kldivergence:  0.16532\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37738\n",
      "kldivergence:   1611.59\n",
      "variational_beta * kldivergence:  0.16116\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32697\n",
      "kldivergence:   1436.53\n",
      "variational_beta * kldivergence:  0.14365\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34902\n",
      "kldivergence:   1434.00\n",
      "variational_beta * kldivergence:  0.14340\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35682\n",
      "kldivergence:   1865.26\n",
      "variational_beta * kldivergence:  0.18653\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34231\n",
      "kldivergence:   1620.01\n",
      "variational_beta * kldivergence:  0.16200\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30616\n",
      "kldivergence:   1580.28\n",
      "variational_beta * kldivergence:  0.15803\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34189\n",
      "kldivergence:   1627.46\n",
      "variational_beta * kldivergence:  0.16275\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39159\n",
      "kldivergence:   1500.80\n",
      "variational_beta * kldivergence:  0.15008\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36585\n",
      "kldivergence:   1491.99\n",
      "variational_beta * kldivergence:  0.14920\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32298\n",
      "kldivergence:   1753.37\n",
      "variational_beta * kldivergence:  0.17534\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35605\n",
      "kldivergence:   1576.26\n",
      "variational_beta * kldivergence:  0.15763\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39147\n",
      "kldivergence:   1774.28\n",
      "variational_beta * kldivergence:  0.17743\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.28923\n",
      "kldivergence:   1553.13\n",
      "variational_beta * kldivergence:  0.15531\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33424\n",
      "kldivergence:   1529.18\n",
      "variational_beta * kldivergence:  0.15292\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31716\n",
      "kldivergence:   1530.97\n",
      "variational_beta * kldivergence:  0.15310\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29695\n",
      "kldivergence:   1512.13\n",
      "variational_beta * kldivergence:  0.15121\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33928\n",
      "kldivergence:   1752.80\n",
      "variational_beta * kldivergence:  0.17528\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37367\n",
      "kldivergence:   1681.77\n",
      "variational_beta * kldivergence:  0.16818\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36731\n",
      "kldivergence:   1845.99\n",
      "variational_beta * kldivergence:  0.18460\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32310\n",
      "kldivergence:   1490.21\n",
      "variational_beta * kldivergence:  0.14902\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35610\n",
      "kldivergence:   1745.81\n",
      "variational_beta * kldivergence:  0.17458\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36180\n",
      "kldivergence:   1738.85\n",
      "variational_beta * kldivergence:  0.17388\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34962\n",
      "kldivergence:   1555.55\n",
      "variational_beta * kldivergence:  0.15555\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35616\n",
      "kldivergence:   1663.59\n",
      "variational_beta * kldivergence:  0.16636\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33059\n",
      "kldivergence:   1590.04\n",
      "variational_beta * kldivergence:  0.15900\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34454\n",
      "kldivergence:   1762.70\n",
      "variational_beta * kldivergence:  0.17627\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29226\n",
      "kldivergence:   1789.47\n",
      "variational_beta * kldivergence:  0.17895\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35312\n",
      "kldivergence:   1631.48\n",
      "variational_beta * kldivergence:  0.16315\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32148\n",
      "kldivergence:   1845.29\n",
      "variational_beta * kldivergence:  0.18453\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33669\n",
      "kldivergence:   1880.43\n",
      "variational_beta * kldivergence:  0.18804\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35017\n",
      "kldivergence:   1561.51\n",
      "variational_beta * kldivergence:  0.15615\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.28908\n",
      "kldivergence:   1552.45\n",
      "variational_beta * kldivergence:  0.15524\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32276\n",
      "kldivergence:   1510.88\n",
      "variational_beta * kldivergence:  0.15109\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33707\n",
      "kldivergence:   1544.83\n",
      "variational_beta * kldivergence:  0.15448\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.26977\n",
      "kldivergence:   1562.80\n",
      "variational_beta * kldivergence:  0.15628\n",
      "batch accuracy: 91.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35156\n",
      "kldivergence:   1823.57\n",
      "variational_beta * kldivergence:  0.18236\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31615\n",
      "kldivergence:   1701.69\n",
      "variational_beta * kldivergence:  0.17017\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37484\n",
      "kldivergence:   1630.61\n",
      "variational_beta * kldivergence:  0.16306\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33604\n",
      "kldivergence:   1653.04\n",
      "variational_beta * kldivergence:  0.16530\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31961\n",
      "kldivergence:   1702.67\n",
      "variational_beta * kldivergence:  0.17027\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38157\n",
      "kldivergence:   1907.84\n",
      "variational_beta * kldivergence:  0.19078\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31600\n",
      "kldivergence:   1662.88\n",
      "variational_beta * kldivergence:  0.16629\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30894\n",
      "kldivergence:   1289.97\n",
      "variational_beta * kldivergence:  0.12900\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29636\n",
      "kldivergence:   1463.83\n",
      "variational_beta * kldivergence:  0.14638\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.28241\n",
      "kldivergence:   1491.16\n",
      "variational_beta * kldivergence:  0.14912\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33433\n",
      "kldivergence:   1531.67\n",
      "variational_beta * kldivergence:  0.15317\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34876\n",
      "kldivergence:   1494.12\n",
      "variational_beta * kldivergence:  0.14941\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38937\n",
      "kldivergence:   1805.81\n",
      "variational_beta * kldivergence:  0.18058\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33863\n",
      "kldivergence:   1512.37\n",
      "variational_beta * kldivergence:  0.15124\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35865\n",
      "kldivergence:   1565.79\n",
      "variational_beta * kldivergence:  0.15658\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33305\n",
      "kldivergence:   1533.01\n",
      "variational_beta * kldivergence:  0.15330\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37020\n",
      "kldivergence:   1928.05\n",
      "variational_beta * kldivergence:  0.19281\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39557\n",
      "kldivergence:   1736.97\n",
      "variational_beta * kldivergence:  0.17370\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34766\n",
      "kldivergence:   1500.20\n",
      "variational_beta * kldivergence:  0.15002\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35772\n",
      "kldivergence:   1793.62\n",
      "variational_beta * kldivergence:  0.17936\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31774\n",
      "kldivergence:   1496.23\n",
      "variational_beta * kldivergence:  0.14962\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38107\n",
      "kldivergence:   1854.88\n",
      "variational_beta * kldivergence:  0.18549\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32738\n",
      "kldivergence:   1628.18\n",
      "variational_beta * kldivergence:  0.16282\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31173\n",
      "kldivergence:   1789.58\n",
      "variational_beta * kldivergence:  0.17896\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33840\n",
      "kldivergence:   1572.99\n",
      "variational_beta * kldivergence:  0.15730\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35034\n",
      "kldivergence:   1577.67\n",
      "variational_beta * kldivergence:  0.15777\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.24271\n",
      "kldivergence:   1528.59\n",
      "variational_beta * kldivergence:  0.15286\n",
      "batch accuracy: 91.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36564\n",
      "kldivergence:   1892.30\n",
      "variational_beta * kldivergence:  0.18923\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33366\n",
      "kldivergence:   1661.18\n",
      "variational_beta * kldivergence:  0.16612\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30936\n",
      "kldivergence:   1501.54\n",
      "variational_beta * kldivergence:  0.15015\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31461\n",
      "kldivergence:   1952.48\n",
      "variational_beta * kldivergence:  0.19525\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33761\n",
      "kldivergence:   1551.77\n",
      "variational_beta * kldivergence:  0.15518\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37053\n",
      "kldivergence:   1793.05\n",
      "variational_beta * kldivergence:  0.17930\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.27295\n",
      "kldivergence:   1520.16\n",
      "variational_beta * kldivergence:  0.15202\n",
      "batch accuracy: 91.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33235\n",
      "kldivergence:   1523.82\n",
      "variational_beta * kldivergence:  0.15238\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33651\n",
      "kldivergence:   1527.95\n",
      "variational_beta * kldivergence:  0.15280\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33318\n",
      "kldivergence:   1594.84\n",
      "variational_beta * kldivergence:  0.15948\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32428\n",
      "kldivergence:   1553.84\n",
      "variational_beta * kldivergence:  0.15538\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30396\n",
      "kldivergence:   1683.59\n",
      "variational_beta * kldivergence:  0.16836\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36799\n",
      "kldivergence:   1652.25\n",
      "variational_beta * kldivergence:  0.16523\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35609\n",
      "kldivergence:   1653.70\n",
      "variational_beta * kldivergence:  0.16537\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34237\n",
      "kldivergence:   1679.36\n",
      "variational_beta * kldivergence:  0.16794\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32075\n",
      "kldivergence:   1658.40\n",
      "variational_beta * kldivergence:  0.16584\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32227\n",
      "kldivergence:   1571.60\n",
      "variational_beta * kldivergence:  0.15716\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34162\n",
      "kldivergence:   1639.45\n",
      "variational_beta * kldivergence:  0.16395\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.40067\n",
      "kldivergence:   1884.81\n",
      "variational_beta * kldivergence:  0.18848\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34687\n",
      "kldivergence:   1512.37\n",
      "variational_beta * kldivergence:  0.15124\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33834\n",
      "kldivergence:   1679.77\n",
      "variational_beta * kldivergence:  0.16798\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37034\n",
      "kldivergence:   1717.08\n",
      "variational_beta * kldivergence:  0.17171\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33213\n",
      "kldivergence:   1883.36\n",
      "variational_beta * kldivergence:  0.18834\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.28531\n",
      "kldivergence:   1608.22\n",
      "variational_beta * kldivergence:  0.16082\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37946\n",
      "kldivergence:   1866.30\n",
      "variational_beta * kldivergence:  0.18663\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39054\n",
      "kldivergence:   1539.37\n",
      "variational_beta * kldivergence:  0.15394\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33383\n",
      "kldivergence:   1504.08\n",
      "variational_beta * kldivergence:  0.15041\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32478\n",
      "kldivergence:   1497.82\n",
      "variational_beta * kldivergence:  0.14978\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31950\n",
      "kldivergence:   1501.03\n",
      "variational_beta * kldivergence:  0.15010\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.28933\n",
      "kldivergence:   1405.60\n",
      "variational_beta * kldivergence:  0.14056\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31189\n",
      "kldivergence:   1591.16\n",
      "variational_beta * kldivergence:  0.15912\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31936\n",
      "kldivergence:   1688.36\n",
      "variational_beta * kldivergence:  0.16884\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35546\n",
      "kldivergence:   1733.47\n",
      "variational_beta * kldivergence:  0.17335\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32062\n",
      "kldivergence:   1457.97\n",
      "variational_beta * kldivergence:  0.14580\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34625\n",
      "kldivergence:   1958.17\n",
      "variational_beta * kldivergence:  0.19582\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32473\n",
      "kldivergence:   1458.92\n",
      "variational_beta * kldivergence:  0.14589\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35835\n",
      "kldivergence:   1464.52\n",
      "variational_beta * kldivergence:  0.14645\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35996\n",
      "kldivergence:   1704.67\n",
      "variational_beta * kldivergence:  0.17047\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.40567\n",
      "kldivergence:   1665.45\n",
      "variational_beta * kldivergence:  0.16655\n",
      "batch accuracy: 86.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38831\n",
      "kldivergence:   1638.19\n",
      "variational_beta * kldivergence:  0.16382\n",
      "batch accuracy: 86.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33960\n",
      "kldivergence:   1685.28\n",
      "variational_beta * kldivergence:  0.16853\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30948\n",
      "kldivergence:   1422.03\n",
      "variational_beta * kldivergence:  0.14220\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33637\n",
      "kldivergence:   1604.40\n",
      "variational_beta * kldivergence:  0.16044\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32185\n",
      "kldivergence:   1617.18\n",
      "variational_beta * kldivergence:  0.16172\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37353\n",
      "kldivergence:   1890.15\n",
      "variational_beta * kldivergence:  0.18901\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32822\n",
      "kldivergence:   1473.58\n",
      "variational_beta * kldivergence:  0.14736\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.43486\n",
      "kldivergence:   1871.94\n",
      "variational_beta * kldivergence:  0.18719\n",
      "batch accuracy: 85.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37043\n",
      "kldivergence:   2150.28\n",
      "variational_beta * kldivergence:  0.21503\n",
      "batch accuracy: 86.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32007\n",
      "kldivergence:   1851.67\n",
      "variational_beta * kldivergence:  0.18517\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30594\n",
      "kldivergence:   1502.48\n",
      "variational_beta * kldivergence:  0.15025\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31632\n",
      "kldivergence:   1936.86\n",
      "variational_beta * kldivergence:  0.19369\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34752\n",
      "kldivergence:   1691.38\n",
      "variational_beta * kldivergence:  0.16914\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29430\n",
      "kldivergence:   1514.77\n",
      "variational_beta * kldivergence:  0.15148\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33833\n",
      "kldivergence:   1681.36\n",
      "variational_beta * kldivergence:  0.16814\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30799\n",
      "kldivergence:   1608.32\n",
      "variational_beta * kldivergence:  0.16083\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33584\n",
      "kldivergence:   1620.04\n",
      "variational_beta * kldivergence:  0.16200\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36040\n",
      "kldivergence:   1364.46\n",
      "variational_beta * kldivergence:  0.13645\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33238\n",
      "kldivergence:   1793.88\n",
      "variational_beta * kldivergence:  0.17939\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29945\n",
      "kldivergence:   1592.01\n",
      "variational_beta * kldivergence:  0.15920\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33272\n",
      "kldivergence:   1492.22\n",
      "variational_beta * kldivergence:  0.14922\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30566\n",
      "kldivergence:   1648.29\n",
      "variational_beta * kldivergence:  0.16483\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37395\n",
      "kldivergence:   1632.86\n",
      "variational_beta * kldivergence:  0.16329\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32162\n",
      "kldivergence:   1570.83\n",
      "variational_beta * kldivergence:  0.15708\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39508\n",
      "kldivergence:   1613.61\n",
      "variational_beta * kldivergence:  0.16136\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33146\n",
      "kldivergence:   1574.79\n",
      "variational_beta * kldivergence:  0.15748\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33669\n",
      "kldivergence:   1510.68\n",
      "variational_beta * kldivergence:  0.15107\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35275\n",
      "kldivergence:   1538.71\n",
      "variational_beta * kldivergence:  0.15387\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34139\n",
      "kldivergence:   1565.91\n",
      "variational_beta * kldivergence:  0.15659\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37194\n",
      "kldivergence:   1754.48\n",
      "variational_beta * kldivergence:  0.17545\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33566\n",
      "kldivergence:   1519.75\n",
      "variational_beta * kldivergence:  0.15197\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32750\n",
      "kldivergence:   1512.26\n",
      "variational_beta * kldivergence:  0.15123\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32347\n",
      "kldivergence:   1625.78\n",
      "variational_beta * kldivergence:  0.16258\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33618\n",
      "kldivergence:   1548.95\n",
      "variational_beta * kldivergence:  0.15489\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29252\n",
      "kldivergence:   1556.72\n",
      "variational_beta * kldivergence:  0.15567\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36024\n",
      "kldivergence:   1648.69\n",
      "variational_beta * kldivergence:  0.16487\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37322\n",
      "kldivergence:   1485.46\n",
      "variational_beta * kldivergence:  0.14855\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32412\n",
      "kldivergence:   1674.97\n",
      "variational_beta * kldivergence:  0.16750\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39344\n",
      "kldivergence:   1734.47\n",
      "variational_beta * kldivergence:  0.17345\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34469\n",
      "kldivergence:   1535.57\n",
      "variational_beta * kldivergence:  0.15356\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38636\n",
      "kldivergence:   1724.30\n",
      "variational_beta * kldivergence:  0.17243\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30395\n",
      "kldivergence:   1692.83\n",
      "variational_beta * kldivergence:  0.16928\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31953\n",
      "kldivergence:   1534.65\n",
      "variational_beta * kldivergence:  0.15346\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36939\n",
      "kldivergence:   1634.04\n",
      "variational_beta * kldivergence:  0.16340\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31985\n",
      "kldivergence:   1477.57\n",
      "variational_beta * kldivergence:  0.14776\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34203\n",
      "kldivergence:   1771.33\n",
      "variational_beta * kldivergence:  0.17713\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35011\n",
      "kldivergence:   1868.92\n",
      "variational_beta * kldivergence:  0.18689\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32377\n",
      "kldivergence:   1491.80\n",
      "variational_beta * kldivergence:  0.14918\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33123\n",
      "kldivergence:   1605.33\n",
      "variational_beta * kldivergence:  0.16053\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33036\n",
      "kldivergence:   1728.95\n",
      "variational_beta * kldivergence:  0.17290\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31405\n",
      "kldivergence:   1562.22\n",
      "variational_beta * kldivergence:  0.15622\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.25993\n",
      "kldivergence:   1692.78\n",
      "variational_beta * kldivergence:  0.16928\n",
      "batch accuracy: 91.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33274\n",
      "kldivergence:   1700.47\n",
      "variational_beta * kldivergence:  0.17005\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29401\n",
      "kldivergence:   1778.00\n",
      "variational_beta * kldivergence:  0.17780\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29455\n",
      "kldivergence:   1546.14\n",
      "variational_beta * kldivergence:  0.15461\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30725\n",
      "kldivergence:   1679.72\n",
      "variational_beta * kldivergence:  0.16797\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33413\n",
      "kldivergence:   1453.92\n",
      "variational_beta * kldivergence:  0.14539\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35529\n",
      "kldivergence:   1696.19\n",
      "variational_beta * kldivergence:  0.16962\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29976\n",
      "kldivergence:   1491.39\n",
      "variational_beta * kldivergence:  0.14914\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34501\n",
      "kldivergence:   1661.68\n",
      "variational_beta * kldivergence:  0.16617\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32115\n",
      "kldivergence:   1521.38\n",
      "variational_beta * kldivergence:  0.15214\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36383\n",
      "kldivergence:   1815.62\n",
      "variational_beta * kldivergence:  0.18156\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35824\n",
      "kldivergence:   1646.52\n",
      "variational_beta * kldivergence:  0.16465\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32805\n",
      "kldivergence:   1525.80\n",
      "variational_beta * kldivergence:  0.15258\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38743\n",
      "kldivergence:   1496.66\n",
      "variational_beta * kldivergence:  0.14967\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31721\n",
      "kldivergence:   1653.93\n",
      "variational_beta * kldivergence:  0.16539\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37496\n",
      "kldivergence:   1827.96\n",
      "variational_beta * kldivergence:  0.18280\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32112\n",
      "kldivergence:   1467.75\n",
      "variational_beta * kldivergence:  0.14678\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37581\n",
      "kldivergence:   1697.76\n",
      "variational_beta * kldivergence:  0.16978\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32203\n",
      "kldivergence:   2090.13\n",
      "variational_beta * kldivergence:  0.20901\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34752\n",
      "kldivergence:   1690.30\n",
      "variational_beta * kldivergence:  0.16903\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35196\n",
      "kldivergence:   1697.83\n",
      "variational_beta * kldivergence:  0.16978\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.36061\n",
      "kldivergence:   1821.06\n",
      "variational_beta * kldivergence:  0.18211\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38918\n",
      "kldivergence:   2049.18\n",
      "variational_beta * kldivergence:  0.20492\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35913\n",
      "kldivergence:   1831.58\n",
      "variational_beta * kldivergence:  0.18316\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33664\n",
      "kldivergence:   1597.10\n",
      "variational_beta * kldivergence:  0.15971\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38915\n",
      "kldivergence:   1793.78\n",
      "variational_beta * kldivergence:  0.17938\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37270\n",
      "kldivergence:   1580.74\n",
      "variational_beta * kldivergence:  0.15807\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33595\n",
      "kldivergence:   1577.28\n",
      "variational_beta * kldivergence:  0.15773\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33368\n",
      "kldivergence:   1606.11\n",
      "variational_beta * kldivergence:  0.16061\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35105\n",
      "kldivergence:   1591.40\n",
      "variational_beta * kldivergence:  0.15914\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33189\n",
      "kldivergence:   1734.36\n",
      "variational_beta * kldivergence:  0.17344\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33623\n",
      "kldivergence:   1628.88\n",
      "variational_beta * kldivergence:  0.16289\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32877\n",
      "kldivergence:   1750.41\n",
      "variational_beta * kldivergence:  0.17504\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35277\n",
      "kldivergence:   1417.90\n",
      "variational_beta * kldivergence:  0.14179\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31413\n",
      "kldivergence:   1473.66\n",
      "variational_beta * kldivergence:  0.14737\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34584\n",
      "kldivergence:   1724.24\n",
      "variational_beta * kldivergence:  0.17242\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34201\n",
      "kldivergence:   1500.26\n",
      "variational_beta * kldivergence:  0.15003\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32489\n",
      "kldivergence:   1473.18\n",
      "variational_beta * kldivergence:  0.14732\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29613\n",
      "kldivergence:   1643.37\n",
      "variational_beta * kldivergence:  0.16434\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31605\n",
      "kldivergence:   1466.89\n",
      "variational_beta * kldivergence:  0.14669\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.28227\n",
      "kldivergence:   1659.55\n",
      "variational_beta * kldivergence:  0.16596\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35498\n",
      "kldivergence:   1533.60\n",
      "variational_beta * kldivergence:  0.15336\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33618\n",
      "kldivergence:   1525.41\n",
      "variational_beta * kldivergence:  0.15254\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.38158\n",
      "kldivergence:   1703.97\n",
      "variational_beta * kldivergence:  0.17040\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.32455\n",
      "kldivergence:   1542.05\n",
      "variational_beta * kldivergence:  0.15421\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37274\n",
      "kldivergence:   1584.37\n",
      "variational_beta * kldivergence:  0.15844\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39480\n",
      "kldivergence:   1724.45\n",
      "variational_beta * kldivergence:  0.17245\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39768\n",
      "kldivergence:   1604.10\n",
      "variational_beta * kldivergence:  0.16041\n",
      "batch accuracy: 86.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.33796\n",
      "kldivergence:   1741.05\n",
      "variational_beta * kldivergence:  0.17411\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.39684\n",
      "kldivergence:   1822.74\n",
      "variational_beta * kldivergence:  0.18227\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.29195\n",
      "kldivergence:   1500.00\n",
      "variational_beta * kldivergence:  0.15000\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.35803\n",
      "kldivergence:   1644.17\n",
      "variational_beta * kldivergence:  0.16442\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34809\n",
      "kldivergence:   1539.74\n",
      "variational_beta * kldivergence:  0.15397\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30869\n",
      "kldivergence:   1709.55\n",
      "variational_beta * kldivergence:  0.17095\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.30026\n",
      "kldivergence:   1484.70\n",
      "variational_beta * kldivergence:  0.14847\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.27747\n",
      "kldivergence:   1437.75\n",
      "variational_beta * kldivergence:  0.14377\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.31437\n",
      "kldivergence:   1686.46\n",
      "variational_beta * kldivergence:  0.16865\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.34689\n",
      "kldivergence:   1531.64\n",
      "variational_beta * kldivergence:  0.15316\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.37759\n",
      "kldivergence:   1641.75\n",
      "variational_beta * kldivergence:  0.16417\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #20\n",
      "reconstruction loss: 0.27001\n",
      "kldivergence:   1608.87\n",
      "variational_beta * kldivergence:  0.16089\n",
      "batch accuracy: 90.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.40551\n",
      "kldivergence:   1437.96\n",
      "variational_beta * kldivergence:  0.14380\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.53723\n",
      "kldivergence:   1631.83\n",
      "variational_beta * kldivergence:  0.16318\n",
      "batch accuracy: 83.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.50043\n",
      "kldivergence:   1580.72\n",
      "variational_beta * kldivergence:  0.15807\n",
      "batch accuracy: 85.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.37976\n",
      "kldivergence:   1637.29\n",
      "variational_beta * kldivergence:  0.16373\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.40420\n",
      "kldivergence:   1515.81\n",
      "variational_beta * kldivergence:  0.15158\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.41180\n",
      "kldivergence:   1712.96\n",
      "variational_beta * kldivergence:  0.17130\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.46335\n",
      "kldivergence:   1438.75\n",
      "variational_beta * kldivergence:  0.14387\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.46503\n",
      "kldivergence:   1493.45\n",
      "variational_beta * kldivergence:  0.14935\n",
      "batch accuracy: 85.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.45163\n",
      "kldivergence:   1574.99\n",
      "variational_beta * kldivergence:  0.15750\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.41666\n",
      "kldivergence:   1489.95\n",
      "variational_beta * kldivergence:  0.14899\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.48260\n",
      "kldivergence:   1524.38\n",
      "variational_beta * kldivergence:  0.15244\n",
      "batch accuracy: 85.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.45488\n",
      "kldivergence:   1513.63\n",
      "variational_beta * kldivergence:  0.15136\n",
      "batch accuracy: 85.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.46952\n",
      "kldivergence:   1571.38\n",
      "variational_beta * kldivergence:  0.15714\n",
      "batch accuracy: 85.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.54689\n",
      "kldivergence:   1645.44\n",
      "variational_beta * kldivergence:  0.16454\n",
      "batch accuracy: 83.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.49444\n",
      "kldivergence:   1647.88\n",
      "variational_beta * kldivergence:  0.16479\n",
      "batch accuracy: 84.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.41273\n",
      "kldivergence:   1474.02\n",
      "variational_beta * kldivergence:  0.14740\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.50728\n",
      "kldivergence:   1558.06\n",
      "variational_beta * kldivergence:  0.15581\n",
      "batch accuracy: 84.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.44774\n",
      "kldivergence:   1582.50\n",
      "variational_beta * kldivergence:  0.15825\n",
      "batch accuracy: 86.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.49193\n",
      "kldivergence:   1527.79\n",
      "variational_beta * kldivergence:  0.15278\n",
      "batch accuracy: 85.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.41116\n",
      "kldivergence:   1391.78\n",
      "variational_beta * kldivergence:  0.13918\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.48026\n",
      "kldivergence:   1634.16\n",
      "variational_beta * kldivergence:  0.16342\n",
      "batch accuracy: 85.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.43543\n",
      "kldivergence:   1526.96\n",
      "variational_beta * kldivergence:  0.15270\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.40970\n",
      "kldivergence:   1469.30\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.38423\n",
      "kldivergence:   1427.11\n",
      "variational_beta * kldivergence:  0.14271\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.46874\n",
      "kldivergence:   1559.09\n",
      "variational_beta * kldivergence:  0.15591\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.43213\n",
      "kldivergence:   1494.16\n",
      "variational_beta * kldivergence:  0.14942\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.43142\n",
      "kldivergence:   1396.21\n",
      "variational_beta * kldivergence:  0.13962\n",
      "batch accuracy: 86.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.46789\n",
      "kldivergence:   1673.89\n",
      "variational_beta * kldivergence:  0.16739\n",
      "batch accuracy: 85.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.46606\n",
      "kldivergence:   1578.52\n",
      "variational_beta * kldivergence:  0.15785\n",
      "batch accuracy: 85.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.43043\n",
      "kldivergence:   1544.73\n",
      "variational_beta * kldivergence:  0.15447\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.59551\n",
      "kldivergence:   1758.92\n",
      "variational_beta * kldivergence:  0.17589\n",
      "batch accuracy: 81.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.46692\n",
      "kldivergence:   1427.50\n",
      "variational_beta * kldivergence:  0.14275\n",
      "batch accuracy: 85.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.32502\n",
      "kldivergence:   1342.92\n",
      "variational_beta * kldivergence:  0.13429\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.39494\n",
      "kldivergence:   1439.27\n",
      "variational_beta * kldivergence:  0.14393\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.41178\n",
      "kldivergence:   1457.81\n",
      "variational_beta * kldivergence:  0.14578\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.38607\n",
      "kldivergence:   1465.02\n",
      "variational_beta * kldivergence:  0.14650\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.35967\n",
      "kldivergence:   1490.43\n",
      "variational_beta * kldivergence:  0.14904\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.48025\n",
      "kldivergence:   1514.54\n",
      "variational_beta * kldivergence:  0.15145\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.45062\n",
      "kldivergence:   1470.61\n",
      "variational_beta * kldivergence:  0.14706\n",
      "batch accuracy: 85.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.46991\n",
      "kldivergence:   1628.20\n",
      "variational_beta * kldivergence:  0.16282\n",
      "batch accuracy: 85.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.47930\n",
      "kldivergence:   1603.97\n",
      "variational_beta * kldivergence:  0.16040\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.38360\n",
      "kldivergence:   1427.73\n",
      "variational_beta * kldivergence:  0.14277\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.49258\n",
      "kldivergence:   1682.24\n",
      "variational_beta * kldivergence:  0.16822\n",
      "batch accuracy: 84.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.50460\n",
      "kldivergence:   1623.13\n",
      "variational_beta * kldivergence:  0.16231\n",
      "batch accuracy: 84.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.43302\n",
      "kldivergence:   1454.09\n",
      "variational_beta * kldivergence:  0.14541\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.45851\n",
      "kldivergence:   1531.85\n",
      "variational_beta * kldivergence:  0.15318\n",
      "batch accuracy: 85.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.52939\n",
      "kldivergence:   1677.70\n",
      "variational_beta * kldivergence:  0.16777\n",
      "batch accuracy: 84.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.47995\n",
      "kldivergence:   1595.12\n",
      "variational_beta * kldivergence:  0.15951\n",
      "batch accuracy: 85.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.49802\n",
      "kldivergence:   1582.60\n",
      "variational_beta * kldivergence:  0.15826\n",
      "batch accuracy: 84.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.51236\n",
      "kldivergence:   1591.65\n",
      "variational_beta * kldivergence:  0.15916\n",
      "batch accuracy: 84.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.46584\n",
      "kldivergence:   1442.69\n",
      "variational_beta * kldivergence:  0.14427\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.48856\n",
      "kldivergence:   1606.69\n",
      "variational_beta * kldivergence:  0.16067\n",
      "batch accuracy: 85.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.46451\n",
      "kldivergence:   1492.73\n",
      "variational_beta * kldivergence:  0.14927\n",
      "batch accuracy: 85.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.47378\n",
      "kldivergence:   1688.69\n",
      "variational_beta * kldivergence:  0.16887\n",
      "batch accuracy: 84.62\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.54488\n",
      "kldivergence:   1661.82\n",
      "variational_beta * kldivergence:  0.16618\n",
      "batch accuracy: 84.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.42240\n",
      "kldivergence:   1527.96\n",
      "variational_beta * kldivergence:  0.15280\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.52688\n",
      "kldivergence:   1519.68\n",
      "variational_beta * kldivergence:  0.15197\n",
      "batch accuracy: 85.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.50149\n",
      "kldivergence:   1508.70\n",
      "variational_beta * kldivergence:  0.15087\n",
      "batch accuracy: 84.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.47453\n",
      "kldivergence:   1553.86\n",
      "variational_beta * kldivergence:  0.15539\n",
      "batch accuracy: 86.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.37936\n",
      "kldivergence:   1460.41\n",
      "variational_beta * kldivergence:  0.14604\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.34903\n",
      "kldivergence:   1487.93\n",
      "variational_beta * kldivergence:  0.14879\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #20\n",
      "reconstruction loss: 0.47561\n",
      "kldivergence:   1558.71\n",
      "variational_beta * kldivergence:  0.15587\n",
      "batch accuracy: 85.49\n",
      "\n",
      "\n",
      "epoch # 20 : train loss is [187.58353052209733] and validation loss is [0.10214501932130726] \n",
      "Epoch [21 / 150] average reconstruction error: 0.505616\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34045\n",
      "kldivergence:   1557.85\n",
      "variational_beta * kldivergence:  0.15579\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29993\n",
      "kldivergence:   1569.41\n",
      "variational_beta * kldivergence:  0.15694\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32981\n",
      "kldivergence:   1524.29\n",
      "variational_beta * kldivergence:  0.15243\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37128\n",
      "kldivergence:   1689.92\n",
      "variational_beta * kldivergence:  0.16899\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34203\n",
      "kldivergence:   1499.12\n",
      "variational_beta * kldivergence:  0.14991\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36550\n",
      "kldivergence:   1811.78\n",
      "variational_beta * kldivergence:  0.18118\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34966\n",
      "kldivergence:   1562.28\n",
      "variational_beta * kldivergence:  0.15623\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38169\n",
      "kldivergence:   1856.15\n",
      "variational_beta * kldivergence:  0.18562\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32182\n",
      "kldivergence:   1686.95\n",
      "variational_beta * kldivergence:  0.16869\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30119\n",
      "kldivergence:   1420.41\n",
      "variational_beta * kldivergence:  0.14204\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32120\n",
      "kldivergence:   1490.47\n",
      "variational_beta * kldivergence:  0.14905\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36642\n",
      "kldivergence:   1633.25\n",
      "variational_beta * kldivergence:  0.16332\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32252\n",
      "kldivergence:   1620.12\n",
      "variational_beta * kldivergence:  0.16201\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28122\n",
      "kldivergence:   1744.50\n",
      "variational_beta * kldivergence:  0.17445\n",
      "batch accuracy: 90.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30439\n",
      "kldivergence:   1523.15\n",
      "variational_beta * kldivergence:  0.15231\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34164\n",
      "kldivergence:   1722.58\n",
      "variational_beta * kldivergence:  0.17226\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.44646\n",
      "kldivergence:   1619.80\n",
      "variational_beta * kldivergence:  0.16198\n",
      "batch accuracy: 84.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34594\n",
      "kldivergence:   1748.73\n",
      "variational_beta * kldivergence:  0.17487\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33721\n",
      "kldivergence:   1453.36\n",
      "variational_beta * kldivergence:  0.14534\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34393\n",
      "kldivergence:   1818.47\n",
      "variational_beta * kldivergence:  0.18185\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36378\n",
      "kldivergence:   1571.03\n",
      "variational_beta * kldivergence:  0.15710\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36678\n",
      "kldivergence:   1611.60\n",
      "variational_beta * kldivergence:  0.16116\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31616\n",
      "kldivergence:   1535.85\n",
      "variational_beta * kldivergence:  0.15358\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33752\n",
      "kldivergence:   1688.33\n",
      "variational_beta * kldivergence:  0.16883\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36117\n",
      "kldivergence:   1711.40\n",
      "variational_beta * kldivergence:  0.17114\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31989\n",
      "kldivergence:   1516.06\n",
      "variational_beta * kldivergence:  0.15161\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32635\n",
      "kldivergence:   1501.47\n",
      "variational_beta * kldivergence:  0.15015\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36274\n",
      "kldivergence:   1631.10\n",
      "variational_beta * kldivergence:  0.16311\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34586\n",
      "kldivergence:   1518.01\n",
      "variational_beta * kldivergence:  0.15180\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.39018\n",
      "kldivergence:   1531.30\n",
      "variational_beta * kldivergence:  0.15313\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34791\n",
      "kldivergence:   1606.02\n",
      "variational_beta * kldivergence:  0.16060\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33446\n",
      "kldivergence:   1576.20\n",
      "variational_beta * kldivergence:  0.15762\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34058\n",
      "kldivergence:   1447.39\n",
      "variational_beta * kldivergence:  0.14474\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33839\n",
      "kldivergence:   1734.05\n",
      "variational_beta * kldivergence:  0.17340\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32164\n",
      "kldivergence:   1559.05\n",
      "variational_beta * kldivergence:  0.15590\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36318\n",
      "kldivergence:   1711.13\n",
      "variational_beta * kldivergence:  0.17111\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31921\n",
      "kldivergence:   1667.74\n",
      "variational_beta * kldivergence:  0.16677\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31033\n",
      "kldivergence:   1540.64\n",
      "variational_beta * kldivergence:  0.15406\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28968\n",
      "kldivergence:   1817.50\n",
      "variational_beta * kldivergence:  0.18175\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30972\n",
      "kldivergence:   1474.56\n",
      "variational_beta * kldivergence:  0.14746\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33792\n",
      "kldivergence:   1452.55\n",
      "variational_beta * kldivergence:  0.14526\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31005\n",
      "kldivergence:   1533.78\n",
      "variational_beta * kldivergence:  0.15338\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36568\n",
      "kldivergence:   1664.40\n",
      "variational_beta * kldivergence:  0.16644\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32119\n",
      "kldivergence:   1545.20\n",
      "variational_beta * kldivergence:  0.15452\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36867\n",
      "kldivergence:   1443.93\n",
      "variational_beta * kldivergence:  0.14439\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37268\n",
      "kldivergence:   1616.97\n",
      "variational_beta * kldivergence:  0.16170\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32010\n",
      "kldivergence:   1531.65\n",
      "variational_beta * kldivergence:  0.15316\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28472\n",
      "kldivergence:   1470.08\n",
      "variational_beta * kldivergence:  0.14701\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32965\n",
      "kldivergence:   1549.97\n",
      "variational_beta * kldivergence:  0.15500\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32993\n",
      "kldivergence:   1508.47\n",
      "variational_beta * kldivergence:  0.15085\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31470\n",
      "kldivergence:   1441.02\n",
      "variational_beta * kldivergence:  0.14410\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31759\n",
      "kldivergence:   1492.20\n",
      "variational_beta * kldivergence:  0.14922\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28853\n",
      "kldivergence:   1613.02\n",
      "variational_beta * kldivergence:  0.16130\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32772\n",
      "kldivergence:   1699.88\n",
      "variational_beta * kldivergence:  0.16999\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33515\n",
      "kldivergence:   1544.57\n",
      "variational_beta * kldivergence:  0.15446\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34338\n",
      "kldivergence:   1674.41\n",
      "variational_beta * kldivergence:  0.16744\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37261\n",
      "kldivergence:   1538.73\n",
      "variational_beta * kldivergence:  0.15387\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.40580\n",
      "kldivergence:   1782.50\n",
      "variational_beta * kldivergence:  0.17825\n",
      "batch accuracy: 86.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32528\n",
      "kldivergence:   1585.38\n",
      "variational_beta * kldivergence:  0.15854\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34054\n",
      "kldivergence:   1484.71\n",
      "variational_beta * kldivergence:  0.14847\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28674\n",
      "kldivergence:   1621.05\n",
      "variational_beta * kldivergence:  0.16210\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31965\n",
      "kldivergence:   1611.94\n",
      "variational_beta * kldivergence:  0.16119\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34804\n",
      "kldivergence:   1712.16\n",
      "variational_beta * kldivergence:  0.17122\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33008\n",
      "kldivergence:   1515.79\n",
      "variational_beta * kldivergence:  0.15158\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32812\n",
      "kldivergence:   1612.13\n",
      "variational_beta * kldivergence:  0.16121\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31997\n",
      "kldivergence:   1641.10\n",
      "variational_beta * kldivergence:  0.16411\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30014\n",
      "kldivergence:   1558.70\n",
      "variational_beta * kldivergence:  0.15587\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29695\n",
      "kldivergence:   1411.92\n",
      "variational_beta * kldivergence:  0.14119\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35262\n",
      "kldivergence:   1528.93\n",
      "variational_beta * kldivergence:  0.15289\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38965\n",
      "kldivergence:   1681.44\n",
      "variational_beta * kldivergence:  0.16814\n",
      "batch accuracy: 86.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31638\n",
      "kldivergence:   1503.24\n",
      "variational_beta * kldivergence:  0.15032\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32979\n",
      "kldivergence:   1610.25\n",
      "variational_beta * kldivergence:  0.16102\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30539\n",
      "kldivergence:   1677.82\n",
      "variational_beta * kldivergence:  0.16778\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30604\n",
      "kldivergence:   1470.82\n",
      "variational_beta * kldivergence:  0.14708\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30381\n",
      "kldivergence:   1429.92\n",
      "variational_beta * kldivergence:  0.14299\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.27976\n",
      "kldivergence:   1655.78\n",
      "variational_beta * kldivergence:  0.16558\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32108\n",
      "kldivergence:   1656.79\n",
      "variational_beta * kldivergence:  0.16568\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35476\n",
      "kldivergence:   1411.48\n",
      "variational_beta * kldivergence:  0.14115\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32427\n",
      "kldivergence:   1838.33\n",
      "variational_beta * kldivergence:  0.18383\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35975\n",
      "kldivergence:   1557.40\n",
      "variational_beta * kldivergence:  0.15574\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34449\n",
      "kldivergence:   1516.18\n",
      "variational_beta * kldivergence:  0.15162\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30509\n",
      "kldivergence:   1379.44\n",
      "variational_beta * kldivergence:  0.13794\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34317\n",
      "kldivergence:   1728.84\n",
      "variational_beta * kldivergence:  0.17288\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33628\n",
      "kldivergence:   1691.90\n",
      "variational_beta * kldivergence:  0.16919\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36866\n",
      "kldivergence:   1608.25\n",
      "variational_beta * kldivergence:  0.16082\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38867\n",
      "kldivergence:   1856.97\n",
      "variational_beta * kldivergence:  0.18570\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36066\n",
      "kldivergence:   1766.43\n",
      "variational_beta * kldivergence:  0.17664\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37723\n",
      "kldivergence:   1598.90\n",
      "variational_beta * kldivergence:  0.15989\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35251\n",
      "kldivergence:   1600.52\n",
      "variational_beta * kldivergence:  0.16005\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32062\n",
      "kldivergence:   1673.40\n",
      "variational_beta * kldivergence:  0.16734\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33067\n",
      "kldivergence:   1542.25\n",
      "variational_beta * kldivergence:  0.15423\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34250\n",
      "kldivergence:   1504.49\n",
      "variational_beta * kldivergence:  0.15045\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33309\n",
      "kldivergence:   1635.97\n",
      "variational_beta * kldivergence:  0.16360\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34568\n",
      "kldivergence:   1606.40\n",
      "variational_beta * kldivergence:  0.16064\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.43133\n",
      "kldivergence:   1524.95\n",
      "variational_beta * kldivergence:  0.15249\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.39027\n",
      "kldivergence:   1591.17\n",
      "variational_beta * kldivergence:  0.15912\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33897\n",
      "kldivergence:   1827.79\n",
      "variational_beta * kldivergence:  0.18278\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.26602\n",
      "kldivergence:   1654.36\n",
      "variational_beta * kldivergence:  0.16544\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33559\n",
      "kldivergence:   1580.97\n",
      "variational_beta * kldivergence:  0.15810\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33751\n",
      "kldivergence:   1539.64\n",
      "variational_beta * kldivergence:  0.15396\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37886\n",
      "kldivergence:   1614.79\n",
      "variational_beta * kldivergence:  0.16148\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33308\n",
      "kldivergence:   1702.23\n",
      "variational_beta * kldivergence:  0.17022\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29190\n",
      "kldivergence:   1693.27\n",
      "variational_beta * kldivergence:  0.16933\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34123\n",
      "kldivergence:   1552.53\n",
      "variational_beta * kldivergence:  0.15525\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34721\n",
      "kldivergence:   1582.02\n",
      "variational_beta * kldivergence:  0.15820\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33781\n",
      "kldivergence:   1643.03\n",
      "variational_beta * kldivergence:  0.16430\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34142\n",
      "kldivergence:   1777.54\n",
      "variational_beta * kldivergence:  0.17775\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35708\n",
      "kldivergence:   1652.20\n",
      "variational_beta * kldivergence:  0.16522\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30747\n",
      "kldivergence:   1524.09\n",
      "variational_beta * kldivergence:  0.15241\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36318\n",
      "kldivergence:   1713.31\n",
      "variational_beta * kldivergence:  0.17133\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.27990\n",
      "kldivergence:   1441.65\n",
      "variational_beta * kldivergence:  0.14416\n",
      "batch accuracy: 90.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36670\n",
      "kldivergence:   1632.05\n",
      "variational_beta * kldivergence:  0.16321\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30786\n",
      "kldivergence:   1672.81\n",
      "variational_beta * kldivergence:  0.16728\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30600\n",
      "kldivergence:   1844.56\n",
      "variational_beta * kldivergence:  0.18446\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36259\n",
      "kldivergence:   1674.51\n",
      "variational_beta * kldivergence:  0.16745\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32288\n",
      "kldivergence:   1699.36\n",
      "variational_beta * kldivergence:  0.16994\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31735\n",
      "kldivergence:   1625.39\n",
      "variational_beta * kldivergence:  0.16254\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34442\n",
      "kldivergence:   1502.03\n",
      "variational_beta * kldivergence:  0.15020\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32602\n",
      "kldivergence:   1438.52\n",
      "variational_beta * kldivergence:  0.14385\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34839\n",
      "kldivergence:   1508.27\n",
      "variational_beta * kldivergence:  0.15083\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38663\n",
      "kldivergence:   1713.07\n",
      "variational_beta * kldivergence:  0.17131\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32726\n",
      "kldivergence:   1654.43\n",
      "variational_beta * kldivergence:  0.16544\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31456\n",
      "kldivergence:   1550.27\n",
      "variational_beta * kldivergence:  0.15503\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35288\n",
      "kldivergence:   1582.19\n",
      "variational_beta * kldivergence:  0.15822\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31954\n",
      "kldivergence:   1611.33\n",
      "variational_beta * kldivergence:  0.16113\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34103\n",
      "kldivergence:   1540.85\n",
      "variational_beta * kldivergence:  0.15408\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35546\n",
      "kldivergence:   1769.84\n",
      "variational_beta * kldivergence:  0.17698\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32681\n",
      "kldivergence:   1484.96\n",
      "variational_beta * kldivergence:  0.14850\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32270\n",
      "kldivergence:   1603.13\n",
      "variational_beta * kldivergence:  0.16031\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33516\n",
      "kldivergence:   1764.84\n",
      "variational_beta * kldivergence:  0.17648\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32608\n",
      "kldivergence:   1653.95\n",
      "variational_beta * kldivergence:  0.16540\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31251\n",
      "kldivergence:   1543.91\n",
      "variational_beta * kldivergence:  0.15439\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30839\n",
      "kldivergence:   1509.20\n",
      "variational_beta * kldivergence:  0.15092\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35152\n",
      "kldivergence:   1583.26\n",
      "variational_beta * kldivergence:  0.15833\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28973\n",
      "kldivergence:   1516.78\n",
      "variational_beta * kldivergence:  0.15168\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37277\n",
      "kldivergence:   1723.47\n",
      "variational_beta * kldivergence:  0.17235\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36584\n",
      "kldivergence:   1637.39\n",
      "variational_beta * kldivergence:  0.16374\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32251\n",
      "kldivergence:   1724.39\n",
      "variational_beta * kldivergence:  0.17244\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35595\n",
      "kldivergence:   1819.35\n",
      "variational_beta * kldivergence:  0.18194\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34104\n",
      "kldivergence:   1722.92\n",
      "variational_beta * kldivergence:  0.17229\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32393\n",
      "kldivergence:   1843.22\n",
      "variational_beta * kldivergence:  0.18432\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32236\n",
      "kldivergence:   1782.45\n",
      "variational_beta * kldivergence:  0.17824\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34569\n",
      "kldivergence:   1788.13\n",
      "variational_beta * kldivergence:  0.17881\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.39151\n",
      "kldivergence:   1969.18\n",
      "variational_beta * kldivergence:  0.19692\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.23853\n",
      "kldivergence:   1469.52\n",
      "variational_beta * kldivergence:  0.14695\n",
      "batch accuracy: 92.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38125\n",
      "kldivergence:   1917.50\n",
      "variational_beta * kldivergence:  0.19175\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31083\n",
      "kldivergence:   1683.73\n",
      "variational_beta * kldivergence:  0.16837\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32719\n",
      "kldivergence:   1683.79\n",
      "variational_beta * kldivergence:  0.16838\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28791\n",
      "kldivergence:   1545.56\n",
      "variational_beta * kldivergence:  0.15456\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32234\n",
      "kldivergence:   1685.30\n",
      "variational_beta * kldivergence:  0.16853\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31375\n",
      "kldivergence:   1613.92\n",
      "variational_beta * kldivergence:  0.16139\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29352\n",
      "kldivergence:   1656.27\n",
      "variational_beta * kldivergence:  0.16563\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32459\n",
      "kldivergence:   1982.76\n",
      "variational_beta * kldivergence:  0.19828\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32214\n",
      "kldivergence:   1521.63\n",
      "variational_beta * kldivergence:  0.15216\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.27734\n",
      "kldivergence:   2389.16\n",
      "variational_beta * kldivergence:  0.23892\n",
      "batch accuracy: 90.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30718\n",
      "kldivergence:   1514.48\n",
      "variational_beta * kldivergence:  0.15145\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35285\n",
      "kldivergence:   1782.02\n",
      "variational_beta * kldivergence:  0.17820\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32285\n",
      "kldivergence:   1555.32\n",
      "variational_beta * kldivergence:  0.15553\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31937\n",
      "kldivergence:   1546.42\n",
      "variational_beta * kldivergence:  0.15464\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35424\n",
      "kldivergence:   1455.14\n",
      "variational_beta * kldivergence:  0.14551\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33962\n",
      "kldivergence:   1467.12\n",
      "variational_beta * kldivergence:  0.14671\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37841\n",
      "kldivergence:   1749.09\n",
      "variational_beta * kldivergence:  0.17491\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33638\n",
      "kldivergence:   1793.48\n",
      "variational_beta * kldivergence:  0.17935\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38153\n",
      "kldivergence:   1747.21\n",
      "variational_beta * kldivergence:  0.17472\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38557\n",
      "kldivergence:   1698.35\n",
      "variational_beta * kldivergence:  0.16983\n",
      "batch accuracy: 86.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33332\n",
      "kldivergence:   1757.14\n",
      "variational_beta * kldivergence:  0.17571\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32220\n",
      "kldivergence:   1607.55\n",
      "variational_beta * kldivergence:  0.16075\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37672\n",
      "kldivergence:   1611.56\n",
      "variational_beta * kldivergence:  0.16116\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36478\n",
      "kldivergence:   1753.09\n",
      "variational_beta * kldivergence:  0.17531\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34998\n",
      "kldivergence:   1620.29\n",
      "variational_beta * kldivergence:  0.16203\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37548\n",
      "kldivergence:   1755.20\n",
      "variational_beta * kldivergence:  0.17552\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36027\n",
      "kldivergence:   1602.34\n",
      "variational_beta * kldivergence:  0.16023\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35002\n",
      "kldivergence:   1720.54\n",
      "variational_beta * kldivergence:  0.17205\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35176\n",
      "kldivergence:   1660.32\n",
      "variational_beta * kldivergence:  0.16603\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32525\n",
      "kldivergence:   1515.32\n",
      "variational_beta * kldivergence:  0.15153\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38460\n",
      "kldivergence:   1582.93\n",
      "variational_beta * kldivergence:  0.15829\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37126\n",
      "kldivergence:   1747.84\n",
      "variational_beta * kldivergence:  0.17478\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.39802\n",
      "kldivergence:   1795.14\n",
      "variational_beta * kldivergence:  0.17951\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30087\n",
      "kldivergence:   1959.96\n",
      "variational_beta * kldivergence:  0.19600\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31076\n",
      "kldivergence:   1470.59\n",
      "variational_beta * kldivergence:  0.14706\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30896\n",
      "kldivergence:   1490.82\n",
      "variational_beta * kldivergence:  0.14908\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31799\n",
      "kldivergence:   1511.96\n",
      "variational_beta * kldivergence:  0.15120\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.41413\n",
      "kldivergence:   1648.95\n",
      "variational_beta * kldivergence:  0.16489\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33417\n",
      "kldivergence:   1602.83\n",
      "variational_beta * kldivergence:  0.16028\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28001\n",
      "kldivergence:   1623.22\n",
      "variational_beta * kldivergence:  0.16232\n",
      "batch accuracy: 90.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30161\n",
      "kldivergence:   1316.01\n",
      "variational_beta * kldivergence:  0.13160\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31599\n",
      "kldivergence:   1598.20\n",
      "variational_beta * kldivergence:  0.15982\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38778\n",
      "kldivergence:   1593.31\n",
      "variational_beta * kldivergence:  0.15933\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35256\n",
      "kldivergence:   1739.29\n",
      "variational_beta * kldivergence:  0.17393\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33602\n",
      "kldivergence:   1674.24\n",
      "variational_beta * kldivergence:  0.16742\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34678\n",
      "kldivergence:   1698.75\n",
      "variational_beta * kldivergence:  0.16988\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32028\n",
      "kldivergence:   1623.72\n",
      "variational_beta * kldivergence:  0.16237\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34556\n",
      "kldivergence:   1726.48\n",
      "variational_beta * kldivergence:  0.17265\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34496\n",
      "kldivergence:   1744.78\n",
      "variational_beta * kldivergence:  0.17448\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34423\n",
      "kldivergence:   1702.72\n",
      "variational_beta * kldivergence:  0.17027\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34053\n",
      "kldivergence:   1758.01\n",
      "variational_beta * kldivergence:  0.17580\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33685\n",
      "kldivergence:   1897.59\n",
      "variational_beta * kldivergence:  0.18976\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30268\n",
      "kldivergence:   1466.90\n",
      "variational_beta * kldivergence:  0.14669\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35203\n",
      "kldivergence:   1662.05\n",
      "variational_beta * kldivergence:  0.16620\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.41921\n",
      "kldivergence:   1677.60\n",
      "variational_beta * kldivergence:  0.16776\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35510\n",
      "kldivergence:   1684.38\n",
      "variational_beta * kldivergence:  0.16844\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.27688\n",
      "kldivergence:   1296.35\n",
      "variational_beta * kldivergence:  0.12964\n",
      "batch accuracy: 90.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33733\n",
      "kldivergence:   1703.70\n",
      "variational_beta * kldivergence:  0.17037\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29344\n",
      "kldivergence:   1299.68\n",
      "variational_beta * kldivergence:  0.12997\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33823\n",
      "kldivergence:   1855.32\n",
      "variational_beta * kldivergence:  0.18553\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35136\n",
      "kldivergence:   1557.74\n",
      "variational_beta * kldivergence:  0.15577\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37140\n",
      "kldivergence:   1555.94\n",
      "variational_beta * kldivergence:  0.15559\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28651\n",
      "kldivergence:   1746.76\n",
      "variational_beta * kldivergence:  0.17468\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33253\n",
      "kldivergence:   1572.71\n",
      "variational_beta * kldivergence:  0.15727\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36623\n",
      "kldivergence:   1756.22\n",
      "variational_beta * kldivergence:  0.17562\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31399\n",
      "kldivergence:   1782.96\n",
      "variational_beta * kldivergence:  0.17830\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32711\n",
      "kldivergence:   1488.49\n",
      "variational_beta * kldivergence:  0.14885\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.27300\n",
      "kldivergence:   1356.60\n",
      "variational_beta * kldivergence:  0.13566\n",
      "batch accuracy: 91.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36973\n",
      "kldivergence:   1496.47\n",
      "variational_beta * kldivergence:  0.14965\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35317\n",
      "kldivergence:   1775.72\n",
      "variational_beta * kldivergence:  0.17757\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.39127\n",
      "kldivergence:   1771.88\n",
      "variational_beta * kldivergence:  0.17719\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34685\n",
      "kldivergence:   1480.52\n",
      "variational_beta * kldivergence:  0.14805\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34459\n",
      "kldivergence:   1713.46\n",
      "variational_beta * kldivergence:  0.17135\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35248\n",
      "kldivergence:   1605.86\n",
      "variational_beta * kldivergence:  0.16059\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30932\n",
      "kldivergence:   1668.69\n",
      "variational_beta * kldivergence:  0.16687\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30443\n",
      "kldivergence:   1581.77\n",
      "variational_beta * kldivergence:  0.15818\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31442\n",
      "kldivergence:   1546.25\n",
      "variational_beta * kldivergence:  0.15463\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.27152\n",
      "kldivergence:   1350.68\n",
      "variational_beta * kldivergence:  0.13507\n",
      "batch accuracy: 90.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36588\n",
      "kldivergence:   1845.99\n",
      "variational_beta * kldivergence:  0.18460\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35770\n",
      "kldivergence:   1789.53\n",
      "variational_beta * kldivergence:  0.17895\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32071\n",
      "kldivergence:   1651.56\n",
      "variational_beta * kldivergence:  0.16516\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28409\n",
      "kldivergence:   1571.83\n",
      "variational_beta * kldivergence:  0.15718\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32914\n",
      "kldivergence:   1872.44\n",
      "variational_beta * kldivergence:  0.18724\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29161\n",
      "kldivergence:   1482.65\n",
      "variational_beta * kldivergence:  0.14827\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31568\n",
      "kldivergence:   1513.65\n",
      "variational_beta * kldivergence:  0.15136\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32580\n",
      "kldivergence:   1782.62\n",
      "variational_beta * kldivergence:  0.17826\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33045\n",
      "kldivergence:   1531.11\n",
      "variational_beta * kldivergence:  0.15311\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32120\n",
      "kldivergence:   1676.86\n",
      "variational_beta * kldivergence:  0.16769\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34351\n",
      "kldivergence:   1659.70\n",
      "variational_beta * kldivergence:  0.16597\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38137\n",
      "kldivergence:   1641.23\n",
      "variational_beta * kldivergence:  0.16412\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34599\n",
      "kldivergence:   1812.37\n",
      "variational_beta * kldivergence:  0.18124\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34365\n",
      "kldivergence:   1608.12\n",
      "variational_beta * kldivergence:  0.16081\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28804\n",
      "kldivergence:   1438.87\n",
      "variational_beta * kldivergence:  0.14389\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31242\n",
      "kldivergence:   1769.07\n",
      "variational_beta * kldivergence:  0.17691\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33543\n",
      "kldivergence:   1563.54\n",
      "variational_beta * kldivergence:  0.15635\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30689\n",
      "kldivergence:   1544.15\n",
      "variational_beta * kldivergence:  0.15441\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33060\n",
      "kldivergence:   1747.15\n",
      "variational_beta * kldivergence:  0.17471\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35013\n",
      "kldivergence:   1846.34\n",
      "variational_beta * kldivergence:  0.18463\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.40289\n",
      "kldivergence:   1777.91\n",
      "variational_beta * kldivergence:  0.17779\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31365\n",
      "kldivergence:   1571.46\n",
      "variational_beta * kldivergence:  0.15715\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38139\n",
      "kldivergence:   1627.62\n",
      "variational_beta * kldivergence:  0.16276\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37668\n",
      "kldivergence:   1537.36\n",
      "variational_beta * kldivergence:  0.15374\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36063\n",
      "kldivergence:   1808.85\n",
      "variational_beta * kldivergence:  0.18089\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30664\n",
      "kldivergence:   1358.00\n",
      "variational_beta * kldivergence:  0.13580\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36027\n",
      "kldivergence:   1624.28\n",
      "variational_beta * kldivergence:  0.16243\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33125\n",
      "kldivergence:   1644.60\n",
      "variational_beta * kldivergence:  0.16446\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35182\n",
      "kldivergence:   1593.58\n",
      "variational_beta * kldivergence:  0.15936\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35634\n",
      "kldivergence:   1621.06\n",
      "variational_beta * kldivergence:  0.16211\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35381\n",
      "kldivergence:   1400.82\n",
      "variational_beta * kldivergence:  0.14008\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28526\n",
      "kldivergence:   1441.07\n",
      "variational_beta * kldivergence:  0.14411\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33129\n",
      "kldivergence:   1582.38\n",
      "variational_beta * kldivergence:  0.15824\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35031\n",
      "kldivergence:   1533.32\n",
      "variational_beta * kldivergence:  0.15333\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29968\n",
      "kldivergence:   1804.39\n",
      "variational_beta * kldivergence:  0.18044\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32558\n",
      "kldivergence:   1596.00\n",
      "variational_beta * kldivergence:  0.15960\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32397\n",
      "kldivergence:   1631.62\n",
      "variational_beta * kldivergence:  0.16316\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34173\n",
      "kldivergence:   1676.65\n",
      "variational_beta * kldivergence:  0.16767\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35234\n",
      "kldivergence:   1464.82\n",
      "variational_beta * kldivergence:  0.14648\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31884\n",
      "kldivergence:   1564.37\n",
      "variational_beta * kldivergence:  0.15644\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38717\n",
      "kldivergence:   1799.42\n",
      "variational_beta * kldivergence:  0.17994\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29946\n",
      "kldivergence:   1693.95\n",
      "variational_beta * kldivergence:  0.16939\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29888\n",
      "kldivergence:   1412.04\n",
      "variational_beta * kldivergence:  0.14120\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33465\n",
      "kldivergence:   1549.75\n",
      "variational_beta * kldivergence:  0.15498\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38534\n",
      "kldivergence:   1706.31\n",
      "variational_beta * kldivergence:  0.17063\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33211\n",
      "kldivergence:   1522.85\n",
      "variational_beta * kldivergence:  0.15228\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36662\n",
      "kldivergence:   1537.61\n",
      "variational_beta * kldivergence:  0.15376\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33722\n",
      "kldivergence:   1611.19\n",
      "variational_beta * kldivergence:  0.16112\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36135\n",
      "kldivergence:   1744.08\n",
      "variational_beta * kldivergence:  0.17441\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38358\n",
      "kldivergence:   1686.09\n",
      "variational_beta * kldivergence:  0.16861\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33507\n",
      "kldivergence:   1507.92\n",
      "variational_beta * kldivergence:  0.15079\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34827\n",
      "kldivergence:   1604.80\n",
      "variational_beta * kldivergence:  0.16048\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33735\n",
      "kldivergence:   1632.71\n",
      "variational_beta * kldivergence:  0.16327\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30963\n",
      "kldivergence:   1725.18\n",
      "variational_beta * kldivergence:  0.17252\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36974\n",
      "kldivergence:   1721.16\n",
      "variational_beta * kldivergence:  0.17212\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34722\n",
      "kldivergence:   1601.47\n",
      "variational_beta * kldivergence:  0.16015\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28281\n",
      "kldivergence:   1467.65\n",
      "variational_beta * kldivergence:  0.14676\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36495\n",
      "kldivergence:   1764.29\n",
      "variational_beta * kldivergence:  0.17643\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31089\n",
      "kldivergence:   1638.73\n",
      "variational_beta * kldivergence:  0.16387\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29639\n",
      "kldivergence:   1734.54\n",
      "variational_beta * kldivergence:  0.17345\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35462\n",
      "kldivergence:   2026.89\n",
      "variational_beta * kldivergence:  0.20269\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.39965\n",
      "kldivergence:   2018.41\n",
      "variational_beta * kldivergence:  0.20184\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34653\n",
      "kldivergence:   1668.56\n",
      "variational_beta * kldivergence:  0.16686\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30103\n",
      "kldivergence:   1626.93\n",
      "variational_beta * kldivergence:  0.16269\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29915\n",
      "kldivergence:   1507.68\n",
      "variational_beta * kldivergence:  0.15077\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33900\n",
      "kldivergence:   1623.86\n",
      "variational_beta * kldivergence:  0.16239\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29174\n",
      "kldivergence:   1402.22\n",
      "variational_beta * kldivergence:  0.14022\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33157\n",
      "kldivergence:   1630.06\n",
      "variational_beta * kldivergence:  0.16301\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.39970\n",
      "kldivergence:   1770.34\n",
      "variational_beta * kldivergence:  0.17703\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34461\n",
      "kldivergence:   1448.98\n",
      "variational_beta * kldivergence:  0.14490\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34590\n",
      "kldivergence:   1618.52\n",
      "variational_beta * kldivergence:  0.16185\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33632\n",
      "kldivergence:   1590.65\n",
      "variational_beta * kldivergence:  0.15906\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31285\n",
      "kldivergence:   1712.38\n",
      "variational_beta * kldivergence:  0.17124\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35619\n",
      "kldivergence:   1613.87\n",
      "variational_beta * kldivergence:  0.16139\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36134\n",
      "kldivergence:   1780.95\n",
      "variational_beta * kldivergence:  0.17810\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35841\n",
      "kldivergence:   1677.94\n",
      "variational_beta * kldivergence:  0.16779\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.39278\n",
      "kldivergence:   1734.18\n",
      "variational_beta * kldivergence:  0.17342\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36076\n",
      "kldivergence:   1616.14\n",
      "variational_beta * kldivergence:  0.16161\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32465\n",
      "kldivergence:   1561.90\n",
      "variational_beta * kldivergence:  0.15619\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34048\n",
      "kldivergence:   1903.07\n",
      "variational_beta * kldivergence:  0.19031\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34867\n",
      "kldivergence:   1378.39\n",
      "variational_beta * kldivergence:  0.13784\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32852\n",
      "kldivergence:   1632.24\n",
      "variational_beta * kldivergence:  0.16322\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31375\n",
      "kldivergence:   1362.44\n",
      "variational_beta * kldivergence:  0.13624\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35056\n",
      "kldivergence:   1942.66\n",
      "variational_beta * kldivergence:  0.19427\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33309\n",
      "kldivergence:   1807.90\n",
      "variational_beta * kldivergence:  0.18079\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30767\n",
      "kldivergence:   1345.39\n",
      "variational_beta * kldivergence:  0.13454\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35649\n",
      "kldivergence:   1583.29\n",
      "variational_beta * kldivergence:  0.15833\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30965\n",
      "kldivergence:   1688.68\n",
      "variational_beta * kldivergence:  0.16887\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38383\n",
      "kldivergence:   1660.14\n",
      "variational_beta * kldivergence:  0.16601\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.38059\n",
      "kldivergence:   1669.58\n",
      "variational_beta * kldivergence:  0.16696\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32597\n",
      "kldivergence:   1525.29\n",
      "variational_beta * kldivergence:  0.15253\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37383\n",
      "kldivergence:   1746.72\n",
      "variational_beta * kldivergence:  0.17467\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32384\n",
      "kldivergence:   1656.66\n",
      "variational_beta * kldivergence:  0.16567\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31489\n",
      "kldivergence:   1569.83\n",
      "variational_beta * kldivergence:  0.15698\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33499\n",
      "kldivergence:   1542.80\n",
      "variational_beta * kldivergence:  0.15428\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37291\n",
      "kldivergence:   1731.65\n",
      "variational_beta * kldivergence:  0.17317\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36618\n",
      "kldivergence:   1730.33\n",
      "variational_beta * kldivergence:  0.17303\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35466\n",
      "kldivergence:   1771.69\n",
      "variational_beta * kldivergence:  0.17717\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31548\n",
      "kldivergence:   1411.10\n",
      "variational_beta * kldivergence:  0.14111\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29676\n",
      "kldivergence:   1479.11\n",
      "variational_beta * kldivergence:  0.14791\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.26890\n",
      "kldivergence:   1493.90\n",
      "variational_beta * kldivergence:  0.14939\n",
      "batch accuracy: 90.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35094\n",
      "kldivergence:   1699.80\n",
      "variational_beta * kldivergence:  0.16998\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32039\n",
      "kldivergence:   1519.00\n",
      "variational_beta * kldivergence:  0.15190\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36890\n",
      "kldivergence:   1707.36\n",
      "variational_beta * kldivergence:  0.17074\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30374\n",
      "kldivergence:   1364.87\n",
      "variational_beta * kldivergence:  0.13649\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36060\n",
      "kldivergence:   1583.72\n",
      "variational_beta * kldivergence:  0.15837\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34349\n",
      "kldivergence:   1682.05\n",
      "variational_beta * kldivergence:  0.16820\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31911\n",
      "kldivergence:   1595.33\n",
      "variational_beta * kldivergence:  0.15953\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.26694\n",
      "kldivergence:   1504.56\n",
      "variational_beta * kldivergence:  0.15046\n",
      "batch accuracy: 91.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35125\n",
      "kldivergence:   1594.23\n",
      "variational_beta * kldivergence:  0.15942\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34153\n",
      "kldivergence:   1515.65\n",
      "variational_beta * kldivergence:  0.15157\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30430\n",
      "kldivergence:   1621.29\n",
      "variational_beta * kldivergence:  0.16213\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35561\n",
      "kldivergence:   1670.91\n",
      "variational_beta * kldivergence:  0.16709\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34343\n",
      "kldivergence:   1599.42\n",
      "variational_beta * kldivergence:  0.15994\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35590\n",
      "kldivergence:   1772.34\n",
      "variational_beta * kldivergence:  0.17723\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33384\n",
      "kldivergence:   1517.18\n",
      "variational_beta * kldivergence:  0.15172\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37802\n",
      "kldivergence:   1838.33\n",
      "variational_beta * kldivergence:  0.18383\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29130\n",
      "kldivergence:   1552.68\n",
      "variational_beta * kldivergence:  0.15527\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30735\n",
      "kldivergence:   1638.46\n",
      "variational_beta * kldivergence:  0.16385\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.39293\n",
      "kldivergence:   1982.03\n",
      "variational_beta * kldivergence:  0.19820\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32805\n",
      "kldivergence:   1432.52\n",
      "variational_beta * kldivergence:  0.14325\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33743\n",
      "kldivergence:   1488.27\n",
      "variational_beta * kldivergence:  0.14883\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36438\n",
      "kldivergence:   1660.72\n",
      "variational_beta * kldivergence:  0.16607\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.39237\n",
      "kldivergence:   1799.79\n",
      "variational_beta * kldivergence:  0.17998\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30609\n",
      "kldivergence:   1551.65\n",
      "variational_beta * kldivergence:  0.15517\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30940\n",
      "kldivergence:   1535.26\n",
      "variational_beta * kldivergence:  0.15353\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31164\n",
      "kldivergence:   1355.65\n",
      "variational_beta * kldivergence:  0.13557\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30003\n",
      "kldivergence:   1509.12\n",
      "variational_beta * kldivergence:  0.15091\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.27449\n",
      "kldivergence:   1390.64\n",
      "variational_beta * kldivergence:  0.13906\n",
      "batch accuracy: 90.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35862\n",
      "kldivergence:   1445.30\n",
      "variational_beta * kldivergence:  0.14453\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33700\n",
      "kldivergence:   1511.40\n",
      "variational_beta * kldivergence:  0.15114\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33106\n",
      "kldivergence:   1478.12\n",
      "variational_beta * kldivergence:  0.14781\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35591\n",
      "kldivergence:   1661.56\n",
      "variational_beta * kldivergence:  0.16616\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.31952\n",
      "kldivergence:   1754.81\n",
      "variational_beta * kldivergence:  0.17548\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33140\n",
      "kldivergence:   1572.45\n",
      "variational_beta * kldivergence:  0.15724\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.35530\n",
      "kldivergence:   1768.74\n",
      "variational_beta * kldivergence:  0.17687\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.28700\n",
      "kldivergence:   1574.73\n",
      "variational_beta * kldivergence:  0.15747\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.36992\n",
      "kldivergence:   1779.61\n",
      "variational_beta * kldivergence:  0.17796\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.42295\n",
      "kldivergence:   1803.89\n",
      "variational_beta * kldivergence:  0.18039\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30751\n",
      "kldivergence:   1515.15\n",
      "variational_beta * kldivergence:  0.15152\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.33759\n",
      "kldivergence:   1444.33\n",
      "variational_beta * kldivergence:  0.14443\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.30998\n",
      "kldivergence:   1533.19\n",
      "variational_beta * kldivergence:  0.15332\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29540\n",
      "kldivergence:   1491.04\n",
      "variational_beta * kldivergence:  0.14910\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.34260\n",
      "kldivergence:   1597.03\n",
      "variational_beta * kldivergence:  0.15970\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.29459\n",
      "kldivergence:   1629.64\n",
      "variational_beta * kldivergence:  0.16296\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.40577\n",
      "kldivergence:   1683.88\n",
      "variational_beta * kldivergence:  0.16839\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.32427\n",
      "kldivergence:   1580.86\n",
      "variational_beta * kldivergence:  0.15809\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #21\n",
      "reconstruction loss: 0.37230\n",
      "kldivergence:   1660.78\n",
      "variational_beta * kldivergence:  0.16608\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.39993\n",
      "kldivergence:   1422.19\n",
      "variational_beta * kldivergence:  0.14222\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.38655\n",
      "kldivergence:   1370.58\n",
      "variational_beta * kldivergence:  0.13706\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.52257\n",
      "kldivergence:   1513.07\n",
      "variational_beta * kldivergence:  0.15131\n",
      "batch accuracy: 84.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.46044\n",
      "kldivergence:   1512.37\n",
      "variational_beta * kldivergence:  0.15124\n",
      "batch accuracy: 86.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.46989\n",
      "kldivergence:   1542.08\n",
      "variational_beta * kldivergence:  0.15421\n",
      "batch accuracy: 85.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.35354\n",
      "kldivergence:   1365.65\n",
      "variational_beta * kldivergence:  0.13656\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.46597\n",
      "kldivergence:   1500.60\n",
      "variational_beta * kldivergence:  0.15006\n",
      "batch accuracy: 85.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.43371\n",
      "kldivergence:   1458.96\n",
      "variational_beta * kldivergence:  0.14590\n",
      "batch accuracy: 86.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.49322\n",
      "kldivergence:   1539.40\n",
      "variational_beta * kldivergence:  0.15394\n",
      "batch accuracy: 85.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.45135\n",
      "kldivergence:   1659.46\n",
      "variational_beta * kldivergence:  0.16595\n",
      "batch accuracy: 85.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.39392\n",
      "kldivergence:   1533.15\n",
      "variational_beta * kldivergence:  0.15331\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.42529\n",
      "kldivergence:   1445.91\n",
      "variational_beta * kldivergence:  0.14459\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.52583\n",
      "kldivergence:   1580.69\n",
      "variational_beta * kldivergence:  0.15807\n",
      "batch accuracy: 84.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.47496\n",
      "kldivergence:   1475.16\n",
      "variational_beta * kldivergence:  0.14752\n",
      "batch accuracy: 85.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.34019\n",
      "kldivergence:   1398.72\n",
      "variational_beta * kldivergence:  0.13987\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.43473\n",
      "kldivergence:   1404.92\n",
      "variational_beta * kldivergence:  0.14049\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.34946\n",
      "kldivergence:   1295.41\n",
      "variational_beta * kldivergence:  0.12954\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.35444\n",
      "kldivergence:   1389.00\n",
      "variational_beta * kldivergence:  0.13890\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.56496\n",
      "kldivergence:   1719.21\n",
      "variational_beta * kldivergence:  0.17192\n",
      "batch accuracy: 82.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.46900\n",
      "kldivergence:   1456.10\n",
      "variational_beta * kldivergence:  0.14561\n",
      "batch accuracy: 85.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.49112\n",
      "kldivergence:   1491.25\n",
      "variational_beta * kldivergence:  0.14912\n",
      "batch accuracy: 84.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.51036\n",
      "kldivergence:   1579.06\n",
      "variational_beta * kldivergence:  0.15791\n",
      "batch accuracy: 84.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.42755\n",
      "kldivergence:   1458.67\n",
      "variational_beta * kldivergence:  0.14587\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.39018\n",
      "kldivergence:   1471.32\n",
      "variational_beta * kldivergence:  0.14713\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.43292\n",
      "kldivergence:   1435.24\n",
      "variational_beta * kldivergence:  0.14352\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.44585\n",
      "kldivergence:   1464.28\n",
      "variational_beta * kldivergence:  0.14643\n",
      "batch accuracy: 85.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.50133\n",
      "kldivergence:   1554.60\n",
      "variational_beta * kldivergence:  0.15546\n",
      "batch accuracy: 84.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.48998\n",
      "kldivergence:   1547.69\n",
      "variational_beta * kldivergence:  0.15477\n",
      "batch accuracy: 85.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.46722\n",
      "kldivergence:   1526.54\n",
      "variational_beta * kldivergence:  0.15265\n",
      "batch accuracy: 85.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.42319\n",
      "kldivergence:   1434.31\n",
      "variational_beta * kldivergence:  0.14343\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.41518\n",
      "kldivergence:   1468.40\n",
      "variational_beta * kldivergence:  0.14684\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.39219\n",
      "kldivergence:   1446.04\n",
      "variational_beta * kldivergence:  0.14460\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.49410\n",
      "kldivergence:   1481.88\n",
      "variational_beta * kldivergence:  0.14819\n",
      "batch accuracy: 85.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.48586\n",
      "kldivergence:   1519.19\n",
      "variational_beta * kldivergence:  0.15192\n",
      "batch accuracy: 85.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.42181\n",
      "kldivergence:   1461.83\n",
      "variational_beta * kldivergence:  0.14618\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.43076\n",
      "kldivergence:   1415.18\n",
      "variational_beta * kldivergence:  0.14152\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.41363\n",
      "kldivergence:   1457.59\n",
      "variational_beta * kldivergence:  0.14576\n",
      "batch accuracy: 86.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.44139\n",
      "kldivergence:   1458.43\n",
      "variational_beta * kldivergence:  0.14584\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.62321\n",
      "kldivergence:   1731.90\n",
      "variational_beta * kldivergence:  0.17319\n",
      "batch accuracy: 81.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.46024\n",
      "kldivergence:   1492.28\n",
      "variational_beta * kldivergence:  0.14923\n",
      "batch accuracy: 86.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.53938\n",
      "kldivergence:   1648.96\n",
      "variational_beta * kldivergence:  0.16490\n",
      "batch accuracy: 83.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.37577\n",
      "kldivergence:   1368.01\n",
      "variational_beta * kldivergence:  0.13680\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.56580\n",
      "kldivergence:   1469.65\n",
      "variational_beta * kldivergence:  0.14696\n",
      "batch accuracy: 85.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.55884\n",
      "kldivergence:   1641.20\n",
      "variational_beta * kldivergence:  0.16412\n",
      "batch accuracy: 83.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.52640\n",
      "kldivergence:   1547.07\n",
      "variational_beta * kldivergence:  0.15471\n",
      "batch accuracy: 84.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.52841\n",
      "kldivergence:   1599.96\n",
      "variational_beta * kldivergence:  0.16000\n",
      "batch accuracy: 84.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.42336\n",
      "kldivergence:   1455.39\n",
      "variational_beta * kldivergence:  0.14554\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.43247\n",
      "kldivergence:   1442.11\n",
      "variational_beta * kldivergence:  0.14421\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.43252\n",
      "kldivergence:   1476.69\n",
      "variational_beta * kldivergence:  0.14767\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.57752\n",
      "kldivergence:   1639.74\n",
      "variational_beta * kldivergence:  0.16397\n",
      "batch accuracy: 84.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.46747\n",
      "kldivergence:   1592.87\n",
      "variational_beta * kldivergence:  0.15929\n",
      "batch accuracy: 84.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.45714\n",
      "kldivergence:   1412.89\n",
      "variational_beta * kldivergence:  0.14129\n",
      "batch accuracy: 86.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.47692\n",
      "kldivergence:   1563.26\n",
      "variational_beta * kldivergence:  0.15633\n",
      "batch accuracy: 84.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.48277\n",
      "kldivergence:   1456.90\n",
      "variational_beta * kldivergence:  0.14569\n",
      "batch accuracy: 85.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.34540\n",
      "kldivergence:   1286.13\n",
      "variational_beta * kldivergence:  0.12861\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.46714\n",
      "kldivergence:   1570.84\n",
      "variational_beta * kldivergence:  0.15708\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.48220\n",
      "kldivergence:   1593.85\n",
      "variational_beta * kldivergence:  0.15938\n",
      "batch accuracy: 84.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.52916\n",
      "kldivergence:   1660.50\n",
      "variational_beta * kldivergence:  0.16605\n",
      "batch accuracy: 83.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.43057\n",
      "kldivergence:   1483.66\n",
      "variational_beta * kldivergence:  0.14837\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.46726\n",
      "kldivergence:   1458.32\n",
      "variational_beta * kldivergence:  0.14583\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.42625\n",
      "kldivergence:   1514.23\n",
      "variational_beta * kldivergence:  0.15142\n",
      "batch accuracy: 86.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #21\n",
      "reconstruction loss: 0.42008\n",
      "kldivergence:   1466.08\n",
      "variational_beta * kldivergence:  0.14661\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "epoch # 21 : train loss is [185.74496266826011] and validation loss is [0.10168643718339004] \n",
      "saved samples\n",
      "Epoch [22 / 150] average reconstruction error: 0.500660\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32733\n",
      "kldivergence:   1751.29\n",
      "variational_beta * kldivergence:  0.17513\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32636\n",
      "kldivergence:   1653.99\n",
      "variational_beta * kldivergence:  0.16540\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33688\n",
      "kldivergence:   1687.31\n",
      "variational_beta * kldivergence:  0.16873\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28447\n",
      "kldivergence:   1732.43\n",
      "variational_beta * kldivergence:  0.17324\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33386\n",
      "kldivergence:   1597.99\n",
      "variational_beta * kldivergence:  0.15980\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33233\n",
      "kldivergence:   1953.78\n",
      "variational_beta * kldivergence:  0.19538\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38290\n",
      "kldivergence:   1744.48\n",
      "variational_beta * kldivergence:  0.17445\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34840\n",
      "kldivergence:   1686.74\n",
      "variational_beta * kldivergence:  0.16867\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.27922\n",
      "kldivergence:   1886.87\n",
      "variational_beta * kldivergence:  0.18869\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33441\n",
      "kldivergence:   1416.40\n",
      "variational_beta * kldivergence:  0.14164\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35806\n",
      "kldivergence:   1555.80\n",
      "variational_beta * kldivergence:  0.15558\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33080\n",
      "kldivergence:   1986.61\n",
      "variational_beta * kldivergence:  0.19866\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29663\n",
      "kldivergence:   1742.72\n",
      "variational_beta * kldivergence:  0.17427\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36796\n",
      "kldivergence:   1955.11\n",
      "variational_beta * kldivergence:  0.19551\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31951\n",
      "kldivergence:   1533.01\n",
      "variational_beta * kldivergence:  0.15330\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.23770\n",
      "kldivergence:   1566.83\n",
      "variational_beta * kldivergence:  0.15668\n",
      "batch accuracy: 91.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32987\n",
      "kldivergence:   1525.77\n",
      "variational_beta * kldivergence:  0.15258\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31619\n",
      "kldivergence:   1499.07\n",
      "variational_beta * kldivergence:  0.14991\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33263\n",
      "kldivergence:   1572.49\n",
      "variational_beta * kldivergence:  0.15725\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36424\n",
      "kldivergence:   1807.74\n",
      "variational_beta * kldivergence:  0.18077\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32919\n",
      "kldivergence:   2085.46\n",
      "variational_beta * kldivergence:  0.20855\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33889\n",
      "kldivergence:   1528.66\n",
      "variational_beta * kldivergence:  0.15287\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36574\n",
      "kldivergence:   1769.52\n",
      "variational_beta * kldivergence:  0.17695\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30619\n",
      "kldivergence:   1637.44\n",
      "variational_beta * kldivergence:  0.16374\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33936\n",
      "kldivergence:   1798.48\n",
      "variational_beta * kldivergence:  0.17985\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32667\n",
      "kldivergence:   1422.20\n",
      "variational_beta * kldivergence:  0.14222\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32479\n",
      "kldivergence:   1537.73\n",
      "variational_beta * kldivergence:  0.15377\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34190\n",
      "kldivergence:   1565.30\n",
      "variational_beta * kldivergence:  0.15653\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32357\n",
      "kldivergence:   1511.32\n",
      "variational_beta * kldivergence:  0.15113\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35962\n",
      "kldivergence:   1484.45\n",
      "variational_beta * kldivergence:  0.14845\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28127\n",
      "kldivergence:   1533.71\n",
      "variational_beta * kldivergence:  0.15337\n",
      "batch accuracy: 90.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31673\n",
      "kldivergence:   1464.89\n",
      "variational_beta * kldivergence:  0.14649\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35345\n",
      "kldivergence:   1462.86\n",
      "variational_beta * kldivergence:  0.14629\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34916\n",
      "kldivergence:   1643.80\n",
      "variational_beta * kldivergence:  0.16438\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32748\n",
      "kldivergence:   1389.17\n",
      "variational_beta * kldivergence:  0.13892\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32842\n",
      "kldivergence:   1511.81\n",
      "variational_beta * kldivergence:  0.15118\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.26907\n",
      "kldivergence:   1654.75\n",
      "variational_beta * kldivergence:  0.16548\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29551\n",
      "kldivergence:   1484.15\n",
      "variational_beta * kldivergence:  0.14841\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30344\n",
      "kldivergence:   1463.78\n",
      "variational_beta * kldivergence:  0.14638\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35695\n",
      "kldivergence:   1702.06\n",
      "variational_beta * kldivergence:  0.17021\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36065\n",
      "kldivergence:   2009.72\n",
      "variational_beta * kldivergence:  0.20097\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30624\n",
      "kldivergence:   1490.52\n",
      "variational_beta * kldivergence:  0.14905\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36495\n",
      "kldivergence:   1834.84\n",
      "variational_beta * kldivergence:  0.18348\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.26843\n",
      "kldivergence:   1698.79\n",
      "variational_beta * kldivergence:  0.16988\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31440\n",
      "kldivergence:   1529.88\n",
      "variational_beta * kldivergence:  0.15299\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30978\n",
      "kldivergence:   1514.54\n",
      "variational_beta * kldivergence:  0.15145\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35253\n",
      "kldivergence:   1580.82\n",
      "variational_beta * kldivergence:  0.15808\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30219\n",
      "kldivergence:   1733.72\n",
      "variational_beta * kldivergence:  0.17337\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29734\n",
      "kldivergence:   1347.93\n",
      "variational_beta * kldivergence:  0.13479\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36380\n",
      "kldivergence:   1519.44\n",
      "variational_beta * kldivergence:  0.15194\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36355\n",
      "kldivergence:   1751.06\n",
      "variational_beta * kldivergence:  0.17511\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34119\n",
      "kldivergence:   1875.17\n",
      "variational_beta * kldivergence:  0.18752\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33881\n",
      "kldivergence:   1555.90\n",
      "variational_beta * kldivergence:  0.15559\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30989\n",
      "kldivergence:   1705.77\n",
      "variational_beta * kldivergence:  0.17058\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31121\n",
      "kldivergence:   1540.72\n",
      "variational_beta * kldivergence:  0.15407\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38882\n",
      "kldivergence:   1761.56\n",
      "variational_beta * kldivergence:  0.17616\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33053\n",
      "kldivergence:   1406.05\n",
      "variational_beta * kldivergence:  0.14060\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30163\n",
      "kldivergence:   1492.19\n",
      "variational_beta * kldivergence:  0.14922\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31362\n",
      "kldivergence:   1778.59\n",
      "variational_beta * kldivergence:  0.17786\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39301\n",
      "kldivergence:   2044.68\n",
      "variational_beta * kldivergence:  0.20447\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34344\n",
      "kldivergence:   1857.67\n",
      "variational_beta * kldivergence:  0.18577\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33392\n",
      "kldivergence:   1664.79\n",
      "variational_beta * kldivergence:  0.16648\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31827\n",
      "kldivergence:   1478.15\n",
      "variational_beta * kldivergence:  0.14781\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33619\n",
      "kldivergence:   1682.06\n",
      "variational_beta * kldivergence:  0.16821\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34720\n",
      "kldivergence:   1638.34\n",
      "variational_beta * kldivergence:  0.16383\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36623\n",
      "kldivergence:   1936.53\n",
      "variational_beta * kldivergence:  0.19365\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36199\n",
      "kldivergence:   1714.48\n",
      "variational_beta * kldivergence:  0.17145\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32857\n",
      "kldivergence:   1572.55\n",
      "variational_beta * kldivergence:  0.15726\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.27674\n",
      "kldivergence:   1569.49\n",
      "variational_beta * kldivergence:  0.15695\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33853\n",
      "kldivergence:   1692.73\n",
      "variational_beta * kldivergence:  0.16927\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35552\n",
      "kldivergence:   1847.94\n",
      "variational_beta * kldivergence:  0.18479\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32403\n",
      "kldivergence:   1580.93\n",
      "variational_beta * kldivergence:  0.15809\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34829\n",
      "kldivergence:   1805.55\n",
      "variational_beta * kldivergence:  0.18055\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34964\n",
      "kldivergence:   1436.42\n",
      "variational_beta * kldivergence:  0.14364\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33493\n",
      "kldivergence:   1421.81\n",
      "variational_beta * kldivergence:  0.14218\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32900\n",
      "kldivergence:   1426.08\n",
      "variational_beta * kldivergence:  0.14261\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.40947\n",
      "kldivergence:   1578.30\n",
      "variational_beta * kldivergence:  0.15783\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32658\n",
      "kldivergence:   1493.37\n",
      "variational_beta * kldivergence:  0.14934\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34467\n",
      "kldivergence:   1574.02\n",
      "variational_beta * kldivergence:  0.15740\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33322\n",
      "kldivergence:   1563.52\n",
      "variational_beta * kldivergence:  0.15635\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35172\n",
      "kldivergence:   1620.22\n",
      "variational_beta * kldivergence:  0.16202\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35438\n",
      "kldivergence:   1588.20\n",
      "variational_beta * kldivergence:  0.15882\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31502\n",
      "kldivergence:   1607.97\n",
      "variational_beta * kldivergence:  0.16080\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.40529\n",
      "kldivergence:   2006.85\n",
      "variational_beta * kldivergence:  0.20068\n",
      "batch accuracy: 86.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35556\n",
      "kldivergence:   1630.94\n",
      "variational_beta * kldivergence:  0.16309\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37313\n",
      "kldivergence:   1843.83\n",
      "variational_beta * kldivergence:  0.18438\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28771\n",
      "kldivergence:   1416.70\n",
      "variational_beta * kldivergence:  0.14167\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31012\n",
      "kldivergence:   1555.77\n",
      "variational_beta * kldivergence:  0.15558\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32393\n",
      "kldivergence:   1423.45\n",
      "variational_beta * kldivergence:  0.14234\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32751\n",
      "kldivergence:   1608.51\n",
      "variational_beta * kldivergence:  0.16085\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36594\n",
      "kldivergence:   1599.17\n",
      "variational_beta * kldivergence:  0.15992\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36665\n",
      "kldivergence:   1699.80\n",
      "variational_beta * kldivergence:  0.16998\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35864\n",
      "kldivergence:   1513.47\n",
      "variational_beta * kldivergence:  0.15135\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28451\n",
      "kldivergence:   1434.30\n",
      "variational_beta * kldivergence:  0.14343\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35754\n",
      "kldivergence:   1742.58\n",
      "variational_beta * kldivergence:  0.17426\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38669\n",
      "kldivergence:   1622.70\n",
      "variational_beta * kldivergence:  0.16227\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38462\n",
      "kldivergence:   1535.81\n",
      "variational_beta * kldivergence:  0.15358\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34382\n",
      "kldivergence:   1612.64\n",
      "variational_beta * kldivergence:  0.16126\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33417\n",
      "kldivergence:   1396.53\n",
      "variational_beta * kldivergence:  0.13965\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33822\n",
      "kldivergence:   1647.70\n",
      "variational_beta * kldivergence:  0.16477\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32346\n",
      "kldivergence:   1690.13\n",
      "variational_beta * kldivergence:  0.16901\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36739\n",
      "kldivergence:   1513.88\n",
      "variational_beta * kldivergence:  0.15139\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35579\n",
      "kldivergence:   1586.82\n",
      "variational_beta * kldivergence:  0.15868\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33097\n",
      "kldivergence:   1634.88\n",
      "variational_beta * kldivergence:  0.16349\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31363\n",
      "kldivergence:   1882.21\n",
      "variational_beta * kldivergence:  0.18822\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30921\n",
      "kldivergence:   1525.93\n",
      "variational_beta * kldivergence:  0.15259\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32406\n",
      "kldivergence:   1725.83\n",
      "variational_beta * kldivergence:  0.17258\n",
      "batch accuracy: 89.11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31746\n",
      "kldivergence:   1660.40\n",
      "variational_beta * kldivergence:  0.16604\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31299\n",
      "kldivergence:   1520.31\n",
      "variational_beta * kldivergence:  0.15203\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32203\n",
      "kldivergence:   1724.20\n",
      "variational_beta * kldivergence:  0.17242\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.26729\n",
      "kldivergence:   1362.23\n",
      "variational_beta * kldivergence:  0.13622\n",
      "batch accuracy: 91.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30477\n",
      "kldivergence:   1468.10\n",
      "variational_beta * kldivergence:  0.14681\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31515\n",
      "kldivergence:   1753.07\n",
      "variational_beta * kldivergence:  0.17531\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32351\n",
      "kldivergence:   1489.15\n",
      "variational_beta * kldivergence:  0.14892\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32193\n",
      "kldivergence:   1608.23\n",
      "variational_beta * kldivergence:  0.16082\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32441\n",
      "kldivergence:   1626.26\n",
      "variational_beta * kldivergence:  0.16263\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29755\n",
      "kldivergence:   1404.60\n",
      "variational_beta * kldivergence:  0.14046\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32145\n",
      "kldivergence:   1620.08\n",
      "variational_beta * kldivergence:  0.16201\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39586\n",
      "kldivergence:   1943.82\n",
      "variational_beta * kldivergence:  0.19438\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38954\n",
      "kldivergence:   1681.97\n",
      "variational_beta * kldivergence:  0.16820\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30170\n",
      "kldivergence:   1584.38\n",
      "variational_beta * kldivergence:  0.15844\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32370\n",
      "kldivergence:   1494.87\n",
      "variational_beta * kldivergence:  0.14949\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34881\n",
      "kldivergence:   1606.29\n",
      "variational_beta * kldivergence:  0.16063\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33198\n",
      "kldivergence:   1690.72\n",
      "variational_beta * kldivergence:  0.16907\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32236\n",
      "kldivergence:   1543.80\n",
      "variational_beta * kldivergence:  0.15438\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34132\n",
      "kldivergence:   1623.69\n",
      "variational_beta * kldivergence:  0.16237\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28644\n",
      "kldivergence:   1985.73\n",
      "variational_beta * kldivergence:  0.19857\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36167\n",
      "kldivergence:   1713.56\n",
      "variational_beta * kldivergence:  0.17136\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36677\n",
      "kldivergence:   1793.13\n",
      "variational_beta * kldivergence:  0.17931\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31934\n",
      "kldivergence:   1489.21\n",
      "variational_beta * kldivergence:  0.14892\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30848\n",
      "kldivergence:   1484.95\n",
      "variational_beta * kldivergence:  0.14849\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33942\n",
      "kldivergence:   1362.14\n",
      "variational_beta * kldivergence:  0.13621\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39703\n",
      "kldivergence:   1845.32\n",
      "variational_beta * kldivergence:  0.18453\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.40568\n",
      "kldivergence:   1771.09\n",
      "variational_beta * kldivergence:  0.17711\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38072\n",
      "kldivergence:   1671.59\n",
      "variational_beta * kldivergence:  0.16716\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34878\n",
      "kldivergence:   1769.70\n",
      "variational_beta * kldivergence:  0.17697\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37380\n",
      "kldivergence:   1568.05\n",
      "variational_beta * kldivergence:  0.15681\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39499\n",
      "kldivergence:   1862.46\n",
      "variational_beta * kldivergence:  0.18625\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29941\n",
      "kldivergence:   1631.86\n",
      "variational_beta * kldivergence:  0.16319\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37248\n",
      "kldivergence:   1473.91\n",
      "variational_beta * kldivergence:  0.14739\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37930\n",
      "kldivergence:   1631.73\n",
      "variational_beta * kldivergence:  0.16317\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.27586\n",
      "kldivergence:   1560.12\n",
      "variational_beta * kldivergence:  0.15601\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32707\n",
      "kldivergence:   1689.09\n",
      "variational_beta * kldivergence:  0.16891\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33526\n",
      "kldivergence:   1610.03\n",
      "variational_beta * kldivergence:  0.16100\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34960\n",
      "kldivergence:   1647.20\n",
      "variational_beta * kldivergence:  0.16472\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31347\n",
      "kldivergence:   1560.43\n",
      "variational_beta * kldivergence:  0.15604\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33115\n",
      "kldivergence:   1549.67\n",
      "variational_beta * kldivergence:  0.15497\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35801\n",
      "kldivergence:   1731.34\n",
      "variational_beta * kldivergence:  0.17313\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35797\n",
      "kldivergence:   1678.16\n",
      "variational_beta * kldivergence:  0.16782\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33385\n",
      "kldivergence:   1964.46\n",
      "variational_beta * kldivergence:  0.19645\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33826\n",
      "kldivergence:   1787.25\n",
      "variational_beta * kldivergence:  0.17872\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.40801\n",
      "kldivergence:   1746.82\n",
      "variational_beta * kldivergence:  0.17468\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31827\n",
      "kldivergence:   1639.56\n",
      "variational_beta * kldivergence:  0.16396\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33204\n",
      "kldivergence:   1896.65\n",
      "variational_beta * kldivergence:  0.18967\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31866\n",
      "kldivergence:   1659.83\n",
      "variational_beta * kldivergence:  0.16598\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31936\n",
      "kldivergence:   1892.86\n",
      "variational_beta * kldivergence:  0.18929\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32864\n",
      "kldivergence:   1557.52\n",
      "variational_beta * kldivergence:  0.15575\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31788\n",
      "kldivergence:   1649.37\n",
      "variational_beta * kldivergence:  0.16494\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33482\n",
      "kldivergence:   1761.73\n",
      "variational_beta * kldivergence:  0.17617\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30707\n",
      "kldivergence:   1629.02\n",
      "variational_beta * kldivergence:  0.16290\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28680\n",
      "kldivergence:   1467.41\n",
      "variational_beta * kldivergence:  0.14674\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31608\n",
      "kldivergence:   1625.37\n",
      "variational_beta * kldivergence:  0.16254\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30739\n",
      "kldivergence:   1571.77\n",
      "variational_beta * kldivergence:  0.15718\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32414\n",
      "kldivergence:   1789.63\n",
      "variational_beta * kldivergence:  0.17896\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32224\n",
      "kldivergence:   1497.75\n",
      "variational_beta * kldivergence:  0.14978\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30450\n",
      "kldivergence:   1640.46\n",
      "variational_beta * kldivergence:  0.16405\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34365\n",
      "kldivergence:   1729.38\n",
      "variational_beta * kldivergence:  0.17294\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35356\n",
      "kldivergence:   1557.63\n",
      "variational_beta * kldivergence:  0.15576\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30151\n",
      "kldivergence:   1510.84\n",
      "variational_beta * kldivergence:  0.15108\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29922\n",
      "kldivergence:   1804.49\n",
      "variational_beta * kldivergence:  0.18045\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35837\n",
      "kldivergence:   1691.17\n",
      "variational_beta * kldivergence:  0.16912\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28326\n",
      "kldivergence:   1378.01\n",
      "variational_beta * kldivergence:  0.13780\n",
      "batch accuracy: 90.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34959\n",
      "kldivergence:   1627.31\n",
      "variational_beta * kldivergence:  0.16273\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32656\n",
      "kldivergence:   1554.88\n",
      "variational_beta * kldivergence:  0.15549\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34013\n",
      "kldivergence:   1618.27\n",
      "variational_beta * kldivergence:  0.16183\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32875\n",
      "kldivergence:   1708.94\n",
      "variational_beta * kldivergence:  0.17089\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34123\n",
      "kldivergence:   1757.31\n",
      "variational_beta * kldivergence:  0.17573\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36476\n",
      "kldivergence:   1495.67\n",
      "variational_beta * kldivergence:  0.14957\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35559\n",
      "kldivergence:   1645.08\n",
      "variational_beta * kldivergence:  0.16451\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31477\n",
      "kldivergence:   1777.74\n",
      "variational_beta * kldivergence:  0.17777\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34430\n",
      "kldivergence:   1439.24\n",
      "variational_beta * kldivergence:  0.14392\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31079\n",
      "kldivergence:   1625.78\n",
      "variational_beta * kldivergence:  0.16258\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35862\n",
      "kldivergence:   1797.33\n",
      "variational_beta * kldivergence:  0.17973\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30310\n",
      "kldivergence:   1607.04\n",
      "variational_beta * kldivergence:  0.16070\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30411\n",
      "kldivergence:   1594.18\n",
      "variational_beta * kldivergence:  0.15942\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35121\n",
      "kldivergence:   1720.16\n",
      "variational_beta * kldivergence:  0.17202\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33557\n",
      "kldivergence:   1540.51\n",
      "variational_beta * kldivergence:  0.15405\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34560\n",
      "kldivergence:   1639.37\n",
      "variational_beta * kldivergence:  0.16394\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32197\n",
      "kldivergence:   1615.62\n",
      "variational_beta * kldivergence:  0.16156\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.27122\n",
      "kldivergence:   1365.24\n",
      "variational_beta * kldivergence:  0.13652\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31016\n",
      "kldivergence:   1519.20\n",
      "variational_beta * kldivergence:  0.15192\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32273\n",
      "kldivergence:   1594.69\n",
      "variational_beta * kldivergence:  0.15947\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32888\n",
      "kldivergence:   1524.31\n",
      "variational_beta * kldivergence:  0.15243\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36577\n",
      "kldivergence:   1707.32\n",
      "variational_beta * kldivergence:  0.17073\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38021\n",
      "kldivergence:   1725.38\n",
      "variational_beta * kldivergence:  0.17254\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31687\n",
      "kldivergence:   1389.06\n",
      "variational_beta * kldivergence:  0.13891\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34562\n",
      "kldivergence:   1616.55\n",
      "variational_beta * kldivergence:  0.16166\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30772\n",
      "kldivergence:   1579.71\n",
      "variational_beta * kldivergence:  0.15797\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38499\n",
      "kldivergence:   1685.11\n",
      "variational_beta * kldivergence:  0.16851\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32601\n",
      "kldivergence:   1608.70\n",
      "variational_beta * kldivergence:  0.16087\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31233\n",
      "kldivergence:   1781.19\n",
      "variational_beta * kldivergence:  0.17812\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28425\n",
      "kldivergence:   1531.06\n",
      "variational_beta * kldivergence:  0.15311\n",
      "batch accuracy: 90.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39765\n",
      "kldivergence:   1848.66\n",
      "variational_beta * kldivergence:  0.18487\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34797\n",
      "kldivergence:   1669.42\n",
      "variational_beta * kldivergence:  0.16694\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33637\n",
      "kldivergence:   1727.08\n",
      "variational_beta * kldivergence:  0.17271\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35977\n",
      "kldivergence:   1495.19\n",
      "variational_beta * kldivergence:  0.14952\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32624\n",
      "kldivergence:   1670.83\n",
      "variational_beta * kldivergence:  0.16708\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31638\n",
      "kldivergence:   1666.68\n",
      "variational_beta * kldivergence:  0.16667\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36639\n",
      "kldivergence:   1839.87\n",
      "variational_beta * kldivergence:  0.18399\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.27325\n",
      "kldivergence:   1599.49\n",
      "variational_beta * kldivergence:  0.15995\n",
      "batch accuracy: 90.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.43229\n",
      "kldivergence:   1904.99\n",
      "variational_beta * kldivergence:  0.19050\n",
      "batch accuracy: 85.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29120\n",
      "kldivergence:   1510.97\n",
      "variational_beta * kldivergence:  0.15110\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34579\n",
      "kldivergence:   1598.23\n",
      "variational_beta * kldivergence:  0.15982\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33877\n",
      "kldivergence:   1632.58\n",
      "variational_beta * kldivergence:  0.16326\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32255\n",
      "kldivergence:   1362.90\n",
      "variational_beta * kldivergence:  0.13629\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28704\n",
      "kldivergence:   1442.19\n",
      "variational_beta * kldivergence:  0.14422\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31244\n",
      "kldivergence:   1406.39\n",
      "variational_beta * kldivergence:  0.14064\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37171\n",
      "kldivergence:   1573.47\n",
      "variational_beta * kldivergence:  0.15735\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34134\n",
      "kldivergence:   1804.84\n",
      "variational_beta * kldivergence:  0.18048\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30101\n",
      "kldivergence:   1624.82\n",
      "variational_beta * kldivergence:  0.16248\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32657\n",
      "kldivergence:   1615.14\n",
      "variational_beta * kldivergence:  0.16151\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32142\n",
      "kldivergence:   1748.43\n",
      "variational_beta * kldivergence:  0.17484\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34881\n",
      "kldivergence:   1597.56\n",
      "variational_beta * kldivergence:  0.15976\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35551\n",
      "kldivergence:   1482.13\n",
      "variational_beta * kldivergence:  0.14821\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30293\n",
      "kldivergence:   1492.83\n",
      "variational_beta * kldivergence:  0.14928\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28843\n",
      "kldivergence:   1598.68\n",
      "variational_beta * kldivergence:  0.15987\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36187\n",
      "kldivergence:   1566.44\n",
      "variational_beta * kldivergence:  0.15664\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35511\n",
      "kldivergence:   1461.18\n",
      "variational_beta * kldivergence:  0.14612\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33102\n",
      "kldivergence:   1749.30\n",
      "variational_beta * kldivergence:  0.17493\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32468\n",
      "kldivergence:   1678.60\n",
      "variational_beta * kldivergence:  0.16786\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32866\n",
      "kldivergence:   1306.98\n",
      "variational_beta * kldivergence:  0.13070\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34209\n",
      "kldivergence:   1503.46\n",
      "variational_beta * kldivergence:  0.15035\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.41826\n",
      "kldivergence:   1744.29\n",
      "variational_beta * kldivergence:  0.17443\n",
      "batch accuracy: 86.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32946\n",
      "kldivergence:   1610.51\n",
      "variational_beta * kldivergence:  0.16105\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.42635\n",
      "kldivergence:   1892.70\n",
      "variational_beta * kldivergence:  0.18927\n",
      "batch accuracy: 85.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31536\n",
      "kldivergence:   1668.32\n",
      "variational_beta * kldivergence:  0.16683\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34206\n",
      "kldivergence:   1649.83\n",
      "variational_beta * kldivergence:  0.16498\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36333\n",
      "kldivergence:   1587.99\n",
      "variational_beta * kldivergence:  0.15880\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35501\n",
      "kldivergence:   1620.92\n",
      "variational_beta * kldivergence:  0.16209\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32137\n",
      "kldivergence:   1572.31\n",
      "variational_beta * kldivergence:  0.15723\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29941\n",
      "kldivergence:   1644.63\n",
      "variational_beta * kldivergence:  0.16446\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28664\n",
      "kldivergence:   1495.62\n",
      "variational_beta * kldivergence:  0.14956\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33460\n",
      "kldivergence:   1479.87\n",
      "variational_beta * kldivergence:  0.14799\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39433\n",
      "kldivergence:   2021.94\n",
      "variational_beta * kldivergence:  0.20219\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31860\n",
      "kldivergence:   1720.94\n",
      "variational_beta * kldivergence:  0.17209\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33310\n",
      "kldivergence:   1649.86\n",
      "variational_beta * kldivergence:  0.16499\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35472\n",
      "kldivergence:   1837.10\n",
      "variational_beta * kldivergence:  0.18371\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32210\n",
      "kldivergence:   1471.10\n",
      "variational_beta * kldivergence:  0.14711\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29851\n",
      "kldivergence:   1672.57\n",
      "variational_beta * kldivergence:  0.16726\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31766\n",
      "kldivergence:   1525.63\n",
      "variational_beta * kldivergence:  0.15256\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35329\n",
      "kldivergence:   1999.52\n",
      "variational_beta * kldivergence:  0.19995\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35278\n",
      "kldivergence:   1457.33\n",
      "variational_beta * kldivergence:  0.14573\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35626\n",
      "kldivergence:   1798.54\n",
      "variational_beta * kldivergence:  0.17985\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.41719\n",
      "kldivergence:   1779.97\n",
      "variational_beta * kldivergence:  0.17800\n",
      "batch accuracy: 85.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34815\n",
      "kldivergence:   1625.29\n",
      "variational_beta * kldivergence:  0.16253\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36204\n",
      "kldivergence:   1566.43\n",
      "variational_beta * kldivergence:  0.15664\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30707\n",
      "kldivergence:   1478.47\n",
      "variational_beta * kldivergence:  0.14785\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33520\n",
      "kldivergence:   1709.47\n",
      "variational_beta * kldivergence:  0.17095\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39614\n",
      "kldivergence:   1718.36\n",
      "variational_beta * kldivergence:  0.17184\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33724\n",
      "kldivergence:   1608.16\n",
      "variational_beta * kldivergence:  0.16082\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34898\n",
      "kldivergence:   1426.91\n",
      "variational_beta * kldivergence:  0.14269\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36285\n",
      "kldivergence:   1591.60\n",
      "variational_beta * kldivergence:  0.15916\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32434\n",
      "kldivergence:   1443.72\n",
      "variational_beta * kldivergence:  0.14437\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30638\n",
      "kldivergence:   1436.60\n",
      "variational_beta * kldivergence:  0.14366\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31064\n",
      "kldivergence:   1491.77\n",
      "variational_beta * kldivergence:  0.14918\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38709\n",
      "kldivergence:   1760.06\n",
      "variational_beta * kldivergence:  0.17601\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33282\n",
      "kldivergence:   1733.33\n",
      "variational_beta * kldivergence:  0.17333\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34680\n",
      "kldivergence:   1641.08\n",
      "variational_beta * kldivergence:  0.16411\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29993\n",
      "kldivergence:   1592.65\n",
      "variational_beta * kldivergence:  0.15927\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34528\n",
      "kldivergence:   1614.21\n",
      "variational_beta * kldivergence:  0.16142\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32667\n",
      "kldivergence:   1640.73\n",
      "variational_beta * kldivergence:  0.16407\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36647\n",
      "kldivergence:   1541.70\n",
      "variational_beta * kldivergence:  0.15417\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36966\n",
      "kldivergence:   1771.10\n",
      "variational_beta * kldivergence:  0.17711\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33137\n",
      "kldivergence:   1602.28\n",
      "variational_beta * kldivergence:  0.16023\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33420\n",
      "kldivergence:   1730.08\n",
      "variational_beta * kldivergence:  0.17301\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33563\n",
      "kldivergence:   1553.18\n",
      "variational_beta * kldivergence:  0.15532\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39147\n",
      "kldivergence:   1645.67\n",
      "variational_beta * kldivergence:  0.16457\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34397\n",
      "kldivergence:   1562.19\n",
      "variational_beta * kldivergence:  0.15622\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34328\n",
      "kldivergence:   1795.27\n",
      "variational_beta * kldivergence:  0.17953\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30462\n",
      "kldivergence:   1510.13\n",
      "variational_beta * kldivergence:  0.15101\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33555\n",
      "kldivergence:   1529.38\n",
      "variational_beta * kldivergence:  0.15294\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33440\n",
      "kldivergence:   1759.56\n",
      "variational_beta * kldivergence:  0.17596\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33806\n",
      "kldivergence:   1609.64\n",
      "variational_beta * kldivergence:  0.16096\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36367\n",
      "kldivergence:   1636.35\n",
      "variational_beta * kldivergence:  0.16364\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37896\n",
      "kldivergence:   1677.18\n",
      "variational_beta * kldivergence:  0.16772\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30538\n",
      "kldivergence:   1579.03\n",
      "variational_beta * kldivergence:  0.15790\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35013\n",
      "kldivergence:   1837.86\n",
      "variational_beta * kldivergence:  0.18379\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32115\n",
      "kldivergence:   1724.47\n",
      "variational_beta * kldivergence:  0.17245\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33434\n",
      "kldivergence:   1582.49\n",
      "variational_beta * kldivergence:  0.15825\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36575\n",
      "kldivergence:   1632.59\n",
      "variational_beta * kldivergence:  0.16326\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32816\n",
      "kldivergence:   1542.70\n",
      "variational_beta * kldivergence:  0.15427\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33229\n",
      "kldivergence:   1648.36\n",
      "variational_beta * kldivergence:  0.16484\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35155\n",
      "kldivergence:   1530.23\n",
      "variational_beta * kldivergence:  0.15302\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32225\n",
      "kldivergence:   1677.78\n",
      "variational_beta * kldivergence:  0.16778\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33368\n",
      "kldivergence:   1627.96\n",
      "variational_beta * kldivergence:  0.16280\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38033\n",
      "kldivergence:   1432.09\n",
      "variational_beta * kldivergence:  0.14321\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35431\n",
      "kldivergence:   1635.02\n",
      "variational_beta * kldivergence:  0.16350\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32736\n",
      "kldivergence:   1694.73\n",
      "variational_beta * kldivergence:  0.16947\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33715\n",
      "kldivergence:   1543.60\n",
      "variational_beta * kldivergence:  0.15436\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34952\n",
      "kldivergence:   1674.61\n",
      "variational_beta * kldivergence:  0.16746\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.25407\n",
      "kldivergence:   1450.49\n",
      "variational_beta * kldivergence:  0.14505\n",
      "batch accuracy: 91.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31703\n",
      "kldivergence:   1596.39\n",
      "variational_beta * kldivergence:  0.15964\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37851\n",
      "kldivergence:   1835.37\n",
      "variational_beta * kldivergence:  0.18354\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30276\n",
      "kldivergence:   1605.34\n",
      "variational_beta * kldivergence:  0.16053\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36215\n",
      "kldivergence:   1747.93\n",
      "variational_beta * kldivergence:  0.17479\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32174\n",
      "kldivergence:   1623.32\n",
      "variational_beta * kldivergence:  0.16233\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39962\n",
      "kldivergence:   1592.01\n",
      "variational_beta * kldivergence:  0.15920\n",
      "batch accuracy: 86.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28678\n",
      "kldivergence:   1604.38\n",
      "variational_beta * kldivergence:  0.16044\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37099\n",
      "kldivergence:   1788.88\n",
      "variational_beta * kldivergence:  0.17889\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33659\n",
      "kldivergence:   1831.56\n",
      "variational_beta * kldivergence:  0.18316\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.27891\n",
      "kldivergence:   1785.87\n",
      "variational_beta * kldivergence:  0.17859\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30979\n",
      "kldivergence:   1574.86\n",
      "variational_beta * kldivergence:  0.15749\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30753\n",
      "kldivergence:   1515.26\n",
      "variational_beta * kldivergence:  0.15153\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35332\n",
      "kldivergence:   1872.64\n",
      "variational_beta * kldivergence:  0.18726\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31338\n",
      "kldivergence:   1675.85\n",
      "variational_beta * kldivergence:  0.16759\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30605\n",
      "kldivergence:   1588.20\n",
      "variational_beta * kldivergence:  0.15882\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37685\n",
      "kldivergence:   1660.61\n",
      "variational_beta * kldivergence:  0.16606\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34817\n",
      "kldivergence:   1693.46\n",
      "variational_beta * kldivergence:  0.16935\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28955\n",
      "kldivergence:   1679.24\n",
      "variational_beta * kldivergence:  0.16792\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32537\n",
      "kldivergence:   2276.88\n",
      "variational_beta * kldivergence:  0.22769\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33885\n",
      "kldivergence:   1661.23\n",
      "variational_beta * kldivergence:  0.16612\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36087\n",
      "kldivergence:   1714.28\n",
      "variational_beta * kldivergence:  0.17143\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37122\n",
      "kldivergence:   1596.42\n",
      "variational_beta * kldivergence:  0.15964\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32715\n",
      "kldivergence:   1628.55\n",
      "variational_beta * kldivergence:  0.16286\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35790\n",
      "kldivergence:   1753.13\n",
      "variational_beta * kldivergence:  0.17531\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35755\n",
      "kldivergence:   1940.50\n",
      "variational_beta * kldivergence:  0.19405\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39617\n",
      "kldivergence:   1521.49\n",
      "variational_beta * kldivergence:  0.15215\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37357\n",
      "kldivergence:   1577.05\n",
      "variational_beta * kldivergence:  0.15771\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35514\n",
      "kldivergence:   1833.31\n",
      "variational_beta * kldivergence:  0.18333\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32016\n",
      "kldivergence:   1633.09\n",
      "variational_beta * kldivergence:  0.16331\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31697\n",
      "kldivergence:   1538.21\n",
      "variational_beta * kldivergence:  0.15382\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.37220\n",
      "kldivergence:   1912.55\n",
      "variational_beta * kldivergence:  0.19125\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31452\n",
      "kldivergence:   1479.70\n",
      "variational_beta * kldivergence:  0.14797\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31420\n",
      "kldivergence:   1790.03\n",
      "variational_beta * kldivergence:  0.17900\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34265\n",
      "kldivergence:   1442.07\n",
      "variational_beta * kldivergence:  0.14421\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32492\n",
      "kldivergence:   1592.82\n",
      "variational_beta * kldivergence:  0.15928\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30256\n",
      "kldivergence:   1845.81\n",
      "variational_beta * kldivergence:  0.18458\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31918\n",
      "kldivergence:   1821.71\n",
      "variational_beta * kldivergence:  0.18217\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30749\n",
      "kldivergence:   1389.78\n",
      "variational_beta * kldivergence:  0.13898\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.27916\n",
      "kldivergence:   1417.71\n",
      "variational_beta * kldivergence:  0.14177\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38413\n",
      "kldivergence:   1822.28\n",
      "variational_beta * kldivergence:  0.18223\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38868\n",
      "kldivergence:   1854.47\n",
      "variational_beta * kldivergence:  0.18545\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39283\n",
      "kldivergence:   1547.81\n",
      "variational_beta * kldivergence:  0.15478\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36058\n",
      "kldivergence:   1505.59\n",
      "variational_beta * kldivergence:  0.15056\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31984\n",
      "kldivergence:   1760.46\n",
      "variational_beta * kldivergence:  0.17605\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32363\n",
      "kldivergence:   1363.33\n",
      "variational_beta * kldivergence:  0.13633\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31612\n",
      "kldivergence:   1504.43\n",
      "variational_beta * kldivergence:  0.15044\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33661\n",
      "kldivergence:   1471.65\n",
      "variational_beta * kldivergence:  0.14716\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33198\n",
      "kldivergence:   1660.39\n",
      "variational_beta * kldivergence:  0.16604\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34726\n",
      "kldivergence:   1657.84\n",
      "variational_beta * kldivergence:  0.16578\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29965\n",
      "kldivergence:   1612.24\n",
      "variational_beta * kldivergence:  0.16122\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.28163\n",
      "kldivergence:   1276.73\n",
      "variational_beta * kldivergence:  0.12767\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36058\n",
      "kldivergence:   1754.07\n",
      "variational_beta * kldivergence:  0.17541\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35787\n",
      "kldivergence:   1709.04\n",
      "variational_beta * kldivergence:  0.17090\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29173\n",
      "kldivergence:   1626.88\n",
      "variational_beta * kldivergence:  0.16269\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31686\n",
      "kldivergence:   1570.82\n",
      "variational_beta * kldivergence:  0.15708\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.39895\n",
      "kldivergence:   1785.12\n",
      "variational_beta * kldivergence:  0.17851\n",
      "batch accuracy: 86.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.34597\n",
      "kldivergence:   1555.73\n",
      "variational_beta * kldivergence:  0.15557\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.41278\n",
      "kldivergence:   1572.35\n",
      "variational_beta * kldivergence:  0.15724\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32992\n",
      "kldivergence:   1499.02\n",
      "variational_beta * kldivergence:  0.14990\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.33504\n",
      "kldivergence:   1643.83\n",
      "variational_beta * kldivergence:  0.16438\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30717\n",
      "kldivergence:   1502.22\n",
      "variational_beta * kldivergence:  0.15022\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.38580\n",
      "kldivergence:   1567.13\n",
      "variational_beta * kldivergence:  0.15671\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36633\n",
      "kldivergence:   1759.51\n",
      "variational_beta * kldivergence:  0.17595\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.30655\n",
      "kldivergence:   1723.07\n",
      "variational_beta * kldivergence:  0.17231\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.36689\n",
      "kldivergence:   1764.16\n",
      "variational_beta * kldivergence:  0.17642\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.35733\n",
      "kldivergence:   1759.70\n",
      "variational_beta * kldivergence:  0.17597\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31314\n",
      "kldivergence:   1457.86\n",
      "variational_beta * kldivergence:  0.14579\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.31233\n",
      "kldivergence:   1512.88\n",
      "variational_beta * kldivergence:  0.15129\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.32641\n",
      "kldivergence:   1516.43\n",
      "variational_beta * kldivergence:  0.15164\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #22\n",
      "reconstruction loss: 0.29108\n",
      "kldivergence:   1665.69\n",
      "variational_beta * kldivergence:  0.16657\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.44088\n",
      "kldivergence:   1524.51\n",
      "variational_beta * kldivergence:  0.15245\n",
      "batch accuracy: 85.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.48524\n",
      "kldivergence:   1690.16\n",
      "variational_beta * kldivergence:  0.16902\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.42464\n",
      "kldivergence:   1529.44\n",
      "variational_beta * kldivergence:  0.15294\n",
      "batch accuracy: 86.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.44696\n",
      "kldivergence:   1492.99\n",
      "variational_beta * kldivergence:  0.14930\n",
      "batch accuracy: 86.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.41105\n",
      "kldivergence:   1419.19\n",
      "variational_beta * kldivergence:  0.14192\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.46070\n",
      "kldivergence:   1506.70\n",
      "variational_beta * kldivergence:  0.15067\n",
      "batch accuracy: 86.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.48618\n",
      "kldivergence:   1604.95\n",
      "variational_beta * kldivergence:  0.16049\n",
      "batch accuracy: 85.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.42958\n",
      "kldivergence:   1617.79\n",
      "variational_beta * kldivergence:  0.16178\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.43219\n",
      "kldivergence:   1496.45\n",
      "variational_beta * kldivergence:  0.14964\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.39477\n",
      "kldivergence:   1508.72\n",
      "variational_beta * kldivergence:  0.15087\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.40397\n",
      "kldivergence:   1487.81\n",
      "variational_beta * kldivergence:  0.14878\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.46109\n",
      "kldivergence:   1585.18\n",
      "variational_beta * kldivergence:  0.15852\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.40096\n",
      "kldivergence:   1522.68\n",
      "variational_beta * kldivergence:  0.15227\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.41489\n",
      "kldivergence:   1456.63\n",
      "variational_beta * kldivergence:  0.14566\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.43769\n",
      "kldivergence:   1544.84\n",
      "variational_beta * kldivergence:  0.15448\n",
      "batch accuracy: 86.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.50482\n",
      "kldivergence:   1658.23\n",
      "variational_beta * kldivergence:  0.16582\n",
      "batch accuracy: 84.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.49120\n",
      "kldivergence:   1524.80\n",
      "variational_beta * kldivergence:  0.15248\n",
      "batch accuracy: 86.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.47523\n",
      "kldivergence:   1501.94\n",
      "variational_beta * kldivergence:  0.15019\n",
      "batch accuracy: 85.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.57545\n",
      "kldivergence:   1661.24\n",
      "variational_beta * kldivergence:  0.16612\n",
      "batch accuracy: 83.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.44267\n",
      "kldivergence:   1608.96\n",
      "variational_beta * kldivergence:  0.16090\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.43034\n",
      "kldivergence:   1522.35\n",
      "variational_beta * kldivergence:  0.15223\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.44720\n",
      "kldivergence:   1593.81\n",
      "variational_beta * kldivergence:  0.15938\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.39836\n",
      "kldivergence:   1582.64\n",
      "variational_beta * kldivergence:  0.15826\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.43336\n",
      "kldivergence:   1453.14\n",
      "variational_beta * kldivergence:  0.14531\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.44624\n",
      "kldivergence:   1510.93\n",
      "variational_beta * kldivergence:  0.15109\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.48703\n",
      "kldivergence:   1652.85\n",
      "variational_beta * kldivergence:  0.16528\n",
      "batch accuracy: 85.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.42110\n",
      "kldivergence:   1610.08\n",
      "variational_beta * kldivergence:  0.16101\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.44853\n",
      "kldivergence:   1497.74\n",
      "variational_beta * kldivergence:  0.14977\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.47087\n",
      "kldivergence:   1586.15\n",
      "variational_beta * kldivergence:  0.15862\n",
      "batch accuracy: 85.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.57244\n",
      "kldivergence:   1612.65\n",
      "variational_beta * kldivergence:  0.16127\n",
      "batch accuracy: 83.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.39294\n",
      "kldivergence:   1574.19\n",
      "variational_beta * kldivergence:  0.15742\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.39592\n",
      "kldivergence:   1588.30\n",
      "variational_beta * kldivergence:  0.15883\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.53698\n",
      "kldivergence:   1667.26\n",
      "variational_beta * kldivergence:  0.16673\n",
      "batch accuracy: 83.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.45235\n",
      "kldivergence:   1636.65\n",
      "variational_beta * kldivergence:  0.16367\n",
      "batch accuracy: 85.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.47762\n",
      "kldivergence:   1636.93\n",
      "variational_beta * kldivergence:  0.16369\n",
      "batch accuracy: 85.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.55348\n",
      "kldivergence:   1729.80\n",
      "variational_beta * kldivergence:  0.17298\n",
      "batch accuracy: 82.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.38763\n",
      "kldivergence:   1469.45\n",
      "variational_beta * kldivergence:  0.14694\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.44479\n",
      "kldivergence:   1630.05\n",
      "variational_beta * kldivergence:  0.16300\n",
      "batch accuracy: 86.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.42702\n",
      "kldivergence:   1540.59\n",
      "variational_beta * kldivergence:  0.15406\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.39729\n",
      "kldivergence:   1419.08\n",
      "variational_beta * kldivergence:  0.14191\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.40813\n",
      "kldivergence:   1527.44\n",
      "variational_beta * kldivergence:  0.15274\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.42695\n",
      "kldivergence:   1620.63\n",
      "variational_beta * kldivergence:  0.16206\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.42591\n",
      "kldivergence:   1589.77\n",
      "variational_beta * kldivergence:  0.15898\n",
      "batch accuracy: 86.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.52162\n",
      "kldivergence:   1695.77\n",
      "variational_beta * kldivergence:  0.16958\n",
      "batch accuracy: 84.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.40346\n",
      "kldivergence:   1528.78\n",
      "variational_beta * kldivergence:  0.15288\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.38444\n",
      "kldivergence:   1375.49\n",
      "variational_beta * kldivergence:  0.13755\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.41709\n",
      "kldivergence:   1527.59\n",
      "variational_beta * kldivergence:  0.15276\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.45214\n",
      "kldivergence:   1645.95\n",
      "variational_beta * kldivergence:  0.16459\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.45838\n",
      "kldivergence:   1655.32\n",
      "variational_beta * kldivergence:  0.16553\n",
      "batch accuracy: 85.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.57133\n",
      "kldivergence:   1537.05\n",
      "variational_beta * kldivergence:  0.15371\n",
      "batch accuracy: 84.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.58301\n",
      "kldivergence:   1768.80\n",
      "variational_beta * kldivergence:  0.17688\n",
      "batch accuracy: 82.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.50669\n",
      "kldivergence:   1638.07\n",
      "variational_beta * kldivergence:  0.16381\n",
      "batch accuracy: 84.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.44983\n",
      "kldivergence:   1512.52\n",
      "variational_beta * kldivergence:  0.15125\n",
      "batch accuracy: 86.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.41273\n",
      "kldivergence:   1630.71\n",
      "variational_beta * kldivergence:  0.16307\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.49735\n",
      "kldivergence:   1523.26\n",
      "variational_beta * kldivergence:  0.15233\n",
      "batch accuracy: 84.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.53958\n",
      "kldivergence:   1692.69\n",
      "variational_beta * kldivergence:  0.16927\n",
      "batch accuracy: 84.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.51716\n",
      "kldivergence:   1608.98\n",
      "variational_beta * kldivergence:  0.16090\n",
      "batch accuracy: 84.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.38406\n",
      "kldivergence:   1344.07\n",
      "variational_beta * kldivergence:  0.13441\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.56124\n",
      "kldivergence:   1840.03\n",
      "variational_beta * kldivergence:  0.18400\n",
      "batch accuracy: 82.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.37899\n",
      "kldivergence:   1521.92\n",
      "variational_beta * kldivergence:  0.15219\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.40774\n",
      "kldivergence:   1446.64\n",
      "variational_beta * kldivergence:  0.14466\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #22\n",
      "reconstruction loss: 0.43361\n",
      "kldivergence:   1504.64\n",
      "variational_beta * kldivergence:  0.15046\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "epoch # 22 : train loss is [185.78185424836778] and validation loss is [0.10243718503956141] \n",
      "Epoch [23 / 150] average reconstruction error: 0.500760\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35175\n",
      "kldivergence:   1851.04\n",
      "variational_beta * kldivergence:  0.18510\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34854\n",
      "kldivergence:   1520.65\n",
      "variational_beta * kldivergence:  0.15206\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28189\n",
      "kldivergence:   1629.85\n",
      "variational_beta * kldivergence:  0.16298\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30996\n",
      "kldivergence:   1652.08\n",
      "variational_beta * kldivergence:  0.16521\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29267\n",
      "kldivergence:   1621.96\n",
      "variational_beta * kldivergence:  0.16220\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34878\n",
      "kldivergence:   1638.51\n",
      "variational_beta * kldivergence:  0.16385\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36671\n",
      "kldivergence:   1676.54\n",
      "variational_beta * kldivergence:  0.16765\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29595\n",
      "kldivergence:   1646.85\n",
      "variational_beta * kldivergence:  0.16469\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33218\n",
      "kldivergence:   1809.38\n",
      "variational_beta * kldivergence:  0.18094\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30929\n",
      "kldivergence:   1477.44\n",
      "variational_beta * kldivergence:  0.14774\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30615\n",
      "kldivergence:   1607.58\n",
      "variational_beta * kldivergence:  0.16076\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35095\n",
      "kldivergence:   1928.85\n",
      "variational_beta * kldivergence:  0.19289\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.39664\n",
      "kldivergence:   1924.83\n",
      "variational_beta * kldivergence:  0.19248\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28791\n",
      "kldivergence:   1705.78\n",
      "variational_beta * kldivergence:  0.17058\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37565\n",
      "kldivergence:   1828.17\n",
      "variational_beta * kldivergence:  0.18282\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31101\n",
      "kldivergence:   1513.92\n",
      "variational_beta * kldivergence:  0.15139\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35233\n",
      "kldivergence:   1608.46\n",
      "variational_beta * kldivergence:  0.16085\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33242\n",
      "kldivergence:   1838.49\n",
      "variational_beta * kldivergence:  0.18385\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29766\n",
      "kldivergence:   1608.52\n",
      "variational_beta * kldivergence:  0.16085\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37359\n",
      "kldivergence:   1680.29\n",
      "variational_beta * kldivergence:  0.16803\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.27950\n",
      "kldivergence:   1987.74\n",
      "variational_beta * kldivergence:  0.19877\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34150\n",
      "kldivergence:   1698.21\n",
      "variational_beta * kldivergence:  0.16982\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37728\n",
      "kldivergence:   1542.53\n",
      "variational_beta * kldivergence:  0.15425\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.39465\n",
      "kldivergence:   1553.94\n",
      "variational_beta * kldivergence:  0.15539\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31944\n",
      "kldivergence:   1407.41\n",
      "variational_beta * kldivergence:  0.14074\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34659\n",
      "kldivergence:   1430.49\n",
      "variational_beta * kldivergence:  0.14305\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34922\n",
      "kldivergence:   1392.93\n",
      "variational_beta * kldivergence:  0.13929\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35737\n",
      "kldivergence:   1770.05\n",
      "variational_beta * kldivergence:  0.17700\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31990\n",
      "kldivergence:   1811.77\n",
      "variational_beta * kldivergence:  0.18118\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34865\n",
      "kldivergence:   1569.66\n",
      "variational_beta * kldivergence:  0.15697\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32906\n",
      "kldivergence:   1482.21\n",
      "variational_beta * kldivergence:  0.14822\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37525\n",
      "kldivergence:   1695.11\n",
      "variational_beta * kldivergence:  0.16951\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33098\n",
      "kldivergence:   1629.84\n",
      "variational_beta * kldivergence:  0.16298\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32736\n",
      "kldivergence:   1549.96\n",
      "variational_beta * kldivergence:  0.15500\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33641\n",
      "kldivergence:   1738.15\n",
      "variational_beta * kldivergence:  0.17381\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36906\n",
      "kldivergence:   1777.90\n",
      "variational_beta * kldivergence:  0.17779\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38374\n",
      "kldivergence:   1626.43\n",
      "variational_beta * kldivergence:  0.16264\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.27303\n",
      "kldivergence:   2631.53\n",
      "variational_beta * kldivergence:  0.26315\n",
      "batch accuracy: 90.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29820\n",
      "kldivergence:   1782.24\n",
      "variational_beta * kldivergence:  0.17822\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31275\n",
      "kldivergence:   1607.69\n",
      "variational_beta * kldivergence:  0.16077\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36204\n",
      "kldivergence:   1442.33\n",
      "variational_beta * kldivergence:  0.14423\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34827\n",
      "kldivergence:   1645.82\n",
      "variational_beta * kldivergence:  0.16458\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.39034\n",
      "kldivergence:   1700.82\n",
      "variational_beta * kldivergence:  0.17008\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36356\n",
      "kldivergence:   1607.62\n",
      "variational_beta * kldivergence:  0.16076\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31240\n",
      "kldivergence:   1359.22\n",
      "variational_beta * kldivergence:  0.13592\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30488\n",
      "kldivergence:   1713.83\n",
      "variational_beta * kldivergence:  0.17138\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32761\n",
      "kldivergence:   1531.07\n",
      "variational_beta * kldivergence:  0.15311\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31787\n",
      "kldivergence:   2046.56\n",
      "variational_beta * kldivergence:  0.20466\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34919\n",
      "kldivergence:   1634.94\n",
      "variational_beta * kldivergence:  0.16349\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32045\n",
      "kldivergence:   1661.91\n",
      "variational_beta * kldivergence:  0.16619\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.27597\n",
      "kldivergence:   1612.19\n",
      "variational_beta * kldivergence:  0.16122\n",
      "batch accuracy: 91.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32048\n",
      "kldivergence:   1444.37\n",
      "variational_beta * kldivergence:  0.14444\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38523\n",
      "kldivergence:   1679.64\n",
      "variational_beta * kldivergence:  0.16796\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35808\n",
      "kldivergence:   1491.16\n",
      "variational_beta * kldivergence:  0.14912\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34255\n",
      "kldivergence:   1587.69\n",
      "variational_beta * kldivergence:  0.15877\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36080\n",
      "kldivergence:   1746.35\n",
      "variational_beta * kldivergence:  0.17463\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30837\n",
      "kldivergence:   1513.53\n",
      "variational_beta * kldivergence:  0.15135\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34450\n",
      "kldivergence:   1611.30\n",
      "variational_beta * kldivergence:  0.16113\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32368\n",
      "kldivergence:   1461.76\n",
      "variational_beta * kldivergence:  0.14618\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36329\n",
      "kldivergence:   1785.45\n",
      "variational_beta * kldivergence:  0.17855\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36575\n",
      "kldivergence:   1916.22\n",
      "variational_beta * kldivergence:  0.19162\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33620\n",
      "kldivergence:   1717.56\n",
      "variational_beta * kldivergence:  0.17176\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.25922\n",
      "kldivergence:   1547.66\n",
      "variational_beta * kldivergence:  0.15477\n",
      "batch accuracy: 91.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31178\n",
      "kldivergence:   1864.71\n",
      "variational_beta * kldivergence:  0.18647\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33394\n",
      "kldivergence:   1523.80\n",
      "variational_beta * kldivergence:  0.15238\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.39192\n",
      "kldivergence:   1542.88\n",
      "variational_beta * kldivergence:  0.15429\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31837\n",
      "kldivergence:   1439.77\n",
      "variational_beta * kldivergence:  0.14398\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29512\n",
      "kldivergence:   1323.44\n",
      "variational_beta * kldivergence:  0.13234\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38323\n",
      "kldivergence:   1549.10\n",
      "variational_beta * kldivergence:  0.15491\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34544\n",
      "kldivergence:   1648.35\n",
      "variational_beta * kldivergence:  0.16484\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35048\n",
      "kldivergence:   1401.16\n",
      "variational_beta * kldivergence:  0.14012\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28992\n",
      "kldivergence:   1403.78\n",
      "variational_beta * kldivergence:  0.14038\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36164\n",
      "kldivergence:   1529.14\n",
      "variational_beta * kldivergence:  0.15291\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32495\n",
      "kldivergence:   1533.70\n",
      "variational_beta * kldivergence:  0.15337\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33448\n",
      "kldivergence:   1554.76\n",
      "variational_beta * kldivergence:  0.15548\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31453\n",
      "kldivergence:   1469.06\n",
      "variational_beta * kldivergence:  0.14691\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34273\n",
      "kldivergence:   1483.72\n",
      "variational_beta * kldivergence:  0.14837\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31318\n",
      "kldivergence:   1477.62\n",
      "variational_beta * kldivergence:  0.14776\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29290\n",
      "kldivergence:   1447.59\n",
      "variational_beta * kldivergence:  0.14476\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36931\n",
      "kldivergence:   1755.19\n",
      "variational_beta * kldivergence:  0.17552\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37989\n",
      "kldivergence:   1675.74\n",
      "variational_beta * kldivergence:  0.16757\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37178\n",
      "kldivergence:   1781.76\n",
      "variational_beta * kldivergence:  0.17818\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35559\n",
      "kldivergence:   1617.21\n",
      "variational_beta * kldivergence:  0.16172\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37592\n",
      "kldivergence:   1897.44\n",
      "variational_beta * kldivergence:  0.18974\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31907\n",
      "kldivergence:   1787.06\n",
      "variational_beta * kldivergence:  0.17871\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32198\n",
      "kldivergence:   1418.79\n",
      "variational_beta * kldivergence:  0.14188\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36945\n",
      "kldivergence:   1775.08\n",
      "variational_beta * kldivergence:  0.17751\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31154\n",
      "kldivergence:   1695.16\n",
      "variational_beta * kldivergence:  0.16952\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34644\n",
      "kldivergence:   1622.63\n",
      "variational_beta * kldivergence:  0.16226\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31699\n",
      "kldivergence:   1645.76\n",
      "variational_beta * kldivergence:  0.16458\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30119\n",
      "kldivergence:   1752.06\n",
      "variational_beta * kldivergence:  0.17521\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31123\n",
      "kldivergence:   1784.37\n",
      "variational_beta * kldivergence:  0.17844\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33140\n",
      "kldivergence:   1931.65\n",
      "variational_beta * kldivergence:  0.19316\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31368\n",
      "kldivergence:   1715.60\n",
      "variational_beta * kldivergence:  0.17156\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33582\n",
      "kldivergence:   1692.53\n",
      "variational_beta * kldivergence:  0.16925\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35681\n",
      "kldivergence:   2016.51\n",
      "variational_beta * kldivergence:  0.20165\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28756\n",
      "kldivergence:   1524.37\n",
      "variational_beta * kldivergence:  0.15244\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31483\n",
      "kldivergence:   1455.88\n",
      "variational_beta * kldivergence:  0.14559\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29634\n",
      "kldivergence:   1646.70\n",
      "variational_beta * kldivergence:  0.16467\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30590\n",
      "kldivergence:   1645.39\n",
      "variational_beta * kldivergence:  0.16454\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34165\n",
      "kldivergence:   1667.54\n",
      "variational_beta * kldivergence:  0.16675\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34759\n",
      "kldivergence:   1694.01\n",
      "variational_beta * kldivergence:  0.16940\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33184\n",
      "kldivergence:   1756.09\n",
      "variational_beta * kldivergence:  0.17561\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32054\n",
      "kldivergence:   1583.54\n",
      "variational_beta * kldivergence:  0.15835\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35343\n",
      "kldivergence:   1805.36\n",
      "variational_beta * kldivergence:  0.18054\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32551\n",
      "kldivergence:   1770.81\n",
      "variational_beta * kldivergence:  0.17708\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38256\n",
      "kldivergence:   1681.19\n",
      "variational_beta * kldivergence:  0.16812\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29117\n",
      "kldivergence:   1515.11\n",
      "variational_beta * kldivergence:  0.15151\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35152\n",
      "kldivergence:   1802.92\n",
      "variational_beta * kldivergence:  0.18029\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33077\n",
      "kldivergence:   1618.45\n",
      "variational_beta * kldivergence:  0.16185\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.40958\n",
      "kldivergence:   1788.96\n",
      "variational_beta * kldivergence:  0.17890\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31525\n",
      "kldivergence:   1626.94\n",
      "variational_beta * kldivergence:  0.16269\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32763\n",
      "kldivergence:   1486.10\n",
      "variational_beta * kldivergence:  0.14861\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34049\n",
      "kldivergence:   1564.56\n",
      "variational_beta * kldivergence:  0.15646\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37768\n",
      "kldivergence:   1774.78\n",
      "variational_beta * kldivergence:  0.17748\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36069\n",
      "kldivergence:   1576.39\n",
      "variational_beta * kldivergence:  0.15764\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33621\n",
      "kldivergence:   1910.43\n",
      "variational_beta * kldivergence:  0.19104\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37819\n",
      "kldivergence:   1830.12\n",
      "variational_beta * kldivergence:  0.18301\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33108\n",
      "kldivergence:   1647.09\n",
      "variational_beta * kldivergence:  0.16471\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36241\n",
      "kldivergence:   1635.01\n",
      "variational_beta * kldivergence:  0.16350\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30187\n",
      "kldivergence:   1609.22\n",
      "variational_beta * kldivergence:  0.16092\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28544\n",
      "kldivergence:   1590.62\n",
      "variational_beta * kldivergence:  0.15906\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.40083\n",
      "kldivergence:   1617.28\n",
      "variational_beta * kldivergence:  0.16173\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31030\n",
      "kldivergence:   1558.84\n",
      "variational_beta * kldivergence:  0.15588\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.39558\n",
      "kldivergence:   1588.88\n",
      "variational_beta * kldivergence:  0.15889\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31567\n",
      "kldivergence:   1611.26\n",
      "variational_beta * kldivergence:  0.16113\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32352\n",
      "kldivergence:   1589.98\n",
      "variational_beta * kldivergence:  0.15900\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29219\n",
      "kldivergence:   1711.64\n",
      "variational_beta * kldivergence:  0.17116\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34890\n",
      "kldivergence:   1682.25\n",
      "variational_beta * kldivergence:  0.16822\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29374\n",
      "kldivergence:   1547.91\n",
      "variational_beta * kldivergence:  0.15479\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33346\n",
      "kldivergence:   1381.02\n",
      "variational_beta * kldivergence:  0.13810\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34210\n",
      "kldivergence:   1729.79\n",
      "variational_beta * kldivergence:  0.17298\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32987\n",
      "kldivergence:   1655.17\n",
      "variational_beta * kldivergence:  0.16552\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30587\n",
      "kldivergence:   1521.64\n",
      "variational_beta * kldivergence:  0.15216\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30809\n",
      "kldivergence:   1611.91\n",
      "variational_beta * kldivergence:  0.16119\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29145\n",
      "kldivergence:   1625.49\n",
      "variational_beta * kldivergence:  0.16255\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33265\n",
      "kldivergence:   1580.61\n",
      "variational_beta * kldivergence:  0.15806\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35847\n",
      "kldivergence:   1506.90\n",
      "variational_beta * kldivergence:  0.15069\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33628\n",
      "kldivergence:   1548.86\n",
      "variational_beta * kldivergence:  0.15489\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33495\n",
      "kldivergence:   1476.64\n",
      "variational_beta * kldivergence:  0.14766\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33162\n",
      "kldivergence:   1498.08\n",
      "variational_beta * kldivergence:  0.14981\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34600\n",
      "kldivergence:   1479.98\n",
      "variational_beta * kldivergence:  0.14800\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37176\n",
      "kldivergence:   1687.38\n",
      "variational_beta * kldivergence:  0.16874\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34567\n",
      "kldivergence:   1930.58\n",
      "variational_beta * kldivergence:  0.19306\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31212\n",
      "kldivergence:   1627.56\n",
      "variational_beta * kldivergence:  0.16276\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34776\n",
      "kldivergence:   1591.68\n",
      "variational_beta * kldivergence:  0.15917\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32922\n",
      "kldivergence:   1576.15\n",
      "variational_beta * kldivergence:  0.15762\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38424\n",
      "kldivergence:   2002.52\n",
      "variational_beta * kldivergence:  0.20025\n",
      "batch accuracy: 86.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.42843\n",
      "kldivergence:   1787.69\n",
      "variational_beta * kldivergence:  0.17877\n",
      "batch accuracy: 85.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30745\n",
      "kldivergence:   1469.29\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33343\n",
      "kldivergence:   1411.41\n",
      "variational_beta * kldivergence:  0.14114\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35744\n",
      "kldivergence:   1825.60\n",
      "variational_beta * kldivergence:  0.18256\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36119\n",
      "kldivergence:   1757.49\n",
      "variational_beta * kldivergence:  0.17575\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37072\n",
      "kldivergence:   1581.60\n",
      "variational_beta * kldivergence:  0.15816\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38490\n",
      "kldivergence:   1807.52\n",
      "variational_beta * kldivergence:  0.18075\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38832\n",
      "kldivergence:   1704.84\n",
      "variational_beta * kldivergence:  0.17048\n",
      "batch accuracy: 86.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.27578\n",
      "kldivergence:   1374.18\n",
      "variational_beta * kldivergence:  0.13742\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34821\n",
      "kldivergence:   1625.34\n",
      "variational_beta * kldivergence:  0.16253\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29605\n",
      "kldivergence:   1512.27\n",
      "variational_beta * kldivergence:  0.15123\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31008\n",
      "kldivergence:   1594.90\n",
      "variational_beta * kldivergence:  0.15949\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34436\n",
      "kldivergence:   1621.61\n",
      "variational_beta * kldivergence:  0.16216\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28888\n",
      "kldivergence:   1648.75\n",
      "variational_beta * kldivergence:  0.16487\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31410\n",
      "kldivergence:   1563.36\n",
      "variational_beta * kldivergence:  0.15634\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31152\n",
      "kldivergence:   1385.63\n",
      "variational_beta * kldivergence:  0.13856\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28674\n",
      "kldivergence:   1625.03\n",
      "variational_beta * kldivergence:  0.16250\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33597\n",
      "kldivergence:   1696.71\n",
      "variational_beta * kldivergence:  0.16967\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29870\n",
      "kldivergence:   1704.38\n",
      "variational_beta * kldivergence:  0.17044\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35806\n",
      "kldivergence:   1653.85\n",
      "variational_beta * kldivergence:  0.16539\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31092\n",
      "kldivergence:   1469.67\n",
      "variational_beta * kldivergence:  0.14697\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33203\n",
      "kldivergence:   1449.12\n",
      "variational_beta * kldivergence:  0.14491\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32083\n",
      "kldivergence:   1554.52\n",
      "variational_beta * kldivergence:  0.15545\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34156\n",
      "kldivergence:   1735.97\n",
      "variational_beta * kldivergence:  0.17360\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37885\n",
      "kldivergence:   1731.24\n",
      "variational_beta * kldivergence:  0.17312\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31392\n",
      "kldivergence:   1635.72\n",
      "variational_beta * kldivergence:  0.16357\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28439\n",
      "kldivergence:   1668.71\n",
      "variational_beta * kldivergence:  0.16687\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38503\n",
      "kldivergence:   1592.18\n",
      "variational_beta * kldivergence:  0.15922\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31235\n",
      "kldivergence:   1468.85\n",
      "variational_beta * kldivergence:  0.14688\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35511\n",
      "kldivergence:   1576.39\n",
      "variational_beta * kldivergence:  0.15764\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31469\n",
      "kldivergence:   1621.43\n",
      "variational_beta * kldivergence:  0.16214\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36823\n",
      "kldivergence:   1498.20\n",
      "variational_beta * kldivergence:  0.14982\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35645\n",
      "kldivergence:   1570.19\n",
      "variational_beta * kldivergence:  0.15702\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36022\n",
      "kldivergence:   1512.93\n",
      "variational_beta * kldivergence:  0.15129\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33657\n",
      "kldivergence:   1695.51\n",
      "variational_beta * kldivergence:  0.16955\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36033\n",
      "kldivergence:   1537.46\n",
      "variational_beta * kldivergence:  0.15375\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34666\n",
      "kldivergence:   1555.77\n",
      "variational_beta * kldivergence:  0.15558\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29817\n",
      "kldivergence:   1576.58\n",
      "variational_beta * kldivergence:  0.15766\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33095\n",
      "kldivergence:   1596.42\n",
      "variational_beta * kldivergence:  0.15964\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33744\n",
      "kldivergence:   1513.66\n",
      "variational_beta * kldivergence:  0.15137\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32334\n",
      "kldivergence:   1667.71\n",
      "variational_beta * kldivergence:  0.16677\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32918\n",
      "kldivergence:   1322.66\n",
      "variational_beta * kldivergence:  0.13227\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36262\n",
      "kldivergence:   1650.12\n",
      "variational_beta * kldivergence:  0.16501\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.39071\n",
      "kldivergence:   1672.42\n",
      "variational_beta * kldivergence:  0.16724\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33168\n",
      "kldivergence:   1597.37\n",
      "variational_beta * kldivergence:  0.15974\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30760\n",
      "kldivergence:   1590.83\n",
      "variational_beta * kldivergence:  0.15908\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34238\n",
      "kldivergence:   1651.42\n",
      "variational_beta * kldivergence:  0.16514\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34176\n",
      "kldivergence:   1695.85\n",
      "variational_beta * kldivergence:  0.16959\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32862\n",
      "kldivergence:   1521.98\n",
      "variational_beta * kldivergence:  0.15220\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31143\n",
      "kldivergence:   1516.99\n",
      "variational_beta * kldivergence:  0.15170\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32287\n",
      "kldivergence:   1551.69\n",
      "variational_beta * kldivergence:  0.15517\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35192\n",
      "kldivergence:   1740.50\n",
      "variational_beta * kldivergence:  0.17405\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33243\n",
      "kldivergence:   1969.65\n",
      "variational_beta * kldivergence:  0.19697\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34656\n",
      "kldivergence:   1748.25\n",
      "variational_beta * kldivergence:  0.17483\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31432\n",
      "kldivergence:   1694.68\n",
      "variational_beta * kldivergence:  0.16947\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30582\n",
      "kldivergence:   1540.01\n",
      "variational_beta * kldivergence:  0.15400\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32316\n",
      "kldivergence:   1553.32\n",
      "variational_beta * kldivergence:  0.15533\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29725\n",
      "kldivergence:   1383.81\n",
      "variational_beta * kldivergence:  0.13838\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32819\n",
      "kldivergence:   1556.01\n",
      "variational_beta * kldivergence:  0.15560\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32645\n",
      "kldivergence:   1579.53\n",
      "variational_beta * kldivergence:  0.15795\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32671\n",
      "kldivergence:   1563.49\n",
      "variational_beta * kldivergence:  0.15635\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.40343\n",
      "kldivergence:   1902.71\n",
      "variational_beta * kldivergence:  0.19027\n",
      "batch accuracy: 86.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34895\n",
      "kldivergence:   1781.71\n",
      "variational_beta * kldivergence:  0.17817\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.27355\n",
      "kldivergence:   1526.03\n",
      "variational_beta * kldivergence:  0.15260\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32237\n",
      "kldivergence:   1464.98\n",
      "variational_beta * kldivergence:  0.14650\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.26105\n",
      "kldivergence:   1584.40\n",
      "variational_beta * kldivergence:  0.15844\n",
      "batch accuracy: 91.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35150\n",
      "kldivergence:   1650.96\n",
      "variational_beta * kldivergence:  0.16510\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30692\n",
      "kldivergence:   1503.45\n",
      "variational_beta * kldivergence:  0.15035\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.27915\n",
      "kldivergence:   1429.54\n",
      "variational_beta * kldivergence:  0.14295\n",
      "batch accuracy: 90.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36508\n",
      "kldivergence:   1607.86\n",
      "variational_beta * kldivergence:  0.16079\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.41361\n",
      "kldivergence:   1585.12\n",
      "variational_beta * kldivergence:  0.15851\n",
      "batch accuracy: 86.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.43059\n",
      "kldivergence:   1930.72\n",
      "variational_beta * kldivergence:  0.19307\n",
      "batch accuracy: 85.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.41150\n",
      "kldivergence:   1818.58\n",
      "variational_beta * kldivergence:  0.18186\n",
      "batch accuracy: 86.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34664\n",
      "kldivergence:   1664.68\n",
      "variational_beta * kldivergence:  0.16647\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29023\n",
      "kldivergence:   1857.26\n",
      "variational_beta * kldivergence:  0.18573\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33204\n",
      "kldivergence:   1770.88\n",
      "variational_beta * kldivergence:  0.17709\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36864\n",
      "kldivergence:   1582.37\n",
      "variational_beta * kldivergence:  0.15824\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32425\n",
      "kldivergence:   1421.14\n",
      "variational_beta * kldivergence:  0.14211\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36199\n",
      "kldivergence:   1558.66\n",
      "variational_beta * kldivergence:  0.15587\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33933\n",
      "kldivergence:   1488.97\n",
      "variational_beta * kldivergence:  0.14890\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36570\n",
      "kldivergence:   1733.54\n",
      "variational_beta * kldivergence:  0.17335\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33879\n",
      "kldivergence:   1506.31\n",
      "variational_beta * kldivergence:  0.15063\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35775\n",
      "kldivergence:   1466.12\n",
      "variational_beta * kldivergence:  0.14661\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33792\n",
      "kldivergence:   1568.67\n",
      "variational_beta * kldivergence:  0.15687\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36792\n",
      "kldivergence:   1639.59\n",
      "variational_beta * kldivergence:  0.16396\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32772\n",
      "kldivergence:   1684.30\n",
      "variational_beta * kldivergence:  0.16843\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31322\n",
      "kldivergence:   1529.91\n",
      "variational_beta * kldivergence:  0.15299\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.43237\n",
      "kldivergence:   1623.37\n",
      "variational_beta * kldivergence:  0.16234\n",
      "batch accuracy: 86.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35608\n",
      "kldivergence:   1663.01\n",
      "variational_beta * kldivergence:  0.16630\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31815\n",
      "kldivergence:   1456.24\n",
      "variational_beta * kldivergence:  0.14562\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36374\n",
      "kldivergence:   1515.77\n",
      "variational_beta * kldivergence:  0.15158\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32319\n",
      "kldivergence:   1881.16\n",
      "variational_beta * kldivergence:  0.18812\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31280\n",
      "kldivergence:   1580.19\n",
      "variational_beta * kldivergence:  0.15802\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38297\n",
      "kldivergence:   1598.89\n",
      "variational_beta * kldivergence:  0.15989\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37526\n",
      "kldivergence:   1596.59\n",
      "variational_beta * kldivergence:  0.15966\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32318\n",
      "kldivergence:   1963.99\n",
      "variational_beta * kldivergence:  0.19640\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37548\n",
      "kldivergence:   1591.82\n",
      "variational_beta * kldivergence:  0.15918\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32778\n",
      "kldivergence:   1531.13\n",
      "variational_beta * kldivergence:  0.15311\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35011\n",
      "kldivergence:   1750.06\n",
      "variational_beta * kldivergence:  0.17501\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32930\n",
      "kldivergence:   1437.51\n",
      "variational_beta * kldivergence:  0.14375\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32690\n",
      "kldivergence:   1540.82\n",
      "variational_beta * kldivergence:  0.15408\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29990\n",
      "kldivergence:   1645.92\n",
      "variational_beta * kldivergence:  0.16459\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34943\n",
      "kldivergence:   1819.05\n",
      "variational_beta * kldivergence:  0.18190\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34673\n",
      "kldivergence:   1580.64\n",
      "variational_beta * kldivergence:  0.15806\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34850\n",
      "kldivergence:   1845.90\n",
      "variational_beta * kldivergence:  0.18459\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30534\n",
      "kldivergence:   1852.92\n",
      "variational_beta * kldivergence:  0.18529\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31459\n",
      "kldivergence:   1970.90\n",
      "variational_beta * kldivergence:  0.19709\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35456\n",
      "kldivergence:   1773.29\n",
      "variational_beta * kldivergence:  0.17733\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31480\n",
      "kldivergence:   1653.13\n",
      "variational_beta * kldivergence:  0.16531\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32111\n",
      "kldivergence:   1671.48\n",
      "variational_beta * kldivergence:  0.16715\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28432\n",
      "kldivergence:   1772.09\n",
      "variational_beta * kldivergence:  0.17721\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33720\n",
      "kldivergence:   1687.22\n",
      "variational_beta * kldivergence:  0.16872\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28520\n",
      "kldivergence:   1737.07\n",
      "variational_beta * kldivergence:  0.17371\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.26796\n",
      "kldivergence:   1457.55\n",
      "variational_beta * kldivergence:  0.14576\n",
      "batch accuracy: 91.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30360\n",
      "kldivergence:   1865.88\n",
      "variational_beta * kldivergence:  0.18659\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32915\n",
      "kldivergence:   1704.00\n",
      "variational_beta * kldivergence:  0.17040\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31386\n",
      "kldivergence:   1690.55\n",
      "variational_beta * kldivergence:  0.16906\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31625\n",
      "kldivergence:   1654.09\n",
      "variational_beta * kldivergence:  0.16541\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32072\n",
      "kldivergence:   1422.21\n",
      "variational_beta * kldivergence:  0.14222\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32337\n",
      "kldivergence:   1647.36\n",
      "variational_beta * kldivergence:  0.16474\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.39690\n",
      "kldivergence:   1622.18\n",
      "variational_beta * kldivergence:  0.16222\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.39955\n",
      "kldivergence:   1769.33\n",
      "variational_beta * kldivergence:  0.17693\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34721\n",
      "kldivergence:   1757.29\n",
      "variational_beta * kldivergence:  0.17573\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37386\n",
      "kldivergence:   1612.10\n",
      "variational_beta * kldivergence:  0.16121\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28910\n",
      "kldivergence:   1633.32\n",
      "variational_beta * kldivergence:  0.16333\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33046\n",
      "kldivergence:   1717.98\n",
      "variational_beta * kldivergence:  0.17180\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31918\n",
      "kldivergence:   1471.20\n",
      "variational_beta * kldivergence:  0.14712\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33359\n",
      "kldivergence:   1618.41\n",
      "variational_beta * kldivergence:  0.16184\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31327\n",
      "kldivergence:   1411.06\n",
      "variational_beta * kldivergence:  0.14111\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.40840\n",
      "kldivergence:   1721.85\n",
      "variational_beta * kldivergence:  0.17219\n",
      "batch accuracy: 85.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33576\n",
      "kldivergence:   1584.99\n",
      "variational_beta * kldivergence:  0.15850\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36202\n",
      "kldivergence:   1576.02\n",
      "variational_beta * kldivergence:  0.15760\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30905\n",
      "kldivergence:   1657.42\n",
      "variational_beta * kldivergence:  0.16574\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33354\n",
      "kldivergence:   1736.67\n",
      "variational_beta * kldivergence:  0.17367\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34986\n",
      "kldivergence:   1475.84\n",
      "variational_beta * kldivergence:  0.14758\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30519\n",
      "kldivergence:   1714.45\n",
      "variational_beta * kldivergence:  0.17145\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32169\n",
      "kldivergence:   1669.43\n",
      "variational_beta * kldivergence:  0.16694\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33325\n",
      "kldivergence:   1574.32\n",
      "variational_beta * kldivergence:  0.15743\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29742\n",
      "kldivergence:   1675.64\n",
      "variational_beta * kldivergence:  0.16756\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34371\n",
      "kldivergence:   1758.91\n",
      "variational_beta * kldivergence:  0.17589\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36180\n",
      "kldivergence:   1639.11\n",
      "variational_beta * kldivergence:  0.16391\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35871\n",
      "kldivergence:   1638.30\n",
      "variational_beta * kldivergence:  0.16383\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35215\n",
      "kldivergence:   1706.24\n",
      "variational_beta * kldivergence:  0.17062\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38163\n",
      "kldivergence:   1578.54\n",
      "variational_beta * kldivergence:  0.15785\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32006\n",
      "kldivergence:   1639.34\n",
      "variational_beta * kldivergence:  0.16393\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29408\n",
      "kldivergence:   1466.68\n",
      "variational_beta * kldivergence:  0.14667\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38021\n",
      "kldivergence:   1689.49\n",
      "variational_beta * kldivergence:  0.16895\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33332\n",
      "kldivergence:   1657.35\n",
      "variational_beta * kldivergence:  0.16574\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34632\n",
      "kldivergence:   1477.68\n",
      "variational_beta * kldivergence:  0.14777\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33670\n",
      "kldivergence:   1534.61\n",
      "variational_beta * kldivergence:  0.15346\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.25811\n",
      "kldivergence:   1527.31\n",
      "variational_beta * kldivergence:  0.15273\n",
      "batch accuracy: 91.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33654\n",
      "kldivergence:   1653.74\n",
      "variational_beta * kldivergence:  0.16537\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35570\n",
      "kldivergence:   1482.80\n",
      "variational_beta * kldivergence:  0.14828\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33347\n",
      "kldivergence:   1569.61\n",
      "variational_beta * kldivergence:  0.15696\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37830\n",
      "kldivergence:   1849.84\n",
      "variational_beta * kldivergence:  0.18498\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31841\n",
      "kldivergence:   1398.08\n",
      "variational_beta * kldivergence:  0.13981\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34004\n",
      "kldivergence:   1509.58\n",
      "variational_beta * kldivergence:  0.15096\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34056\n",
      "kldivergence:   1507.45\n",
      "variational_beta * kldivergence:  0.15075\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32608\n",
      "kldivergence:   1718.54\n",
      "variational_beta * kldivergence:  0.17185\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30373\n",
      "kldivergence:   1445.59\n",
      "variational_beta * kldivergence:  0.14456\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32736\n",
      "kldivergence:   1414.13\n",
      "variational_beta * kldivergence:  0.14141\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.41043\n",
      "kldivergence:   1670.55\n",
      "variational_beta * kldivergence:  0.16705\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37437\n",
      "kldivergence:   1845.96\n",
      "variational_beta * kldivergence:  0.18460\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35481\n",
      "kldivergence:   1873.10\n",
      "variational_beta * kldivergence:  0.18731\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28668\n",
      "kldivergence:   1507.08\n",
      "variational_beta * kldivergence:  0.15071\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32269\n",
      "kldivergence:   1504.45\n",
      "variational_beta * kldivergence:  0.15045\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31339\n",
      "kldivergence:   1761.93\n",
      "variational_beta * kldivergence:  0.17619\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36200\n",
      "kldivergence:   1511.92\n",
      "variational_beta * kldivergence:  0.15119\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31047\n",
      "kldivergence:   1631.86\n",
      "variational_beta * kldivergence:  0.16319\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32063\n",
      "kldivergence:   1539.57\n",
      "variational_beta * kldivergence:  0.15396\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35830\n",
      "kldivergence:   1653.01\n",
      "variational_beta * kldivergence:  0.16530\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35309\n",
      "kldivergence:   1610.95\n",
      "variational_beta * kldivergence:  0.16110\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.27502\n",
      "kldivergence:   1462.69\n",
      "variational_beta * kldivergence:  0.14627\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.29990\n",
      "kldivergence:   1757.02\n",
      "variational_beta * kldivergence:  0.17570\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33981\n",
      "kldivergence:   1611.20\n",
      "variational_beta * kldivergence:  0.16112\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.27016\n",
      "kldivergence:   1407.65\n",
      "variational_beta * kldivergence:  0.14076\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32739\n",
      "kldivergence:   1495.46\n",
      "variational_beta * kldivergence:  0.14955\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30044\n",
      "kldivergence:   1432.37\n",
      "variational_beta * kldivergence:  0.14324\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36290\n",
      "kldivergence:   1453.67\n",
      "variational_beta * kldivergence:  0.14537\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30418\n",
      "kldivergence:   1659.55\n",
      "variational_beta * kldivergence:  0.16596\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32049\n",
      "kldivergence:   1429.34\n",
      "variational_beta * kldivergence:  0.14293\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33845\n",
      "kldivergence:   1664.83\n",
      "variational_beta * kldivergence:  0.16648\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34853\n",
      "kldivergence:   1517.52\n",
      "variational_beta * kldivergence:  0.15175\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37204\n",
      "kldivergence:   1550.60\n",
      "variational_beta * kldivergence:  0.15506\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30918\n",
      "kldivergence:   1635.94\n",
      "variational_beta * kldivergence:  0.16359\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35582\n",
      "kldivergence:   1570.13\n",
      "variational_beta * kldivergence:  0.15701\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32644\n",
      "kldivergence:   1568.99\n",
      "variational_beta * kldivergence:  0.15690\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35607\n",
      "kldivergence:   1554.51\n",
      "variational_beta * kldivergence:  0.15545\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31209\n",
      "kldivergence:   1652.24\n",
      "variational_beta * kldivergence:  0.16522\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30703\n",
      "kldivergence:   1481.30\n",
      "variational_beta * kldivergence:  0.14813\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33493\n",
      "kldivergence:   1427.96\n",
      "variational_beta * kldivergence:  0.14280\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.37297\n",
      "kldivergence:   1460.34\n",
      "variational_beta * kldivergence:  0.14603\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.41829\n",
      "kldivergence:   1722.53\n",
      "variational_beta * kldivergence:  0.17225\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38932\n",
      "kldivergence:   1606.13\n",
      "variational_beta * kldivergence:  0.16061\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.39368\n",
      "kldivergence:   1880.38\n",
      "variational_beta * kldivergence:  0.18804\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32382\n",
      "kldivergence:   1695.49\n",
      "variational_beta * kldivergence:  0.16955\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32093\n",
      "kldivergence:   1778.09\n",
      "variational_beta * kldivergence:  0.17781\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36481\n",
      "kldivergence:   1581.35\n",
      "variational_beta * kldivergence:  0.15814\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32770\n",
      "kldivergence:   1563.15\n",
      "variational_beta * kldivergence:  0.15631\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30600\n",
      "kldivergence:   1890.55\n",
      "variational_beta * kldivergence:  0.18905\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31181\n",
      "kldivergence:   1702.78\n",
      "variational_beta * kldivergence:  0.17028\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30492\n",
      "kldivergence:   1484.22\n",
      "variational_beta * kldivergence:  0.14842\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38477\n",
      "kldivergence:   1852.05\n",
      "variational_beta * kldivergence:  0.18521\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34762\n",
      "kldivergence:   1619.71\n",
      "variational_beta * kldivergence:  0.16197\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31300\n",
      "kldivergence:   1549.43\n",
      "variational_beta * kldivergence:  0.15494\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35371\n",
      "kldivergence:   1658.89\n",
      "variational_beta * kldivergence:  0.16589\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30708\n",
      "kldivergence:   1372.75\n",
      "variational_beta * kldivergence:  0.13728\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36981\n",
      "kldivergence:   1753.74\n",
      "variational_beta * kldivergence:  0.17537\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35571\n",
      "kldivergence:   1646.53\n",
      "variational_beta * kldivergence:  0.16465\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36976\n",
      "kldivergence:   1678.75\n",
      "variational_beta * kldivergence:  0.16788\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35152\n",
      "kldivergence:   1626.58\n",
      "variational_beta * kldivergence:  0.16266\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.33869\n",
      "kldivergence:   1576.27\n",
      "variational_beta * kldivergence:  0.15763\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.31466\n",
      "kldivergence:   1783.07\n",
      "variational_beta * kldivergence:  0.17831\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.34377\n",
      "kldivergence:   1668.35\n",
      "variational_beta * kldivergence:  0.16683\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.30660\n",
      "kldivergence:   1691.27\n",
      "variational_beta * kldivergence:  0.16913\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.36424\n",
      "kldivergence:   1564.66\n",
      "variational_beta * kldivergence:  0.15647\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38795\n",
      "kldivergence:   1759.10\n",
      "variational_beta * kldivergence:  0.17591\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.38055\n",
      "kldivergence:   1669.63\n",
      "variational_beta * kldivergence:  0.16696\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.28619\n",
      "kldivergence:   1873.86\n",
      "variational_beta * kldivergence:  0.18739\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.40767\n",
      "kldivergence:   1934.94\n",
      "variational_beta * kldivergence:  0.19349\n",
      "batch accuracy: 85.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32702\n",
      "kldivergence:   1436.97\n",
      "variational_beta * kldivergence:  0.14370\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.35434\n",
      "kldivergence:   1650.61\n",
      "variational_beta * kldivergence:  0.16506\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #23\n",
      "reconstruction loss: 0.32799\n",
      "kldivergence:   1770.25\n",
      "variational_beta * kldivergence:  0.17703\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.53714\n",
      "kldivergence:   1572.51\n",
      "variational_beta * kldivergence:  0.15725\n",
      "batch accuracy: 84.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.44474\n",
      "kldivergence:   1548.95\n",
      "variational_beta * kldivergence:  0.15489\n",
      "batch accuracy: 85.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.48142\n",
      "kldivergence:   1558.26\n",
      "variational_beta * kldivergence:  0.15583\n",
      "batch accuracy: 85.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.51802\n",
      "kldivergence:   1722.54\n",
      "variational_beta * kldivergence:  0.17225\n",
      "batch accuracy: 83.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.42110\n",
      "kldivergence:   1434.12\n",
      "variational_beta * kldivergence:  0.14341\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.45565\n",
      "kldivergence:   1469.37\n",
      "variational_beta * kldivergence:  0.14694\n",
      "batch accuracy: 86.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.46541\n",
      "kldivergence:   1570.20\n",
      "variational_beta * kldivergence:  0.15702\n",
      "batch accuracy: 86.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.44085\n",
      "kldivergence:   1521.35\n",
      "variational_beta * kldivergence:  0.15213\n",
      "batch accuracy: 85.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.41835\n",
      "kldivergence:   1423.60\n",
      "variational_beta * kldivergence:  0.14236\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.42447\n",
      "kldivergence:   1507.11\n",
      "variational_beta * kldivergence:  0.15071\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.43337\n",
      "kldivergence:   1505.21\n",
      "variational_beta * kldivergence:  0.15052\n",
      "batch accuracy: 86.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.51335\n",
      "kldivergence:   1622.99\n",
      "variational_beta * kldivergence:  0.16230\n",
      "batch accuracy: 85.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.42591\n",
      "kldivergence:   1496.61\n",
      "variational_beta * kldivergence:  0.14966\n",
      "batch accuracy: 86.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.40561\n",
      "kldivergence:   1477.06\n",
      "variational_beta * kldivergence:  0.14771\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.56940\n",
      "kldivergence:   1723.85\n",
      "variational_beta * kldivergence:  0.17238\n",
      "batch accuracy: 82.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.49880\n",
      "kldivergence:   1557.44\n",
      "variational_beta * kldivergence:  0.15574\n",
      "batch accuracy: 84.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.49615\n",
      "kldivergence:   1494.79\n",
      "variational_beta * kldivergence:  0.14948\n",
      "batch accuracy: 85.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.49119\n",
      "kldivergence:   1611.78\n",
      "variational_beta * kldivergence:  0.16118\n",
      "batch accuracy: 84.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.41778\n",
      "kldivergence:   1398.88\n",
      "variational_beta * kldivergence:  0.13989\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.47897\n",
      "kldivergence:   1611.95\n",
      "variational_beta * kldivergence:  0.16119\n",
      "batch accuracy: 84.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.33963\n",
      "kldivergence:   1292.91\n",
      "variational_beta * kldivergence:  0.12929\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.44423\n",
      "kldivergence:   1602.40\n",
      "variational_beta * kldivergence:  0.16024\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.61287\n",
      "kldivergence:   1684.75\n",
      "variational_beta * kldivergence:  0.16848\n",
      "batch accuracy: 81.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.43305\n",
      "kldivergence:   1358.67\n",
      "variational_beta * kldivergence:  0.13587\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.42653\n",
      "kldivergence:   1499.92\n",
      "variational_beta * kldivergence:  0.14999\n",
      "batch accuracy: 86.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.42090\n",
      "kldivergence:   1526.09\n",
      "variational_beta * kldivergence:  0.15261\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.36106\n",
      "kldivergence:   1343.92\n",
      "variational_beta * kldivergence:  0.13439\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.45175\n",
      "kldivergence:   1477.85\n",
      "variational_beta * kldivergence:  0.14778\n",
      "batch accuracy: 85.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.47887\n",
      "kldivergence:   1512.80\n",
      "variational_beta * kldivergence:  0.15128\n",
      "batch accuracy: 85.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.54154\n",
      "kldivergence:   1586.72\n",
      "variational_beta * kldivergence:  0.15867\n",
      "batch accuracy: 84.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.45218\n",
      "kldivergence:   1582.12\n",
      "variational_beta * kldivergence:  0.15821\n",
      "batch accuracy: 86.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.44822\n",
      "kldivergence:   1491.69\n",
      "variational_beta * kldivergence:  0.14917\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.45037\n",
      "kldivergence:   1458.71\n",
      "variational_beta * kldivergence:  0.14587\n",
      "batch accuracy: 86.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.42178\n",
      "kldivergence:   1418.98\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.44364\n",
      "kldivergence:   1489.44\n",
      "variational_beta * kldivergence:  0.14894\n",
      "batch accuracy: 86.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.40116\n",
      "kldivergence:   1362.18\n",
      "variational_beta * kldivergence:  0.13622\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.45165\n",
      "kldivergence:   1557.55\n",
      "variational_beta * kldivergence:  0.15575\n",
      "batch accuracy: 86.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.47133\n",
      "kldivergence:   1469.74\n",
      "variational_beta * kldivergence:  0.14697\n",
      "batch accuracy: 84.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.48594\n",
      "kldivergence:   1647.96\n",
      "variational_beta * kldivergence:  0.16480\n",
      "batch accuracy: 84.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.39744\n",
      "kldivergence:   1381.57\n",
      "variational_beta * kldivergence:  0.13816\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.44826\n",
      "kldivergence:   1452.63\n",
      "variational_beta * kldivergence:  0.14526\n",
      "batch accuracy: 86.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.41188\n",
      "kldivergence:   1436.39\n",
      "variational_beta * kldivergence:  0.14364\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.46205\n",
      "kldivergence:   1532.07\n",
      "variational_beta * kldivergence:  0.15321\n",
      "batch accuracy: 85.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.44731\n",
      "kldivergence:   1379.59\n",
      "variational_beta * kldivergence:  0.13796\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.38181\n",
      "kldivergence:   1526.92\n",
      "variational_beta * kldivergence:  0.15269\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.42687\n",
      "kldivergence:   1495.91\n",
      "variational_beta * kldivergence:  0.14959\n",
      "batch accuracy: 86.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.52572\n",
      "kldivergence:   1664.29\n",
      "variational_beta * kldivergence:  0.16643\n",
      "batch accuracy: 84.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.42932\n",
      "kldivergence:   1444.52\n",
      "variational_beta * kldivergence:  0.14445\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.38347\n",
      "kldivergence:   1367.21\n",
      "variational_beta * kldivergence:  0.13672\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.42259\n",
      "kldivergence:   1434.27\n",
      "variational_beta * kldivergence:  0.14343\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.48594\n",
      "kldivergence:   1500.37\n",
      "variational_beta * kldivergence:  0.15004\n",
      "batch accuracy: 85.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.53285\n",
      "kldivergence:   1729.22\n",
      "variational_beta * kldivergence:  0.17292\n",
      "batch accuracy: 82.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.50001\n",
      "kldivergence:   1468.14\n",
      "variational_beta * kldivergence:  0.14681\n",
      "batch accuracy: 84.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.49956\n",
      "kldivergence:   1554.62\n",
      "variational_beta * kldivergence:  0.15546\n",
      "batch accuracy: 84.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.38935\n",
      "kldivergence:   1371.27\n",
      "variational_beta * kldivergence:  0.13713\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.43626\n",
      "kldivergence:   1423.40\n",
      "variational_beta * kldivergence:  0.14234\n",
      "batch accuracy: 85.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.51958\n",
      "kldivergence:   1639.58\n",
      "variational_beta * kldivergence:  0.16396\n",
      "batch accuracy: 83.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.60012\n",
      "kldivergence:   1587.39\n",
      "variational_beta * kldivergence:  0.15874\n",
      "batch accuracy: 83.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.35480\n",
      "kldivergence:   1419.62\n",
      "variational_beta * kldivergence:  0.14196\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.59610\n",
      "kldivergence:   1669.24\n",
      "variational_beta * kldivergence:  0.16692\n",
      "batch accuracy: 82.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.47497\n",
      "kldivergence:   1613.31\n",
      "variational_beta * kldivergence:  0.16133\n",
      "batch accuracy: 85.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #23\n",
      "reconstruction loss: 0.51228\n",
      "kldivergence:   1503.75\n",
      "variational_beta * kldivergence:  0.15038\n",
      "batch accuracy: 84.53\n",
      "\n",
      "\n",
      "epoch # 23 : train loss is [185.93555348526843] and validation loss is [0.10241020300636405] \n",
      "Epoch [24 / 150] average reconstruction error: 0.501174\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35561\n",
      "kldivergence:   1699.41\n",
      "variational_beta * kldivergence:  0.16994\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34078\n",
      "kldivergence:   1466.38\n",
      "variational_beta * kldivergence:  0.14664\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32837\n",
      "kldivergence:   1512.97\n",
      "variational_beta * kldivergence:  0.15130\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37440\n",
      "kldivergence:   1650.80\n",
      "variational_beta * kldivergence:  0.16508\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33323\n",
      "kldivergence:   1496.69\n",
      "variational_beta * kldivergence:  0.14967\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36516\n",
      "kldivergence:   1721.46\n",
      "variational_beta * kldivergence:  0.17215\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32107\n",
      "kldivergence:   1410.55\n",
      "variational_beta * kldivergence:  0.14105\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36740\n",
      "kldivergence:   1751.13\n",
      "variational_beta * kldivergence:  0.17511\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29686\n",
      "kldivergence:   1279.65\n",
      "variational_beta * kldivergence:  0.12797\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30201\n",
      "kldivergence:   1534.70\n",
      "variational_beta * kldivergence:  0.15347\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.26461\n",
      "kldivergence:   1170.04\n",
      "variational_beta * kldivergence:  0.11700\n",
      "batch accuracy: 91.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35289\n",
      "kldivergence:   1511.09\n",
      "variational_beta * kldivergence:  0.15111\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29563\n",
      "kldivergence:   1641.91\n",
      "variational_beta * kldivergence:  0.16419\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.42653\n",
      "kldivergence:   1925.86\n",
      "variational_beta * kldivergence:  0.19259\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37524\n",
      "kldivergence:   1616.45\n",
      "variational_beta * kldivergence:  0.16164\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35991\n",
      "kldivergence:   1643.08\n",
      "variational_beta * kldivergence:  0.16431\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36019\n",
      "kldivergence:   1400.43\n",
      "variational_beta * kldivergence:  0.14004\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33883\n",
      "kldivergence:   1462.02\n",
      "variational_beta * kldivergence:  0.14620\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33420\n",
      "kldivergence:   1594.52\n",
      "variational_beta * kldivergence:  0.15945\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35069\n",
      "kldivergence:   1557.00\n",
      "variational_beta * kldivergence:  0.15570\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37175\n",
      "kldivergence:   1793.57\n",
      "variational_beta * kldivergence:  0.17936\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29540\n",
      "kldivergence:   1472.96\n",
      "variational_beta * kldivergence:  0.14730\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32162\n",
      "kldivergence:   1797.91\n",
      "variational_beta * kldivergence:  0.17979\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35699\n",
      "kldivergence:   1512.45\n",
      "variational_beta * kldivergence:  0.15125\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33237\n",
      "kldivergence:   1428.39\n",
      "variational_beta * kldivergence:  0.14284\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30946\n",
      "kldivergence:   1848.36\n",
      "variational_beta * kldivergence:  0.18484\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35758\n",
      "kldivergence:   1593.39\n",
      "variational_beta * kldivergence:  0.15934\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29417\n",
      "kldivergence:   1626.41\n",
      "variational_beta * kldivergence:  0.16264\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29734\n",
      "kldivergence:   1640.34\n",
      "variational_beta * kldivergence:  0.16403\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34305\n",
      "kldivergence:   1644.50\n",
      "variational_beta * kldivergence:  0.16445\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.27976\n",
      "kldivergence:   1418.99\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36660\n",
      "kldivergence:   1618.32\n",
      "variational_beta * kldivergence:  0.16183\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34207\n",
      "kldivergence:   1962.68\n",
      "variational_beta * kldivergence:  0.19627\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31478\n",
      "kldivergence:   1540.11\n",
      "variational_beta * kldivergence:  0.15401\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29656\n",
      "kldivergence:   1477.94\n",
      "variational_beta * kldivergence:  0.14779\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33636\n",
      "kldivergence:   1735.46\n",
      "variational_beta * kldivergence:  0.17355\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31479\n",
      "kldivergence:   1726.55\n",
      "variational_beta * kldivergence:  0.17266\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34234\n",
      "kldivergence:   1663.89\n",
      "variational_beta * kldivergence:  0.16639\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38935\n",
      "kldivergence:   1661.32\n",
      "variational_beta * kldivergence:  0.16613\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36036\n",
      "kldivergence:   1481.25\n",
      "variational_beta * kldivergence:  0.14812\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36485\n",
      "kldivergence:   1716.10\n",
      "variational_beta * kldivergence:  0.17161\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.28371\n",
      "kldivergence:   1389.87\n",
      "variational_beta * kldivergence:  0.13899\n",
      "batch accuracy: 90.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38540\n",
      "kldivergence:   1523.22\n",
      "variational_beta * kldivergence:  0.15232\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.39008\n",
      "kldivergence:   1728.56\n",
      "variational_beta * kldivergence:  0.17286\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30575\n",
      "kldivergence:   1487.16\n",
      "variational_beta * kldivergence:  0.14872\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31418\n",
      "kldivergence:   1669.95\n",
      "variational_beta * kldivergence:  0.16700\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32439\n",
      "kldivergence:   1469.71\n",
      "variational_beta * kldivergence:  0.14697\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34817\n",
      "kldivergence:   1678.90\n",
      "variational_beta * kldivergence:  0.16789\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30967\n",
      "kldivergence:   1471.33\n",
      "variational_beta * kldivergence:  0.14713\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35782\n",
      "kldivergence:   1609.13\n",
      "variational_beta * kldivergence:  0.16091\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29510\n",
      "kldivergence:   1602.34\n",
      "variational_beta * kldivergence:  0.16023\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31638\n",
      "kldivergence:   1728.78\n",
      "variational_beta * kldivergence:  0.17288\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32821\n",
      "kldivergence:   1687.49\n",
      "variational_beta * kldivergence:  0.16875\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37039\n",
      "kldivergence:   1626.23\n",
      "variational_beta * kldivergence:  0.16262\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33817\n",
      "kldivergence:   1692.06\n",
      "variational_beta * kldivergence:  0.16921\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29780\n",
      "kldivergence:   1557.58\n",
      "variational_beta * kldivergence:  0.15576\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36360\n",
      "kldivergence:   1734.63\n",
      "variational_beta * kldivergence:  0.17346\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31245\n",
      "kldivergence:   1661.63\n",
      "variational_beta * kldivergence:  0.16616\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34031\n",
      "kldivergence:   2099.62\n",
      "variational_beta * kldivergence:  0.20996\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.27654\n",
      "kldivergence:   1608.96\n",
      "variational_beta * kldivergence:  0.16090\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35607\n",
      "kldivergence:   1730.91\n",
      "variational_beta * kldivergence:  0.17309\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35244\n",
      "kldivergence:   1709.99\n",
      "variational_beta * kldivergence:  0.17100\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31906\n",
      "kldivergence:   1552.09\n",
      "variational_beta * kldivergence:  0.15521\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.28901\n",
      "kldivergence:   1440.91\n",
      "variational_beta * kldivergence:  0.14409\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38320\n",
      "kldivergence:   1930.52\n",
      "variational_beta * kldivergence:  0.19305\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34701\n",
      "kldivergence:   1743.53\n",
      "variational_beta * kldivergence:  0.17435\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36816\n",
      "kldivergence:   1677.08\n",
      "variational_beta * kldivergence:  0.16771\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36007\n",
      "kldivergence:   1724.89\n",
      "variational_beta * kldivergence:  0.17249\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30880\n",
      "kldivergence:   1568.22\n",
      "variational_beta * kldivergence:  0.15682\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33561\n",
      "kldivergence:   1610.68\n",
      "variational_beta * kldivergence:  0.16107\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36514\n",
      "kldivergence:   1715.40\n",
      "variational_beta * kldivergence:  0.17154\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30110\n",
      "kldivergence:   1416.29\n",
      "variational_beta * kldivergence:  0.14163\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33947\n",
      "kldivergence:   1575.16\n",
      "variational_beta * kldivergence:  0.15752\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34381\n",
      "kldivergence:   2121.43\n",
      "variational_beta * kldivergence:  0.21214\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33949\n",
      "kldivergence:   1389.28\n",
      "variational_beta * kldivergence:  0.13893\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33406\n",
      "kldivergence:   1533.47\n",
      "variational_beta * kldivergence:  0.15335\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32702\n",
      "kldivergence:   1688.41\n",
      "variational_beta * kldivergence:  0.16884\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38886\n",
      "kldivergence:   1635.22\n",
      "variational_beta * kldivergence:  0.16352\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33308\n",
      "kldivergence:   1436.68\n",
      "variational_beta * kldivergence:  0.14367\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.40860\n",
      "kldivergence:   1743.94\n",
      "variational_beta * kldivergence:  0.17439\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32095\n",
      "kldivergence:   1877.21\n",
      "variational_beta * kldivergence:  0.18772\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33098\n",
      "kldivergence:   1685.04\n",
      "variational_beta * kldivergence:  0.16850\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32595\n",
      "kldivergence:   1614.51\n",
      "variational_beta * kldivergence:  0.16145\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31294\n",
      "kldivergence:   1718.67\n",
      "variational_beta * kldivergence:  0.17187\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31193\n",
      "kldivergence:   1406.97\n",
      "variational_beta * kldivergence:  0.14070\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31612\n",
      "kldivergence:   1563.69\n",
      "variational_beta * kldivergence:  0.15637\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33546\n",
      "kldivergence:   1624.58\n",
      "variational_beta * kldivergence:  0.16246\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32499\n",
      "kldivergence:   1743.06\n",
      "variational_beta * kldivergence:  0.17431\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32441\n",
      "kldivergence:   1465.03\n",
      "variational_beta * kldivergence:  0.14650\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34875\n",
      "kldivergence:   1593.33\n",
      "variational_beta * kldivergence:  0.15933\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33525\n",
      "kldivergence:   1907.40\n",
      "variational_beta * kldivergence:  0.19074\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33329\n",
      "kldivergence:   1405.52\n",
      "variational_beta * kldivergence:  0.14055\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36285\n",
      "kldivergence:   1389.45\n",
      "variational_beta * kldivergence:  0.13895\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37971\n",
      "kldivergence:   1549.26\n",
      "variational_beta * kldivergence:  0.15493\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.26489\n",
      "kldivergence:   1647.12\n",
      "variational_beta * kldivergence:  0.16471\n",
      "batch accuracy: 90.82\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.28838\n",
      "kldivergence:   1282.84\n",
      "variational_beta * kldivergence:  0.12828\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32562\n",
      "kldivergence:   1392.16\n",
      "variational_beta * kldivergence:  0.13922\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.40036\n",
      "kldivergence:   1883.86\n",
      "variational_beta * kldivergence:  0.18839\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29743\n",
      "kldivergence:   1768.36\n",
      "variational_beta * kldivergence:  0.17684\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33399\n",
      "kldivergence:   1590.99\n",
      "variational_beta * kldivergence:  0.15910\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.28927\n",
      "kldivergence:   1499.06\n",
      "variational_beta * kldivergence:  0.14991\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29937\n",
      "kldivergence:   1547.10\n",
      "variational_beta * kldivergence:  0.15471\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35128\n",
      "kldivergence:   1760.95\n",
      "variational_beta * kldivergence:  0.17610\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38921\n",
      "kldivergence:   1827.19\n",
      "variational_beta * kldivergence:  0.18272\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38975\n",
      "kldivergence:   1732.61\n",
      "variational_beta * kldivergence:  0.17326\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31387\n",
      "kldivergence:   1552.80\n",
      "variational_beta * kldivergence:  0.15528\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31733\n",
      "kldivergence:   1562.97\n",
      "variational_beta * kldivergence:  0.15630\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30714\n",
      "kldivergence:   1451.49\n",
      "variational_beta * kldivergence:  0.14515\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38234\n",
      "kldivergence:   1592.27\n",
      "variational_beta * kldivergence:  0.15923\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30953\n",
      "kldivergence:   1523.12\n",
      "variational_beta * kldivergence:  0.15231\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29877\n",
      "kldivergence:   1451.91\n",
      "variational_beta * kldivergence:  0.14519\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.28305\n",
      "kldivergence:   1641.08\n",
      "variational_beta * kldivergence:  0.16411\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32545\n",
      "kldivergence:   1559.31\n",
      "variational_beta * kldivergence:  0.15593\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29366\n",
      "kldivergence:   1605.24\n",
      "variational_beta * kldivergence:  0.16052\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35381\n",
      "kldivergence:   1864.16\n",
      "variational_beta * kldivergence:  0.18642\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.28825\n",
      "kldivergence:   1387.90\n",
      "variational_beta * kldivergence:  0.13879\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34487\n",
      "kldivergence:   1612.59\n",
      "variational_beta * kldivergence:  0.16126\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29227\n",
      "kldivergence:   1509.12\n",
      "variational_beta * kldivergence:  0.15091\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33500\n",
      "kldivergence:   1460.05\n",
      "variational_beta * kldivergence:  0.14600\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32431\n",
      "kldivergence:   1705.30\n",
      "variational_beta * kldivergence:  0.17053\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.27973\n",
      "kldivergence:   1795.05\n",
      "variational_beta * kldivergence:  0.17950\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38460\n",
      "kldivergence:   1676.23\n",
      "variational_beta * kldivergence:  0.16762\n",
      "batch accuracy: 86.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34916\n",
      "kldivergence:   1650.89\n",
      "variational_beta * kldivergence:  0.16509\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32595\n",
      "kldivergence:   1693.70\n",
      "variational_beta * kldivergence:  0.16937\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36151\n",
      "kldivergence:   1585.87\n",
      "variational_beta * kldivergence:  0.15859\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.27626\n",
      "kldivergence:   1532.94\n",
      "variational_beta * kldivergence:  0.15329\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34873\n",
      "kldivergence:   1794.46\n",
      "variational_beta * kldivergence:  0.17945\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29336\n",
      "kldivergence:   1465.23\n",
      "variational_beta * kldivergence:  0.14652\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32300\n",
      "kldivergence:   1571.25\n",
      "variational_beta * kldivergence:  0.15713\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34549\n",
      "kldivergence:   1739.89\n",
      "variational_beta * kldivergence:  0.17399\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31286\n",
      "kldivergence:   1605.10\n",
      "variational_beta * kldivergence:  0.16051\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29705\n",
      "kldivergence:   1486.90\n",
      "variational_beta * kldivergence:  0.14869\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33596\n",
      "kldivergence:   1675.86\n",
      "variational_beta * kldivergence:  0.16759\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34931\n",
      "kldivergence:   1601.13\n",
      "variational_beta * kldivergence:  0.16011\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35675\n",
      "kldivergence:   1678.18\n",
      "variational_beta * kldivergence:  0.16782\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33287\n",
      "kldivergence:   1646.30\n",
      "variational_beta * kldivergence:  0.16463\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30246\n",
      "kldivergence:   1510.59\n",
      "variational_beta * kldivergence:  0.15106\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37227\n",
      "kldivergence:   1800.99\n",
      "variational_beta * kldivergence:  0.18010\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33754\n",
      "kldivergence:   1881.52\n",
      "variational_beta * kldivergence:  0.18815\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32072\n",
      "kldivergence:   1644.65\n",
      "variational_beta * kldivergence:  0.16446\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32207\n",
      "kldivergence:   1516.36\n",
      "variational_beta * kldivergence:  0.15164\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.40513\n",
      "kldivergence:   1447.66\n",
      "variational_beta * kldivergence:  0.14477\n",
      "batch accuracy: 86.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33433\n",
      "kldivergence:   1518.43\n",
      "variational_beta * kldivergence:  0.15184\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32384\n",
      "kldivergence:   1513.31\n",
      "variational_beta * kldivergence:  0.15133\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35237\n",
      "kldivergence:   1653.56\n",
      "variational_beta * kldivergence:  0.16536\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31805\n",
      "kldivergence:   1502.73\n",
      "variational_beta * kldivergence:  0.15027\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.39958\n",
      "kldivergence:   1999.03\n",
      "variational_beta * kldivergence:  0.19990\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32842\n",
      "kldivergence:   1587.55\n",
      "variational_beta * kldivergence:  0.15875\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31024\n",
      "kldivergence:   1485.17\n",
      "variational_beta * kldivergence:  0.14852\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.27585\n",
      "kldivergence:   1429.10\n",
      "variational_beta * kldivergence:  0.14291\n",
      "batch accuracy: 90.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35201\n",
      "kldivergence:   1519.03\n",
      "variational_beta * kldivergence:  0.15190\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35350\n",
      "kldivergence:   1768.46\n",
      "variational_beta * kldivergence:  0.17685\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37184\n",
      "kldivergence:   1688.69\n",
      "variational_beta * kldivergence:  0.16887\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29099\n",
      "kldivergence:   1427.38\n",
      "variational_beta * kldivergence:  0.14274\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32038\n",
      "kldivergence:   1528.19\n",
      "variational_beta * kldivergence:  0.15282\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33518\n",
      "kldivergence:   1511.18\n",
      "variational_beta * kldivergence:  0.15112\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36145\n",
      "kldivergence:   1661.81\n",
      "variational_beta * kldivergence:  0.16618\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32636\n",
      "kldivergence:   1499.28\n",
      "variational_beta * kldivergence:  0.14993\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32771\n",
      "kldivergence:   1493.35\n",
      "variational_beta * kldivergence:  0.14933\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32016\n",
      "kldivergence:   1575.51\n",
      "variational_beta * kldivergence:  0.15755\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33589\n",
      "kldivergence:   1895.94\n",
      "variational_beta * kldivergence:  0.18959\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37993\n",
      "kldivergence:   1595.03\n",
      "variational_beta * kldivergence:  0.15950\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38912\n",
      "kldivergence:   1835.85\n",
      "variational_beta * kldivergence:  0.18358\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30728\n",
      "kldivergence:   1469.29\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32615\n",
      "kldivergence:   1510.26\n",
      "variational_beta * kldivergence:  0.15103\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35081\n",
      "kldivergence:   1658.10\n",
      "variational_beta * kldivergence:  0.16581\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35752\n",
      "kldivergence:   1786.52\n",
      "variational_beta * kldivergence:  0.17865\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31243\n",
      "kldivergence:   1576.86\n",
      "variational_beta * kldivergence:  0.15769\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34543\n",
      "kldivergence:   1758.27\n",
      "variational_beta * kldivergence:  0.17583\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.39169\n",
      "kldivergence:   1735.14\n",
      "variational_beta * kldivergence:  0.17351\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35145\n",
      "kldivergence:   1849.60\n",
      "variational_beta * kldivergence:  0.18496\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29907\n",
      "kldivergence:   1676.39\n",
      "variational_beta * kldivergence:  0.16764\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34637\n",
      "kldivergence:   1906.75\n",
      "variational_beta * kldivergence:  0.19067\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33155\n",
      "kldivergence:   1771.86\n",
      "variational_beta * kldivergence:  0.17719\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33288\n",
      "kldivergence:   1634.55\n",
      "variational_beta * kldivergence:  0.16345\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33607\n",
      "kldivergence:   1440.56\n",
      "variational_beta * kldivergence:  0.14406\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32407\n",
      "kldivergence:   1609.97\n",
      "variational_beta * kldivergence:  0.16100\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30734\n",
      "kldivergence:   1509.68\n",
      "variational_beta * kldivergence:  0.15097\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36897\n",
      "kldivergence:   1599.76\n",
      "variational_beta * kldivergence:  0.15998\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.26171\n",
      "kldivergence:   1495.78\n",
      "variational_beta * kldivergence:  0.14958\n",
      "batch accuracy: 91.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37936\n",
      "kldivergence:   1584.10\n",
      "variational_beta * kldivergence:  0.15841\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32426\n",
      "kldivergence:   1622.78\n",
      "variational_beta * kldivergence:  0.16228\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37204\n",
      "kldivergence:   1585.34\n",
      "variational_beta * kldivergence:  0.15853\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29572\n",
      "kldivergence:   1396.32\n",
      "variational_beta * kldivergence:  0.13963\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29464\n",
      "kldivergence:   1452.09\n",
      "variational_beta * kldivergence:  0.14521\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34254\n",
      "kldivergence:   1437.64\n",
      "variational_beta * kldivergence:  0.14376\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33849\n",
      "kldivergence:   1756.76\n",
      "variational_beta * kldivergence:  0.17568\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32425\n",
      "kldivergence:   1313.61\n",
      "variational_beta * kldivergence:  0.13136\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36886\n",
      "kldivergence:   1771.49\n",
      "variational_beta * kldivergence:  0.17715\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38717\n",
      "kldivergence:   1574.18\n",
      "variational_beta * kldivergence:  0.15742\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30690\n",
      "kldivergence:   1534.50\n",
      "variational_beta * kldivergence:  0.15345\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38193\n",
      "kldivergence:   1958.52\n",
      "variational_beta * kldivergence:  0.19585\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36313\n",
      "kldivergence:   1530.09\n",
      "variational_beta * kldivergence:  0.15301\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38921\n",
      "kldivergence:   1663.44\n",
      "variational_beta * kldivergence:  0.16634\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29258\n",
      "kldivergence:   1435.87\n",
      "variational_beta * kldivergence:  0.14359\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35359\n",
      "kldivergence:   1611.61\n",
      "variational_beta * kldivergence:  0.16116\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30722\n",
      "kldivergence:   1439.07\n",
      "variational_beta * kldivergence:  0.14391\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30899\n",
      "kldivergence:   1623.57\n",
      "variational_beta * kldivergence:  0.16236\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35148\n",
      "kldivergence:   1543.27\n",
      "variational_beta * kldivergence:  0.15433\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34662\n",
      "kldivergence:   1514.29\n",
      "variational_beta * kldivergence:  0.15143\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33552\n",
      "kldivergence:   1548.61\n",
      "variational_beta * kldivergence:  0.15486\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38285\n",
      "kldivergence:   1693.90\n",
      "variational_beta * kldivergence:  0.16939\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30520\n",
      "kldivergence:   1660.72\n",
      "variational_beta * kldivergence:  0.16607\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34839\n",
      "kldivergence:   1708.91\n",
      "variational_beta * kldivergence:  0.17089\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36906\n",
      "kldivergence:   1573.22\n",
      "variational_beta * kldivergence:  0.15732\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34986\n",
      "kldivergence:   1463.14\n",
      "variational_beta * kldivergence:  0.14631\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34486\n",
      "kldivergence:   1547.83\n",
      "variational_beta * kldivergence:  0.15478\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33997\n",
      "kldivergence:   1509.16\n",
      "variational_beta * kldivergence:  0.15092\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31519\n",
      "kldivergence:   1592.59\n",
      "variational_beta * kldivergence:  0.15926\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31953\n",
      "kldivergence:   1423.27\n",
      "variational_beta * kldivergence:  0.14233\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36692\n",
      "kldivergence:   1648.95\n",
      "variational_beta * kldivergence:  0.16490\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31493\n",
      "kldivergence:   1643.24\n",
      "variational_beta * kldivergence:  0.16432\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30647\n",
      "kldivergence:   1455.47\n",
      "variational_beta * kldivergence:  0.14555\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34317\n",
      "kldivergence:   1468.15\n",
      "variational_beta * kldivergence:  0.14682\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30966\n",
      "kldivergence:   1669.22\n",
      "variational_beta * kldivergence:  0.16692\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32601\n",
      "kldivergence:   1560.99\n",
      "variational_beta * kldivergence:  0.15610\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34153\n",
      "kldivergence:   1611.62\n",
      "variational_beta * kldivergence:  0.16116\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30823\n",
      "kldivergence:   1618.51\n",
      "variational_beta * kldivergence:  0.16185\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37702\n",
      "kldivergence:   1899.84\n",
      "variational_beta * kldivergence:  0.18998\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36427\n",
      "kldivergence:   1759.77\n",
      "variational_beta * kldivergence:  0.17598\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33565\n",
      "kldivergence:   1533.69\n",
      "variational_beta * kldivergence:  0.15337\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.39231\n",
      "kldivergence:   1681.06\n",
      "variational_beta * kldivergence:  0.16811\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30113\n",
      "kldivergence:   1595.87\n",
      "variational_beta * kldivergence:  0.15959\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37807\n",
      "kldivergence:   1621.65\n",
      "variational_beta * kldivergence:  0.16217\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29748\n",
      "kldivergence:   1708.73\n",
      "variational_beta * kldivergence:  0.17087\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36488\n",
      "kldivergence:   1635.02\n",
      "variational_beta * kldivergence:  0.16350\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.39901\n",
      "kldivergence:   2003.59\n",
      "variational_beta * kldivergence:  0.20036\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38423\n",
      "kldivergence:   1561.03\n",
      "variational_beta * kldivergence:  0.15610\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35737\n",
      "kldivergence:   1568.32\n",
      "variational_beta * kldivergence:  0.15683\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34870\n",
      "kldivergence:   1503.37\n",
      "variational_beta * kldivergence:  0.15034\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32694\n",
      "kldivergence:   1773.05\n",
      "variational_beta * kldivergence:  0.17730\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31055\n",
      "kldivergence:   1532.68\n",
      "variational_beta * kldivergence:  0.15327\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.28910\n",
      "kldivergence:   1526.72\n",
      "variational_beta * kldivergence:  0.15267\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36563\n",
      "kldivergence:   1831.75\n",
      "variational_beta * kldivergence:  0.18318\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31325\n",
      "kldivergence:   1513.22\n",
      "variational_beta * kldivergence:  0.15132\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30640\n",
      "kldivergence:   1414.21\n",
      "variational_beta * kldivergence:  0.14142\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35721\n",
      "kldivergence:   1400.54\n",
      "variational_beta * kldivergence:  0.14005\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34628\n",
      "kldivergence:   1633.97\n",
      "variational_beta * kldivergence:  0.16340\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31898\n",
      "kldivergence:   1531.62\n",
      "variational_beta * kldivergence:  0.15316\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32644\n",
      "kldivergence:   1563.71\n",
      "variational_beta * kldivergence:  0.15637\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31392\n",
      "kldivergence:   1613.31\n",
      "variational_beta * kldivergence:  0.16133\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30709\n",
      "kldivergence:   1627.45\n",
      "variational_beta * kldivergence:  0.16275\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33941\n",
      "kldivergence:   1575.29\n",
      "variational_beta * kldivergence:  0.15753\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31664\n",
      "kldivergence:   1413.83\n",
      "variational_beta * kldivergence:  0.14138\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36099\n",
      "kldivergence:   1816.91\n",
      "variational_beta * kldivergence:  0.18169\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31890\n",
      "kldivergence:   1494.20\n",
      "variational_beta * kldivergence:  0.14942\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32569\n",
      "kldivergence:   1654.94\n",
      "variational_beta * kldivergence:  0.16549\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.27059\n",
      "kldivergence:   1303.61\n",
      "variational_beta * kldivergence:  0.13036\n",
      "batch accuracy: 91.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34558\n",
      "kldivergence:   1590.49\n",
      "variational_beta * kldivergence:  0.15905\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33240\n",
      "kldivergence:   1723.00\n",
      "variational_beta * kldivergence:  0.17230\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30374\n",
      "kldivergence:   1393.16\n",
      "variational_beta * kldivergence:  0.13932\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35521\n",
      "kldivergence:   1699.99\n",
      "variational_beta * kldivergence:  0.17000\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35062\n",
      "kldivergence:   1661.11\n",
      "variational_beta * kldivergence:  0.16611\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.26139\n",
      "kldivergence:   1371.06\n",
      "variational_beta * kldivergence:  0.13711\n",
      "batch accuracy: 91.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29006\n",
      "kldivergence:   1646.32\n",
      "variational_beta * kldivergence:  0.16463\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31599\n",
      "kldivergence:   1507.42\n",
      "variational_beta * kldivergence:  0.15074\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32122\n",
      "kldivergence:   1615.54\n",
      "variational_beta * kldivergence:  0.16155\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33318\n",
      "kldivergence:   1529.15\n",
      "variational_beta * kldivergence:  0.15291\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32577\n",
      "kldivergence:   1722.16\n",
      "variational_beta * kldivergence:  0.17222\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29514\n",
      "kldivergence:   1937.25\n",
      "variational_beta * kldivergence:  0.19373\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36746\n",
      "kldivergence:   1829.82\n",
      "variational_beta * kldivergence:  0.18298\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30504\n",
      "kldivergence:   1487.24\n",
      "variational_beta * kldivergence:  0.14872\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31839\n",
      "kldivergence:   1695.45\n",
      "variational_beta * kldivergence:  0.16955\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33565\n",
      "kldivergence:   1421.55\n",
      "variational_beta * kldivergence:  0.14215\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37809\n",
      "kldivergence:   1580.70\n",
      "variational_beta * kldivergence:  0.15807\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32351\n",
      "kldivergence:   1449.01\n",
      "variational_beta * kldivergence:  0.14490\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37417\n",
      "kldivergence:   1687.79\n",
      "variational_beta * kldivergence:  0.16878\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30980\n",
      "kldivergence:   1743.77\n",
      "variational_beta * kldivergence:  0.17438\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38378\n",
      "kldivergence:   1762.47\n",
      "variational_beta * kldivergence:  0.17625\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36768\n",
      "kldivergence:   1794.17\n",
      "variational_beta * kldivergence:  0.17942\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.28927\n",
      "kldivergence:   1567.47\n",
      "variational_beta * kldivergence:  0.15675\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32196\n",
      "kldivergence:   1641.76\n",
      "variational_beta * kldivergence:  0.16418\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31964\n",
      "kldivergence:   1421.00\n",
      "variational_beta * kldivergence:  0.14210\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32574\n",
      "kldivergence:   1745.03\n",
      "variational_beta * kldivergence:  0.17450\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37106\n",
      "kldivergence:   1532.89\n",
      "variational_beta * kldivergence:  0.15329\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34466\n",
      "kldivergence:   1738.56\n",
      "variational_beta * kldivergence:  0.17386\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35584\n",
      "kldivergence:   1539.63\n",
      "variational_beta * kldivergence:  0.15396\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35307\n",
      "kldivergence:   1760.18\n",
      "variational_beta * kldivergence:  0.17602\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30688\n",
      "kldivergence:   1409.94\n",
      "variational_beta * kldivergence:  0.14099\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34345\n",
      "kldivergence:   1579.32\n",
      "variational_beta * kldivergence:  0.15793\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30943\n",
      "kldivergence:   1501.44\n",
      "variational_beta * kldivergence:  0.15014\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38832\n",
      "kldivergence:   1497.01\n",
      "variational_beta * kldivergence:  0.14970\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34566\n",
      "kldivergence:   1509.77\n",
      "variational_beta * kldivergence:  0.15098\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30092\n",
      "kldivergence:   1302.80\n",
      "variational_beta * kldivergence:  0.13028\n",
      "batch accuracy: 90.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37602\n",
      "kldivergence:   1524.34\n",
      "variational_beta * kldivergence:  0.15243\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36775\n",
      "kldivergence:   1676.16\n",
      "variational_beta * kldivergence:  0.16762\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32369\n",
      "kldivergence:   1568.47\n",
      "variational_beta * kldivergence:  0.15685\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31372\n",
      "kldivergence:   1586.20\n",
      "variational_beta * kldivergence:  0.15862\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.40932\n",
      "kldivergence:   1725.57\n",
      "variational_beta * kldivergence:  0.17256\n",
      "batch accuracy: 86.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37611\n",
      "kldivergence:   1784.35\n",
      "variational_beta * kldivergence:  0.17844\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35684\n",
      "kldivergence:   1547.92\n",
      "variational_beta * kldivergence:  0.15479\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36451\n",
      "kldivergence:   1689.81\n",
      "variational_beta * kldivergence:  0.16898\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33554\n",
      "kldivergence:   1951.42\n",
      "variational_beta * kldivergence:  0.19514\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34960\n",
      "kldivergence:   1660.92\n",
      "variational_beta * kldivergence:  0.16609\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33558\n",
      "kldivergence:   1794.30\n",
      "variational_beta * kldivergence:  0.17943\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34161\n",
      "kldivergence:   1671.64\n",
      "variational_beta * kldivergence:  0.16716\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35804\n",
      "kldivergence:   1452.66\n",
      "variational_beta * kldivergence:  0.14527\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36082\n",
      "kldivergence:   1744.74\n",
      "variational_beta * kldivergence:  0.17447\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30137\n",
      "kldivergence:   1638.26\n",
      "variational_beta * kldivergence:  0.16383\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36323\n",
      "kldivergence:   1461.43\n",
      "variational_beta * kldivergence:  0.14614\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34732\n",
      "kldivergence:   1692.02\n",
      "variational_beta * kldivergence:  0.16920\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34871\n",
      "kldivergence:   2093.08\n",
      "variational_beta * kldivergence:  0.20931\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.41878\n",
      "kldivergence:   1684.90\n",
      "variational_beta * kldivergence:  0.16849\n",
      "batch accuracy: 85.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34959\n",
      "kldivergence:   1658.78\n",
      "variational_beta * kldivergence:  0.16588\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35773\n",
      "kldivergence:   1834.34\n",
      "variational_beta * kldivergence:  0.18343\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35215\n",
      "kldivergence:   1725.73\n",
      "variational_beta * kldivergence:  0.17257\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35926\n",
      "kldivergence:   1759.82\n",
      "variational_beta * kldivergence:  0.17598\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31752\n",
      "kldivergence:   1496.80\n",
      "variational_beta * kldivergence:  0.14968\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32584\n",
      "kldivergence:   1787.93\n",
      "variational_beta * kldivergence:  0.17879\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.28898\n",
      "kldivergence:   1571.13\n",
      "variational_beta * kldivergence:  0.15711\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31668\n",
      "kldivergence:   1784.78\n",
      "variational_beta * kldivergence:  0.17848\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31515\n",
      "kldivergence:   1686.52\n",
      "variational_beta * kldivergence:  0.16865\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32912\n",
      "kldivergence:   1541.40\n",
      "variational_beta * kldivergence:  0.15414\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35988\n",
      "kldivergence:   1561.02\n",
      "variational_beta * kldivergence:  0.15610\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33848\n",
      "kldivergence:   1503.80\n",
      "variational_beta * kldivergence:  0.15038\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33348\n",
      "kldivergence:   1654.84\n",
      "variational_beta * kldivergence:  0.16548\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36054\n",
      "kldivergence:   1668.06\n",
      "variational_beta * kldivergence:  0.16681\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37435\n",
      "kldivergence:   1508.86\n",
      "variational_beta * kldivergence:  0.15089\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29557\n",
      "kldivergence:   1817.96\n",
      "variational_beta * kldivergence:  0.18180\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37554\n",
      "kldivergence:   1781.01\n",
      "variational_beta * kldivergence:  0.17810\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37733\n",
      "kldivergence:   1580.06\n",
      "variational_beta * kldivergence:  0.15801\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30586\n",
      "kldivergence:   1606.96\n",
      "variational_beta * kldivergence:  0.16070\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35410\n",
      "kldivergence:   1750.83\n",
      "variational_beta * kldivergence:  0.17508\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34525\n",
      "kldivergence:   1730.29\n",
      "variational_beta * kldivergence:  0.17303\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.37132\n",
      "kldivergence:   1643.65\n",
      "variational_beta * kldivergence:  0.16436\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35263\n",
      "kldivergence:   1668.20\n",
      "variational_beta * kldivergence:  0.16682\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31904\n",
      "kldivergence:   1758.51\n",
      "variational_beta * kldivergence:  0.17585\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.40082\n",
      "kldivergence:   1761.33\n",
      "variational_beta * kldivergence:  0.17613\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34171\n",
      "kldivergence:   1660.29\n",
      "variational_beta * kldivergence:  0.16603\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.27697\n",
      "kldivergence:   1678.59\n",
      "variational_beta * kldivergence:  0.16786\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32862\n",
      "kldivergence:   1556.68\n",
      "variational_beta * kldivergence:  0.15567\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34332\n",
      "kldivergence:   1701.67\n",
      "variational_beta * kldivergence:  0.17017\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36565\n",
      "kldivergence:   1621.86\n",
      "variational_beta * kldivergence:  0.16219\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.29533\n",
      "kldivergence:   1677.68\n",
      "variational_beta * kldivergence:  0.16777\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.25454\n",
      "kldivergence:   1481.99\n",
      "variational_beta * kldivergence:  0.14820\n",
      "batch accuracy: 91.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35020\n",
      "kldivergence:   1440.47\n",
      "variational_beta * kldivergence:  0.14405\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31433\n",
      "kldivergence:   1642.74\n",
      "variational_beta * kldivergence:  0.16427\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35381\n",
      "kldivergence:   1559.20\n",
      "variational_beta * kldivergence:  0.15592\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31726\n",
      "kldivergence:   1469.89\n",
      "variational_beta * kldivergence:  0.14699\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33677\n",
      "kldivergence:   1727.36\n",
      "variational_beta * kldivergence:  0.17274\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33587\n",
      "kldivergence:   1725.80\n",
      "variational_beta * kldivergence:  0.17258\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32962\n",
      "kldivergence:   1735.82\n",
      "variational_beta * kldivergence:  0.17358\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30582\n",
      "kldivergence:   1490.87\n",
      "variational_beta * kldivergence:  0.14909\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33345\n",
      "kldivergence:   1660.70\n",
      "variational_beta * kldivergence:  0.16607\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33083\n",
      "kldivergence:   1494.96\n",
      "variational_beta * kldivergence:  0.14950\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30174\n",
      "kldivergence:   1584.72\n",
      "variational_beta * kldivergence:  0.15847\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32624\n",
      "kldivergence:   1617.01\n",
      "variational_beta * kldivergence:  0.16170\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31586\n",
      "kldivergence:   1522.02\n",
      "variational_beta * kldivergence:  0.15220\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.31352\n",
      "kldivergence:   2094.65\n",
      "variational_beta * kldivergence:  0.20946\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30311\n",
      "kldivergence:   1524.03\n",
      "variational_beta * kldivergence:  0.15240\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.35373\n",
      "kldivergence:   1708.02\n",
      "variational_beta * kldivergence:  0.17080\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38823\n",
      "kldivergence:   1660.06\n",
      "variational_beta * kldivergence:  0.16601\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33038\n",
      "kldivergence:   1499.90\n",
      "variational_beta * kldivergence:  0.14999\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33414\n",
      "kldivergence:   1617.18\n",
      "variational_beta * kldivergence:  0.16172\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33899\n",
      "kldivergence:   1694.36\n",
      "variational_beta * kldivergence:  0.16944\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.38275\n",
      "kldivergence:   1837.71\n",
      "variational_beta * kldivergence:  0.18377\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36793\n",
      "kldivergence:   1896.53\n",
      "variational_beta * kldivergence:  0.18965\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33157\n",
      "kldivergence:   1544.72\n",
      "variational_beta * kldivergence:  0.15447\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36663\n",
      "kldivergence:   1456.37\n",
      "variational_beta * kldivergence:  0.14564\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33643\n",
      "kldivergence:   1599.24\n",
      "variational_beta * kldivergence:  0.15992\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32400\n",
      "kldivergence:   1428.34\n",
      "variational_beta * kldivergence:  0.14283\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.34763\n",
      "kldivergence:   1583.76\n",
      "variational_beta * kldivergence:  0.15838\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.30777\n",
      "kldivergence:   1718.36\n",
      "variational_beta * kldivergence:  0.17184\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32809\n",
      "kldivergence:   1456.76\n",
      "variational_beta * kldivergence:  0.14568\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.42713\n",
      "kldivergence:   1792.47\n",
      "variational_beta * kldivergence:  0.17925\n",
      "batch accuracy: 85.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32795\n",
      "kldivergence:   1718.83\n",
      "variational_beta * kldivergence:  0.17188\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33293\n",
      "kldivergence:   1658.82\n",
      "variational_beta * kldivergence:  0.16588\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.32925\n",
      "kldivergence:   1776.12\n",
      "variational_beta * kldivergence:  0.17761\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36848\n",
      "kldivergence:   1594.19\n",
      "variational_beta * kldivergence:  0.15942\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.36952\n",
      "kldivergence:   1752.96\n",
      "variational_beta * kldivergence:  0.17530\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #24\n",
      "reconstruction loss: 0.33805\n",
      "kldivergence:   1574.76\n",
      "variational_beta * kldivergence:  0.15748\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.42940\n",
      "kldivergence:   1473.88\n",
      "variational_beta * kldivergence:  0.14739\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.44896\n",
      "kldivergence:   1394.38\n",
      "variational_beta * kldivergence:  0.13944\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.42050\n",
      "kldivergence:   1439.84\n",
      "variational_beta * kldivergence:  0.14398\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.41759\n",
      "kldivergence:   1581.40\n",
      "variational_beta * kldivergence:  0.15814\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.48273\n",
      "kldivergence:   1537.32\n",
      "variational_beta * kldivergence:  0.15373\n",
      "batch accuracy: 85.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.48353\n",
      "kldivergence:   1558.40\n",
      "variational_beta * kldivergence:  0.15584\n",
      "batch accuracy: 85.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.47420\n",
      "kldivergence:   1580.48\n",
      "variational_beta * kldivergence:  0.15805\n",
      "batch accuracy: 84.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.53008\n",
      "kldivergence:   1582.62\n",
      "variational_beta * kldivergence:  0.15826\n",
      "batch accuracy: 84.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.45825\n",
      "kldivergence:   1521.79\n",
      "variational_beta * kldivergence:  0.15218\n",
      "batch accuracy: 86.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.41375\n",
      "kldivergence:   1550.74\n",
      "variational_beta * kldivergence:  0.15507\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.49884\n",
      "kldivergence:   1437.60\n",
      "variational_beta * kldivergence:  0.14376\n",
      "batch accuracy: 84.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.46706\n",
      "kldivergence:   1526.73\n",
      "variational_beta * kldivergence:  0.15267\n",
      "batch accuracy: 85.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.42732\n",
      "kldivergence:   1425.30\n",
      "variational_beta * kldivergence:  0.14253\n",
      "batch accuracy: 85.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.46400\n",
      "kldivergence:   1526.18\n",
      "variational_beta * kldivergence:  0.15262\n",
      "batch accuracy: 85.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.54821\n",
      "kldivergence:   1758.06\n",
      "variational_beta * kldivergence:  0.17581\n",
      "batch accuracy: 83.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.43671\n",
      "kldivergence:   1448.68\n",
      "variational_beta * kldivergence:  0.14487\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.42612\n",
      "kldivergence:   1525.56\n",
      "variational_beta * kldivergence:  0.15256\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.48653\n",
      "kldivergence:   1579.64\n",
      "variational_beta * kldivergence:  0.15796\n",
      "batch accuracy: 84.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.41057\n",
      "kldivergence:   1368.94\n",
      "variational_beta * kldivergence:  0.13689\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.44515\n",
      "kldivergence:   1591.91\n",
      "variational_beta * kldivergence:  0.15919\n",
      "batch accuracy: 86.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.55604\n",
      "kldivergence:   1671.11\n",
      "variational_beta * kldivergence:  0.16711\n",
      "batch accuracy: 83.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.47887\n",
      "kldivergence:   1657.36\n",
      "variational_beta * kldivergence:  0.16574\n",
      "batch accuracy: 84.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.52853\n",
      "kldivergence:   1604.14\n",
      "variational_beta * kldivergence:  0.16041\n",
      "batch accuracy: 83.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.54353\n",
      "kldivergence:   1760.47\n",
      "variational_beta * kldivergence:  0.17605\n",
      "batch accuracy: 84.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.47838\n",
      "kldivergence:   1545.74\n",
      "variational_beta * kldivergence:  0.15457\n",
      "batch accuracy: 85.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.44085\n",
      "kldivergence:   1489.75\n",
      "variational_beta * kldivergence:  0.14897\n",
      "batch accuracy: 86.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.50118\n",
      "kldivergence:   1615.79\n",
      "variational_beta * kldivergence:  0.16158\n",
      "batch accuracy: 84.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.49390\n",
      "kldivergence:   1599.17\n",
      "variational_beta * kldivergence:  0.15992\n",
      "batch accuracy: 85.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.47789\n",
      "kldivergence:   1512.64\n",
      "variational_beta * kldivergence:  0.15126\n",
      "batch accuracy: 85.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.48987\n",
      "kldivergence:   1581.98\n",
      "variational_beta * kldivergence:  0.15820\n",
      "batch accuracy: 84.71\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.51150\n",
      "kldivergence:   1494.55\n",
      "variational_beta * kldivergence:  0.14945\n",
      "batch accuracy: 84.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.43002\n",
      "kldivergence:   1443.77\n",
      "variational_beta * kldivergence:  0.14438\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.49689\n",
      "kldivergence:   1559.01\n",
      "variational_beta * kldivergence:  0.15590\n",
      "batch accuracy: 84.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.47041\n",
      "kldivergence:   1460.17\n",
      "variational_beta * kldivergence:  0.14602\n",
      "batch accuracy: 85.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.48958\n",
      "kldivergence:   1603.45\n",
      "variational_beta * kldivergence:  0.16035\n",
      "batch accuracy: 84.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.42672\n",
      "kldivergence:   1553.45\n",
      "variational_beta * kldivergence:  0.15535\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.43747\n",
      "kldivergence:   1453.96\n",
      "variational_beta * kldivergence:  0.14540\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.52220\n",
      "kldivergence:   1683.03\n",
      "variational_beta * kldivergence:  0.16830\n",
      "batch accuracy: 84.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.49177\n",
      "kldivergence:   1579.03\n",
      "variational_beta * kldivergence:  0.15790\n",
      "batch accuracy: 85.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.45991\n",
      "kldivergence:   1476.71\n",
      "variational_beta * kldivergence:  0.14767\n",
      "batch accuracy: 86.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.47237\n",
      "kldivergence:   1657.51\n",
      "variational_beta * kldivergence:  0.16575\n",
      "batch accuracy: 85.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.44560\n",
      "kldivergence:   1384.07\n",
      "variational_beta * kldivergence:  0.13841\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.46068\n",
      "kldivergence:   1598.65\n",
      "variational_beta * kldivergence:  0.15987\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.41126\n",
      "kldivergence:   1478.74\n",
      "variational_beta * kldivergence:  0.14787\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.39235\n",
      "kldivergence:   1357.29\n",
      "variational_beta * kldivergence:  0.13573\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.42581\n",
      "kldivergence:   1483.94\n",
      "variational_beta * kldivergence:  0.14839\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.45145\n",
      "kldivergence:   1573.63\n",
      "variational_beta * kldivergence:  0.15736\n",
      "batch accuracy: 86.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.41462\n",
      "kldivergence:   1557.27\n",
      "variational_beta * kldivergence:  0.15573\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.41503\n",
      "kldivergence:   1540.13\n",
      "variational_beta * kldivergence:  0.15401\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.47542\n",
      "kldivergence:   1526.94\n",
      "variational_beta * kldivergence:  0.15269\n",
      "batch accuracy: 85.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.40303\n",
      "kldivergence:   1427.74\n",
      "variational_beta * kldivergence:  0.14277\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.47324\n",
      "kldivergence:   1440.42\n",
      "variational_beta * kldivergence:  0.14404\n",
      "batch accuracy: 85.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.43236\n",
      "kldivergence:   1409.80\n",
      "variational_beta * kldivergence:  0.14098\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.37208\n",
      "kldivergence:   1444.26\n",
      "variational_beta * kldivergence:  0.14443\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.37712\n",
      "kldivergence:   1368.92\n",
      "variational_beta * kldivergence:  0.13689\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.42193\n",
      "kldivergence:   1565.10\n",
      "variational_beta * kldivergence:  0.15651\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.38468\n",
      "kldivergence:   1469.40\n",
      "variational_beta * kldivergence:  0.14694\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.52271\n",
      "kldivergence:   1626.43\n",
      "variational_beta * kldivergence:  0.16264\n",
      "batch accuracy: 83.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.40556\n",
      "kldivergence:   1409.98\n",
      "variational_beta * kldivergence:  0.14100\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.42975\n",
      "kldivergence:   1530.59\n",
      "variational_beta * kldivergence:  0.15306\n",
      "batch accuracy: 86.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.41880\n",
      "kldivergence:   1482.08\n",
      "variational_beta * kldivergence:  0.14821\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #24\n",
      "reconstruction loss: 0.47733\n",
      "kldivergence:   1538.09\n",
      "variational_beta * kldivergence:  0.15381\n",
      "batch accuracy: 85.87\n",
      "\n",
      "\n",
      "epoch # 24 : train loss is [185.3827836470787] and validation loss is [0.1022726882333771] \n",
      "saved samples\n",
      "Epoch [25 / 150] average reconstruction error: 0.499684\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.37171\n",
      "kldivergence:   1898.13\n",
      "variational_beta * kldivergence:  0.18981\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35278\n",
      "kldivergence:   1600.19\n",
      "variational_beta * kldivergence:  0.16002\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.36076\n",
      "kldivergence:   1741.25\n",
      "variational_beta * kldivergence:  0.17413\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33661\n",
      "kldivergence:   1523.11\n",
      "variational_beta * kldivergence:  0.15231\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34169\n",
      "kldivergence:   1858.72\n",
      "variational_beta * kldivergence:  0.18587\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.38288\n",
      "kldivergence:   1853.59\n",
      "variational_beta * kldivergence:  0.18536\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35097\n",
      "kldivergence:   1564.41\n",
      "variational_beta * kldivergence:  0.15644\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34539\n",
      "kldivergence:   1532.14\n",
      "variational_beta * kldivergence:  0.15321\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32113\n",
      "kldivergence:   1508.64\n",
      "variational_beta * kldivergence:  0.15086\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33465\n",
      "kldivergence:   1616.76\n",
      "variational_beta * kldivergence:  0.16168\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.39226\n",
      "kldivergence:   1732.79\n",
      "variational_beta * kldivergence:  0.17328\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.30874\n",
      "kldivergence:   1521.70\n",
      "variational_beta * kldivergence:  0.15217\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.29928\n",
      "kldivergence:   1513.93\n",
      "variational_beta * kldivergence:  0.15139\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.37737\n",
      "kldivergence:   1785.92\n",
      "variational_beta * kldivergence:  0.17859\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33571\n",
      "kldivergence:   1398.03\n",
      "variational_beta * kldivergence:  0.13980\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33607\n",
      "kldivergence:   1486.84\n",
      "variational_beta * kldivergence:  0.14868\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.39034\n",
      "kldivergence:   1502.81\n",
      "variational_beta * kldivergence:  0.15028\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32289\n",
      "kldivergence:   1556.26\n",
      "variational_beta * kldivergence:  0.15563\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31676\n",
      "kldivergence:   1523.35\n",
      "variational_beta * kldivergence:  0.15233\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32202\n",
      "kldivergence:   1519.41\n",
      "variational_beta * kldivergence:  0.15194\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.36672\n",
      "kldivergence:   1831.56\n",
      "variational_beta * kldivergence:  0.18316\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35559\n",
      "kldivergence:   1530.06\n",
      "variational_beta * kldivergence:  0.15301\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31692\n",
      "kldivergence:   1544.29\n",
      "variational_beta * kldivergence:  0.15443\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32557\n",
      "kldivergence:   1700.82\n",
      "variational_beta * kldivergence:  0.17008\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33943\n",
      "kldivergence:   1648.05\n",
      "variational_beta * kldivergence:  0.16481\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.30615\n",
      "kldivergence:   1487.84\n",
      "variational_beta * kldivergence:  0.14878\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35738\n",
      "kldivergence:   1749.66\n",
      "variational_beta * kldivergence:  0.17497\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.39666\n",
      "kldivergence:   1765.09\n",
      "variational_beta * kldivergence:  0.17651\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35161\n",
      "kldivergence:   1828.99\n",
      "variational_beta * kldivergence:  0.18290\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34518\n",
      "kldivergence:   1669.86\n",
      "variational_beta * kldivergence:  0.16699\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35542\n",
      "kldivergence:   1704.63\n",
      "variational_beta * kldivergence:  0.17046\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.27155\n",
      "kldivergence:   1543.82\n",
      "variational_beta * kldivergence:  0.15438\n",
      "batch accuracy: 90.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.27580\n",
      "kldivergence:   1565.15\n",
      "variational_beta * kldivergence:  0.15652\n",
      "batch accuracy: 91.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.39178\n",
      "kldivergence:   1786.14\n",
      "variational_beta * kldivergence:  0.17861\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32456\n",
      "kldivergence:   1569.64\n",
      "variational_beta * kldivergence:  0.15696\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34494\n",
      "kldivergence:   1669.27\n",
      "variational_beta * kldivergence:  0.16693\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.36844\n",
      "kldivergence:   1693.48\n",
      "variational_beta * kldivergence:  0.16935\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31007\n",
      "kldivergence:   1523.03\n",
      "variational_beta * kldivergence:  0.15230\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32089\n",
      "kldivergence:   1683.60\n",
      "variational_beta * kldivergence:  0.16836\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33457\n",
      "kldivergence:   1855.91\n",
      "variational_beta * kldivergence:  0.18559\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.36568\n",
      "kldivergence:   1722.95\n",
      "variational_beta * kldivergence:  0.17230\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32201\n",
      "kldivergence:   1598.30\n",
      "variational_beta * kldivergence:  0.15983\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33659\n",
      "kldivergence:   1835.13\n",
      "variational_beta * kldivergence:  0.18351\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33784\n",
      "kldivergence:   1594.99\n",
      "variational_beta * kldivergence:  0.15950\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31760\n",
      "kldivergence:   1506.54\n",
      "variational_beta * kldivergence:  0.15065\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35539\n",
      "kldivergence:   1553.07\n",
      "variational_beta * kldivergence:  0.15531\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33337\n",
      "kldivergence:   1498.38\n",
      "variational_beta * kldivergence:  0.14984\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32784\n",
      "kldivergence:   1834.17\n",
      "variational_beta * kldivergence:  0.18342\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.41138\n",
      "kldivergence:   1634.48\n",
      "variational_beta * kldivergence:  0.16345\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31089\n",
      "kldivergence:   1703.01\n",
      "variational_beta * kldivergence:  0.17030\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35559\n",
      "kldivergence:   1655.71\n",
      "variational_beta * kldivergence:  0.16557\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31181\n",
      "kldivergence:   1590.73\n",
      "variational_beta * kldivergence:  0.15907\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34289\n",
      "kldivergence:   1721.48\n",
      "variational_beta * kldivergence:  0.17215\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.29909\n",
      "kldivergence:   1527.48\n",
      "variational_beta * kldivergence:  0.15275\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.29958\n",
      "kldivergence:   1603.46\n",
      "variational_beta * kldivergence:  0.16035\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32556\n",
      "kldivergence:   1468.82\n",
      "variational_beta * kldivergence:  0.14688\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.37684\n",
      "kldivergence:   1809.38\n",
      "variational_beta * kldivergence:  0.18094\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.36732\n",
      "kldivergence:   1664.34\n",
      "variational_beta * kldivergence:  0.16643\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34421\n",
      "kldivergence:   1838.36\n",
      "variational_beta * kldivergence:  0.18384\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31873\n",
      "kldivergence:   1579.37\n",
      "variational_beta * kldivergence:  0.15794\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34474\n",
      "kldivergence:   1625.81\n",
      "variational_beta * kldivergence:  0.16258\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.37513\n",
      "kldivergence:   1726.61\n",
      "variational_beta * kldivergence:  0.17266\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33860\n",
      "kldivergence:   1684.17\n",
      "variational_beta * kldivergence:  0.16842\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.37723\n",
      "kldivergence:   1936.40\n",
      "variational_beta * kldivergence:  0.19364\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.38240\n",
      "kldivergence:   1716.00\n",
      "variational_beta * kldivergence:  0.17160\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.37395\n",
      "kldivergence:   1578.10\n",
      "variational_beta * kldivergence:  0.15781\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33571\n",
      "kldivergence:   1470.15\n",
      "variational_beta * kldivergence:  0.14702\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.30729\n",
      "kldivergence:   1533.67\n",
      "variational_beta * kldivergence:  0.15337\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.30724\n",
      "kldivergence:   1652.86\n",
      "variational_beta * kldivergence:  0.16529\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.27785\n",
      "kldivergence:   1726.30\n",
      "variational_beta * kldivergence:  0.17263\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34992\n",
      "kldivergence:   1633.50\n",
      "variational_beta * kldivergence:  0.16335\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.37638\n",
      "kldivergence:   1756.89\n",
      "variational_beta * kldivergence:  0.17569\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.30137\n",
      "kldivergence:   1644.69\n",
      "variational_beta * kldivergence:  0.16447\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31544\n",
      "kldivergence:   1977.12\n",
      "variational_beta * kldivergence:  0.19771\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.38419\n",
      "kldivergence:   1744.19\n",
      "variational_beta * kldivergence:  0.17442\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31604\n",
      "kldivergence:   1590.23\n",
      "variational_beta * kldivergence:  0.15902\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34682\n",
      "kldivergence:   1769.74\n",
      "variational_beta * kldivergence:  0.17697\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33832\n",
      "kldivergence:   1636.85\n",
      "variational_beta * kldivergence:  0.16368\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.29354\n",
      "kldivergence:   1674.20\n",
      "variational_beta * kldivergence:  0.16742\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31494\n",
      "kldivergence:   1653.99\n",
      "variational_beta * kldivergence:  0.16540\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.26768\n",
      "kldivergence:   1547.81\n",
      "variational_beta * kldivergence:  0.15478\n",
      "batch accuracy: 91.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34757\n",
      "kldivergence:   1940.03\n",
      "variational_beta * kldivergence:  0.19400\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33768\n",
      "kldivergence:   1706.40\n",
      "variational_beta * kldivergence:  0.17064\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31824\n",
      "kldivergence:   1529.62\n",
      "variational_beta * kldivergence:  0.15296\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32573\n",
      "kldivergence:   1665.60\n",
      "variational_beta * kldivergence:  0.16656\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35586\n",
      "kldivergence:   1736.79\n",
      "variational_beta * kldivergence:  0.17368\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34404\n",
      "kldivergence:   1650.93\n",
      "variational_beta * kldivergence:  0.16509\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31272\n",
      "kldivergence:   1674.41\n",
      "variational_beta * kldivergence:  0.16744\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35211\n",
      "kldivergence:   1720.10\n",
      "variational_beta * kldivergence:  0.17201\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.36054\n",
      "kldivergence:   1643.12\n",
      "variational_beta * kldivergence:  0.16431\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34740\n",
      "kldivergence:   1577.68\n",
      "variational_beta * kldivergence:  0.15777\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.30764\n",
      "kldivergence:   1687.42\n",
      "variational_beta * kldivergence:  0.16874\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.38338\n",
      "kldivergence:   1553.35\n",
      "variational_beta * kldivergence:  0.15533\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.29991\n",
      "kldivergence:   1704.47\n",
      "variational_beta * kldivergence:  0.17045\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32296\n",
      "kldivergence:   1689.70\n",
      "variational_beta * kldivergence:  0.16897\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.40958\n",
      "kldivergence:   1783.17\n",
      "variational_beta * kldivergence:  0.17832\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34750\n",
      "kldivergence:   1801.21\n",
      "variational_beta * kldivergence:  0.18012\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33751\n",
      "kldivergence:   1502.52\n",
      "variational_beta * kldivergence:  0.15025\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34654\n",
      "kldivergence:   1614.11\n",
      "variational_beta * kldivergence:  0.16141\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33576\n",
      "kldivergence:   1510.10\n",
      "variational_beta * kldivergence:  0.15101\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.30670\n",
      "kldivergence:   1739.63\n",
      "variational_beta * kldivergence:  0.17396\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33560\n",
      "kldivergence:   1594.57\n",
      "variational_beta * kldivergence:  0.15946\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.40719\n",
      "kldivergence:   1615.97\n",
      "variational_beta * kldivergence:  0.16160\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.36647\n",
      "kldivergence:   1643.29\n",
      "variational_beta * kldivergence:  0.16433\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34048\n",
      "kldivergence:   1712.57\n",
      "variational_beta * kldivergence:  0.17126\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.29517\n",
      "kldivergence:   1470.49\n",
      "variational_beta * kldivergence:  0.14705\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32908\n",
      "kldivergence:   1510.75\n",
      "variational_beta * kldivergence:  0.15108\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.39406\n",
      "kldivergence:   1743.11\n",
      "variational_beta * kldivergence:  0.17431\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33772\n",
      "kldivergence:   1480.65\n",
      "variational_beta * kldivergence:  0.14806\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33683\n",
      "kldivergence:   1621.11\n",
      "variational_beta * kldivergence:  0.16211\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.36087\n",
      "kldivergence:   1617.03\n",
      "variational_beta * kldivergence:  0.16170\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35310\n",
      "kldivergence:   1566.93\n",
      "variational_beta * kldivergence:  0.15669\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.36866\n",
      "kldivergence:   1558.51\n",
      "variational_beta * kldivergence:  0.15585\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32939\n",
      "kldivergence:   1575.51\n",
      "variational_beta * kldivergence:  0.15755\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.30681\n",
      "kldivergence:   1425.82\n",
      "variational_beta * kldivergence:  0.14258\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.39548\n",
      "kldivergence:   1853.60\n",
      "variational_beta * kldivergence:  0.18536\n",
      "batch accuracy: 86.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.29566\n",
      "kldivergence:   1475.78\n",
      "variational_beta * kldivergence:  0.14758\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34963\n",
      "kldivergence:   1556.04\n",
      "variational_beta * kldivergence:  0.15560\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32600\n",
      "kldivergence:   1488.54\n",
      "variational_beta * kldivergence:  0.14885\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.36472\n",
      "kldivergence:   1597.15\n",
      "variational_beta * kldivergence:  0.15972\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.39336\n",
      "kldivergence:   1710.46\n",
      "variational_beta * kldivergence:  0.17105\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33008\n",
      "kldivergence:   1658.54\n",
      "variational_beta * kldivergence:  0.16585\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33972\n",
      "kldivergence:   1637.94\n",
      "variational_beta * kldivergence:  0.16379\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33198\n",
      "kldivergence:   1450.66\n",
      "variational_beta * kldivergence:  0.14507\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.31120\n",
      "kldivergence:   1560.92\n",
      "variational_beta * kldivergence:  0.15609\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34636\n",
      "kldivergence:   1695.93\n",
      "variational_beta * kldivergence:  0.16959\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.37323\n",
      "kldivergence:   1754.80\n",
      "variational_beta * kldivergence:  0.17548\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.29209\n",
      "kldivergence:   1509.13\n",
      "variational_beta * kldivergence:  0.15091\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.30855\n",
      "kldivergence:   1577.81\n",
      "variational_beta * kldivergence:  0.15778\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.37370\n",
      "kldivergence:   1696.48\n",
      "variational_beta * kldivergence:  0.16965\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34447\n",
      "kldivergence:   1650.63\n",
      "variational_beta * kldivergence:  0.16506\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.37429\n",
      "kldivergence:   1662.97\n",
      "variational_beta * kldivergence:  0.16630\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.28275\n",
      "kldivergence:   1596.25\n",
      "variational_beta * kldivergence:  0.15963\n",
      "batch accuracy: 90.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.40815\n",
      "kldivergence:   1934.55\n",
      "variational_beta * kldivergence:  0.19345\n",
      "batch accuracy: 86.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33335\n",
      "kldivergence:   1701.20\n",
      "variational_beta * kldivergence:  0.17012\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.27934\n",
      "kldivergence:   1428.00\n",
      "variational_beta * kldivergence:  0.14280\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33947\n",
      "kldivergence:   1579.10\n",
      "variational_beta * kldivergence:  0.15791\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32027\n",
      "kldivergence:   1551.45\n",
      "variational_beta * kldivergence:  0.15515\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.28489\n",
      "kldivergence:   1623.06\n",
      "variational_beta * kldivergence:  0.16231\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.34089\n",
      "kldivergence:   1613.78\n",
      "variational_beta * kldivergence:  0.16138\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.35815\n",
      "kldivergence:   1535.90\n",
      "variational_beta * kldivergence:  0.15359\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.32330\n",
      "kldivergence:   1618.92\n",
      "variational_beta * kldivergence:  0.16189\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #25\n",
      "reconstruction loss: 0.33870\n",
      "kldivergence:   1783.02\n",
      "variational_beta * kldivergence:  0.17830\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.31531\n",
      "kldivergence:   1502.45\n",
      "variational_beta * kldivergence:  0.15025\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.34614\n",
      "kldivergence:   1498.34\n",
      "variational_beta * kldivergence:  0.14983\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.31917\n",
      "kldivergence:   1501.50\n",
      "variational_beta * kldivergence:  0.15015\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.34342\n",
      "kldivergence:   1433.93\n",
      "variational_beta * kldivergence:  0.14339\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.34768\n",
      "kldivergence:   1484.38\n",
      "variational_beta * kldivergence:  0.14844\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.34611\n",
      "kldivergence:   1294.90\n",
      "variational_beta * kldivergence:  0.12949\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.31855\n",
      "kldivergence:   1803.78\n",
      "variational_beta * kldivergence:  0.18038\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.30624\n",
      "kldivergence:   1562.92\n",
      "variational_beta * kldivergence:  0.15629\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.27880\n",
      "kldivergence:   1329.07\n",
      "variational_beta * kldivergence:  0.13291\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.36681\n",
      "kldivergence:   1637.76\n",
      "variational_beta * kldivergence:  0.16378\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.32740\n",
      "kldivergence:   1561.84\n",
      "variational_beta * kldivergence:  0.15618\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.28609\n",
      "kldivergence:   1665.28\n",
      "variational_beta * kldivergence:  0.16653\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.30163\n",
      "kldivergence:   1469.20\n",
      "variational_beta * kldivergence:  0.14692\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.29110\n",
      "kldivergence:   1369.76\n",
      "variational_beta * kldivergence:  0.13698\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.32237\n",
      "kldivergence:   1548.67\n",
      "variational_beta * kldivergence:  0.15487\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.32606\n",
      "kldivergence:   1551.19\n",
      "variational_beta * kldivergence:  0.15512\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.35752\n",
      "kldivergence:   1535.08\n",
      "variational_beta * kldivergence:  0.15351\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.30970\n",
      "kldivergence:   1710.07\n",
      "variational_beta * kldivergence:  0.17101\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.31461\n",
      "kldivergence:   1812.23\n",
      "variational_beta * kldivergence:  0.18122\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.33130\n",
      "kldivergence:   1443.88\n",
      "variational_beta * kldivergence:  0.14439\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.33749\n",
      "kldivergence:   1813.26\n",
      "variational_beta * kldivergence:  0.18133\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.36582\n",
      "kldivergence:   1590.46\n",
      "variational_beta * kldivergence:  0.15905\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.39785\n",
      "kldivergence:   1532.40\n",
      "variational_beta * kldivergence:  0.15324\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.30970\n",
      "kldivergence:   1326.60\n",
      "variational_beta * kldivergence:  0.13266\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.36154\n",
      "kldivergence:   1497.54\n",
      "variational_beta * kldivergence:  0.14975\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.38518\n",
      "kldivergence:   1757.60\n",
      "variational_beta * kldivergence:  0.17576\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.38606\n",
      "kldivergence:   1507.13\n",
      "variational_beta * kldivergence:  0.15071\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.36099\n",
      "kldivergence:   1638.75\n",
      "variational_beta * kldivergence:  0.16388\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.38866\n",
      "kldivergence:   1806.52\n",
      "variational_beta * kldivergence:  0.18065\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.35758\n",
      "kldivergence:   1793.41\n",
      "variational_beta * kldivergence:  0.17934\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.32499\n",
      "kldivergence:   1472.07\n",
      "variational_beta * kldivergence:  0.14721\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.33552\n",
      "kldivergence:   1458.53\n",
      "variational_beta * kldivergence:  0.14585\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.32575\n",
      "kldivergence:   1553.09\n",
      "variational_beta * kldivergence:  0.15531\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.37794\n",
      "kldivergence:   1687.75\n",
      "variational_beta * kldivergence:  0.16877\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.34242\n",
      "kldivergence:   1406.26\n",
      "variational_beta * kldivergence:  0.14063\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.35777\n",
      "kldivergence:   1454.98\n",
      "variational_beta * kldivergence:  0.14550\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.32015\n",
      "kldivergence:   1423.15\n",
      "variational_beta * kldivergence:  0.14231\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.29663\n",
      "kldivergence:   1343.97\n",
      "variational_beta * kldivergence:  0.13440\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.32077\n",
      "kldivergence:   1512.98\n",
      "variational_beta * kldivergence:  0.15130\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #33\n",
      "reconstruction loss: 0.35749\n",
      "kldivergence:   1570.76\n",
      "variational_beta * kldivergence:  0.15708\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.43478\n",
      "kldivergence:   1493.74\n",
      "variational_beta * kldivergence:  0.14937\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.40372\n",
      "kldivergence:   1366.33\n",
      "variational_beta * kldivergence:  0.13663\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.36937\n",
      "kldivergence:   1406.61\n",
      "variational_beta * kldivergence:  0.14066\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.53890\n",
      "kldivergence:   1504.71\n",
      "variational_beta * kldivergence:  0.15047\n",
      "batch accuracy: 84.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.39101\n",
      "kldivergence:   1326.02\n",
      "variational_beta * kldivergence:  0.13260\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.39904\n",
      "kldivergence:   1305.23\n",
      "variational_beta * kldivergence:  0.13052\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.45177\n",
      "kldivergence:   1451.23\n",
      "variational_beta * kldivergence:  0.14512\n",
      "batch accuracy: 85.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.50128\n",
      "kldivergence:   1362.00\n",
      "variational_beta * kldivergence:  0.13620\n",
      "batch accuracy: 85.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.47738\n",
      "kldivergence:   1520.99\n",
      "variational_beta * kldivergence:  0.15210\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.35487\n",
      "kldivergence:   1378.54\n",
      "variational_beta * kldivergence:  0.13785\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.42249\n",
      "kldivergence:   1401.93\n",
      "variational_beta * kldivergence:  0.14019\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.47181\n",
      "kldivergence:   1423.21\n",
      "variational_beta * kldivergence:  0.14232\n",
      "batch accuracy: 85.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.44343\n",
      "kldivergence:   1401.20\n",
      "variational_beta * kldivergence:  0.14012\n",
      "batch accuracy: 86.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.48970\n",
      "kldivergence:   1480.19\n",
      "variational_beta * kldivergence:  0.14802\n",
      "batch accuracy: 84.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.52059\n",
      "kldivergence:   1475.60\n",
      "variational_beta * kldivergence:  0.14756\n",
      "batch accuracy: 85.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.44611\n",
      "kldivergence:   1470.71\n",
      "variational_beta * kldivergence:  0.14707\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.50968\n",
      "kldivergence:   1535.48\n",
      "variational_beta * kldivergence:  0.15355\n",
      "batch accuracy: 85.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.36038\n",
      "kldivergence:   1401.45\n",
      "variational_beta * kldivergence:  0.14014\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.49199\n",
      "kldivergence:   1472.47\n",
      "variational_beta * kldivergence:  0.14725\n",
      "batch accuracy: 85.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.45696\n",
      "kldivergence:   1521.80\n",
      "variational_beta * kldivergence:  0.15218\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.48316\n",
      "kldivergence:   1569.63\n",
      "variational_beta * kldivergence:  0.15696\n",
      "batch accuracy: 85.38\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.37206\n",
      "kldivergence:   1474.96\n",
      "variational_beta * kldivergence:  0.14750\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.46161\n",
      "kldivergence:   1429.18\n",
      "variational_beta * kldivergence:  0.14292\n",
      "batch accuracy: 86.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.53628\n",
      "kldivergence:   1548.75\n",
      "variational_beta * kldivergence:  0.15488\n",
      "batch accuracy: 83.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.47307\n",
      "kldivergence:   1479.79\n",
      "variational_beta * kldivergence:  0.14798\n",
      "batch accuracy: 85.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.39863\n",
      "kldivergence:   1450.70\n",
      "variational_beta * kldivergence:  0.14507\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.44859\n",
      "kldivergence:   1404.38\n",
      "variational_beta * kldivergence:  0.14044\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.43574\n",
      "kldivergence:   1370.51\n",
      "variational_beta * kldivergence:  0.13705\n",
      "batch accuracy: 86.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.41665\n",
      "kldivergence:   1435.85\n",
      "variational_beta * kldivergence:  0.14358\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.53426\n",
      "kldivergence:   1563.48\n",
      "variational_beta * kldivergence:  0.15635\n",
      "batch accuracy: 83.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.49391\n",
      "kldivergence:   1558.02\n",
      "variational_beta * kldivergence:  0.15580\n",
      "batch accuracy: 84.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.43219\n",
      "kldivergence:   1454.34\n",
      "variational_beta * kldivergence:  0.14543\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.58735\n",
      "kldivergence:   1585.93\n",
      "variational_beta * kldivergence:  0.15859\n",
      "batch accuracy: 82.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.42501\n",
      "kldivergence:   1533.66\n",
      "variational_beta * kldivergence:  0.15337\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.43826\n",
      "kldivergence:   1456.73\n",
      "variational_beta * kldivergence:  0.14567\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.50331\n",
      "kldivergence:   1396.05\n",
      "variational_beta * kldivergence:  0.13960\n",
      "batch accuracy: 85.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.48407\n",
      "kldivergence:   1454.31\n",
      "variational_beta * kldivergence:  0.14543\n",
      "batch accuracy: 85.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.40027\n",
      "kldivergence:   1385.37\n",
      "variational_beta * kldivergence:  0.13854\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.41380\n",
      "kldivergence:   1394.25\n",
      "variational_beta * kldivergence:  0.13943\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.49594\n",
      "kldivergence:   1536.26\n",
      "variational_beta * kldivergence:  0.15363\n",
      "batch accuracy: 84.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.41447\n",
      "kldivergence:   1507.81\n",
      "variational_beta * kldivergence:  0.15078\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.51232\n",
      "kldivergence:   1413.21\n",
      "variational_beta * kldivergence:  0.14132\n",
      "batch accuracy: 85.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.43280\n",
      "kldivergence:   1391.89\n",
      "variational_beta * kldivergence:  0.13919\n",
      "batch accuracy: 86.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.44418\n",
      "kldivergence:   1463.95\n",
      "variational_beta * kldivergence:  0.14640\n",
      "batch accuracy: 85.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.56242\n",
      "kldivergence:   1498.70\n",
      "variational_beta * kldivergence:  0.14987\n",
      "batch accuracy: 84.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.50271\n",
      "kldivergence:   1435.00\n",
      "variational_beta * kldivergence:  0.14350\n",
      "batch accuracy: 85.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.36350\n",
      "kldivergence:   1291.81\n",
      "variational_beta * kldivergence:  0.12918\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.47898\n",
      "kldivergence:   1534.20\n",
      "variational_beta * kldivergence:  0.15342\n",
      "batch accuracy: 85.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.41931\n",
      "kldivergence:   1450.87\n",
      "variational_beta * kldivergence:  0.14509\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.42073\n",
      "kldivergence:   1312.57\n",
      "variational_beta * kldivergence:  0.13126\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.43932\n",
      "kldivergence:   1402.43\n",
      "variational_beta * kldivergence:  0.14024\n",
      "batch accuracy: 85.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.46542\n",
      "kldivergence:   1480.06\n",
      "variational_beta * kldivergence:  0.14801\n",
      "batch accuracy: 85.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.52508\n",
      "kldivergence:   1522.25\n",
      "variational_beta * kldivergence:  0.15222\n",
      "batch accuracy: 84.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.51479\n",
      "kldivergence:   1521.19\n",
      "variational_beta * kldivergence:  0.15212\n",
      "batch accuracy: 84.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.46408\n",
      "kldivergence:   1445.65\n",
      "variational_beta * kldivergence:  0.14457\n",
      "batch accuracy: 85.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.47162\n",
      "kldivergence:   1454.57\n",
      "variational_beta * kldivergence:  0.14546\n",
      "batch accuracy: 85.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.50380\n",
      "kldivergence:   1429.97\n",
      "variational_beta * kldivergence:  0.14300\n",
      "batch accuracy: 84.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.46025\n",
      "kldivergence:   1516.65\n",
      "variational_beta * kldivergence:  0.15166\n",
      "batch accuracy: 85.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.38431\n",
      "kldivergence:   1451.73\n",
      "variational_beta * kldivergence:  0.14517\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.42603\n",
      "kldivergence:   1408.84\n",
      "variational_beta * kldivergence:  0.14088\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.41102\n",
      "kldivergence:   1508.94\n",
      "variational_beta * kldivergence:  0.15089\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #33\n",
      "reconstruction loss: 0.55873\n",
      "kldivergence:   1659.97\n",
      "variational_beta * kldivergence:  0.16600\n",
      "batch accuracy: 83.33\n",
      "\n",
      "\n",
      "epoch # 33 : train loss is [181.82271544533944] and validation loss is [0.10101146382401957] \n",
      "saved samples\n",
      "Epoch [34 / 150] average reconstruction error: 0.490088\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35455\n",
      "kldivergence:   1635.32\n",
      "variational_beta * kldivergence:  0.16353\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29906\n",
      "kldivergence:   1594.77\n",
      "variational_beta * kldivergence:  0.15948\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31917\n",
      "kldivergence:   1971.92\n",
      "variational_beta * kldivergence:  0.19719\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30861\n",
      "kldivergence:   1471.56\n",
      "variational_beta * kldivergence:  0.14716\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35806\n",
      "kldivergence:   1514.31\n",
      "variational_beta * kldivergence:  0.15143\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33175\n",
      "kldivergence:   1647.62\n",
      "variational_beta * kldivergence:  0.16476\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35586\n",
      "kldivergence:   1570.30\n",
      "variational_beta * kldivergence:  0.15703\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.39738\n",
      "kldivergence:   1867.01\n",
      "variational_beta * kldivergence:  0.18670\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.26318\n",
      "kldivergence:   1339.67\n",
      "variational_beta * kldivergence:  0.13397\n",
      "batch accuracy: 91.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29901\n",
      "kldivergence:   1777.29\n",
      "variational_beta * kldivergence:  0.17773\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34406\n",
      "kldivergence:   1592.06\n",
      "variational_beta * kldivergence:  0.15921\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34797\n",
      "kldivergence:   1406.68\n",
      "variational_beta * kldivergence:  0.14067\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36937\n",
      "kldivergence:   2177.98\n",
      "variational_beta * kldivergence:  0.21780\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30128\n",
      "kldivergence:   1367.13\n",
      "variational_beta * kldivergence:  0.13671\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37705\n",
      "kldivergence:   1619.65\n",
      "variational_beta * kldivergence:  0.16197\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31599\n",
      "kldivergence:   1523.29\n",
      "variational_beta * kldivergence:  0.15233\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.39026\n",
      "kldivergence:   1732.99\n",
      "variational_beta * kldivergence:  0.17330\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32897\n",
      "kldivergence:   1670.65\n",
      "variational_beta * kldivergence:  0.16706\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31444\n",
      "kldivergence:   1664.60\n",
      "variational_beta * kldivergence:  0.16646\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29890\n",
      "kldivergence:   1388.95\n",
      "variational_beta * kldivergence:  0.13890\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34407\n",
      "kldivergence:   1629.47\n",
      "variational_beta * kldivergence:  0.16295\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34594\n",
      "kldivergence:   1585.68\n",
      "variational_beta * kldivergence:  0.15857\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34067\n",
      "kldivergence:   1572.75\n",
      "variational_beta * kldivergence:  0.15727\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32541\n",
      "kldivergence:   1576.65\n",
      "variational_beta * kldivergence:  0.15766\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32870\n",
      "kldivergence:   1520.89\n",
      "variational_beta * kldivergence:  0.15209\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31984\n",
      "kldivergence:   1540.98\n",
      "variational_beta * kldivergence:  0.15410\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34048\n",
      "kldivergence:   1510.55\n",
      "variational_beta * kldivergence:  0.15105\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35058\n",
      "kldivergence:   1678.25\n",
      "variational_beta * kldivergence:  0.16783\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37403\n",
      "kldivergence:   1722.21\n",
      "variational_beta * kldivergence:  0.17222\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33387\n",
      "kldivergence:   1415.93\n",
      "variational_beta * kldivergence:  0.14159\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35151\n",
      "kldivergence:   1488.16\n",
      "variational_beta * kldivergence:  0.14882\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.38469\n",
      "kldivergence:   1684.35\n",
      "variational_beta * kldivergence:  0.16844\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36102\n",
      "kldivergence:   1801.14\n",
      "variational_beta * kldivergence:  0.18011\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33226\n",
      "kldivergence:   1467.55\n",
      "variational_beta * kldivergence:  0.14676\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31896\n",
      "kldivergence:   1639.15\n",
      "variational_beta * kldivergence:  0.16391\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29090\n",
      "kldivergence:   1508.23\n",
      "variational_beta * kldivergence:  0.15082\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34206\n",
      "kldivergence:   1740.13\n",
      "variational_beta * kldivergence:  0.17401\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36124\n",
      "kldivergence:   1679.11\n",
      "variational_beta * kldivergence:  0.16791\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31763\n",
      "kldivergence:   1538.97\n",
      "variational_beta * kldivergence:  0.15390\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28874\n",
      "kldivergence:   1571.78\n",
      "variational_beta * kldivergence:  0.15718\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.40253\n",
      "kldivergence:   1759.63\n",
      "variational_beta * kldivergence:  0.17596\n",
      "batch accuracy: 86.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36694\n",
      "kldivergence:   1487.84\n",
      "variational_beta * kldivergence:  0.14878\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33097\n",
      "kldivergence:   1778.78\n",
      "variational_beta * kldivergence:  0.17788\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29217\n",
      "kldivergence:   1567.90\n",
      "variational_beta * kldivergence:  0.15679\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.38817\n",
      "kldivergence:   2237.65\n",
      "variational_beta * kldivergence:  0.22377\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35870\n",
      "kldivergence:   1680.77\n",
      "variational_beta * kldivergence:  0.16808\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33301\n",
      "kldivergence:   1412.10\n",
      "variational_beta * kldivergence:  0.14121\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30470\n",
      "kldivergence:   1473.38\n",
      "variational_beta * kldivergence:  0.14734\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29762\n",
      "kldivergence:   1515.37\n",
      "variational_beta * kldivergence:  0.15154\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30896\n",
      "kldivergence:   1742.05\n",
      "variational_beta * kldivergence:  0.17421\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32459\n",
      "kldivergence:   1454.30\n",
      "variational_beta * kldivergence:  0.14543\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33342\n",
      "kldivergence:   1678.03\n",
      "variational_beta * kldivergence:  0.16780\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32718\n",
      "kldivergence:   1439.57\n",
      "variational_beta * kldivergence:  0.14396\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35311\n",
      "kldivergence:   1476.94\n",
      "variational_beta * kldivergence:  0.14769\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35586\n",
      "kldivergence:   1485.99\n",
      "variational_beta * kldivergence:  0.14860\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32406\n",
      "kldivergence:   1568.44\n",
      "variational_beta * kldivergence:  0.15684\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35880\n",
      "kldivergence:   1468.67\n",
      "variational_beta * kldivergence:  0.14687\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35359\n",
      "kldivergence:   1503.13\n",
      "variational_beta * kldivergence:  0.15031\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35482\n",
      "kldivergence:   1687.01\n",
      "variational_beta * kldivergence:  0.16870\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32801\n",
      "kldivergence:   1429.62\n",
      "variational_beta * kldivergence:  0.14296\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37930\n",
      "kldivergence:   1557.14\n",
      "variational_beta * kldivergence:  0.15571\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34443\n",
      "kldivergence:   1577.74\n",
      "variational_beta * kldivergence:  0.15777\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35729\n",
      "kldivergence:   1589.51\n",
      "variational_beta * kldivergence:  0.15895\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.26523\n",
      "kldivergence:   1397.07\n",
      "variational_beta * kldivergence:  0.13971\n",
      "batch accuracy: 91.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33441\n",
      "kldivergence:   1571.67\n",
      "variational_beta * kldivergence:  0.15717\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33593\n",
      "kldivergence:   1523.54\n",
      "variational_beta * kldivergence:  0.15235\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31296\n",
      "kldivergence:   1430.08\n",
      "variational_beta * kldivergence:  0.14301\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30299\n",
      "kldivergence:   1474.37\n",
      "variational_beta * kldivergence:  0.14744\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33740\n",
      "kldivergence:   1573.10\n",
      "variational_beta * kldivergence:  0.15731\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34640\n",
      "kldivergence:   1558.79\n",
      "variational_beta * kldivergence:  0.15588\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36455\n",
      "kldivergence:   1544.43\n",
      "variational_beta * kldivergence:  0.15444\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30854\n",
      "kldivergence:   1487.11\n",
      "variational_beta * kldivergence:  0.14871\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34135\n",
      "kldivergence:   1421.32\n",
      "variational_beta * kldivergence:  0.14213\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37836\n",
      "kldivergence:   1719.37\n",
      "variational_beta * kldivergence:  0.17194\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34770\n",
      "kldivergence:   1796.35\n",
      "variational_beta * kldivergence:  0.17963\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28345\n",
      "kldivergence:   1380.59\n",
      "variational_beta * kldivergence:  0.13806\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.38468\n",
      "kldivergence:   1684.49\n",
      "variational_beta * kldivergence:  0.16845\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37077\n",
      "kldivergence:   1750.63\n",
      "variational_beta * kldivergence:  0.17506\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30232\n",
      "kldivergence:   1695.85\n",
      "variational_beta * kldivergence:  0.16958\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35666\n",
      "kldivergence:   1476.42\n",
      "variational_beta * kldivergence:  0.14764\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27628\n",
      "kldivergence:   1310.83\n",
      "variational_beta * kldivergence:  0.13108\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32782\n",
      "kldivergence:   1534.39\n",
      "variational_beta * kldivergence:  0.15344\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36709\n",
      "kldivergence:   1795.97\n",
      "variational_beta * kldivergence:  0.17960\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35239\n",
      "kldivergence:   1708.00\n",
      "variational_beta * kldivergence:  0.17080\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32818\n",
      "kldivergence:   1810.25\n",
      "variational_beta * kldivergence:  0.18102\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34694\n",
      "kldivergence:   1516.99\n",
      "variational_beta * kldivergence:  0.15170\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29931\n",
      "kldivergence:   1543.79\n",
      "variational_beta * kldivergence:  0.15438\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31633\n",
      "kldivergence:   1631.56\n",
      "variational_beta * kldivergence:  0.16316\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34257\n",
      "kldivergence:   1775.16\n",
      "variational_beta * kldivergence:  0.17752\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28471\n",
      "kldivergence:   1455.19\n",
      "variational_beta * kldivergence:  0.14552\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.25089\n",
      "kldivergence:   1394.95\n",
      "variational_beta * kldivergence:  0.13950\n",
      "batch accuracy: 91.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30773\n",
      "kldivergence:   1632.77\n",
      "variational_beta * kldivergence:  0.16328\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30257\n",
      "kldivergence:   2268.23\n",
      "variational_beta * kldivergence:  0.22682\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28147\n",
      "kldivergence:   1535.91\n",
      "variational_beta * kldivergence:  0.15359\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36786\n",
      "kldivergence:   1601.74\n",
      "variational_beta * kldivergence:  0.16017\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33624\n",
      "kldivergence:   1750.23\n",
      "variational_beta * kldivergence:  0.17502\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32765\n",
      "kldivergence:   1714.30\n",
      "variational_beta * kldivergence:  0.17143\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33121\n",
      "kldivergence:   1624.55\n",
      "variational_beta * kldivergence:  0.16246\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33187\n",
      "kldivergence:   1566.18\n",
      "variational_beta * kldivergence:  0.15662\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30561\n",
      "kldivergence:   1398.68\n",
      "variational_beta * kldivergence:  0.13987\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32225\n",
      "kldivergence:   1418.57\n",
      "variational_beta * kldivergence:  0.14186\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35412\n",
      "kldivergence:   1562.92\n",
      "variational_beta * kldivergence:  0.15629\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33776\n",
      "kldivergence:   1348.34\n",
      "variational_beta * kldivergence:  0.13483\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35159\n",
      "kldivergence:   1717.60\n",
      "variational_beta * kldivergence:  0.17176\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34247\n",
      "kldivergence:   1558.91\n",
      "variational_beta * kldivergence:  0.15589\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31052\n",
      "kldivergence:   1410.67\n",
      "variational_beta * kldivergence:  0.14107\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35737\n",
      "kldivergence:   1532.19\n",
      "variational_beta * kldivergence:  0.15322\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37598\n",
      "kldivergence:   1689.20\n",
      "variational_beta * kldivergence:  0.16892\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33718\n",
      "kldivergence:   1511.44\n",
      "variational_beta * kldivergence:  0.15114\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32776\n",
      "kldivergence:   1400.93\n",
      "variational_beta * kldivergence:  0.14009\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29770\n",
      "kldivergence:   1634.57\n",
      "variational_beta * kldivergence:  0.16346\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28906\n",
      "kldivergence:   1471.94\n",
      "variational_beta * kldivergence:  0.14719\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37508\n",
      "kldivergence:   1693.31\n",
      "variational_beta * kldivergence:  0.16933\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36822\n",
      "kldivergence:   1838.56\n",
      "variational_beta * kldivergence:  0.18386\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35117\n",
      "kldivergence:   1506.77\n",
      "variational_beta * kldivergence:  0.15068\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34597\n",
      "kldivergence:   1434.46\n",
      "variational_beta * kldivergence:  0.14345\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34159\n",
      "kldivergence:   1536.93\n",
      "variational_beta * kldivergence:  0.15369\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36088\n",
      "kldivergence:   1501.95\n",
      "variational_beta * kldivergence:  0.15019\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35039\n",
      "kldivergence:   1432.80\n",
      "variational_beta * kldivergence:  0.14328\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32525\n",
      "kldivergence:   1679.44\n",
      "variational_beta * kldivergence:  0.16794\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30774\n",
      "kldivergence:   1690.93\n",
      "variational_beta * kldivergence:  0.16909\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36264\n",
      "kldivergence:   1559.74\n",
      "variational_beta * kldivergence:  0.15597\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27754\n",
      "kldivergence:   1531.18\n",
      "variational_beta * kldivergence:  0.15312\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34316\n",
      "kldivergence:   1696.13\n",
      "variational_beta * kldivergence:  0.16961\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33426\n",
      "kldivergence:   1657.74\n",
      "variational_beta * kldivergence:  0.16577\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34696\n",
      "kldivergence:   1755.22\n",
      "variational_beta * kldivergence:  0.17552\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33750\n",
      "kldivergence:   1661.75\n",
      "variational_beta * kldivergence:  0.16618\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33445\n",
      "kldivergence:   1591.75\n",
      "variational_beta * kldivergence:  0.15917\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33893\n",
      "kldivergence:   1643.95\n",
      "variational_beta * kldivergence:  0.16439\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31937\n",
      "kldivergence:   1688.77\n",
      "variational_beta * kldivergence:  0.16888\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33016\n",
      "kldivergence:   1645.86\n",
      "variational_beta * kldivergence:  0.16459\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34707\n",
      "kldivergence:   1520.30\n",
      "variational_beta * kldivergence:  0.15203\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37147\n",
      "kldivergence:   1619.86\n",
      "variational_beta * kldivergence:  0.16199\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32263\n",
      "kldivergence:   1918.16\n",
      "variational_beta * kldivergence:  0.19182\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33374\n",
      "kldivergence:   1671.37\n",
      "variational_beta * kldivergence:  0.16714\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33352\n",
      "kldivergence:   1672.18\n",
      "variational_beta * kldivergence:  0.16722\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32735\n",
      "kldivergence:   1621.04\n",
      "variational_beta * kldivergence:  0.16210\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30110\n",
      "kldivergence:   1528.13\n",
      "variational_beta * kldivergence:  0.15281\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35913\n",
      "kldivergence:   1542.65\n",
      "variational_beta * kldivergence:  0.15427\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32798\n",
      "kldivergence:   1621.20\n",
      "variational_beta * kldivergence:  0.16212\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32152\n",
      "kldivergence:   1401.89\n",
      "variational_beta * kldivergence:  0.14019\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33775\n",
      "kldivergence:   1678.03\n",
      "variational_beta * kldivergence:  0.16780\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.26613\n",
      "kldivergence:   1440.81\n",
      "variational_beta * kldivergence:  0.14408\n",
      "batch accuracy: 90.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35148\n",
      "kldivergence:   1586.41\n",
      "variational_beta * kldivergence:  0.15864\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29264\n",
      "kldivergence:   1389.41\n",
      "variational_beta * kldivergence:  0.13894\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37554\n",
      "kldivergence:   1554.34\n",
      "variational_beta * kldivergence:  0.15543\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31560\n",
      "kldivergence:   1532.86\n",
      "variational_beta * kldivergence:  0.15329\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31623\n",
      "kldivergence:   1276.67\n",
      "variational_beta * kldivergence:  0.12767\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27605\n",
      "kldivergence:   1452.34\n",
      "variational_beta * kldivergence:  0.14523\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30585\n",
      "kldivergence:   1582.97\n",
      "variational_beta * kldivergence:  0.15830\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32117\n",
      "kldivergence:   1499.05\n",
      "variational_beta * kldivergence:  0.14991\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32296\n",
      "kldivergence:   1504.84\n",
      "variational_beta * kldivergence:  0.15048\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28651\n",
      "kldivergence:   1420.64\n",
      "variational_beta * kldivergence:  0.14206\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27554\n",
      "kldivergence:   1405.99\n",
      "variational_beta * kldivergence:  0.14060\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36425\n",
      "kldivergence:   1524.21\n",
      "variational_beta * kldivergence:  0.15242\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35413\n",
      "kldivergence:   1821.69\n",
      "variational_beta * kldivergence:  0.18217\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37378\n",
      "kldivergence:   1808.56\n",
      "variational_beta * kldivergence:  0.18086\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35462\n",
      "kldivergence:   1901.53\n",
      "variational_beta * kldivergence:  0.19015\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37347\n",
      "kldivergence:   1650.53\n",
      "variational_beta * kldivergence:  0.16505\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36378\n",
      "kldivergence:   1736.25\n",
      "variational_beta * kldivergence:  0.17362\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29428\n",
      "kldivergence:   1302.48\n",
      "variational_beta * kldivergence:  0.13025\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31408\n",
      "kldivergence:   1398.82\n",
      "variational_beta * kldivergence:  0.13988\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35265\n",
      "kldivergence:   1487.60\n",
      "variational_beta * kldivergence:  0.14876\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29131\n",
      "kldivergence:   1280.80\n",
      "variational_beta * kldivergence:  0.12808\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.38120\n",
      "kldivergence:   1536.17\n",
      "variational_beta * kldivergence:  0.15362\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31760\n",
      "kldivergence:   1289.92\n",
      "variational_beta * kldivergence:  0.12899\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34854\n",
      "kldivergence:   1484.60\n",
      "variational_beta * kldivergence:  0.14846\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33546\n",
      "kldivergence:   1670.62\n",
      "variational_beta * kldivergence:  0.16706\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37408\n",
      "kldivergence:   1553.85\n",
      "variational_beta * kldivergence:  0.15539\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36081\n",
      "kldivergence:   1828.57\n",
      "variational_beta * kldivergence:  0.18286\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27962\n",
      "kldivergence:   1448.55\n",
      "variational_beta * kldivergence:  0.14485\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35285\n",
      "kldivergence:   1525.17\n",
      "variational_beta * kldivergence:  0.15252\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33087\n",
      "kldivergence:   1401.77\n",
      "variational_beta * kldivergence:  0.14018\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33644\n",
      "kldivergence:   1589.41\n",
      "variational_beta * kldivergence:  0.15894\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34994\n",
      "kldivergence:   1594.12\n",
      "variational_beta * kldivergence:  0.15941\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32900\n",
      "kldivergence:   1607.41\n",
      "variational_beta * kldivergence:  0.16074\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29453\n",
      "kldivergence:   1482.27\n",
      "variational_beta * kldivergence:  0.14823\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37077\n",
      "kldivergence:   1666.60\n",
      "variational_beta * kldivergence:  0.16666\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32811\n",
      "kldivergence:   1895.41\n",
      "variational_beta * kldivergence:  0.18954\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29064\n",
      "kldivergence:   1543.22\n",
      "variational_beta * kldivergence:  0.15432\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36310\n",
      "kldivergence:   1604.40\n",
      "variational_beta * kldivergence:  0.16044\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28846\n",
      "kldivergence:   1766.10\n",
      "variational_beta * kldivergence:  0.17661\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30141\n",
      "kldivergence:   1478.36\n",
      "variational_beta * kldivergence:  0.14784\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33483\n",
      "kldivergence:   1806.16\n",
      "variational_beta * kldivergence:  0.18062\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36249\n",
      "kldivergence:   1662.56\n",
      "variational_beta * kldivergence:  0.16626\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34372\n",
      "kldivergence:   1541.74\n",
      "variational_beta * kldivergence:  0.15417\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34136\n",
      "kldivergence:   1547.17\n",
      "variational_beta * kldivergence:  0.15472\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35579\n",
      "kldivergence:   1659.41\n",
      "variational_beta * kldivergence:  0.16594\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32413\n",
      "kldivergence:   1579.65\n",
      "variational_beta * kldivergence:  0.15796\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34007\n",
      "kldivergence:   1628.85\n",
      "variational_beta * kldivergence:  0.16288\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36996\n",
      "kldivergence:   1476.03\n",
      "variational_beta * kldivergence:  0.14760\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.26212\n",
      "kldivergence:   1466.93\n",
      "variational_beta * kldivergence:  0.14669\n",
      "batch accuracy: 91.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34257\n",
      "kldivergence:   1585.28\n",
      "variational_beta * kldivergence:  0.15853\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33704\n",
      "kldivergence:   1371.32\n",
      "variational_beta * kldivergence:  0.13713\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27923\n",
      "kldivergence:   1261.09\n",
      "variational_beta * kldivergence:  0.12611\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30785\n",
      "kldivergence:   1442.16\n",
      "variational_beta * kldivergence:  0.14422\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34527\n",
      "kldivergence:   1628.42\n",
      "variational_beta * kldivergence:  0.16284\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34665\n",
      "kldivergence:   1457.85\n",
      "variational_beta * kldivergence:  0.14579\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35781\n",
      "kldivergence:   1516.46\n",
      "variational_beta * kldivergence:  0.15165\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35655\n",
      "kldivergence:   1684.75\n",
      "variational_beta * kldivergence:  0.16848\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36672\n",
      "kldivergence:   1877.10\n",
      "variational_beta * kldivergence:  0.18771\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35849\n",
      "kldivergence:   1749.74\n",
      "variational_beta * kldivergence:  0.17497\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35110\n",
      "kldivergence:   1663.77\n",
      "variational_beta * kldivergence:  0.16638\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33368\n",
      "kldivergence:   1763.88\n",
      "variational_beta * kldivergence:  0.17639\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31868\n",
      "kldivergence:   1693.51\n",
      "variational_beta * kldivergence:  0.16935\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32808\n",
      "kldivergence:   1673.16\n",
      "variational_beta * kldivergence:  0.16732\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27803\n",
      "kldivergence:   1401.83\n",
      "variational_beta * kldivergence:  0.14018\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36496\n",
      "kldivergence:   1714.25\n",
      "variational_beta * kldivergence:  0.17143\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29092\n",
      "kldivergence:   1528.20\n",
      "variational_beta * kldivergence:  0.15282\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36136\n",
      "kldivergence:   1433.79\n",
      "variational_beta * kldivergence:  0.14338\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35308\n",
      "kldivergence:   1596.82\n",
      "variational_beta * kldivergence:  0.15968\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33903\n",
      "kldivergence:   1573.35\n",
      "variational_beta * kldivergence:  0.15733\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34322\n",
      "kldivergence:   1686.94\n",
      "variational_beta * kldivergence:  0.16869\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30180\n",
      "kldivergence:   1526.34\n",
      "variational_beta * kldivergence:  0.15263\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33223\n",
      "kldivergence:   1535.70\n",
      "variational_beta * kldivergence:  0.15357\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30165\n",
      "kldivergence:   1581.60\n",
      "variational_beta * kldivergence:  0.15816\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30761\n",
      "kldivergence:   1574.97\n",
      "variational_beta * kldivergence:  0.15750\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30279\n",
      "kldivergence:   1666.69\n",
      "variational_beta * kldivergence:  0.16667\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34050\n",
      "kldivergence:   1490.88\n",
      "variational_beta * kldivergence:  0.14909\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36626\n",
      "kldivergence:   1478.33\n",
      "variational_beta * kldivergence:  0.14783\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35687\n",
      "kldivergence:   1593.53\n",
      "variational_beta * kldivergence:  0.15935\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32330\n",
      "kldivergence:   1439.13\n",
      "variational_beta * kldivergence:  0.14391\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33452\n",
      "kldivergence:   1726.53\n",
      "variational_beta * kldivergence:  0.17265\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35021\n",
      "kldivergence:   1729.93\n",
      "variational_beta * kldivergence:  0.17299\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33396\n",
      "kldivergence:   1448.81\n",
      "variational_beta * kldivergence:  0.14488\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28464\n",
      "kldivergence:   1390.55\n",
      "variational_beta * kldivergence:  0.13906\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33079\n",
      "kldivergence:   1445.47\n",
      "variational_beta * kldivergence:  0.14455\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33454\n",
      "kldivergence:   1458.48\n",
      "variational_beta * kldivergence:  0.14585\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37268\n",
      "kldivergence:   1844.91\n",
      "variational_beta * kldivergence:  0.18449\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32150\n",
      "kldivergence:   1483.84\n",
      "variational_beta * kldivergence:  0.14838\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30077\n",
      "kldivergence:   1544.65\n",
      "variational_beta * kldivergence:  0.15446\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32096\n",
      "kldivergence:   1592.89\n",
      "variational_beta * kldivergence:  0.15929\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30666\n",
      "kldivergence:   1917.86\n",
      "variational_beta * kldivergence:  0.19179\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30904\n",
      "kldivergence:   1692.05\n",
      "variational_beta * kldivergence:  0.16921\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27617\n",
      "kldivergence:   1763.87\n",
      "variational_beta * kldivergence:  0.17639\n",
      "batch accuracy: 90.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30587\n",
      "kldivergence:   1368.90\n",
      "variational_beta * kldivergence:  0.13689\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34690\n",
      "kldivergence:   1474.01\n",
      "variational_beta * kldivergence:  0.14740\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32191\n",
      "kldivergence:   1639.13\n",
      "variational_beta * kldivergence:  0.16391\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34562\n",
      "kldivergence:   1512.10\n",
      "variational_beta * kldivergence:  0.15121\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37733\n",
      "kldivergence:   1494.44\n",
      "variational_beta * kldivergence:  0.14944\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34075\n",
      "kldivergence:   1495.95\n",
      "variational_beta * kldivergence:  0.14960\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30518\n",
      "kldivergence:   1531.62\n",
      "variational_beta * kldivergence:  0.15316\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.38111\n",
      "kldivergence:   1578.48\n",
      "variational_beta * kldivergence:  0.15785\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31745\n",
      "kldivergence:   1464.02\n",
      "variational_beta * kldivergence:  0.14640\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34981\n",
      "kldivergence:   1492.05\n",
      "variational_beta * kldivergence:  0.14920\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30405\n",
      "kldivergence:   1511.60\n",
      "variational_beta * kldivergence:  0.15116\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32795\n",
      "kldivergence:   1633.25\n",
      "variational_beta * kldivergence:  0.16332\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30846\n",
      "kldivergence:   1531.17\n",
      "variational_beta * kldivergence:  0.15312\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37302\n",
      "kldivergence:   1543.58\n",
      "variational_beta * kldivergence:  0.15436\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34686\n",
      "kldivergence:   1646.13\n",
      "variational_beta * kldivergence:  0.16461\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32337\n",
      "kldivergence:   1724.66\n",
      "variational_beta * kldivergence:  0.17247\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32417\n",
      "kldivergence:   1692.11\n",
      "variational_beta * kldivergence:  0.16921\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32855\n",
      "kldivergence:   1649.53\n",
      "variational_beta * kldivergence:  0.16495\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35684\n",
      "kldivergence:   1713.15\n",
      "variational_beta * kldivergence:  0.17132\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35601\n",
      "kldivergence:   1609.91\n",
      "variational_beta * kldivergence:  0.16099\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.38238\n",
      "kldivergence:   1598.11\n",
      "variational_beta * kldivergence:  0.15981\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31759\n",
      "kldivergence:   1606.74\n",
      "variational_beta * kldivergence:  0.16067\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34835\n",
      "kldivergence:   1827.18\n",
      "variational_beta * kldivergence:  0.18272\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31659\n",
      "kldivergence:   1413.74\n",
      "variational_beta * kldivergence:  0.14137\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30805\n",
      "kldivergence:   1652.97\n",
      "variational_beta * kldivergence:  0.16530\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32706\n",
      "kldivergence:   1843.71\n",
      "variational_beta * kldivergence:  0.18437\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35169\n",
      "kldivergence:   1589.04\n",
      "variational_beta * kldivergence:  0.15890\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31073\n",
      "kldivergence:   1531.10\n",
      "variational_beta * kldivergence:  0.15311\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32578\n",
      "kldivergence:   1398.65\n",
      "variational_beta * kldivergence:  0.13986\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27580\n",
      "kldivergence:   1443.36\n",
      "variational_beta * kldivergence:  0.14434\n",
      "batch accuracy: 90.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37144\n",
      "kldivergence:   1539.41\n",
      "variational_beta * kldivergence:  0.15394\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29892\n",
      "kldivergence:   1543.34\n",
      "variational_beta * kldivergence:  0.15433\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34343\n",
      "kldivergence:   1740.88\n",
      "variational_beta * kldivergence:  0.17409\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33294\n",
      "kldivergence:   1618.08\n",
      "variational_beta * kldivergence:  0.16181\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33386\n",
      "kldivergence:   1656.43\n",
      "variational_beta * kldivergence:  0.16564\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35541\n",
      "kldivergence:   1565.26\n",
      "variational_beta * kldivergence:  0.15653\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28988\n",
      "kldivergence:   1382.59\n",
      "variational_beta * kldivergence:  0.13826\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35437\n",
      "kldivergence:   1438.52\n",
      "variational_beta * kldivergence:  0.14385\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34367\n",
      "kldivergence:   1585.46\n",
      "variational_beta * kldivergence:  0.15855\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37117\n",
      "kldivergence:   1620.95\n",
      "variational_beta * kldivergence:  0.16210\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31874\n",
      "kldivergence:   1677.39\n",
      "variational_beta * kldivergence:  0.16774\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37975\n",
      "kldivergence:   1712.45\n",
      "variational_beta * kldivergence:  0.17125\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32298\n",
      "kldivergence:   1702.41\n",
      "variational_beta * kldivergence:  0.17024\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32317\n",
      "kldivergence:   1520.64\n",
      "variational_beta * kldivergence:  0.15206\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34240\n",
      "kldivergence:   1607.44\n",
      "variational_beta * kldivergence:  0.16074\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28555\n",
      "kldivergence:   1426.53\n",
      "variational_beta * kldivergence:  0.14265\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33312\n",
      "kldivergence:   1562.79\n",
      "variational_beta * kldivergence:  0.15628\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32632\n",
      "kldivergence:   1471.95\n",
      "variational_beta * kldivergence:  0.14719\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33657\n",
      "kldivergence:   1613.52\n",
      "variational_beta * kldivergence:  0.16135\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32216\n",
      "kldivergence:   1590.87\n",
      "variational_beta * kldivergence:  0.15909\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31859\n",
      "kldivergence:   1435.14\n",
      "variational_beta * kldivergence:  0.14351\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32555\n",
      "kldivergence:   1370.08\n",
      "variational_beta * kldivergence:  0.13701\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.38608\n",
      "kldivergence:   1746.43\n",
      "variational_beta * kldivergence:  0.17464\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32518\n",
      "kldivergence:   1638.75\n",
      "variational_beta * kldivergence:  0.16388\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33931\n",
      "kldivergence:   1731.78\n",
      "variational_beta * kldivergence:  0.17318\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31225\n",
      "kldivergence:   1553.46\n",
      "variational_beta * kldivergence:  0.15535\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33964\n",
      "kldivergence:   1618.05\n",
      "variational_beta * kldivergence:  0.16181\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31198\n",
      "kldivergence:   1419.30\n",
      "variational_beta * kldivergence:  0.14193\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37797\n",
      "kldivergence:   1642.22\n",
      "variational_beta * kldivergence:  0.16422\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35769\n",
      "kldivergence:   1776.01\n",
      "variational_beta * kldivergence:  0.17760\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31708\n",
      "kldivergence:   1617.63\n",
      "variational_beta * kldivergence:  0.16176\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30751\n",
      "kldivergence:   1388.42\n",
      "variational_beta * kldivergence:  0.13884\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31998\n",
      "kldivergence:   1422.50\n",
      "variational_beta * kldivergence:  0.14225\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30646\n",
      "kldivergence:   1476.30\n",
      "variational_beta * kldivergence:  0.14763\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33981\n",
      "kldivergence:   1699.16\n",
      "variational_beta * kldivergence:  0.16992\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33614\n",
      "kldivergence:   1398.09\n",
      "variational_beta * kldivergence:  0.13981\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33379\n",
      "kldivergence:   1698.33\n",
      "variational_beta * kldivergence:  0.16983\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31488\n",
      "kldivergence:   1438.68\n",
      "variational_beta * kldivergence:  0.14387\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37685\n",
      "kldivergence:   1547.46\n",
      "variational_beta * kldivergence:  0.15475\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31570\n",
      "kldivergence:   1749.98\n",
      "variational_beta * kldivergence:  0.17500\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34429\n",
      "kldivergence:   1600.14\n",
      "variational_beta * kldivergence:  0.16001\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.42360\n",
      "kldivergence:   1785.42\n",
      "variational_beta * kldivergence:  0.17854\n",
      "batch accuracy: 85.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33755\n",
      "kldivergence:   1873.98\n",
      "variational_beta * kldivergence:  0.18740\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30321\n",
      "kldivergence:   1492.55\n",
      "variational_beta * kldivergence:  0.14926\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31018\n",
      "kldivergence:   1728.34\n",
      "variational_beta * kldivergence:  0.17283\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33933\n",
      "kldivergence:   1600.44\n",
      "variational_beta * kldivergence:  0.16004\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32354\n",
      "kldivergence:   1443.09\n",
      "variational_beta * kldivergence:  0.14431\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32172\n",
      "kldivergence:   1642.20\n",
      "variational_beta * kldivergence:  0.16422\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31671\n",
      "kldivergence:   1459.80\n",
      "variational_beta * kldivergence:  0.14598\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34017\n",
      "kldivergence:   1387.06\n",
      "variational_beta * kldivergence:  0.13871\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32949\n",
      "kldivergence:   1623.00\n",
      "variational_beta * kldivergence:  0.16230\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30460\n",
      "kldivergence:   1532.86\n",
      "variational_beta * kldivergence:  0.15329\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34704\n",
      "kldivergence:   1510.80\n",
      "variational_beta * kldivergence:  0.15108\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30455\n",
      "kldivergence:   1589.84\n",
      "variational_beta * kldivergence:  0.15898\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34906\n",
      "kldivergence:   1578.20\n",
      "variational_beta * kldivergence:  0.15782\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32256\n",
      "kldivergence:   1372.27\n",
      "variational_beta * kldivergence:  0.13723\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30025\n",
      "kldivergence:   1425.45\n",
      "variational_beta * kldivergence:  0.14254\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31919\n",
      "kldivergence:   1457.41\n",
      "variational_beta * kldivergence:  0.14574\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33793\n",
      "kldivergence:   1617.62\n",
      "variational_beta * kldivergence:  0.16176\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34938\n",
      "kldivergence:   1684.01\n",
      "variational_beta * kldivergence:  0.16840\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33605\n",
      "kldivergence:   1742.76\n",
      "variational_beta * kldivergence:  0.17428\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.37616\n",
      "kldivergence:   1793.46\n",
      "variational_beta * kldivergence:  0.17935\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31550\n",
      "kldivergence:   1266.68\n",
      "variational_beta * kldivergence:  0.12667\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32255\n",
      "kldivergence:   1550.79\n",
      "variational_beta * kldivergence:  0.15508\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35131\n",
      "kldivergence:   1468.70\n",
      "variational_beta * kldivergence:  0.14687\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36266\n",
      "kldivergence:   1651.41\n",
      "variational_beta * kldivergence:  0.16514\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33123\n",
      "kldivergence:   1477.83\n",
      "variational_beta * kldivergence:  0.14778\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35008\n",
      "kldivergence:   1546.02\n",
      "variational_beta * kldivergence:  0.15460\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31570\n",
      "kldivergence:   1555.94\n",
      "variational_beta * kldivergence:  0.15559\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36170\n",
      "kldivergence:   1812.04\n",
      "variational_beta * kldivergence:  0.18120\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33532\n",
      "kldivergence:   1631.96\n",
      "variational_beta * kldivergence:  0.16320\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31336\n",
      "kldivergence:   1591.87\n",
      "variational_beta * kldivergence:  0.15919\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34432\n",
      "kldivergence:   1531.12\n",
      "variational_beta * kldivergence:  0.15311\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33697\n",
      "kldivergence:   1489.49\n",
      "variational_beta * kldivergence:  0.14895\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35416\n",
      "kldivergence:   1488.71\n",
      "variational_beta * kldivergence:  0.14887\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36582\n",
      "kldivergence:   1536.65\n",
      "variational_beta * kldivergence:  0.15366\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.31690\n",
      "kldivergence:   1391.63\n",
      "variational_beta * kldivergence:  0.13916\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34287\n",
      "kldivergence:   1514.39\n",
      "variational_beta * kldivergence:  0.15144\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30940\n",
      "kldivergence:   1396.43\n",
      "variational_beta * kldivergence:  0.13964\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36749\n",
      "kldivergence:   1487.86\n",
      "variational_beta * kldivergence:  0.14879\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.28434\n",
      "kldivergence:   1497.12\n",
      "variational_beta * kldivergence:  0.14971\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36375\n",
      "kldivergence:   1580.94\n",
      "variational_beta * kldivergence:  0.15809\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35830\n",
      "kldivergence:   1432.22\n",
      "variational_beta * kldivergence:  0.14322\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33033\n",
      "kldivergence:   1665.61\n",
      "variational_beta * kldivergence:  0.16656\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29170\n",
      "kldivergence:   1449.55\n",
      "variational_beta * kldivergence:  0.14495\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35917\n",
      "kldivergence:   1453.74\n",
      "variational_beta * kldivergence:  0.14537\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27144\n",
      "kldivergence:   1573.05\n",
      "variational_beta * kldivergence:  0.15731\n",
      "batch accuracy: 91.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.26167\n",
      "kldivergence:   1433.35\n",
      "variational_beta * kldivergence:  0.14334\n",
      "batch accuracy: 91.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29722\n",
      "kldivergence:   1443.86\n",
      "variational_beta * kldivergence:  0.14439\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29623\n",
      "kldivergence:   1550.13\n",
      "variational_beta * kldivergence:  0.15501\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33956\n",
      "kldivergence:   1753.40\n",
      "variational_beta * kldivergence:  0.17534\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33191\n",
      "kldivergence:   1746.61\n",
      "variational_beta * kldivergence:  0.17466\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32143\n",
      "kldivergence:   1525.18\n",
      "variational_beta * kldivergence:  0.15252\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33073\n",
      "kldivergence:   1776.15\n",
      "variational_beta * kldivergence:  0.17762\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.35847\n",
      "kldivergence:   1543.38\n",
      "variational_beta * kldivergence:  0.15434\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29261\n",
      "kldivergence:   1498.68\n",
      "variational_beta * kldivergence:  0.14987\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.27309\n",
      "kldivergence:   1573.52\n",
      "variational_beta * kldivergence:  0.15735\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33074\n",
      "kldivergence:   1539.24\n",
      "variational_beta * kldivergence:  0.15392\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.33932\n",
      "kldivergence:   1370.46\n",
      "variational_beta * kldivergence:  0.13705\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.32040\n",
      "kldivergence:   1529.21\n",
      "variational_beta * kldivergence:  0.15292\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.36057\n",
      "kldivergence:   1532.99\n",
      "variational_beta * kldivergence:  0.15330\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.38194\n",
      "kldivergence:   1760.31\n",
      "variational_beta * kldivergence:  0.17603\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.30542\n",
      "kldivergence:   1363.64\n",
      "variational_beta * kldivergence:  0.13636\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.29892\n",
      "kldivergence:   1518.43\n",
      "variational_beta * kldivergence:  0.15184\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34511\n",
      "kldivergence:   1683.97\n",
      "variational_beta * kldivergence:  0.16840\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #34\n",
      "reconstruction loss: 0.34085\n",
      "kldivergence:   1446.52\n",
      "variational_beta * kldivergence:  0.14465\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.43352\n",
      "kldivergence:   1486.53\n",
      "variational_beta * kldivergence:  0.14865\n",
      "batch accuracy: 86.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.44926\n",
      "kldivergence:   1440.97\n",
      "variational_beta * kldivergence:  0.14410\n",
      "batch accuracy: 86.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.44227\n",
      "kldivergence:   1435.01\n",
      "variational_beta * kldivergence:  0.14350\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.42999\n",
      "kldivergence:   1336.30\n",
      "variational_beta * kldivergence:  0.13363\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.44635\n",
      "kldivergence:   1401.08\n",
      "variational_beta * kldivergence:  0.14011\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.51375\n",
      "kldivergence:   1446.43\n",
      "variational_beta * kldivergence:  0.14464\n",
      "batch accuracy: 84.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.45828\n",
      "kldivergence:   1416.79\n",
      "variational_beta * kldivergence:  0.14168\n",
      "batch accuracy: 85.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.50206\n",
      "kldivergence:   1526.83\n",
      "variational_beta * kldivergence:  0.15268\n",
      "batch accuracy: 84.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.42128\n",
      "kldivergence:   1366.41\n",
      "variational_beta * kldivergence:  0.13664\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.37997\n",
      "kldivergence:   1425.67\n",
      "variational_beta * kldivergence:  0.14257\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.50376\n",
      "kldivergence:   1574.35\n",
      "variational_beta * kldivergence:  0.15743\n",
      "batch accuracy: 85.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.41833\n",
      "kldivergence:   1538.37\n",
      "variational_beta * kldivergence:  0.15384\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.38971\n",
      "kldivergence:   1468.96\n",
      "variational_beta * kldivergence:  0.14690\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.45811\n",
      "kldivergence:   1406.03\n",
      "variational_beta * kldivergence:  0.14060\n",
      "batch accuracy: 85.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.50639\n",
      "kldivergence:   1466.06\n",
      "variational_beta * kldivergence:  0.14661\n",
      "batch accuracy: 85.08\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.45024\n",
      "kldivergence:   1460.44\n",
      "variational_beta * kldivergence:  0.14604\n",
      "batch accuracy: 85.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.54612\n",
      "kldivergence:   1627.65\n",
      "variational_beta * kldivergence:  0.16276\n",
      "batch accuracy: 83.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.47704\n",
      "kldivergence:   1451.53\n",
      "variational_beta * kldivergence:  0.14515\n",
      "batch accuracy: 85.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.52664\n",
      "kldivergence:   1573.56\n",
      "variational_beta * kldivergence:  0.15736\n",
      "batch accuracy: 83.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.44968\n",
      "kldivergence:   1420.97\n",
      "variational_beta * kldivergence:  0.14210\n",
      "batch accuracy: 86.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.43418\n",
      "kldivergence:   1445.21\n",
      "variational_beta * kldivergence:  0.14452\n",
      "batch accuracy: 85.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.50594\n",
      "kldivergence:   1594.92\n",
      "variational_beta * kldivergence:  0.15949\n",
      "batch accuracy: 84.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.44308\n",
      "kldivergence:   1453.34\n",
      "variational_beta * kldivergence:  0.14533\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.36888\n",
      "kldivergence:   1378.23\n",
      "variational_beta * kldivergence:  0.13782\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.50972\n",
      "kldivergence:   1502.94\n",
      "variational_beta * kldivergence:  0.15029\n",
      "batch accuracy: 84.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.41222\n",
      "kldivergence:   1490.21\n",
      "variational_beta * kldivergence:  0.14902\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.49452\n",
      "kldivergence:   1579.98\n",
      "variational_beta * kldivergence:  0.15800\n",
      "batch accuracy: 84.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.36476\n",
      "kldivergence:   1369.67\n",
      "variational_beta * kldivergence:  0.13697\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.38721\n",
      "kldivergence:   1332.18\n",
      "variational_beta * kldivergence:  0.13322\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.37822\n",
      "kldivergence:   1312.97\n",
      "variational_beta * kldivergence:  0.13130\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.41450\n",
      "kldivergence:   1303.97\n",
      "variational_beta * kldivergence:  0.13040\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.40508\n",
      "kldivergence:   1378.33\n",
      "variational_beta * kldivergence:  0.13783\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.47651\n",
      "kldivergence:   1515.16\n",
      "variational_beta * kldivergence:  0.15152\n",
      "batch accuracy: 85.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.45468\n",
      "kldivergence:   1525.95\n",
      "variational_beta * kldivergence:  0.15259\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.46730\n",
      "kldivergence:   1516.15\n",
      "variational_beta * kldivergence:  0.15162\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.48682\n",
      "kldivergence:   1561.01\n",
      "variational_beta * kldivergence:  0.15610\n",
      "batch accuracy: 85.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.46945\n",
      "kldivergence:   1541.75\n",
      "variational_beta * kldivergence:  0.15418\n",
      "batch accuracy: 85.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.36479\n",
      "kldivergence:   1323.77\n",
      "variational_beta * kldivergence:  0.13238\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.55505\n",
      "kldivergence:   1592.61\n",
      "variational_beta * kldivergence:  0.15926\n",
      "batch accuracy: 83.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.47311\n",
      "kldivergence:   1436.56\n",
      "variational_beta * kldivergence:  0.14366\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.46720\n",
      "kldivergence:   1562.46\n",
      "variational_beta * kldivergence:  0.15625\n",
      "batch accuracy: 85.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.50048\n",
      "kldivergence:   1442.64\n",
      "variational_beta * kldivergence:  0.14426\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.46040\n",
      "kldivergence:   1575.93\n",
      "variational_beta * kldivergence:  0.15759\n",
      "batch accuracy: 86.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.44564\n",
      "kldivergence:   1475.85\n",
      "variational_beta * kldivergence:  0.14759\n",
      "batch accuracy: 86.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.47627\n",
      "kldivergence:   1524.50\n",
      "variational_beta * kldivergence:  0.15245\n",
      "batch accuracy: 85.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.49347\n",
      "kldivergence:   1513.39\n",
      "variational_beta * kldivergence:  0.15134\n",
      "batch accuracy: 85.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.48960\n",
      "kldivergence:   1565.53\n",
      "variational_beta * kldivergence:  0.15655\n",
      "batch accuracy: 84.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.50453\n",
      "kldivergence:   1401.39\n",
      "variational_beta * kldivergence:  0.14014\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.42139\n",
      "kldivergence:   1353.34\n",
      "variational_beta * kldivergence:  0.13533\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.42362\n",
      "kldivergence:   1419.77\n",
      "variational_beta * kldivergence:  0.14198\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.49315\n",
      "kldivergence:   1477.30\n",
      "variational_beta * kldivergence:  0.14773\n",
      "batch accuracy: 85.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.43974\n",
      "kldivergence:   1453.32\n",
      "variational_beta * kldivergence:  0.14533\n",
      "batch accuracy: 86.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.44192\n",
      "kldivergence:   1436.28\n",
      "variational_beta * kldivergence:  0.14363\n",
      "batch accuracy: 86.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.46550\n",
      "kldivergence:   1419.86\n",
      "variational_beta * kldivergence:  0.14199\n",
      "batch accuracy: 85.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.36825\n",
      "kldivergence:   1398.51\n",
      "variational_beta * kldivergence:  0.13985\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.47549\n",
      "kldivergence:   1378.21\n",
      "variational_beta * kldivergence:  0.13782\n",
      "batch accuracy: 85.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.40442\n",
      "kldivergence:   1475.11\n",
      "variational_beta * kldivergence:  0.14751\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.51611\n",
      "kldivergence:   1540.59\n",
      "variational_beta * kldivergence:  0.15406\n",
      "batch accuracy: 84.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.48225\n",
      "kldivergence:   1459.89\n",
      "variational_beta * kldivergence:  0.14599\n",
      "batch accuracy: 85.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.43717\n",
      "kldivergence:   1390.63\n",
      "variational_beta * kldivergence:  0.13906\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.40775\n",
      "kldivergence:   1442.43\n",
      "variational_beta * kldivergence:  0.14424\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #34\n",
      "reconstruction loss: 0.44710\n",
      "kldivergence:   1372.63\n",
      "variational_beta * kldivergence:  0.13726\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "epoch # 34 : train loss is [182.41313104540077] and validation loss is [0.10048971851672957] \n",
      "Epoch [35 / 150] average reconstruction error: 0.491680\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34100\n",
      "kldivergence:   1852.34\n",
      "variational_beta * kldivergence:  0.18523\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29573\n",
      "kldivergence:   1467.63\n",
      "variational_beta * kldivergence:  0.14676\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34014\n",
      "kldivergence:   1731.28\n",
      "variational_beta * kldivergence:  0.17313\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29222\n",
      "kldivergence:   1582.77\n",
      "variational_beta * kldivergence:  0.15828\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38070\n",
      "kldivergence:   1819.41\n",
      "variational_beta * kldivergence:  0.18194\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33911\n",
      "kldivergence:   1601.99\n",
      "variational_beta * kldivergence:  0.16020\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36258\n",
      "kldivergence:   1586.68\n",
      "variational_beta * kldivergence:  0.15867\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30854\n",
      "kldivergence:   1789.66\n",
      "variational_beta * kldivergence:  0.17897\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.40488\n",
      "kldivergence:   1939.06\n",
      "variational_beta * kldivergence:  0.19391\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32810\n",
      "kldivergence:   1440.60\n",
      "variational_beta * kldivergence:  0.14406\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35750\n",
      "kldivergence:   1689.99\n",
      "variational_beta * kldivergence:  0.16900\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33848\n",
      "kldivergence:   1602.07\n",
      "variational_beta * kldivergence:  0.16021\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28328\n",
      "kldivergence:   1276.85\n",
      "variational_beta * kldivergence:  0.12769\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28912\n",
      "kldivergence:   1497.15\n",
      "variational_beta * kldivergence:  0.14971\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35019\n",
      "kldivergence:   1913.55\n",
      "variational_beta * kldivergence:  0.19135\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29958\n",
      "kldivergence:   1494.18\n",
      "variational_beta * kldivergence:  0.14942\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31520\n",
      "kldivergence:   1612.97\n",
      "variational_beta * kldivergence:  0.16130\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.25835\n",
      "kldivergence:   1374.56\n",
      "variational_beta * kldivergence:  0.13746\n",
      "batch accuracy: 91.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31987\n",
      "kldivergence:   1457.46\n",
      "variational_beta * kldivergence:  0.14575\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29116\n",
      "kldivergence:   1415.89\n",
      "variational_beta * kldivergence:  0.14159\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34991\n",
      "kldivergence:   1572.00\n",
      "variational_beta * kldivergence:  0.15720\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37754\n",
      "kldivergence:   1725.57\n",
      "variational_beta * kldivergence:  0.17256\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35372\n",
      "kldivergence:   1479.36\n",
      "variational_beta * kldivergence:  0.14794\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30791\n",
      "kldivergence:   1732.34\n",
      "variational_beta * kldivergence:  0.17323\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35981\n",
      "kldivergence:   1723.29\n",
      "variational_beta * kldivergence:  0.17233\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38389\n",
      "kldivergence:   1648.46\n",
      "variational_beta * kldivergence:  0.16485\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31872\n",
      "kldivergence:   1537.71\n",
      "variational_beta * kldivergence:  0.15377\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32332\n",
      "kldivergence:   1436.41\n",
      "variational_beta * kldivergence:  0.14364\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35655\n",
      "kldivergence:   1427.53\n",
      "variational_beta * kldivergence:  0.14275\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33073\n",
      "kldivergence:   1852.86\n",
      "variational_beta * kldivergence:  0.18529\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31288\n",
      "kldivergence:   1381.33\n",
      "variational_beta * kldivergence:  0.13813\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32457\n",
      "kldivergence:   1379.05\n",
      "variational_beta * kldivergence:  0.13790\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35628\n",
      "kldivergence:   1631.53\n",
      "variational_beta * kldivergence:  0.16315\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30586\n",
      "kldivergence:   1479.43\n",
      "variational_beta * kldivergence:  0.14794\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32317\n",
      "kldivergence:   1489.72\n",
      "variational_beta * kldivergence:  0.14897\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30964\n",
      "kldivergence:   1409.67\n",
      "variational_beta * kldivergence:  0.14097\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36430\n",
      "kldivergence:   1596.63\n",
      "variational_beta * kldivergence:  0.15966\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33508\n",
      "kldivergence:   1445.89\n",
      "variational_beta * kldivergence:  0.14459\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34377\n",
      "kldivergence:   1654.84\n",
      "variational_beta * kldivergence:  0.16548\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30727\n",
      "kldivergence:   1686.62\n",
      "variational_beta * kldivergence:  0.16866\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33791\n",
      "kldivergence:   1699.57\n",
      "variational_beta * kldivergence:  0.16996\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35216\n",
      "kldivergence:   1599.69\n",
      "variational_beta * kldivergence:  0.15997\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36955\n",
      "kldivergence:   1578.89\n",
      "variational_beta * kldivergence:  0.15789\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30566\n",
      "kldivergence:   1518.26\n",
      "variational_beta * kldivergence:  0.15183\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35436\n",
      "kldivergence:   1537.49\n",
      "variational_beta * kldivergence:  0.15375\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32938\n",
      "kldivergence:   1656.45\n",
      "variational_beta * kldivergence:  0.16565\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35073\n",
      "kldivergence:   1401.64\n",
      "variational_beta * kldivergence:  0.14016\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30163\n",
      "kldivergence:   1470.37\n",
      "variational_beta * kldivergence:  0.14704\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29441\n",
      "kldivergence:   1474.45\n",
      "variational_beta * kldivergence:  0.14745\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30288\n",
      "kldivergence:   1504.16\n",
      "variational_beta * kldivergence:  0.15042\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34173\n",
      "kldivergence:   1728.54\n",
      "variational_beta * kldivergence:  0.17285\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37307\n",
      "kldivergence:   1565.25\n",
      "variational_beta * kldivergence:  0.15653\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30212\n",
      "kldivergence:   1421.35\n",
      "variational_beta * kldivergence:  0.14214\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36506\n",
      "kldivergence:   1596.91\n",
      "variational_beta * kldivergence:  0.15969\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36913\n",
      "kldivergence:   1629.87\n",
      "variational_beta * kldivergence:  0.16299\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34961\n",
      "kldivergence:   1564.76\n",
      "variational_beta * kldivergence:  0.15648\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32136\n",
      "kldivergence:   1550.45\n",
      "variational_beta * kldivergence:  0.15505\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28732\n",
      "kldivergence:   1332.45\n",
      "variational_beta * kldivergence:  0.13325\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33632\n",
      "kldivergence:   1612.07\n",
      "variational_beta * kldivergence:  0.16121\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30856\n",
      "kldivergence:   1608.50\n",
      "variational_beta * kldivergence:  0.16085\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36743\n",
      "kldivergence:   1643.45\n",
      "variational_beta * kldivergence:  0.16434\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38697\n",
      "kldivergence:   1693.06\n",
      "variational_beta * kldivergence:  0.16931\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32061\n",
      "kldivergence:   1620.97\n",
      "variational_beta * kldivergence:  0.16210\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30991\n",
      "kldivergence:   1509.54\n",
      "variational_beta * kldivergence:  0.15095\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30780\n",
      "kldivergence:   1548.41\n",
      "variational_beta * kldivergence:  0.15484\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36613\n",
      "kldivergence:   1546.42\n",
      "variational_beta * kldivergence:  0.15464\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31727\n",
      "kldivergence:   1637.75\n",
      "variational_beta * kldivergence:  0.16377\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35079\n",
      "kldivergence:   1550.63\n",
      "variational_beta * kldivergence:  0.15506\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37550\n",
      "kldivergence:   1664.86\n",
      "variational_beta * kldivergence:  0.16649\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33553\n",
      "kldivergence:   1520.75\n",
      "variational_beta * kldivergence:  0.15208\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31335\n",
      "kldivergence:   1483.69\n",
      "variational_beta * kldivergence:  0.14837\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38201\n",
      "kldivergence:   1615.03\n",
      "variational_beta * kldivergence:  0.16150\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35741\n",
      "kldivergence:   1466.20\n",
      "variational_beta * kldivergence:  0.14662\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38626\n",
      "kldivergence:   1832.81\n",
      "variational_beta * kldivergence:  0.18328\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34068\n",
      "kldivergence:   1592.34\n",
      "variational_beta * kldivergence:  0.15923\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33522\n",
      "kldivergence:   1389.48\n",
      "variational_beta * kldivergence:  0.13895\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34883\n",
      "kldivergence:   1564.96\n",
      "variational_beta * kldivergence:  0.15650\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30722\n",
      "kldivergence:   1400.20\n",
      "variational_beta * kldivergence:  0.14002\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27166\n",
      "kldivergence:   1530.92\n",
      "variational_beta * kldivergence:  0.15309\n",
      "batch accuracy: 91.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34005\n",
      "kldivergence:   1580.33\n",
      "variational_beta * kldivergence:  0.15803\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32573\n",
      "kldivergence:   1656.69\n",
      "variational_beta * kldivergence:  0.16567\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36274\n",
      "kldivergence:   1551.37\n",
      "variational_beta * kldivergence:  0.15514\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34698\n",
      "kldivergence:   1422.07\n",
      "variational_beta * kldivergence:  0.14221\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32419\n",
      "kldivergence:   1511.23\n",
      "variational_beta * kldivergence:  0.15112\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34157\n",
      "kldivergence:   1413.43\n",
      "variational_beta * kldivergence:  0.14134\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38149\n",
      "kldivergence:   1624.42\n",
      "variational_beta * kldivergence:  0.16244\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33529\n",
      "kldivergence:   1541.39\n",
      "variational_beta * kldivergence:  0.15414\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31869\n",
      "kldivergence:   1509.64\n",
      "variational_beta * kldivergence:  0.15096\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33026\n",
      "kldivergence:   1522.94\n",
      "variational_beta * kldivergence:  0.15229\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35446\n",
      "kldivergence:   1805.37\n",
      "variational_beta * kldivergence:  0.18054\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34998\n",
      "kldivergence:   1559.55\n",
      "variational_beta * kldivergence:  0.15596\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34160\n",
      "kldivergence:   1513.87\n",
      "variational_beta * kldivergence:  0.15139\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31483\n",
      "kldivergence:   1538.29\n",
      "variational_beta * kldivergence:  0.15383\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33252\n",
      "kldivergence:   1524.68\n",
      "variational_beta * kldivergence:  0.15247\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31279\n",
      "kldivergence:   1429.30\n",
      "variational_beta * kldivergence:  0.14293\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29119\n",
      "kldivergence:   1499.52\n",
      "variational_beta * kldivergence:  0.14995\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.39998\n",
      "kldivergence:   1661.04\n",
      "variational_beta * kldivergence:  0.16610\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30288\n",
      "kldivergence:   1815.72\n",
      "variational_beta * kldivergence:  0.18157\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32007\n",
      "kldivergence:   1739.68\n",
      "variational_beta * kldivergence:  0.17397\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35175\n",
      "kldivergence:   1654.36\n",
      "variational_beta * kldivergence:  0.16544\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28842\n",
      "kldivergence:   1426.36\n",
      "variational_beta * kldivergence:  0.14264\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33746\n",
      "kldivergence:   1770.44\n",
      "variational_beta * kldivergence:  0.17704\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28658\n",
      "kldivergence:   1585.48\n",
      "variational_beta * kldivergence:  0.15855\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32532\n",
      "kldivergence:   1577.28\n",
      "variational_beta * kldivergence:  0.15773\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34958\n",
      "kldivergence:   1551.65\n",
      "variational_beta * kldivergence:  0.15517\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27683\n",
      "kldivergence:   1422.92\n",
      "variational_beta * kldivergence:  0.14229\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.26585\n",
      "kldivergence:   1488.68\n",
      "variational_beta * kldivergence:  0.14887\n",
      "batch accuracy: 90.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32647\n",
      "kldivergence:   1700.35\n",
      "variational_beta * kldivergence:  0.17003\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35712\n",
      "kldivergence:   1496.71\n",
      "variational_beta * kldivergence:  0.14967\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28999\n",
      "kldivergence:   1525.15\n",
      "variational_beta * kldivergence:  0.15251\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38048\n",
      "kldivergence:   1604.86\n",
      "variational_beta * kldivergence:  0.16049\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.39110\n",
      "kldivergence:   1762.26\n",
      "variational_beta * kldivergence:  0.17623\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29556\n",
      "kldivergence:   1381.80\n",
      "variational_beta * kldivergence:  0.13818\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37641\n",
      "kldivergence:   1562.03\n",
      "variational_beta * kldivergence:  0.15620\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.40185\n",
      "kldivergence:   1566.69\n",
      "variational_beta * kldivergence:  0.15667\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33070\n",
      "kldivergence:   1611.61\n",
      "variational_beta * kldivergence:  0.16116\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37667\n",
      "kldivergence:   1707.81\n",
      "variational_beta * kldivergence:  0.17078\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30070\n",
      "kldivergence:   1380.36\n",
      "variational_beta * kldivergence:  0.13804\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29835\n",
      "kldivergence:   1540.82\n",
      "variational_beta * kldivergence:  0.15408\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34275\n",
      "kldivergence:   1593.80\n",
      "variational_beta * kldivergence:  0.15938\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36254\n",
      "kldivergence:   1730.65\n",
      "variational_beta * kldivergence:  0.17307\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30468\n",
      "kldivergence:   1574.82\n",
      "variational_beta * kldivergence:  0.15748\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36391\n",
      "kldivergence:   1558.74\n",
      "variational_beta * kldivergence:  0.15587\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33954\n",
      "kldivergence:   1512.71\n",
      "variational_beta * kldivergence:  0.15127\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36312\n",
      "kldivergence:   1738.69\n",
      "variational_beta * kldivergence:  0.17387\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27663\n",
      "kldivergence:   1647.60\n",
      "variational_beta * kldivergence:  0.16476\n",
      "batch accuracy: 90.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27742\n",
      "kldivergence:   1467.81\n",
      "variational_beta * kldivergence:  0.14678\n",
      "batch accuracy: 90.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33332\n",
      "kldivergence:   1536.56\n",
      "variational_beta * kldivergence:  0.15366\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33468\n",
      "kldivergence:   1565.28\n",
      "variational_beta * kldivergence:  0.15653\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36156\n",
      "kldivergence:   1546.82\n",
      "variational_beta * kldivergence:  0.15468\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33617\n",
      "kldivergence:   1411.94\n",
      "variational_beta * kldivergence:  0.14119\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35656\n",
      "kldivergence:   1603.78\n",
      "variational_beta * kldivergence:  0.16038\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36440\n",
      "kldivergence:   1568.13\n",
      "variational_beta * kldivergence:  0.15681\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37018\n",
      "kldivergence:   1556.44\n",
      "variational_beta * kldivergence:  0.15564\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30914\n",
      "kldivergence:   1594.02\n",
      "variational_beta * kldivergence:  0.15940\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34027\n",
      "kldivergence:   1634.49\n",
      "variational_beta * kldivergence:  0.16345\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34961\n",
      "kldivergence:   1666.45\n",
      "variational_beta * kldivergence:  0.16664\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29493\n",
      "kldivergence:   1408.04\n",
      "variational_beta * kldivergence:  0.14080\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36656\n",
      "kldivergence:   1792.82\n",
      "variational_beta * kldivergence:  0.17928\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37378\n",
      "kldivergence:   1656.97\n",
      "variational_beta * kldivergence:  0.16570\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34273\n",
      "kldivergence:   1669.36\n",
      "variational_beta * kldivergence:  0.16694\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30311\n",
      "kldivergence:   1468.08\n",
      "variational_beta * kldivergence:  0.14681\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30418\n",
      "kldivergence:   1472.88\n",
      "variational_beta * kldivergence:  0.14729\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33801\n",
      "kldivergence:   2151.31\n",
      "variational_beta * kldivergence:  0.21513\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30963\n",
      "kldivergence:   1494.75\n",
      "variational_beta * kldivergence:  0.14947\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35220\n",
      "kldivergence:   1511.28\n",
      "variational_beta * kldivergence:  0.15113\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27486\n",
      "kldivergence:   1419.21\n",
      "variational_beta * kldivergence:  0.14192\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32466\n",
      "kldivergence:   1486.04\n",
      "variational_beta * kldivergence:  0.14860\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38373\n",
      "kldivergence:   1489.95\n",
      "variational_beta * kldivergence:  0.14899\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31409\n",
      "kldivergence:   1716.00\n",
      "variational_beta * kldivergence:  0.17160\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35042\n",
      "kldivergence:   1621.61\n",
      "variational_beta * kldivergence:  0.16216\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30298\n",
      "kldivergence:   1568.35\n",
      "variational_beta * kldivergence:  0.15684\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36626\n",
      "kldivergence:   1525.70\n",
      "variational_beta * kldivergence:  0.15257\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32345\n",
      "kldivergence:   1586.94\n",
      "variational_beta * kldivergence:  0.15869\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33858\n",
      "kldivergence:   1392.41\n",
      "variational_beta * kldivergence:  0.13924\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32784\n",
      "kldivergence:   1503.76\n",
      "variational_beta * kldivergence:  0.15038\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35925\n",
      "kldivergence:   1686.04\n",
      "variational_beta * kldivergence:  0.16860\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29539\n",
      "kldivergence:   1432.05\n",
      "variational_beta * kldivergence:  0.14321\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27712\n",
      "kldivergence:   1460.33\n",
      "variational_beta * kldivergence:  0.14603\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28527\n",
      "kldivergence:   1382.37\n",
      "variational_beta * kldivergence:  0.13824\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.39416\n",
      "kldivergence:   1634.55\n",
      "variational_beta * kldivergence:  0.16346\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36104\n",
      "kldivergence:   1364.66\n",
      "variational_beta * kldivergence:  0.13647\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35093\n",
      "kldivergence:   1814.16\n",
      "variational_beta * kldivergence:  0.18142\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31651\n",
      "kldivergence:   1670.51\n",
      "variational_beta * kldivergence:  0.16705\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34953\n",
      "kldivergence:   1609.51\n",
      "variational_beta * kldivergence:  0.16095\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33357\n",
      "kldivergence:   1586.50\n",
      "variational_beta * kldivergence:  0.15865\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35476\n",
      "kldivergence:   1545.94\n",
      "variational_beta * kldivergence:  0.15459\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30901\n",
      "kldivergence:   1424.60\n",
      "variational_beta * kldivergence:  0.14246\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34223\n",
      "kldivergence:   1583.96\n",
      "variational_beta * kldivergence:  0.15840\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31659\n",
      "kldivergence:   1528.91\n",
      "variational_beta * kldivergence:  0.15289\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33156\n",
      "kldivergence:   1786.06\n",
      "variational_beta * kldivergence:  0.17861\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35151\n",
      "kldivergence:   1709.80\n",
      "variational_beta * kldivergence:  0.17098\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28391\n",
      "kldivergence:   1538.37\n",
      "variational_beta * kldivergence:  0.15384\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30024\n",
      "kldivergence:   1414.69\n",
      "variational_beta * kldivergence:  0.14147\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31515\n",
      "kldivergence:   1428.48\n",
      "variational_beta * kldivergence:  0.14285\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29395\n",
      "kldivergence:   1604.17\n",
      "variational_beta * kldivergence:  0.16042\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.40073\n",
      "kldivergence:   1971.90\n",
      "variational_beta * kldivergence:  0.19719\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32972\n",
      "kldivergence:   1445.14\n",
      "variational_beta * kldivergence:  0.14451\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38245\n",
      "kldivergence:   1570.86\n",
      "variational_beta * kldivergence:  0.15709\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34906\n",
      "kldivergence:   1463.51\n",
      "variational_beta * kldivergence:  0.14635\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30262\n",
      "kldivergence:   1565.82\n",
      "variational_beta * kldivergence:  0.15658\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33202\n",
      "kldivergence:   1535.90\n",
      "variational_beta * kldivergence:  0.15359\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34633\n",
      "kldivergence:   1377.16\n",
      "variational_beta * kldivergence:  0.13772\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33305\n",
      "kldivergence:   1726.27\n",
      "variational_beta * kldivergence:  0.17263\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30712\n",
      "kldivergence:   1559.21\n",
      "variational_beta * kldivergence:  0.15592\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35103\n",
      "kldivergence:   1585.25\n",
      "variational_beta * kldivergence:  0.15852\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35662\n",
      "kldivergence:   1654.18\n",
      "variational_beta * kldivergence:  0.16542\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33672\n",
      "kldivergence:   1776.38\n",
      "variational_beta * kldivergence:  0.17764\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32837\n",
      "kldivergence:   1694.55\n",
      "variational_beta * kldivergence:  0.16945\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38724\n",
      "kldivergence:   1634.34\n",
      "variational_beta * kldivergence:  0.16343\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33741\n",
      "kldivergence:   1559.61\n",
      "variational_beta * kldivergence:  0.15596\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32445\n",
      "kldivergence:   1598.43\n",
      "variational_beta * kldivergence:  0.15984\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36300\n",
      "kldivergence:   1619.26\n",
      "variational_beta * kldivergence:  0.16193\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28041\n",
      "kldivergence:   1587.24\n",
      "variational_beta * kldivergence:  0.15872\n",
      "batch accuracy: 90.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29880\n",
      "kldivergence:   1506.81\n",
      "variational_beta * kldivergence:  0.15068\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29813\n",
      "kldivergence:   1755.92\n",
      "variational_beta * kldivergence:  0.17559\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31580\n",
      "kldivergence:   1466.54\n",
      "variational_beta * kldivergence:  0.14665\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33203\n",
      "kldivergence:   1669.18\n",
      "variational_beta * kldivergence:  0.16692\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32063\n",
      "kldivergence:   1626.38\n",
      "variational_beta * kldivergence:  0.16264\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33037\n",
      "kldivergence:   1764.63\n",
      "variational_beta * kldivergence:  0.17646\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31432\n",
      "kldivergence:   1448.88\n",
      "variational_beta * kldivergence:  0.14489\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36997\n",
      "kldivergence:   1878.52\n",
      "variational_beta * kldivergence:  0.18785\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27227\n",
      "kldivergence:   1539.29\n",
      "variational_beta * kldivergence:  0.15393\n",
      "batch accuracy: 91.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28672\n",
      "kldivergence:   1404.30\n",
      "variational_beta * kldivergence:  0.14043\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29975\n",
      "kldivergence:   1406.79\n",
      "variational_beta * kldivergence:  0.14068\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37522\n",
      "kldivergence:   1794.43\n",
      "variational_beta * kldivergence:  0.17944\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33489\n",
      "kldivergence:   1654.00\n",
      "variational_beta * kldivergence:  0.16540\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35889\n",
      "kldivergence:   1566.21\n",
      "variational_beta * kldivergence:  0.15662\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31923\n",
      "kldivergence:   1522.05\n",
      "variational_beta * kldivergence:  0.15221\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38043\n",
      "kldivergence:   1518.88\n",
      "variational_beta * kldivergence:  0.15189\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28960\n",
      "kldivergence:   1403.88\n",
      "variational_beta * kldivergence:  0.14039\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33097\n",
      "kldivergence:   1597.66\n",
      "variational_beta * kldivergence:  0.15977\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36842\n",
      "kldivergence:   1584.92\n",
      "variational_beta * kldivergence:  0.15849\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33653\n",
      "kldivergence:   1691.35\n",
      "variational_beta * kldivergence:  0.16914\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38882\n",
      "kldivergence:   1639.27\n",
      "variational_beta * kldivergence:  0.16393\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27224\n",
      "kldivergence:   1293.07\n",
      "variational_beta * kldivergence:  0.12931\n",
      "batch accuracy: 90.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.39168\n",
      "kldivergence:   1582.69\n",
      "variational_beta * kldivergence:  0.15827\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33762\n",
      "kldivergence:   1453.87\n",
      "variational_beta * kldivergence:  0.14539\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29024\n",
      "kldivergence:   1453.52\n",
      "variational_beta * kldivergence:  0.14535\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30432\n",
      "kldivergence:   1539.02\n",
      "variational_beta * kldivergence:  0.15390\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34358\n",
      "kldivergence:   1545.89\n",
      "variational_beta * kldivergence:  0.15459\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37402\n",
      "kldivergence:   1586.54\n",
      "variational_beta * kldivergence:  0.15865\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38226\n",
      "kldivergence:   1803.90\n",
      "variational_beta * kldivergence:  0.18039\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35013\n",
      "kldivergence:   1613.40\n",
      "variational_beta * kldivergence:  0.16134\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34398\n",
      "kldivergence:   1555.63\n",
      "variational_beta * kldivergence:  0.15556\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34350\n",
      "kldivergence:   1416.65\n",
      "variational_beta * kldivergence:  0.14166\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33972\n",
      "kldivergence:   1494.98\n",
      "variational_beta * kldivergence:  0.14950\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33151\n",
      "kldivergence:   1429.11\n",
      "variational_beta * kldivergence:  0.14291\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29861\n",
      "kldivergence:   1492.85\n",
      "variational_beta * kldivergence:  0.14928\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30949\n",
      "kldivergence:   1322.94\n",
      "variational_beta * kldivergence:  0.13229\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33455\n",
      "kldivergence:   1625.27\n",
      "variational_beta * kldivergence:  0.16253\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30475\n",
      "kldivergence:   1591.44\n",
      "variational_beta * kldivergence:  0.15914\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30513\n",
      "kldivergence:   1317.16\n",
      "variational_beta * kldivergence:  0.13172\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33463\n",
      "kldivergence:   1414.23\n",
      "variational_beta * kldivergence:  0.14142\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30941\n",
      "kldivergence:   1461.64\n",
      "variational_beta * kldivergence:  0.14616\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32419\n",
      "kldivergence:   1415.14\n",
      "variational_beta * kldivergence:  0.14151\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35482\n",
      "kldivergence:   1715.88\n",
      "variational_beta * kldivergence:  0.17159\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37166\n",
      "kldivergence:   1579.97\n",
      "variational_beta * kldivergence:  0.15800\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31927\n",
      "kldivergence:   1599.19\n",
      "variational_beta * kldivergence:  0.15992\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38744\n",
      "kldivergence:   1697.54\n",
      "variational_beta * kldivergence:  0.16975\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35357\n",
      "kldivergence:   1535.18\n",
      "variational_beta * kldivergence:  0.15352\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31542\n",
      "kldivergence:   1668.38\n",
      "variational_beta * kldivergence:  0.16684\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36234\n",
      "kldivergence:   1666.97\n",
      "variational_beta * kldivergence:  0.16670\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30695\n",
      "kldivergence:   1465.24\n",
      "variational_beta * kldivergence:  0.14652\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29201\n",
      "kldivergence:   1526.83\n",
      "variational_beta * kldivergence:  0.15268\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33378\n",
      "kldivergence:   1661.35\n",
      "variational_beta * kldivergence:  0.16613\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32209\n",
      "kldivergence:   1788.69\n",
      "variational_beta * kldivergence:  0.17887\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34196\n",
      "kldivergence:   1487.51\n",
      "variational_beta * kldivergence:  0.14875\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35834\n",
      "kldivergence:   1598.29\n",
      "variational_beta * kldivergence:  0.15983\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35622\n",
      "kldivergence:   1587.47\n",
      "variational_beta * kldivergence:  0.15875\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33207\n",
      "kldivergence:   1652.51\n",
      "variational_beta * kldivergence:  0.16525\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33076\n",
      "kldivergence:   1580.36\n",
      "variational_beta * kldivergence:  0.15804\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33764\n",
      "kldivergence:   1649.79\n",
      "variational_beta * kldivergence:  0.16498\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30852\n",
      "kldivergence:   1454.44\n",
      "variational_beta * kldivergence:  0.14544\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38431\n",
      "kldivergence:   1667.40\n",
      "variational_beta * kldivergence:  0.16674\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33909\n",
      "kldivergence:   1816.62\n",
      "variational_beta * kldivergence:  0.18166\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29633\n",
      "kldivergence:   1626.40\n",
      "variational_beta * kldivergence:  0.16264\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34017\n",
      "kldivergence:   1561.54\n",
      "variational_beta * kldivergence:  0.15615\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34548\n",
      "kldivergence:   1551.77\n",
      "variational_beta * kldivergence:  0.15518\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33798\n",
      "kldivergence:   1839.44\n",
      "variational_beta * kldivergence:  0.18394\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.26792\n",
      "kldivergence:   1532.01\n",
      "variational_beta * kldivergence:  0.15320\n",
      "batch accuracy: 91.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31024\n",
      "kldivergence:   1382.90\n",
      "variational_beta * kldivergence:  0.13829\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28576\n",
      "kldivergence:   1463.21\n",
      "variational_beta * kldivergence:  0.14632\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.26901\n",
      "kldivergence:   1570.98\n",
      "variational_beta * kldivergence:  0.15710\n",
      "batch accuracy: 91.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35589\n",
      "kldivergence:   1621.25\n",
      "variational_beta * kldivergence:  0.16213\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30279\n",
      "kldivergence:   1673.48\n",
      "variational_beta * kldivergence:  0.16735\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33477\n",
      "kldivergence:   1877.98\n",
      "variational_beta * kldivergence:  0.18780\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34104\n",
      "kldivergence:   1551.34\n",
      "variational_beta * kldivergence:  0.15513\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.42695\n",
      "kldivergence:   1806.86\n",
      "variational_beta * kldivergence:  0.18069\n",
      "batch accuracy: 86.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35416\n",
      "kldivergence:   1948.42\n",
      "variational_beta * kldivergence:  0.19484\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29874\n",
      "kldivergence:   2004.52\n",
      "variational_beta * kldivergence:  0.20045\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28232\n",
      "kldivergence:   1406.76\n",
      "variational_beta * kldivergence:  0.14068\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31249\n",
      "kldivergence:   1688.26\n",
      "variational_beta * kldivergence:  0.16883\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31617\n",
      "kldivergence:   1568.90\n",
      "variational_beta * kldivergence:  0.15689\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31097\n",
      "kldivergence:   1607.86\n",
      "variational_beta * kldivergence:  0.16079\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32925\n",
      "kldivergence:   1546.38\n",
      "variational_beta * kldivergence:  0.15464\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34756\n",
      "kldivergence:   1527.72\n",
      "variational_beta * kldivergence:  0.15277\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34846\n",
      "kldivergence:   1522.45\n",
      "variational_beta * kldivergence:  0.15225\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33620\n",
      "kldivergence:   1608.60\n",
      "variational_beta * kldivergence:  0.16086\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36580\n",
      "kldivergence:   1741.04\n",
      "variational_beta * kldivergence:  0.17410\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34041\n",
      "kldivergence:   1764.54\n",
      "variational_beta * kldivergence:  0.17645\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35831\n",
      "kldivergence:   1705.19\n",
      "variational_beta * kldivergence:  0.17052\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33725\n",
      "kldivergence:   1610.64\n",
      "variational_beta * kldivergence:  0.16106\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38448\n",
      "kldivergence:   1831.56\n",
      "variational_beta * kldivergence:  0.18316\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31009\n",
      "kldivergence:   1520.38\n",
      "variational_beta * kldivergence:  0.15204\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33349\n",
      "kldivergence:   1639.64\n",
      "variational_beta * kldivergence:  0.16396\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30585\n",
      "kldivergence:   1464.58\n",
      "variational_beta * kldivergence:  0.14646\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31014\n",
      "kldivergence:   1641.41\n",
      "variational_beta * kldivergence:  0.16414\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28891\n",
      "kldivergence:   1368.56\n",
      "variational_beta * kldivergence:  0.13686\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33145\n",
      "kldivergence:   1680.83\n",
      "variational_beta * kldivergence:  0.16808\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29020\n",
      "kldivergence:   1581.05\n",
      "variational_beta * kldivergence:  0.15810\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31352\n",
      "kldivergence:   1537.08\n",
      "variational_beta * kldivergence:  0.15371\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33037\n",
      "kldivergence:   1538.94\n",
      "variational_beta * kldivergence:  0.15389\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31881\n",
      "kldivergence:   1381.42\n",
      "variational_beta * kldivergence:  0.13814\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35173\n",
      "kldivergence:   1652.61\n",
      "variational_beta * kldivergence:  0.16526\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35308\n",
      "kldivergence:   1755.97\n",
      "variational_beta * kldivergence:  0.17560\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27702\n",
      "kldivergence:   1440.70\n",
      "variational_beta * kldivergence:  0.14407\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29828\n",
      "kldivergence:   1634.67\n",
      "variational_beta * kldivergence:  0.16347\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30466\n",
      "kldivergence:   1636.15\n",
      "variational_beta * kldivergence:  0.16361\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34093\n",
      "kldivergence:   1783.97\n",
      "variational_beta * kldivergence:  0.17840\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30831\n",
      "kldivergence:   1681.66\n",
      "variational_beta * kldivergence:  0.16817\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30862\n",
      "kldivergence:   1495.22\n",
      "variational_beta * kldivergence:  0.14952\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38391\n",
      "kldivergence:   1534.72\n",
      "variational_beta * kldivergence:  0.15347\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35862\n",
      "kldivergence:   1549.59\n",
      "variational_beta * kldivergence:  0.15496\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33227\n",
      "kldivergence:   1502.39\n",
      "variational_beta * kldivergence:  0.15024\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30565\n",
      "kldivergence:   1390.13\n",
      "variational_beta * kldivergence:  0.13901\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37037\n",
      "kldivergence:   1782.32\n",
      "variational_beta * kldivergence:  0.17823\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32774\n",
      "kldivergence:   1572.56\n",
      "variational_beta * kldivergence:  0.15726\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31089\n",
      "kldivergence:   1593.22\n",
      "variational_beta * kldivergence:  0.15932\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36460\n",
      "kldivergence:   1526.91\n",
      "variational_beta * kldivergence:  0.15269\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35665\n",
      "kldivergence:   1431.47\n",
      "variational_beta * kldivergence:  0.14315\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34830\n",
      "kldivergence:   1751.28\n",
      "variational_beta * kldivergence:  0.17513\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29308\n",
      "kldivergence:   1419.00\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35244\n",
      "kldivergence:   1545.98\n",
      "variational_beta * kldivergence:  0.15460\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32129\n",
      "kldivergence:   1499.85\n",
      "variational_beta * kldivergence:  0.14998\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36052\n",
      "kldivergence:   1652.57\n",
      "variational_beta * kldivergence:  0.16526\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37396\n",
      "kldivergence:   1876.54\n",
      "variational_beta * kldivergence:  0.18765\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30752\n",
      "kldivergence:   1446.63\n",
      "variational_beta * kldivergence:  0.14466\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37296\n",
      "kldivergence:   1628.43\n",
      "variational_beta * kldivergence:  0.16284\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32251\n",
      "kldivergence:   1615.51\n",
      "variational_beta * kldivergence:  0.16155\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31187\n",
      "kldivergence:   1505.14\n",
      "variational_beta * kldivergence:  0.15051\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31343\n",
      "kldivergence:   1512.19\n",
      "variational_beta * kldivergence:  0.15122\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.38762\n",
      "kldivergence:   1715.57\n",
      "variational_beta * kldivergence:  0.17156\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31152\n",
      "kldivergence:   1565.82\n",
      "variational_beta * kldivergence:  0.15658\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31458\n",
      "kldivergence:   1425.04\n",
      "variational_beta * kldivergence:  0.14250\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33276\n",
      "kldivergence:   1648.71\n",
      "variational_beta * kldivergence:  0.16487\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28402\n",
      "kldivergence:   1441.08\n",
      "variational_beta * kldivergence:  0.14411\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34478\n",
      "kldivergence:   1737.81\n",
      "variational_beta * kldivergence:  0.17378\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34520\n",
      "kldivergence:   1365.68\n",
      "variational_beta * kldivergence:  0.13657\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32251\n",
      "kldivergence:   1587.67\n",
      "variational_beta * kldivergence:  0.15877\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.39294\n",
      "kldivergence:   1821.90\n",
      "variational_beta * kldivergence:  0.18219\n",
      "batch accuracy: 86.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35770\n",
      "kldivergence:   1417.27\n",
      "variational_beta * kldivergence:  0.14173\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30428\n",
      "kldivergence:   1556.50\n",
      "variational_beta * kldivergence:  0.15565\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34794\n",
      "kldivergence:   1665.40\n",
      "variational_beta * kldivergence:  0.16654\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32161\n",
      "kldivergence:   1462.67\n",
      "variational_beta * kldivergence:  0.14627\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30249\n",
      "kldivergence:   1685.90\n",
      "variational_beta * kldivergence:  0.16859\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34448\n",
      "kldivergence:   1661.00\n",
      "variational_beta * kldivergence:  0.16610\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37646\n",
      "kldivergence:   1646.51\n",
      "variational_beta * kldivergence:  0.16465\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33940\n",
      "kldivergence:   1299.44\n",
      "variational_beta * kldivergence:  0.12994\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27374\n",
      "kldivergence:   1472.13\n",
      "variational_beta * kldivergence:  0.14721\n",
      "batch accuracy: 90.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32881\n",
      "kldivergence:   1531.11\n",
      "variational_beta * kldivergence:  0.15311\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33241\n",
      "kldivergence:   1569.58\n",
      "variational_beta * kldivergence:  0.15696\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.29785\n",
      "kldivergence:   1475.28\n",
      "variational_beta * kldivergence:  0.14753\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28971\n",
      "kldivergence:   1624.62\n",
      "variational_beta * kldivergence:  0.16246\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31048\n",
      "kldivergence:   1713.33\n",
      "variational_beta * kldivergence:  0.17133\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33783\n",
      "kldivergence:   1468.15\n",
      "variational_beta * kldivergence:  0.14681\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35056\n",
      "kldivergence:   1662.04\n",
      "variational_beta * kldivergence:  0.16620\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35169\n",
      "kldivergence:   1439.65\n",
      "variational_beta * kldivergence:  0.14397\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34795\n",
      "kldivergence:   1744.91\n",
      "variational_beta * kldivergence:  0.17449\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37991\n",
      "kldivergence:   1634.22\n",
      "variational_beta * kldivergence:  0.16342\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33962\n",
      "kldivergence:   1460.15\n",
      "variational_beta * kldivergence:  0.14602\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30709\n",
      "kldivergence:   1650.24\n",
      "variational_beta * kldivergence:  0.16502\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.28669\n",
      "kldivergence:   1496.10\n",
      "variational_beta * kldivergence:  0.14961\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32215\n",
      "kldivergence:   1511.57\n",
      "variational_beta * kldivergence:  0.15116\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.36839\n",
      "kldivergence:   1571.23\n",
      "variational_beta * kldivergence:  0.15712\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34275\n",
      "kldivergence:   1473.57\n",
      "variational_beta * kldivergence:  0.14736\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31782\n",
      "kldivergence:   1537.09\n",
      "variational_beta * kldivergence:  0.15371\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30898\n",
      "kldivergence:   1478.17\n",
      "variational_beta * kldivergence:  0.14782\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37771\n",
      "kldivergence:   1683.37\n",
      "variational_beta * kldivergence:  0.16834\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.26942\n",
      "kldivergence:   1663.46\n",
      "variational_beta * kldivergence:  0.16635\n",
      "batch accuracy: 91.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31878\n",
      "kldivergence:   1481.25\n",
      "variational_beta * kldivergence:  0.14812\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35497\n",
      "kldivergence:   1661.06\n",
      "variational_beta * kldivergence:  0.16611\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.27258\n",
      "kldivergence:   1536.94\n",
      "variational_beta * kldivergence:  0.15369\n",
      "batch accuracy: 90.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.37876\n",
      "kldivergence:   1615.04\n",
      "variational_beta * kldivergence:  0.16150\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.31671\n",
      "kldivergence:   1441.23\n",
      "variational_beta * kldivergence:  0.14412\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.24604\n",
      "kldivergence:   1493.91\n",
      "variational_beta * kldivergence:  0.14939\n",
      "batch accuracy: 92.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.34136\n",
      "kldivergence:   1693.26\n",
      "variational_beta * kldivergence:  0.16933\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.30935\n",
      "kldivergence:   1679.09\n",
      "variational_beta * kldivergence:  0.16791\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.32213\n",
      "kldivergence:   1498.43\n",
      "variational_beta * kldivergence:  0.14984\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.35200\n",
      "kldivergence:   1564.37\n",
      "variational_beta * kldivergence:  0.15644\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #35\n",
      "reconstruction loss: 0.33585\n",
      "kldivergence:   1636.36\n",
      "variational_beta * kldivergence:  0.16364\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.56197\n",
      "kldivergence:   1582.16\n",
      "variational_beta * kldivergence:  0.15822\n",
      "batch accuracy: 83.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.50736\n",
      "kldivergence:   1532.45\n",
      "variational_beta * kldivergence:  0.15325\n",
      "batch accuracy: 83.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.38563\n",
      "kldivergence:   1451.86\n",
      "variational_beta * kldivergence:  0.14519\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.42404\n",
      "kldivergence:   1444.02\n",
      "variational_beta * kldivergence:  0.14440\n",
      "batch accuracy: 86.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.42539\n",
      "kldivergence:   1470.88\n",
      "variational_beta * kldivergence:  0.14709\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.52535\n",
      "kldivergence:   1487.84\n",
      "variational_beta * kldivergence:  0.14878\n",
      "batch accuracy: 84.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.45167\n",
      "kldivergence:   1514.39\n",
      "variational_beta * kldivergence:  0.15144\n",
      "batch accuracy: 85.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.44804\n",
      "kldivergence:   1453.82\n",
      "variational_beta * kldivergence:  0.14538\n",
      "batch accuracy: 86.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.40117\n",
      "kldivergence:   1502.02\n",
      "variational_beta * kldivergence:  0.15020\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.50851\n",
      "kldivergence:   1574.99\n",
      "variational_beta * kldivergence:  0.15750\n",
      "batch accuracy: 85.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.49328\n",
      "kldivergence:   1557.33\n",
      "variational_beta * kldivergence:  0.15573\n",
      "batch accuracy: 85.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.45477\n",
      "kldivergence:   1555.93\n",
      "variational_beta * kldivergence:  0.15559\n",
      "batch accuracy: 86.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.49372\n",
      "kldivergence:   1486.52\n",
      "variational_beta * kldivergence:  0.14865\n",
      "batch accuracy: 85.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.43007\n",
      "kldivergence:   1531.12\n",
      "variational_beta * kldivergence:  0.15311\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.40177\n",
      "kldivergence:   1332.19\n",
      "variational_beta * kldivergence:  0.13322\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.53080\n",
      "kldivergence:   1579.61\n",
      "variational_beta * kldivergence:  0.15796\n",
      "batch accuracy: 83.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.40126\n",
      "kldivergence:   1394.75\n",
      "variational_beta * kldivergence:  0.13947\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.43636\n",
      "kldivergence:   1473.60\n",
      "variational_beta * kldivergence:  0.14736\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.43547\n",
      "kldivergence:   1417.74\n",
      "variational_beta * kldivergence:  0.14177\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.48298\n",
      "kldivergence:   1485.22\n",
      "variational_beta * kldivergence:  0.14852\n",
      "batch accuracy: 84.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.53997\n",
      "kldivergence:   1649.49\n",
      "variational_beta * kldivergence:  0.16495\n",
      "batch accuracy: 83.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.44448\n",
      "kldivergence:   1460.85\n",
      "variational_beta * kldivergence:  0.14608\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.38142\n",
      "kldivergence:   1444.23\n",
      "variational_beta * kldivergence:  0.14442\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.43516\n",
      "kldivergence:   1448.99\n",
      "variational_beta * kldivergence:  0.14490\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.40159\n",
      "kldivergence:   1418.95\n",
      "variational_beta * kldivergence:  0.14189\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.41420\n",
      "kldivergence:   1450.91\n",
      "variational_beta * kldivergence:  0.14509\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.44343\n",
      "kldivergence:   1552.71\n",
      "variational_beta * kldivergence:  0.15527\n",
      "batch accuracy: 86.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.39522\n",
      "kldivergence:   1417.44\n",
      "variational_beta * kldivergence:  0.14174\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.40447\n",
      "kldivergence:   1418.06\n",
      "variational_beta * kldivergence:  0.14181\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.42704\n",
      "kldivergence:   1518.16\n",
      "variational_beta * kldivergence:  0.15182\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.39461\n",
      "kldivergence:   1488.13\n",
      "variational_beta * kldivergence:  0.14881\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.39311\n",
      "kldivergence:   1426.88\n",
      "variational_beta * kldivergence:  0.14269\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.48702\n",
      "kldivergence:   1492.37\n",
      "variational_beta * kldivergence:  0.14924\n",
      "batch accuracy: 85.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.52911\n",
      "kldivergence:   1768.04\n",
      "variational_beta * kldivergence:  0.17680\n",
      "batch accuracy: 83.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.51295\n",
      "kldivergence:   1631.30\n",
      "variational_beta * kldivergence:  0.16313\n",
      "batch accuracy: 84.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.48705\n",
      "kldivergence:   1605.43\n",
      "variational_beta * kldivergence:  0.16054\n",
      "batch accuracy: 85.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.40192\n",
      "kldivergence:   1504.24\n",
      "variational_beta * kldivergence:  0.15042\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.44722\n",
      "kldivergence:   1433.37\n",
      "variational_beta * kldivergence:  0.14334\n",
      "batch accuracy: 85.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.41683\n",
      "kldivergence:   1485.30\n",
      "variational_beta * kldivergence:  0.14853\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.45270\n",
      "kldivergence:   1511.76\n",
      "variational_beta * kldivergence:  0.15118\n",
      "batch accuracy: 85.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.42222\n",
      "kldivergence:   1589.60\n",
      "variational_beta * kldivergence:  0.15896\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.50612\n",
      "kldivergence:   1579.37\n",
      "variational_beta * kldivergence:  0.15794\n",
      "batch accuracy: 85.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.49101\n",
      "kldivergence:   1567.56\n",
      "variational_beta * kldivergence:  0.15676\n",
      "batch accuracy: 85.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.39691\n",
      "kldivergence:   1420.11\n",
      "variational_beta * kldivergence:  0.14201\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.49063\n",
      "kldivergence:   1576.82\n",
      "variational_beta * kldivergence:  0.15768\n",
      "batch accuracy: 85.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.45633\n",
      "kldivergence:   1460.52\n",
      "variational_beta * kldivergence:  0.14605\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.41777\n",
      "kldivergence:   1438.83\n",
      "variational_beta * kldivergence:  0.14388\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.55195\n",
      "kldivergence:   1617.77\n",
      "variational_beta * kldivergence:  0.16178\n",
      "batch accuracy: 83.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.37259\n",
      "kldivergence:   1371.26\n",
      "variational_beta * kldivergence:  0.13713\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.37456\n",
      "kldivergence:   1471.63\n",
      "variational_beta * kldivergence:  0.14716\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.45855\n",
      "kldivergence:   1430.24\n",
      "variational_beta * kldivergence:  0.14302\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.49707\n",
      "kldivergence:   1633.76\n",
      "variational_beta * kldivergence:  0.16338\n",
      "batch accuracy: 85.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.50823\n",
      "kldivergence:   1429.22\n",
      "variational_beta * kldivergence:  0.14292\n",
      "batch accuracy: 85.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.45238\n",
      "kldivergence:   1436.61\n",
      "variational_beta * kldivergence:  0.14366\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.45431\n",
      "kldivergence:   1501.30\n",
      "variational_beta * kldivergence:  0.15013\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.44812\n",
      "kldivergence:   1429.32\n",
      "variational_beta * kldivergence:  0.14293\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.40897\n",
      "kldivergence:   1409.35\n",
      "variational_beta * kldivergence:  0.14094\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.48071\n",
      "kldivergence:   1585.47\n",
      "variational_beta * kldivergence:  0.15855\n",
      "batch accuracy: 85.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.47359\n",
      "kldivergence:   1496.91\n",
      "variational_beta * kldivergence:  0.14969\n",
      "batch accuracy: 85.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.45204\n",
      "kldivergence:   1460.30\n",
      "variational_beta * kldivergence:  0.14603\n",
      "batch accuracy: 85.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.39560\n",
      "kldivergence:   1467.24\n",
      "variational_beta * kldivergence:  0.14672\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #35\n",
      "reconstruction loss: 0.46450\n",
      "kldivergence:   1538.17\n",
      "variational_beta * kldivergence:  0.15382\n",
      "batch accuracy: 85.76\n",
      "\n",
      "\n",
      "epoch # 35 : train loss is [182.2896426812955] and validation loss is [0.10072877620965232] \n",
      "Epoch [36 / 150] average reconstruction error: 0.491347\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29378\n",
      "kldivergence:   1497.07\n",
      "variational_beta * kldivergence:  0.14971\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33518\n",
      "kldivergence:   1773.50\n",
      "variational_beta * kldivergence:  0.17735\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32523\n",
      "kldivergence:   1707.76\n",
      "variational_beta * kldivergence:  0.17078\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31357\n",
      "kldivergence:   1512.74\n",
      "variational_beta * kldivergence:  0.15127\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29570\n",
      "kldivergence:   1497.35\n",
      "variational_beta * kldivergence:  0.14974\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36076\n",
      "kldivergence:   1692.52\n",
      "variational_beta * kldivergence:  0.16925\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.39054\n",
      "kldivergence:   1666.77\n",
      "variational_beta * kldivergence:  0.16668\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34503\n",
      "kldivergence:   1698.05\n",
      "variational_beta * kldivergence:  0.16980\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29535\n",
      "kldivergence:   1538.85\n",
      "variational_beta * kldivergence:  0.15389\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34033\n",
      "kldivergence:   1608.38\n",
      "variational_beta * kldivergence:  0.16084\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33020\n",
      "kldivergence:   1641.57\n",
      "variational_beta * kldivergence:  0.16416\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28344\n",
      "kldivergence:   1412.53\n",
      "variational_beta * kldivergence:  0.14125\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35400\n",
      "kldivergence:   1515.94\n",
      "variational_beta * kldivergence:  0.15159\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31211\n",
      "kldivergence:   1624.39\n",
      "variational_beta * kldivergence:  0.16244\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35514\n",
      "kldivergence:   1633.82\n",
      "variational_beta * kldivergence:  0.16338\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36582\n",
      "kldivergence:   1518.36\n",
      "variational_beta * kldivergence:  0.15184\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36762\n",
      "kldivergence:   1650.95\n",
      "variational_beta * kldivergence:  0.16510\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30539\n",
      "kldivergence:   1478.08\n",
      "variational_beta * kldivergence:  0.14781\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32003\n",
      "kldivergence:   1733.99\n",
      "variational_beta * kldivergence:  0.17340\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.40603\n",
      "kldivergence:   1868.22\n",
      "variational_beta * kldivergence:  0.18682\n",
      "batch accuracy: 86.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34106\n",
      "kldivergence:   1580.84\n",
      "variational_beta * kldivergence:  0.15808\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36441\n",
      "kldivergence:   1996.68\n",
      "variational_beta * kldivergence:  0.19967\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30634\n",
      "kldivergence:   1607.28\n",
      "variational_beta * kldivergence:  0.16073\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32860\n",
      "kldivergence:   1587.26\n",
      "variational_beta * kldivergence:  0.15873\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35796\n",
      "kldivergence:   1597.57\n",
      "variational_beta * kldivergence:  0.15976\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37006\n",
      "kldivergence:   1804.34\n",
      "variational_beta * kldivergence:  0.18043\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32215\n",
      "kldivergence:   1575.65\n",
      "variational_beta * kldivergence:  0.15756\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32711\n",
      "kldivergence:   1948.15\n",
      "variational_beta * kldivergence:  0.19482\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33927\n",
      "kldivergence:   1861.29\n",
      "variational_beta * kldivergence:  0.18613\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31657\n",
      "kldivergence:   1579.51\n",
      "variational_beta * kldivergence:  0.15795\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33789\n",
      "kldivergence:   1681.19\n",
      "variational_beta * kldivergence:  0.16812\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34973\n",
      "kldivergence:   1642.27\n",
      "variational_beta * kldivergence:  0.16423\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30058\n",
      "kldivergence:   1647.00\n",
      "variational_beta * kldivergence:  0.16470\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35498\n",
      "kldivergence:   1701.28\n",
      "variational_beta * kldivergence:  0.17013\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34557\n",
      "kldivergence:   1725.39\n",
      "variational_beta * kldivergence:  0.17254\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33881\n",
      "kldivergence:   1619.12\n",
      "variational_beta * kldivergence:  0.16191\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32243\n",
      "kldivergence:   1594.97\n",
      "variational_beta * kldivergence:  0.15950\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29562\n",
      "kldivergence:   1573.55\n",
      "variational_beta * kldivergence:  0.15735\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.25188\n",
      "kldivergence:   1378.80\n",
      "variational_beta * kldivergence:  0.13788\n",
      "batch accuracy: 91.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37768\n",
      "kldivergence:   1670.28\n",
      "variational_beta * kldivergence:  0.16703\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34205\n",
      "kldivergence:   1578.42\n",
      "variational_beta * kldivergence:  0.15784\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.27732\n",
      "kldivergence:   1727.00\n",
      "variational_beta * kldivergence:  0.17270\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35725\n",
      "kldivergence:   1624.52\n",
      "variational_beta * kldivergence:  0.16245\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.40339\n",
      "kldivergence:   1808.83\n",
      "variational_beta * kldivergence:  0.18088\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32073\n",
      "kldivergence:   1653.93\n",
      "variational_beta * kldivergence:  0.16539\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33361\n",
      "kldivergence:   1616.69\n",
      "variational_beta * kldivergence:  0.16167\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.39563\n",
      "kldivergence:   1910.86\n",
      "variational_beta * kldivergence:  0.19109\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33996\n",
      "kldivergence:   1389.58\n",
      "variational_beta * kldivergence:  0.13896\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36458\n",
      "kldivergence:   1669.61\n",
      "variational_beta * kldivergence:  0.16696\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35922\n",
      "kldivergence:   1518.38\n",
      "variational_beta * kldivergence:  0.15184\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30410\n",
      "kldivergence:   1654.66\n",
      "variational_beta * kldivergence:  0.16547\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.26081\n",
      "kldivergence:   1440.10\n",
      "variational_beta * kldivergence:  0.14401\n",
      "batch accuracy: 91.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37117\n",
      "kldivergence:   1927.38\n",
      "variational_beta * kldivergence:  0.19274\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34788\n",
      "kldivergence:   1393.39\n",
      "variational_beta * kldivergence:  0.13934\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32366\n",
      "kldivergence:   1445.19\n",
      "variational_beta * kldivergence:  0.14452\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32075\n",
      "kldivergence:   1586.54\n",
      "variational_beta * kldivergence:  0.15865\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35906\n",
      "kldivergence:   1690.18\n",
      "variational_beta * kldivergence:  0.16902\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32369\n",
      "kldivergence:   1623.56\n",
      "variational_beta * kldivergence:  0.16236\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30155\n",
      "kldivergence:   1644.54\n",
      "variational_beta * kldivergence:  0.16445\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29876\n",
      "kldivergence:   1707.83\n",
      "variational_beta * kldivergence:  0.17078\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29400\n",
      "kldivergence:   1574.39\n",
      "variational_beta * kldivergence:  0.15744\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31365\n",
      "kldivergence:   1635.14\n",
      "variational_beta * kldivergence:  0.16351\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37512\n",
      "kldivergence:   1703.16\n",
      "variational_beta * kldivergence:  0.17032\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36554\n",
      "kldivergence:   1492.25\n",
      "variational_beta * kldivergence:  0.14923\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29789\n",
      "kldivergence:   1460.01\n",
      "variational_beta * kldivergence:  0.14600\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34776\n",
      "kldivergence:   1561.23\n",
      "variational_beta * kldivergence:  0.15612\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30573\n",
      "kldivergence:   1436.58\n",
      "variational_beta * kldivergence:  0.14366\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34759\n",
      "kldivergence:   1577.13\n",
      "variational_beta * kldivergence:  0.15771\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32382\n",
      "kldivergence:   1595.84\n",
      "variational_beta * kldivergence:  0.15958\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34614\n",
      "kldivergence:   1309.44\n",
      "variational_beta * kldivergence:  0.13094\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35308\n",
      "kldivergence:   1652.37\n",
      "variational_beta * kldivergence:  0.16524\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36216\n",
      "kldivergence:   1739.73\n",
      "variational_beta * kldivergence:  0.17397\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29030\n",
      "kldivergence:   1498.96\n",
      "variational_beta * kldivergence:  0.14990\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38349\n",
      "kldivergence:   1695.97\n",
      "variational_beta * kldivergence:  0.16960\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34694\n",
      "kldivergence:   1707.57\n",
      "variational_beta * kldivergence:  0.17076\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.39812\n",
      "kldivergence:   1694.52\n",
      "variational_beta * kldivergence:  0.16945\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29186\n",
      "kldivergence:   1445.89\n",
      "variational_beta * kldivergence:  0.14459\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32892\n",
      "kldivergence:   1658.67\n",
      "variational_beta * kldivergence:  0.16587\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31121\n",
      "kldivergence:   1448.55\n",
      "variational_beta * kldivergence:  0.14485\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37002\n",
      "kldivergence:   1647.39\n",
      "variational_beta * kldivergence:  0.16474\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35671\n",
      "kldivergence:   1685.01\n",
      "variational_beta * kldivergence:  0.16850\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33688\n",
      "kldivergence:   1421.40\n",
      "variational_beta * kldivergence:  0.14214\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.27561\n",
      "kldivergence:   1565.04\n",
      "variational_beta * kldivergence:  0.15650\n",
      "batch accuracy: 90.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33990\n",
      "kldivergence:   1441.55\n",
      "variational_beta * kldivergence:  0.14415\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33192\n",
      "kldivergence:   1506.19\n",
      "variational_beta * kldivergence:  0.15062\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33577\n",
      "kldivergence:   1543.77\n",
      "variational_beta * kldivergence:  0.15438\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36970\n",
      "kldivergence:   1553.67\n",
      "variational_beta * kldivergence:  0.15537\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30132\n",
      "kldivergence:   1361.06\n",
      "variational_beta * kldivergence:  0.13611\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30462\n",
      "kldivergence:   1493.17\n",
      "variational_beta * kldivergence:  0.14932\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29292\n",
      "kldivergence:   1434.06\n",
      "variational_beta * kldivergence:  0.14341\n",
      "batch accuracy: 90.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33184\n",
      "kldivergence:   1761.15\n",
      "variational_beta * kldivergence:  0.17611\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35082\n",
      "kldivergence:   1550.88\n",
      "variational_beta * kldivergence:  0.15509\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37789\n",
      "kldivergence:   1746.56\n",
      "variational_beta * kldivergence:  0.17466\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31096\n",
      "kldivergence:   1509.50\n",
      "variational_beta * kldivergence:  0.15095\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31727\n",
      "kldivergence:   1659.52\n",
      "variational_beta * kldivergence:  0.16595\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35406\n",
      "kldivergence:   1739.72\n",
      "variational_beta * kldivergence:  0.17397\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32470\n",
      "kldivergence:   1507.20\n",
      "variational_beta * kldivergence:  0.15072\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38414\n",
      "kldivergence:   1895.09\n",
      "variational_beta * kldivergence:  0.18951\n",
      "batch accuracy: 87.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33065\n",
      "kldivergence:   1759.72\n",
      "variational_beta * kldivergence:  0.17597\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.39331\n",
      "kldivergence:   1696.08\n",
      "variational_beta * kldivergence:  0.16961\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33860\n",
      "kldivergence:   1670.81\n",
      "variational_beta * kldivergence:  0.16708\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35472\n",
      "kldivergence:   1602.82\n",
      "variational_beta * kldivergence:  0.16028\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33148\n",
      "kldivergence:   1499.87\n",
      "variational_beta * kldivergence:  0.14999\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30139\n",
      "kldivergence:   1395.43\n",
      "variational_beta * kldivergence:  0.13954\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30715\n",
      "kldivergence:   1612.58\n",
      "variational_beta * kldivergence:  0.16126\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35193\n",
      "kldivergence:   1564.61\n",
      "variational_beta * kldivergence:  0.15646\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31686\n",
      "kldivergence:   1487.94\n",
      "variational_beta * kldivergence:  0.14879\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.27605\n",
      "kldivergence:   1351.70\n",
      "variational_beta * kldivergence:  0.13517\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35712\n",
      "kldivergence:   1524.71\n",
      "variational_beta * kldivergence:  0.15247\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38365\n",
      "kldivergence:   1519.50\n",
      "variational_beta * kldivergence:  0.15195\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37339\n",
      "kldivergence:   1889.69\n",
      "variational_beta * kldivergence:  0.18897\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28073\n",
      "kldivergence:   1466.48\n",
      "variational_beta * kldivergence:  0.14665\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29162\n",
      "kldivergence:   1520.68\n",
      "variational_beta * kldivergence:  0.15207\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31880\n",
      "kldivergence:   1537.85\n",
      "variational_beta * kldivergence:  0.15379\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.40544\n",
      "kldivergence:   1839.30\n",
      "variational_beta * kldivergence:  0.18393\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34694\n",
      "kldivergence:   1450.78\n",
      "variational_beta * kldivergence:  0.14508\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28778\n",
      "kldivergence:   1454.58\n",
      "variational_beta * kldivergence:  0.14546\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33623\n",
      "kldivergence:   1681.79\n",
      "variational_beta * kldivergence:  0.16818\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33618\n",
      "kldivergence:   1467.40\n",
      "variational_beta * kldivergence:  0.14674\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33224\n",
      "kldivergence:   1512.82\n",
      "variational_beta * kldivergence:  0.15128\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30988\n",
      "kldivergence:   1631.64\n",
      "variational_beta * kldivergence:  0.16316\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32813\n",
      "kldivergence:   1661.82\n",
      "variational_beta * kldivergence:  0.16618\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33872\n",
      "kldivergence:   1510.08\n",
      "variational_beta * kldivergence:  0.15101\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29143\n",
      "kldivergence:   1421.46\n",
      "variational_beta * kldivergence:  0.14215\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33180\n",
      "kldivergence:   1575.06\n",
      "variational_beta * kldivergence:  0.15751\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36036\n",
      "kldivergence:   1650.15\n",
      "variational_beta * kldivergence:  0.16502\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35983\n",
      "kldivergence:   1810.84\n",
      "variational_beta * kldivergence:  0.18108\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32160\n",
      "kldivergence:   1487.52\n",
      "variational_beta * kldivergence:  0.14875\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.39225\n",
      "kldivergence:   1626.22\n",
      "variational_beta * kldivergence:  0.16262\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35761\n",
      "kldivergence:   1482.37\n",
      "variational_beta * kldivergence:  0.14824\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30595\n",
      "kldivergence:   1258.37\n",
      "variational_beta * kldivergence:  0.12584\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31144\n",
      "kldivergence:   1594.32\n",
      "variational_beta * kldivergence:  0.15943\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33152\n",
      "kldivergence:   1646.62\n",
      "variational_beta * kldivergence:  0.16466\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33028\n",
      "kldivergence:   1461.48\n",
      "variational_beta * kldivergence:  0.14615\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31689\n",
      "kldivergence:   1484.63\n",
      "variational_beta * kldivergence:  0.14846\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28059\n",
      "kldivergence:   1454.20\n",
      "variational_beta * kldivergence:  0.14542\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32250\n",
      "kldivergence:   1615.37\n",
      "variational_beta * kldivergence:  0.16154\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.27989\n",
      "kldivergence:   1449.85\n",
      "variational_beta * kldivergence:  0.14499\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.40130\n",
      "kldivergence:   1727.92\n",
      "variational_beta * kldivergence:  0.17279\n",
      "batch accuracy: 86.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37429\n",
      "kldivergence:   1565.74\n",
      "variational_beta * kldivergence:  0.15657\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33295\n",
      "kldivergence:   1508.97\n",
      "variational_beta * kldivergence:  0.15090\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36787\n",
      "kldivergence:   1550.12\n",
      "variational_beta * kldivergence:  0.15501\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30839\n",
      "kldivergence:   1504.55\n",
      "variational_beta * kldivergence:  0.15045\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33908\n",
      "kldivergence:   1544.03\n",
      "variational_beta * kldivergence:  0.15440\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33503\n",
      "kldivergence:   1544.31\n",
      "variational_beta * kldivergence:  0.15443\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33523\n",
      "kldivergence:   1513.70\n",
      "variational_beta * kldivergence:  0.15137\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37012\n",
      "kldivergence:   1583.32\n",
      "variational_beta * kldivergence:  0.15833\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30424\n",
      "kldivergence:   1782.40\n",
      "variational_beta * kldivergence:  0.17824\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30490\n",
      "kldivergence:   1549.26\n",
      "variational_beta * kldivergence:  0.15493\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34094\n",
      "kldivergence:   1687.83\n",
      "variational_beta * kldivergence:  0.16878\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34391\n",
      "kldivergence:   1376.17\n",
      "variational_beta * kldivergence:  0.13762\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33886\n",
      "kldivergence:   1973.71\n",
      "variational_beta * kldivergence:  0.19737\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33709\n",
      "kldivergence:   1698.01\n",
      "variational_beta * kldivergence:  0.16980\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36806\n",
      "kldivergence:   1570.94\n",
      "variational_beta * kldivergence:  0.15709\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38930\n",
      "kldivergence:   1527.13\n",
      "variational_beta * kldivergence:  0.15271\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31966\n",
      "kldivergence:   1471.15\n",
      "variational_beta * kldivergence:  0.14711\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30733\n",
      "kldivergence:   1645.96\n",
      "variational_beta * kldivergence:  0.16460\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32976\n",
      "kldivergence:   1673.10\n",
      "variational_beta * kldivergence:  0.16731\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34757\n",
      "kldivergence:   1619.72\n",
      "variational_beta * kldivergence:  0.16197\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31042\n",
      "kldivergence:   1560.16\n",
      "variational_beta * kldivergence:  0.15602\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34730\n",
      "kldivergence:   1524.20\n",
      "variational_beta * kldivergence:  0.15242\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31011\n",
      "kldivergence:   1573.48\n",
      "variational_beta * kldivergence:  0.15735\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33725\n",
      "kldivergence:   1596.93\n",
      "variational_beta * kldivergence:  0.15969\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32715\n",
      "kldivergence:   1593.74\n",
      "variational_beta * kldivergence:  0.15937\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34498\n",
      "kldivergence:   1511.46\n",
      "variational_beta * kldivergence:  0.15115\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35480\n",
      "kldivergence:   1704.80\n",
      "variational_beta * kldivergence:  0.17048\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36232\n",
      "kldivergence:   1483.81\n",
      "variational_beta * kldivergence:  0.14838\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.27146\n",
      "kldivergence:   1287.89\n",
      "variational_beta * kldivergence:  0.12879\n",
      "batch accuracy: 90.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32018\n",
      "kldivergence:   1416.54\n",
      "variational_beta * kldivergence:  0.14165\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35914\n",
      "kldivergence:   1735.27\n",
      "variational_beta * kldivergence:  0.17353\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35134\n",
      "kldivergence:   1515.45\n",
      "variational_beta * kldivergence:  0.15155\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31692\n",
      "kldivergence:   1486.84\n",
      "variational_beta * kldivergence:  0.14868\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32273\n",
      "kldivergence:   1470.71\n",
      "variational_beta * kldivergence:  0.14707\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34289\n",
      "kldivergence:   1639.40\n",
      "variational_beta * kldivergence:  0.16394\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.39931\n",
      "kldivergence:   1611.06\n",
      "variational_beta * kldivergence:  0.16111\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28718\n",
      "kldivergence:   1402.09\n",
      "variational_beta * kldivergence:  0.14021\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38658\n",
      "kldivergence:   1706.15\n",
      "variational_beta * kldivergence:  0.17061\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.26627\n",
      "kldivergence:   1594.64\n",
      "variational_beta * kldivergence:  0.15946\n",
      "batch accuracy: 91.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.27822\n",
      "kldivergence:   1400.90\n",
      "variational_beta * kldivergence:  0.14009\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35271\n",
      "kldivergence:   1574.50\n",
      "variational_beta * kldivergence:  0.15745\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.39107\n",
      "kldivergence:   2060.69\n",
      "variational_beta * kldivergence:  0.20607\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32278\n",
      "kldivergence:   1752.15\n",
      "variational_beta * kldivergence:  0.17521\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34357\n",
      "kldivergence:   1712.64\n",
      "variational_beta * kldivergence:  0.17126\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28407\n",
      "kldivergence:   1591.35\n",
      "variational_beta * kldivergence:  0.15913\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29370\n",
      "kldivergence:   1691.26\n",
      "variational_beta * kldivergence:  0.16913\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34466\n",
      "kldivergence:   1704.35\n",
      "variational_beta * kldivergence:  0.17044\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33238\n",
      "kldivergence:   1771.87\n",
      "variational_beta * kldivergence:  0.17719\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.39537\n",
      "kldivergence:   1784.84\n",
      "variational_beta * kldivergence:  0.17848\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32738\n",
      "kldivergence:   1591.05\n",
      "variational_beta * kldivergence:  0.15910\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35882\n",
      "kldivergence:   1858.95\n",
      "variational_beta * kldivergence:  0.18589\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30670\n",
      "kldivergence:   1659.26\n",
      "variational_beta * kldivergence:  0.16593\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34030\n",
      "kldivergence:   1836.62\n",
      "variational_beta * kldivergence:  0.18366\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32768\n",
      "kldivergence:   1766.94\n",
      "variational_beta * kldivergence:  0.17669\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37188\n",
      "kldivergence:   1751.93\n",
      "variational_beta * kldivergence:  0.17519\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.27931\n",
      "kldivergence:   1669.31\n",
      "variational_beta * kldivergence:  0.16693\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30568\n",
      "kldivergence:   1417.98\n",
      "variational_beta * kldivergence:  0.14180\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.41782\n",
      "kldivergence:   2011.06\n",
      "variational_beta * kldivergence:  0.20111\n",
      "batch accuracy: 86.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31152\n",
      "kldivergence:   1930.96\n",
      "variational_beta * kldivergence:  0.19310\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.39790\n",
      "kldivergence:   1935.07\n",
      "variational_beta * kldivergence:  0.19351\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31935\n",
      "kldivergence:   1551.62\n",
      "variational_beta * kldivergence:  0.15516\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33576\n",
      "kldivergence:   1734.76\n",
      "variational_beta * kldivergence:  0.17348\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33002\n",
      "kldivergence:   1609.37\n",
      "variational_beta * kldivergence:  0.16094\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32763\n",
      "kldivergence:   1367.07\n",
      "variational_beta * kldivergence:  0.13671\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33476\n",
      "kldivergence:   1789.19\n",
      "variational_beta * kldivergence:  0.17892\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29625\n",
      "kldivergence:   1818.99\n",
      "variational_beta * kldivergence:  0.18190\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33209\n",
      "kldivergence:   1799.19\n",
      "variational_beta * kldivergence:  0.17992\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36526\n",
      "kldivergence:   1802.09\n",
      "variational_beta * kldivergence:  0.18021\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32459\n",
      "kldivergence:   1746.95\n",
      "variational_beta * kldivergence:  0.17470\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32881\n",
      "kldivergence:   1714.34\n",
      "variational_beta * kldivergence:  0.17143\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32160\n",
      "kldivergence:   1619.61\n",
      "variational_beta * kldivergence:  0.16196\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33892\n",
      "kldivergence:   1426.60\n",
      "variational_beta * kldivergence:  0.14266\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36072\n",
      "kldivergence:   1693.67\n",
      "variational_beta * kldivergence:  0.16937\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32853\n",
      "kldivergence:   1700.26\n",
      "variational_beta * kldivergence:  0.17003\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31337\n",
      "kldivergence:   1496.55\n",
      "variational_beta * kldivergence:  0.14965\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34105\n",
      "kldivergence:   1752.70\n",
      "variational_beta * kldivergence:  0.17527\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36869\n",
      "kldivergence:   1561.10\n",
      "variational_beta * kldivergence:  0.15611\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29330\n",
      "kldivergence:   1413.80\n",
      "variational_beta * kldivergence:  0.14138\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33888\n",
      "kldivergence:   1794.07\n",
      "variational_beta * kldivergence:  0.17941\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31291\n",
      "kldivergence:   1672.44\n",
      "variational_beta * kldivergence:  0.16724\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33597\n",
      "kldivergence:   1462.36\n",
      "variational_beta * kldivergence:  0.14624\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32875\n",
      "kldivergence:   1569.23\n",
      "variational_beta * kldivergence:  0.15692\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35981\n",
      "kldivergence:   1790.46\n",
      "variational_beta * kldivergence:  0.17905\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29918\n",
      "kldivergence:   1445.40\n",
      "variational_beta * kldivergence:  0.14454\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28471\n",
      "kldivergence:   1595.97\n",
      "variational_beta * kldivergence:  0.15960\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31203\n",
      "kldivergence:   1579.04\n",
      "variational_beta * kldivergence:  0.15790\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37338\n",
      "kldivergence:   1723.87\n",
      "variational_beta * kldivergence:  0.17239\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34394\n",
      "kldivergence:   1666.14\n",
      "variational_beta * kldivergence:  0.16661\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35448\n",
      "kldivergence:   1594.16\n",
      "variational_beta * kldivergence:  0.15942\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29877\n",
      "kldivergence:   1857.35\n",
      "variational_beta * kldivergence:  0.18574\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34206\n",
      "kldivergence:   1791.38\n",
      "variational_beta * kldivergence:  0.17914\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38063\n",
      "kldivergence:   1673.93\n",
      "variational_beta * kldivergence:  0.16739\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29476\n",
      "kldivergence:   1360.78\n",
      "variational_beta * kldivergence:  0.13608\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36651\n",
      "kldivergence:   1659.63\n",
      "variational_beta * kldivergence:  0.16596\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30635\n",
      "kldivergence:   1448.69\n",
      "variational_beta * kldivergence:  0.14487\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32692\n",
      "kldivergence:   1885.81\n",
      "variational_beta * kldivergence:  0.18858\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35308\n",
      "kldivergence:   1599.98\n",
      "variational_beta * kldivergence:  0.16000\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33821\n",
      "kldivergence:   1527.92\n",
      "variational_beta * kldivergence:  0.15279\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.40227\n",
      "kldivergence:   1535.53\n",
      "variational_beta * kldivergence:  0.15355\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33216\n",
      "kldivergence:   1535.09\n",
      "variational_beta * kldivergence:  0.15351\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32567\n",
      "kldivergence:   1573.55\n",
      "variational_beta * kldivergence:  0.15736\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30707\n",
      "kldivergence:   1496.96\n",
      "variational_beta * kldivergence:  0.14970\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34839\n",
      "kldivergence:   1716.52\n",
      "variational_beta * kldivergence:  0.17165\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31724\n",
      "kldivergence:   1488.93\n",
      "variational_beta * kldivergence:  0.14889\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32683\n",
      "kldivergence:   1478.70\n",
      "variational_beta * kldivergence:  0.14787\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34118\n",
      "kldivergence:   1798.12\n",
      "variational_beta * kldivergence:  0.17981\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32623\n",
      "kldivergence:   1893.02\n",
      "variational_beta * kldivergence:  0.18930\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.26383\n",
      "kldivergence:   1431.72\n",
      "variational_beta * kldivergence:  0.14317\n",
      "batch accuracy: 91.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31325\n",
      "kldivergence:   1629.36\n",
      "variational_beta * kldivergence:  0.16294\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38954\n",
      "kldivergence:   1758.09\n",
      "variational_beta * kldivergence:  0.17581\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31495\n",
      "kldivergence:   1518.91\n",
      "variational_beta * kldivergence:  0.15189\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33938\n",
      "kldivergence:   1403.14\n",
      "variational_beta * kldivergence:  0.14031\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34494\n",
      "kldivergence:   1583.47\n",
      "variational_beta * kldivergence:  0.15835\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34447\n",
      "kldivergence:   1532.92\n",
      "variational_beta * kldivergence:  0.15329\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29733\n",
      "kldivergence:   1747.25\n",
      "variational_beta * kldivergence:  0.17472\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33822\n",
      "kldivergence:   1441.66\n",
      "variational_beta * kldivergence:  0.14417\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34671\n",
      "kldivergence:   1576.06\n",
      "variational_beta * kldivergence:  0.15761\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.27478\n",
      "kldivergence:   1479.67\n",
      "variational_beta * kldivergence:  0.14797\n",
      "batch accuracy: 90.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33743\n",
      "kldivergence:   1594.82\n",
      "variational_beta * kldivergence:  0.15948\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31635\n",
      "kldivergence:   1481.74\n",
      "variational_beta * kldivergence:  0.14817\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30024\n",
      "kldivergence:   1444.10\n",
      "variational_beta * kldivergence:  0.14441\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34709\n",
      "kldivergence:   1661.05\n",
      "variational_beta * kldivergence:  0.16610\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33112\n",
      "kldivergence:   1753.51\n",
      "variational_beta * kldivergence:  0.17535\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33208\n",
      "kldivergence:   1667.11\n",
      "variational_beta * kldivergence:  0.16671\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30583\n",
      "kldivergence:   1270.12\n",
      "variational_beta * kldivergence:  0.12701\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33411\n",
      "kldivergence:   1499.90\n",
      "variational_beta * kldivergence:  0.14999\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31686\n",
      "kldivergence:   1698.20\n",
      "variational_beta * kldivergence:  0.16982\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31690\n",
      "kldivergence:   1569.33\n",
      "variational_beta * kldivergence:  0.15693\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33105\n",
      "kldivergence:   1353.73\n",
      "variational_beta * kldivergence:  0.13537\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30055\n",
      "kldivergence:   1545.24\n",
      "variational_beta * kldivergence:  0.15452\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35039\n",
      "kldivergence:   1456.97\n",
      "variational_beta * kldivergence:  0.14570\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33147\n",
      "kldivergence:   1460.10\n",
      "variational_beta * kldivergence:  0.14601\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38373\n",
      "kldivergence:   1603.85\n",
      "variational_beta * kldivergence:  0.16039\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35036\n",
      "kldivergence:   1620.32\n",
      "variational_beta * kldivergence:  0.16203\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35311\n",
      "kldivergence:   1476.53\n",
      "variational_beta * kldivergence:  0.14765\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36621\n",
      "kldivergence:   1691.52\n",
      "variational_beta * kldivergence:  0.16915\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32162\n",
      "kldivergence:   1731.33\n",
      "variational_beta * kldivergence:  0.17313\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31037\n",
      "kldivergence:   1397.59\n",
      "variational_beta * kldivergence:  0.13976\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34335\n",
      "kldivergence:   1669.26\n",
      "variational_beta * kldivergence:  0.16693\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34137\n",
      "kldivergence:   1620.02\n",
      "variational_beta * kldivergence:  0.16200\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33951\n",
      "kldivergence:   1517.03\n",
      "variational_beta * kldivergence:  0.15170\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36455\n",
      "kldivergence:   1596.98\n",
      "variational_beta * kldivergence:  0.15970\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28308\n",
      "kldivergence:   1985.09\n",
      "variational_beta * kldivergence:  0.19851\n",
      "batch accuracy: 90.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32948\n",
      "kldivergence:   1611.80\n",
      "variational_beta * kldivergence:  0.16118\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32306\n",
      "kldivergence:   1432.28\n",
      "variational_beta * kldivergence:  0.14323\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34143\n",
      "kldivergence:   1473.59\n",
      "variational_beta * kldivergence:  0.14736\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34544\n",
      "kldivergence:   1567.15\n",
      "variational_beta * kldivergence:  0.15672\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28120\n",
      "kldivergence:   1411.77\n",
      "variational_beta * kldivergence:  0.14118\n",
      "batch accuracy: 90.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31486\n",
      "kldivergence:   1417.54\n",
      "variational_beta * kldivergence:  0.14175\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31771\n",
      "kldivergence:   1506.91\n",
      "variational_beta * kldivergence:  0.15069\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34484\n",
      "kldivergence:   1588.31\n",
      "variational_beta * kldivergence:  0.15883\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32479\n",
      "kldivergence:   1589.88\n",
      "variational_beta * kldivergence:  0.15899\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38201\n",
      "kldivergence:   1593.61\n",
      "variational_beta * kldivergence:  0.15936\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32542\n",
      "kldivergence:   1670.71\n",
      "variational_beta * kldivergence:  0.16707\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33945\n",
      "kldivergence:   1688.69\n",
      "variational_beta * kldivergence:  0.16887\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28894\n",
      "kldivergence:   1337.00\n",
      "variational_beta * kldivergence:  0.13370\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36484\n",
      "kldivergence:   1407.30\n",
      "variational_beta * kldivergence:  0.14073\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30258\n",
      "kldivergence:   1453.06\n",
      "variational_beta * kldivergence:  0.14531\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.40056\n",
      "kldivergence:   1569.98\n",
      "variational_beta * kldivergence:  0.15700\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33404\n",
      "kldivergence:   1561.88\n",
      "variational_beta * kldivergence:  0.15619\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31497\n",
      "kldivergence:   1400.61\n",
      "variational_beta * kldivergence:  0.14006\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35340\n",
      "kldivergence:   1452.53\n",
      "variational_beta * kldivergence:  0.14525\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36742\n",
      "kldivergence:   1458.30\n",
      "variational_beta * kldivergence:  0.14583\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.39593\n",
      "kldivergence:   1687.35\n",
      "variational_beta * kldivergence:  0.16873\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30309\n",
      "kldivergence:   1405.70\n",
      "variational_beta * kldivergence:  0.14057\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30030\n",
      "kldivergence:   1536.46\n",
      "variational_beta * kldivergence:  0.15365\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34861\n",
      "kldivergence:   1622.67\n",
      "variational_beta * kldivergence:  0.16227\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33375\n",
      "kldivergence:   1720.21\n",
      "variational_beta * kldivergence:  0.17202\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34452\n",
      "kldivergence:   1807.44\n",
      "variational_beta * kldivergence:  0.18074\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30950\n",
      "kldivergence:   1507.38\n",
      "variational_beta * kldivergence:  0.15074\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33024\n",
      "kldivergence:   1572.22\n",
      "variational_beta * kldivergence:  0.15722\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36035\n",
      "kldivergence:   1499.32\n",
      "variational_beta * kldivergence:  0.14993\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.23901\n",
      "kldivergence:   1468.92\n",
      "variational_beta * kldivergence:  0.14689\n",
      "batch accuracy: 92.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31101\n",
      "kldivergence:   1643.93\n",
      "variational_beta * kldivergence:  0.16439\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31859\n",
      "kldivergence:   1624.48\n",
      "variational_beta * kldivergence:  0.16245\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31260\n",
      "kldivergence:   1421.24\n",
      "variational_beta * kldivergence:  0.14212\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32137\n",
      "kldivergence:   1553.27\n",
      "variational_beta * kldivergence:  0.15533\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31607\n",
      "kldivergence:   1452.46\n",
      "variational_beta * kldivergence:  0.14525\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.29172\n",
      "kldivergence:   1476.04\n",
      "variational_beta * kldivergence:  0.14760\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33965\n",
      "kldivergence:   1644.54\n",
      "variational_beta * kldivergence:  0.16445\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.44656\n",
      "kldivergence:   1792.89\n",
      "variational_beta * kldivergence:  0.17929\n",
      "batch accuracy: 84.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38144\n",
      "kldivergence:   1712.88\n",
      "variational_beta * kldivergence:  0.17129\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31989\n",
      "kldivergence:   1714.30\n",
      "variational_beta * kldivergence:  0.17143\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34408\n",
      "kldivergence:   1605.73\n",
      "variational_beta * kldivergence:  0.16057\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36406\n",
      "kldivergence:   1702.58\n",
      "variational_beta * kldivergence:  0.17026\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31749\n",
      "kldivergence:   1678.13\n",
      "variational_beta * kldivergence:  0.16781\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35725\n",
      "kldivergence:   1642.71\n",
      "variational_beta * kldivergence:  0.16427\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36496\n",
      "kldivergence:   1537.25\n",
      "variational_beta * kldivergence:  0.15373\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32415\n",
      "kldivergence:   1688.59\n",
      "variational_beta * kldivergence:  0.16886\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30325\n",
      "kldivergence:   1524.07\n",
      "variational_beta * kldivergence:  0.15241\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.38424\n",
      "kldivergence:   1743.81\n",
      "variational_beta * kldivergence:  0.17438\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33210\n",
      "kldivergence:   1477.28\n",
      "variational_beta * kldivergence:  0.14773\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.37064\n",
      "kldivergence:   1572.76\n",
      "variational_beta * kldivergence:  0.15728\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34043\n",
      "kldivergence:   1593.22\n",
      "variational_beta * kldivergence:  0.15932\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.26528\n",
      "kldivergence:   1497.48\n",
      "variational_beta * kldivergence:  0.14975\n",
      "batch accuracy: 90.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32855\n",
      "kldivergence:   1655.59\n",
      "variational_beta * kldivergence:  0.16556\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34981\n",
      "kldivergence:   1600.72\n",
      "variational_beta * kldivergence:  0.16007\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32122\n",
      "kldivergence:   1700.40\n",
      "variational_beta * kldivergence:  0.17004\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31185\n",
      "kldivergence:   1641.21\n",
      "variational_beta * kldivergence:  0.16412\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34329\n",
      "kldivergence:   1932.67\n",
      "variational_beta * kldivergence:  0.19327\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.35019\n",
      "kldivergence:   1679.51\n",
      "variational_beta * kldivergence:  0.16795\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28918\n",
      "kldivergence:   1582.29\n",
      "variational_beta * kldivergence:  0.15823\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36627\n",
      "kldivergence:   1788.12\n",
      "variational_beta * kldivergence:  0.17881\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34473\n",
      "kldivergence:   1567.39\n",
      "variational_beta * kldivergence:  0.15674\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.25518\n",
      "kldivergence:   1362.65\n",
      "variational_beta * kldivergence:  0.13626\n",
      "batch accuracy: 91.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30178\n",
      "kldivergence:   1559.18\n",
      "variational_beta * kldivergence:  0.15592\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33061\n",
      "kldivergence:   1667.95\n",
      "variational_beta * kldivergence:  0.16680\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36410\n",
      "kldivergence:   1727.30\n",
      "variational_beta * kldivergence:  0.17273\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32633\n",
      "kldivergence:   1901.37\n",
      "variational_beta * kldivergence:  0.19014\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30747\n",
      "kldivergence:   1634.87\n",
      "variational_beta * kldivergence:  0.16349\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34898\n",
      "kldivergence:   1423.79\n",
      "variational_beta * kldivergence:  0.14238\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36370\n",
      "kldivergence:   1663.42\n",
      "variational_beta * kldivergence:  0.16634\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28122\n",
      "kldivergence:   1690.90\n",
      "variational_beta * kldivergence:  0.16909\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33524\n",
      "kldivergence:   1539.22\n",
      "variational_beta * kldivergence:  0.15392\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32029\n",
      "kldivergence:   1528.90\n",
      "variational_beta * kldivergence:  0.15289\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31879\n",
      "kldivergence:   1460.06\n",
      "variational_beta * kldivergence:  0.14601\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.28653\n",
      "kldivergence:   1571.17\n",
      "variational_beta * kldivergence:  0.15712\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30820\n",
      "kldivergence:   1465.34\n",
      "variational_beta * kldivergence:  0.14653\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33023\n",
      "kldivergence:   1530.73\n",
      "variational_beta * kldivergence:  0.15307\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30810\n",
      "kldivergence:   1526.87\n",
      "variational_beta * kldivergence:  0.15269\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33201\n",
      "kldivergence:   1505.07\n",
      "variational_beta * kldivergence:  0.15051\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30368\n",
      "kldivergence:   1557.91\n",
      "variational_beta * kldivergence:  0.15579\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30675\n",
      "kldivergence:   1579.55\n",
      "variational_beta * kldivergence:  0.15796\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33843\n",
      "kldivergence:   1665.70\n",
      "variational_beta * kldivergence:  0.16657\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.33641\n",
      "kldivergence:   1538.18\n",
      "variational_beta * kldivergence:  0.15382\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.31821\n",
      "kldivergence:   1593.37\n",
      "variational_beta * kldivergence:  0.15934\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34781\n",
      "kldivergence:   1550.75\n",
      "variational_beta * kldivergence:  0.15508\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30137\n",
      "kldivergence:   1640.67\n",
      "variational_beta * kldivergence:  0.16407\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.30479\n",
      "kldivergence:   1480.97\n",
      "variational_beta * kldivergence:  0.14810\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.32458\n",
      "kldivergence:   1516.60\n",
      "variational_beta * kldivergence:  0.15166\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.36032\n",
      "kldivergence:   1573.79\n",
      "variational_beta * kldivergence:  0.15738\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #36\n",
      "reconstruction loss: 0.34395\n",
      "kldivergence:   1512.14\n",
      "variational_beta * kldivergence:  0.15121\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.47067\n",
      "kldivergence:   1527.08\n",
      "variational_beta * kldivergence:  0.15271\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.57612\n",
      "kldivergence:   1738.87\n",
      "variational_beta * kldivergence:  0.17389\n",
      "batch accuracy: 82.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.57838\n",
      "kldivergence:   1461.41\n",
      "variational_beta * kldivergence:  0.14614\n",
      "batch accuracy: 83.91\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.47464\n",
      "kldivergence:   1644.15\n",
      "variational_beta * kldivergence:  0.16442\n",
      "batch accuracy: 85.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.39446\n",
      "kldivergence:   1370.42\n",
      "variational_beta * kldivergence:  0.13704\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.46886\n",
      "kldivergence:   1472.44\n",
      "variational_beta * kldivergence:  0.14724\n",
      "batch accuracy: 85.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.49665\n",
      "kldivergence:   1394.43\n",
      "variational_beta * kldivergence:  0.13944\n",
      "batch accuracy: 85.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.42004\n",
      "kldivergence:   1387.27\n",
      "variational_beta * kldivergence:  0.13873\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.39057\n",
      "kldivergence:   1371.95\n",
      "variational_beta * kldivergence:  0.13720\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.46261\n",
      "kldivergence:   1425.29\n",
      "variational_beta * kldivergence:  0.14253\n",
      "batch accuracy: 86.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.41715\n",
      "kldivergence:   1414.29\n",
      "variational_beta * kldivergence:  0.14143\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.40131\n",
      "kldivergence:   1342.64\n",
      "variational_beta * kldivergence:  0.13426\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.45416\n",
      "kldivergence:   1436.71\n",
      "variational_beta * kldivergence:  0.14367\n",
      "batch accuracy: 85.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.43133\n",
      "kldivergence:   1528.64\n",
      "variational_beta * kldivergence:  0.15286\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.42358\n",
      "kldivergence:   1386.17\n",
      "variational_beta * kldivergence:  0.13862\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.42400\n",
      "kldivergence:   1438.53\n",
      "variational_beta * kldivergence:  0.14385\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.40038\n",
      "kldivergence:   1435.65\n",
      "variational_beta * kldivergence:  0.14356\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.42066\n",
      "kldivergence:   1465.82\n",
      "variational_beta * kldivergence:  0.14658\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.38685\n",
      "kldivergence:   1392.57\n",
      "variational_beta * kldivergence:  0.13926\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.43300\n",
      "kldivergence:   1409.56\n",
      "variational_beta * kldivergence:  0.14096\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.38905\n",
      "kldivergence:   1337.28\n",
      "variational_beta * kldivergence:  0.13373\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.41022\n",
      "kldivergence:   1402.95\n",
      "variational_beta * kldivergence:  0.14029\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.43080\n",
      "kldivergence:   1365.94\n",
      "variational_beta * kldivergence:  0.13659\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.43929\n",
      "kldivergence:   1520.82\n",
      "variational_beta * kldivergence:  0.15208\n",
      "batch accuracy: 85.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.50895\n",
      "kldivergence:   1509.93\n",
      "variational_beta * kldivergence:  0.15099\n",
      "batch accuracy: 85.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.42997\n",
      "kldivergence:   1367.74\n",
      "variational_beta * kldivergence:  0.13677\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.43700\n",
      "kldivergence:   1374.89\n",
      "variational_beta * kldivergence:  0.13749\n",
      "batch accuracy: 86.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.47795\n",
      "kldivergence:   1511.87\n",
      "variational_beta * kldivergence:  0.15119\n",
      "batch accuracy: 85.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.49660\n",
      "kldivergence:   1534.87\n",
      "variational_beta * kldivergence:  0.15349\n",
      "batch accuracy: 84.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.39711\n",
      "kldivergence:   1394.57\n",
      "variational_beta * kldivergence:  0.13946\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.47284\n",
      "kldivergence:   1436.07\n",
      "variational_beta * kldivergence:  0.14361\n",
      "batch accuracy: 85.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.61115\n",
      "kldivergence:   1599.01\n",
      "variational_beta * kldivergence:  0.15990\n",
      "batch accuracy: 83.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.36566\n",
      "kldivergence:   1368.17\n",
      "variational_beta * kldivergence:  0.13682\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.41662\n",
      "kldivergence:   1476.22\n",
      "variational_beta * kldivergence:  0.14762\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.41749\n",
      "kldivergence:   1488.07\n",
      "variational_beta * kldivergence:  0.14881\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.50218\n",
      "kldivergence:   1449.71\n",
      "variational_beta * kldivergence:  0.14497\n",
      "batch accuracy: 84.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.51973\n",
      "kldivergence:   1624.90\n",
      "variational_beta * kldivergence:  0.16249\n",
      "batch accuracy: 83.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.49638\n",
      "kldivergence:   1582.31\n",
      "variational_beta * kldivergence:  0.15823\n",
      "batch accuracy: 84.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.41415\n",
      "kldivergence:   1424.39\n",
      "variational_beta * kldivergence:  0.14244\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.41174\n",
      "kldivergence:   1433.43\n",
      "variational_beta * kldivergence:  0.14334\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.43438\n",
      "kldivergence:   1431.02\n",
      "variational_beta * kldivergence:  0.14310\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.47136\n",
      "kldivergence:   1420.99\n",
      "variational_beta * kldivergence:  0.14210\n",
      "batch accuracy: 85.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.52391\n",
      "kldivergence:   1602.51\n",
      "variational_beta * kldivergence:  0.16025\n",
      "batch accuracy: 84.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.51442\n",
      "kldivergence:   1511.36\n",
      "variational_beta * kldivergence:  0.15114\n",
      "batch accuracy: 84.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.41717\n",
      "kldivergence:   1375.02\n",
      "variational_beta * kldivergence:  0.13750\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.44868\n",
      "kldivergence:   1537.57\n",
      "variational_beta * kldivergence:  0.15376\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.36414\n",
      "kldivergence:   1324.75\n",
      "variational_beta * kldivergence:  0.13248\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.41156\n",
      "kldivergence:   1303.03\n",
      "variational_beta * kldivergence:  0.13030\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.51068\n",
      "kldivergence:   1471.92\n",
      "variational_beta * kldivergence:  0.14719\n",
      "batch accuracy: 84.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.51732\n",
      "kldivergence:   1521.39\n",
      "variational_beta * kldivergence:  0.15214\n",
      "batch accuracy: 84.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.43801\n",
      "kldivergence:   1415.95\n",
      "variational_beta * kldivergence:  0.14160\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.45804\n",
      "kldivergence:   1420.78\n",
      "variational_beta * kldivergence:  0.14208\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.43024\n",
      "kldivergence:   1507.11\n",
      "variational_beta * kldivergence:  0.15071\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.49885\n",
      "kldivergence:   1491.80\n",
      "variational_beta * kldivergence:  0.14918\n",
      "batch accuracy: 84.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.50204\n",
      "kldivergence:   1577.43\n",
      "variational_beta * kldivergence:  0.15774\n",
      "batch accuracy: 84.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.55748\n",
      "kldivergence:   1600.14\n",
      "variational_beta * kldivergence:  0.16001\n",
      "batch accuracy: 83.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.44612\n",
      "kldivergence:   1394.33\n",
      "variational_beta * kldivergence:  0.13943\n",
      "batch accuracy: 85.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.34735\n",
      "kldivergence:   1273.71\n",
      "variational_beta * kldivergence:  0.12737\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.47973\n",
      "kldivergence:   1471.37\n",
      "variational_beta * kldivergence:  0.14714\n",
      "batch accuracy: 85.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.40995\n",
      "kldivergence:   1265.41\n",
      "variational_beta * kldivergence:  0.12654\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.50006\n",
      "kldivergence:   1610.30\n",
      "variational_beta * kldivergence:  0.16103\n",
      "batch accuracy: 85.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #36\n",
      "reconstruction loss: 0.48193\n",
      "kldivergence:   1502.68\n",
      "variational_beta * kldivergence:  0.15027\n",
      "batch accuracy: 84.86\n",
      "\n",
      "\n",
      "epoch # 36 : train loss is [183.3970255544608] and validation loss is [0.10043713320874219] \n",
      "saved samples\n",
      "Epoch [37 / 150] average reconstruction error: 0.494332\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31192\n",
      "kldivergence:   1439.99\n",
      "variational_beta * kldivergence:  0.14400\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33760\n",
      "kldivergence:   1512.29\n",
      "variational_beta * kldivergence:  0.15123\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32308\n",
      "kldivergence:   1529.07\n",
      "variational_beta * kldivergence:  0.15291\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32300\n",
      "kldivergence:   1796.19\n",
      "variational_beta * kldivergence:  0.17962\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33837\n",
      "kldivergence:   1611.11\n",
      "variational_beta * kldivergence:  0.16111\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31256\n",
      "kldivergence:   1480.69\n",
      "variational_beta * kldivergence:  0.14807\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31947\n",
      "kldivergence:   1430.08\n",
      "variational_beta * kldivergence:  0.14301\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32742\n",
      "kldivergence:   1789.40\n",
      "variational_beta * kldivergence:  0.17894\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.25335\n",
      "kldivergence:   1382.86\n",
      "variational_beta * kldivergence:  0.13829\n",
      "batch accuracy: 91.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34935\n",
      "kldivergence:   1568.40\n",
      "variational_beta * kldivergence:  0.15684\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33459\n",
      "kldivergence:   1420.51\n",
      "variational_beta * kldivergence:  0.14205\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32685\n",
      "kldivergence:   1526.54\n",
      "variational_beta * kldivergence:  0.15265\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32999\n",
      "kldivergence:   1513.05\n",
      "variational_beta * kldivergence:  0.15131\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.39146\n",
      "kldivergence:   1694.68\n",
      "variational_beta * kldivergence:  0.16947\n",
      "batch accuracy: 86.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34649\n",
      "kldivergence:   1541.15\n",
      "variational_beta * kldivergence:  0.15411\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33278\n",
      "kldivergence:   1626.78\n",
      "variational_beta * kldivergence:  0.16268\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31513\n",
      "kldivergence:   1580.37\n",
      "variational_beta * kldivergence:  0.15804\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34373\n",
      "kldivergence:   1476.85\n",
      "variational_beta * kldivergence:  0.14769\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34444\n",
      "kldivergence:   1629.06\n",
      "variational_beta * kldivergence:  0.16291\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.28033\n",
      "kldivergence:   1522.95\n",
      "variational_beta * kldivergence:  0.15229\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.26909\n",
      "kldivergence:   1265.62\n",
      "variational_beta * kldivergence:  0.12656\n",
      "batch accuracy: 91.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33770\n",
      "kldivergence:   1366.82\n",
      "variational_beta * kldivergence:  0.13668\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31598\n",
      "kldivergence:   1494.74\n",
      "variational_beta * kldivergence:  0.14947\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36977\n",
      "kldivergence:   1516.57\n",
      "variational_beta * kldivergence:  0.15166\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33326\n",
      "kldivergence:   1515.25\n",
      "variational_beta * kldivergence:  0.15152\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31825\n",
      "kldivergence:   1754.66\n",
      "variational_beta * kldivergence:  0.17547\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31898\n",
      "kldivergence:   1745.54\n",
      "variational_beta * kldivergence:  0.17455\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33246\n",
      "kldivergence:   1681.26\n",
      "variational_beta * kldivergence:  0.16813\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29913\n",
      "kldivergence:   1609.57\n",
      "variational_beta * kldivergence:  0.16096\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35644\n",
      "kldivergence:   1453.86\n",
      "variational_beta * kldivergence:  0.14539\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31906\n",
      "kldivergence:   1578.67\n",
      "variational_beta * kldivergence:  0.15787\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34004\n",
      "kldivergence:   1522.97\n",
      "variational_beta * kldivergence:  0.15230\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33592\n",
      "kldivergence:   1533.16\n",
      "variational_beta * kldivergence:  0.15332\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32402\n",
      "kldivergence:   1501.78\n",
      "variational_beta * kldivergence:  0.15018\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34896\n",
      "kldivergence:   1542.42\n",
      "variational_beta * kldivergence:  0.15424\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34247\n",
      "kldivergence:   1485.26\n",
      "variational_beta * kldivergence:  0.14853\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.26246\n",
      "kldivergence:   1469.28\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 91.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37907\n",
      "kldivergence:   1688.23\n",
      "variational_beta * kldivergence:  0.16882\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33538\n",
      "kldivergence:   1499.45\n",
      "variational_beta * kldivergence:  0.14995\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31572\n",
      "kldivergence:   1567.97\n",
      "variational_beta * kldivergence:  0.15680\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34708\n",
      "kldivergence:   1694.81\n",
      "variational_beta * kldivergence:  0.16948\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34723\n",
      "kldivergence:   1425.74\n",
      "variational_beta * kldivergence:  0.14257\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29016\n",
      "kldivergence:   1324.70\n",
      "variational_beta * kldivergence:  0.13247\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.28164\n",
      "kldivergence:   1417.60\n",
      "variational_beta * kldivergence:  0.14176\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36786\n",
      "kldivergence:   1631.05\n",
      "variational_beta * kldivergence:  0.16310\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30841\n",
      "kldivergence:   1635.82\n",
      "variational_beta * kldivergence:  0.16358\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33804\n",
      "kldivergence:   1452.84\n",
      "variational_beta * kldivergence:  0.14528\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32495\n",
      "kldivergence:   1688.42\n",
      "variational_beta * kldivergence:  0.16884\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30191\n",
      "kldivergence:   1432.75\n",
      "variational_beta * kldivergence:  0.14327\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29460\n",
      "kldivergence:   1441.08\n",
      "variational_beta * kldivergence:  0.14411\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34908\n",
      "kldivergence:   1534.47\n",
      "variational_beta * kldivergence:  0.15345\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34559\n",
      "kldivergence:   1510.59\n",
      "variational_beta * kldivergence:  0.15106\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30359\n",
      "kldivergence:   1488.40\n",
      "variational_beta * kldivergence:  0.14884\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29121\n",
      "kldivergence:   1363.13\n",
      "variational_beta * kldivergence:  0.13631\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31125\n",
      "kldivergence:   1474.23\n",
      "variational_beta * kldivergence:  0.14742\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29512\n",
      "kldivergence:   1358.36\n",
      "variational_beta * kldivergence:  0.13584\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34070\n",
      "kldivergence:   1444.46\n",
      "variational_beta * kldivergence:  0.14445\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33482\n",
      "kldivergence:   1364.29\n",
      "variational_beta * kldivergence:  0.13643\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31662\n",
      "kldivergence:   1798.86\n",
      "variational_beta * kldivergence:  0.17989\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35176\n",
      "kldivergence:   1762.58\n",
      "variational_beta * kldivergence:  0.17626\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33515\n",
      "kldivergence:   1610.68\n",
      "variational_beta * kldivergence:  0.16107\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34146\n",
      "kldivergence:   1657.99\n",
      "variational_beta * kldivergence:  0.16580\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33096\n",
      "kldivergence:   1637.21\n",
      "variational_beta * kldivergence:  0.16372\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29328\n",
      "kldivergence:   1642.89\n",
      "variational_beta * kldivergence:  0.16429\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34016\n",
      "kldivergence:   1638.00\n",
      "variational_beta * kldivergence:  0.16380\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29301\n",
      "kldivergence:   1374.96\n",
      "variational_beta * kldivergence:  0.13750\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29828\n",
      "kldivergence:   1633.91\n",
      "variational_beta * kldivergence:  0.16339\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37218\n",
      "kldivergence:   1695.95\n",
      "variational_beta * kldivergence:  0.16959\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29769\n",
      "kldivergence:   1425.23\n",
      "variational_beta * kldivergence:  0.14252\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29737\n",
      "kldivergence:   1423.11\n",
      "variational_beta * kldivergence:  0.14231\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33052\n",
      "kldivergence:   1549.40\n",
      "variational_beta * kldivergence:  0.15494\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37021\n",
      "kldivergence:   1508.34\n",
      "variational_beta * kldivergence:  0.15083\n",
      "batch accuracy: 86.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31536\n",
      "kldivergence:   1365.28\n",
      "variational_beta * kldivergence:  0.13653\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31364\n",
      "kldivergence:   1548.08\n",
      "variational_beta * kldivergence:  0.15481\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36412\n",
      "kldivergence:   1435.06\n",
      "variational_beta * kldivergence:  0.14351\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34811\n",
      "kldivergence:   1574.56\n",
      "variational_beta * kldivergence:  0.15746\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35064\n",
      "kldivergence:   1587.30\n",
      "variational_beta * kldivergence:  0.15873\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36736\n",
      "kldivergence:   1718.41\n",
      "variational_beta * kldivergence:  0.17184\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38125\n",
      "kldivergence:   1543.82\n",
      "variational_beta * kldivergence:  0.15438\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37693\n",
      "kldivergence:   1720.40\n",
      "variational_beta * kldivergence:  0.17204\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.28071\n",
      "kldivergence:   1363.71\n",
      "variational_beta * kldivergence:  0.13637\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38033\n",
      "kldivergence:   1460.21\n",
      "variational_beta * kldivergence:  0.14602\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35292\n",
      "kldivergence:   1674.98\n",
      "variational_beta * kldivergence:  0.16750\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30388\n",
      "kldivergence:   1633.16\n",
      "variational_beta * kldivergence:  0.16332\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33552\n",
      "kldivergence:   1444.70\n",
      "variational_beta * kldivergence:  0.14447\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33485\n",
      "kldivergence:   1518.87\n",
      "variational_beta * kldivergence:  0.15189\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32102\n",
      "kldivergence:   1597.19\n",
      "variational_beta * kldivergence:  0.15972\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34131\n",
      "kldivergence:   1714.46\n",
      "variational_beta * kldivergence:  0.17145\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33778\n",
      "kldivergence:   1478.83\n",
      "variational_beta * kldivergence:  0.14788\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36154\n",
      "kldivergence:   1628.03\n",
      "variational_beta * kldivergence:  0.16280\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33150\n",
      "kldivergence:   1426.28\n",
      "variational_beta * kldivergence:  0.14263\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32410\n",
      "kldivergence:   1449.58\n",
      "variational_beta * kldivergence:  0.14496\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36992\n",
      "kldivergence:   1600.48\n",
      "variational_beta * kldivergence:  0.16005\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33750\n",
      "kldivergence:   1364.62\n",
      "variational_beta * kldivergence:  0.13646\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37562\n",
      "kldivergence:   1572.07\n",
      "variational_beta * kldivergence:  0.15721\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34762\n",
      "kldivergence:   1468.10\n",
      "variational_beta * kldivergence:  0.14681\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33497\n",
      "kldivergence:   1622.33\n",
      "variational_beta * kldivergence:  0.16223\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29924\n",
      "kldivergence:   1675.15\n",
      "variational_beta * kldivergence:  0.16752\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31520\n",
      "kldivergence:   1629.89\n",
      "variational_beta * kldivergence:  0.16299\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36820\n",
      "kldivergence:   1790.17\n",
      "variational_beta * kldivergence:  0.17902\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33331\n",
      "kldivergence:   1561.75\n",
      "variational_beta * kldivergence:  0.15618\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31360\n",
      "kldivergence:   1552.68\n",
      "variational_beta * kldivergence:  0.15527\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32412\n",
      "kldivergence:   1779.88\n",
      "variational_beta * kldivergence:  0.17799\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33513\n",
      "kldivergence:   1748.30\n",
      "variational_beta * kldivergence:  0.17483\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34363\n",
      "kldivergence:   1442.10\n",
      "variational_beta * kldivergence:  0.14421\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30053\n",
      "kldivergence:   1625.43\n",
      "variational_beta * kldivergence:  0.16254\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.27851\n",
      "kldivergence:   1468.37\n",
      "variational_beta * kldivergence:  0.14684\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35172\n",
      "kldivergence:   1634.04\n",
      "variational_beta * kldivergence:  0.16340\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37564\n",
      "kldivergence:   1564.36\n",
      "variational_beta * kldivergence:  0.15644\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34111\n",
      "kldivergence:   1570.46\n",
      "variational_beta * kldivergence:  0.15705\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33252\n",
      "kldivergence:   1622.64\n",
      "variational_beta * kldivergence:  0.16226\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31504\n",
      "kldivergence:   1695.16\n",
      "variational_beta * kldivergence:  0.16952\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.24893\n",
      "kldivergence:   1600.09\n",
      "variational_beta * kldivergence:  0.16001\n",
      "batch accuracy: 91.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29064\n",
      "kldivergence:   1428.42\n",
      "variational_beta * kldivergence:  0.14284\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34581\n",
      "kldivergence:   1699.87\n",
      "variational_beta * kldivergence:  0.16999\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34636\n",
      "kldivergence:   1759.88\n",
      "variational_beta * kldivergence:  0.17599\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36118\n",
      "kldivergence:   1617.78\n",
      "variational_beta * kldivergence:  0.16178\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29157\n",
      "kldivergence:   1580.56\n",
      "variational_beta * kldivergence:  0.15806\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33009\n",
      "kldivergence:   1485.01\n",
      "variational_beta * kldivergence:  0.14850\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37037\n",
      "kldivergence:   1615.97\n",
      "variational_beta * kldivergence:  0.16160\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36496\n",
      "kldivergence:   1511.39\n",
      "variational_beta * kldivergence:  0.15114\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32599\n",
      "kldivergence:   1533.71\n",
      "variational_beta * kldivergence:  0.15337\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.27634\n",
      "kldivergence:   1264.38\n",
      "variational_beta * kldivergence:  0.12644\n",
      "batch accuracy: 90.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38343\n",
      "kldivergence:   1836.64\n",
      "variational_beta * kldivergence:  0.18366\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30017\n",
      "kldivergence:   1546.73\n",
      "variational_beta * kldivergence:  0.15467\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30734\n",
      "kldivergence:   1517.53\n",
      "variational_beta * kldivergence:  0.15175\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33970\n",
      "kldivergence:   1450.45\n",
      "variational_beta * kldivergence:  0.14505\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34203\n",
      "kldivergence:   1682.00\n",
      "variational_beta * kldivergence:  0.16820\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34371\n",
      "kldivergence:   1632.36\n",
      "variational_beta * kldivergence:  0.16324\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35156\n",
      "kldivergence:   1563.25\n",
      "variational_beta * kldivergence:  0.15633\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33486\n",
      "kldivergence:   1553.17\n",
      "variational_beta * kldivergence:  0.15532\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.28156\n",
      "kldivergence:   1601.88\n",
      "variational_beta * kldivergence:  0.16019\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34563\n",
      "kldivergence:   1369.78\n",
      "variational_beta * kldivergence:  0.13698\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34663\n",
      "kldivergence:   1689.12\n",
      "variational_beta * kldivergence:  0.16891\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33474\n",
      "kldivergence:   1399.74\n",
      "variational_beta * kldivergence:  0.13997\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33004\n",
      "kldivergence:   1312.29\n",
      "variational_beta * kldivergence:  0.13123\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34997\n",
      "kldivergence:   1446.56\n",
      "variational_beta * kldivergence:  0.14466\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35988\n",
      "kldivergence:   1646.00\n",
      "variational_beta * kldivergence:  0.16460\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34900\n",
      "kldivergence:   1631.36\n",
      "variational_beta * kldivergence:  0.16314\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34146\n",
      "kldivergence:   1492.30\n",
      "variational_beta * kldivergence:  0.14923\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32633\n",
      "kldivergence:   1495.03\n",
      "variational_beta * kldivergence:  0.14950\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33001\n",
      "kldivergence:   1653.48\n",
      "variational_beta * kldivergence:  0.16535\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31813\n",
      "kldivergence:   2328.75\n",
      "variational_beta * kldivergence:  0.23288\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31483\n",
      "kldivergence:   1521.12\n",
      "variational_beta * kldivergence:  0.15211\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34804\n",
      "kldivergence:   1741.49\n",
      "variational_beta * kldivergence:  0.17415\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35302\n",
      "kldivergence:   1552.79\n",
      "variational_beta * kldivergence:  0.15528\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.28991\n",
      "kldivergence:   1342.27\n",
      "variational_beta * kldivergence:  0.13423\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33333\n",
      "kldivergence:   1750.01\n",
      "variational_beta * kldivergence:  0.17500\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.26915\n",
      "kldivergence:   1325.36\n",
      "variational_beta * kldivergence:  0.13254\n",
      "batch accuracy: 90.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33337\n",
      "kldivergence:   1477.08\n",
      "variational_beta * kldivergence:  0.14771\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31015\n",
      "kldivergence:   1445.26\n",
      "variational_beta * kldivergence:  0.14453\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32983\n",
      "kldivergence:   1679.97\n",
      "variational_beta * kldivergence:  0.16800\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32250\n",
      "kldivergence:   1642.08\n",
      "variational_beta * kldivergence:  0.16421\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37757\n",
      "kldivergence:   1550.08\n",
      "variational_beta * kldivergence:  0.15501\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.40155\n",
      "kldivergence:   1710.46\n",
      "variational_beta * kldivergence:  0.17105\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33643\n",
      "kldivergence:   1688.52\n",
      "variational_beta * kldivergence:  0.16885\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.39332\n",
      "kldivergence:   1798.41\n",
      "variational_beta * kldivergence:  0.17984\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.39042\n",
      "kldivergence:   1692.64\n",
      "variational_beta * kldivergence:  0.16926\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35711\n",
      "kldivergence:   1576.90\n",
      "variational_beta * kldivergence:  0.15769\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30357\n",
      "kldivergence:   1460.54\n",
      "variational_beta * kldivergence:  0.14605\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30847\n",
      "kldivergence:   1512.35\n",
      "variational_beta * kldivergence:  0.15123\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33427\n",
      "kldivergence:   1800.81\n",
      "variational_beta * kldivergence:  0.18008\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35387\n",
      "kldivergence:   1856.68\n",
      "variational_beta * kldivergence:  0.18567\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31832\n",
      "kldivergence:   1360.83\n",
      "variational_beta * kldivergence:  0.13608\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33153\n",
      "kldivergence:   1438.16\n",
      "variational_beta * kldivergence:  0.14382\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34305\n",
      "kldivergence:   1692.16\n",
      "variational_beta * kldivergence:  0.16922\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35392\n",
      "kldivergence:   1671.30\n",
      "variational_beta * kldivergence:  0.16713\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32938\n",
      "kldivergence:   1482.56\n",
      "variational_beta * kldivergence:  0.14826\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36458\n",
      "kldivergence:   1615.51\n",
      "variational_beta * kldivergence:  0.16155\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29330\n",
      "kldivergence:   1300.69\n",
      "variational_beta * kldivergence:  0.13007\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38492\n",
      "kldivergence:   1604.28\n",
      "variational_beta * kldivergence:  0.16043\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30839\n",
      "kldivergence:   1596.82\n",
      "variational_beta * kldivergence:  0.15968\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32353\n",
      "kldivergence:   1631.17\n",
      "variational_beta * kldivergence:  0.16312\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33130\n",
      "kldivergence:   1566.05\n",
      "variational_beta * kldivergence:  0.15660\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35184\n",
      "kldivergence:   1503.50\n",
      "variational_beta * kldivergence:  0.15035\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36000\n",
      "kldivergence:   1592.97\n",
      "variational_beta * kldivergence:  0.15930\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36339\n",
      "kldivergence:   1355.89\n",
      "variational_beta * kldivergence:  0.13559\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35640\n",
      "kldivergence:   1475.41\n",
      "variational_beta * kldivergence:  0.14754\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31116\n",
      "kldivergence:   1433.42\n",
      "variational_beta * kldivergence:  0.14334\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30180\n",
      "kldivergence:   1592.49\n",
      "variational_beta * kldivergence:  0.15925\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36423\n",
      "kldivergence:   1711.44\n",
      "variational_beta * kldivergence:  0.17114\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34370\n",
      "kldivergence:   1432.63\n",
      "variational_beta * kldivergence:  0.14326\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34127\n",
      "kldivergence:   1605.19\n",
      "variational_beta * kldivergence:  0.16052\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35195\n",
      "kldivergence:   1565.43\n",
      "variational_beta * kldivergence:  0.15654\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31286\n",
      "kldivergence:   1371.53\n",
      "variational_beta * kldivergence:  0.13715\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35459\n",
      "kldivergence:   1645.79\n",
      "variational_beta * kldivergence:  0.16458\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.27857\n",
      "kldivergence:   1444.19\n",
      "variational_beta * kldivergence:  0.14442\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32574\n",
      "kldivergence:   1392.17\n",
      "variational_beta * kldivergence:  0.13922\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31497\n",
      "kldivergence:   1415.02\n",
      "variational_beta * kldivergence:  0.14150\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37059\n",
      "kldivergence:   1650.27\n",
      "variational_beta * kldivergence:  0.16503\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30792\n",
      "kldivergence:   1509.77\n",
      "variational_beta * kldivergence:  0.15098\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29152\n",
      "kldivergence:   1396.53\n",
      "variational_beta * kldivergence:  0.13965\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38587\n",
      "kldivergence:   1669.79\n",
      "variational_beta * kldivergence:  0.16698\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36596\n",
      "kldivergence:   1545.21\n",
      "variational_beta * kldivergence:  0.15452\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34694\n",
      "kldivergence:   1679.45\n",
      "variational_beta * kldivergence:  0.16795\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.27924\n",
      "kldivergence:   1391.19\n",
      "variational_beta * kldivergence:  0.13912\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37477\n",
      "kldivergence:   1894.62\n",
      "variational_beta * kldivergence:  0.18946\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36443\n",
      "kldivergence:   1682.53\n",
      "variational_beta * kldivergence:  0.16825\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32127\n",
      "kldivergence:   1701.19\n",
      "variational_beta * kldivergence:  0.17012\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30067\n",
      "kldivergence:   1674.51\n",
      "variational_beta * kldivergence:  0.16745\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.27235\n",
      "kldivergence:   1628.22\n",
      "variational_beta * kldivergence:  0.16282\n",
      "batch accuracy: 90.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31612\n",
      "kldivergence:   1656.43\n",
      "variational_beta * kldivergence:  0.16564\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32425\n",
      "kldivergence:   1629.23\n",
      "variational_beta * kldivergence:  0.16292\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33232\n",
      "kldivergence:   1576.98\n",
      "variational_beta * kldivergence:  0.15770\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37253\n",
      "kldivergence:   1663.30\n",
      "variational_beta * kldivergence:  0.16633\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34713\n",
      "kldivergence:   1942.16\n",
      "variational_beta * kldivergence:  0.19422\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33595\n",
      "kldivergence:   1521.20\n",
      "variational_beta * kldivergence:  0.15212\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33535\n",
      "kldivergence:   1481.94\n",
      "variational_beta * kldivergence:  0.14819\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34417\n",
      "kldivergence:   1372.27\n",
      "variational_beta * kldivergence:  0.13723\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31841\n",
      "kldivergence:   1704.52\n",
      "variational_beta * kldivergence:  0.17045\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36828\n",
      "kldivergence:   1470.38\n",
      "variational_beta * kldivergence:  0.14704\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31845\n",
      "kldivergence:   1585.74\n",
      "variational_beta * kldivergence:  0.15857\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30430\n",
      "kldivergence:   1506.07\n",
      "variational_beta * kldivergence:  0.15061\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31192\n",
      "kldivergence:   1545.86\n",
      "variational_beta * kldivergence:  0.15459\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.25135\n",
      "kldivergence:   1324.16\n",
      "variational_beta * kldivergence:  0.13242\n",
      "batch accuracy: 91.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34684\n",
      "kldivergence:   1587.79\n",
      "variational_beta * kldivergence:  0.15878\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30676\n",
      "kldivergence:   1724.69\n",
      "variational_beta * kldivergence:  0.17247\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36501\n",
      "kldivergence:   1608.45\n",
      "variational_beta * kldivergence:  0.16084\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.40908\n",
      "kldivergence:   1707.10\n",
      "variational_beta * kldivergence:  0.17071\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29550\n",
      "kldivergence:   1447.10\n",
      "variational_beta * kldivergence:  0.14471\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33400\n",
      "kldivergence:   1401.21\n",
      "variational_beta * kldivergence:  0.14012\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32902\n",
      "kldivergence:   1590.73\n",
      "variational_beta * kldivergence:  0.15907\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.26944\n",
      "kldivergence:   1416.22\n",
      "variational_beta * kldivergence:  0.14162\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.40996\n",
      "kldivergence:   1685.08\n",
      "variational_beta * kldivergence:  0.16851\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.28629\n",
      "kldivergence:   1598.77\n",
      "variational_beta * kldivergence:  0.15988\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32184\n",
      "kldivergence:   1575.24\n",
      "variational_beta * kldivergence:  0.15752\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.28618\n",
      "kldivergence:   1472.19\n",
      "variational_beta * kldivergence:  0.14722\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32080\n",
      "kldivergence:   1636.05\n",
      "variational_beta * kldivergence:  0.16360\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32925\n",
      "kldivergence:   1410.95\n",
      "variational_beta * kldivergence:  0.14110\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33386\n",
      "kldivergence:   1692.56\n",
      "variational_beta * kldivergence:  0.16926\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34007\n",
      "kldivergence:   1677.52\n",
      "variational_beta * kldivergence:  0.16775\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33074\n",
      "kldivergence:   1562.56\n",
      "variational_beta * kldivergence:  0.15626\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.28483\n",
      "kldivergence:   1649.75\n",
      "variational_beta * kldivergence:  0.16498\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32653\n",
      "kldivergence:   1671.26\n",
      "variational_beta * kldivergence:  0.16713\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30344\n",
      "kldivergence:   1905.52\n",
      "variational_beta * kldivergence:  0.19055\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33491\n",
      "kldivergence:   1741.80\n",
      "variational_beta * kldivergence:  0.17418\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29185\n",
      "kldivergence:   1455.23\n",
      "variational_beta * kldivergence:  0.14552\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31420\n",
      "kldivergence:   1472.88\n",
      "variational_beta * kldivergence:  0.14729\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29185\n",
      "kldivergence:   1439.76\n",
      "variational_beta * kldivergence:  0.14398\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32807\n",
      "kldivergence:   1588.05\n",
      "variational_beta * kldivergence:  0.15880\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33856\n",
      "kldivergence:   1468.95\n",
      "variational_beta * kldivergence:  0.14689\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30117\n",
      "kldivergence:   1437.50\n",
      "variational_beta * kldivergence:  0.14375\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33942\n",
      "kldivergence:   1515.69\n",
      "variational_beta * kldivergence:  0.15157\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30487\n",
      "kldivergence:   1290.79\n",
      "variational_beta * kldivergence:  0.12908\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.27792\n",
      "kldivergence:   1442.48\n",
      "variational_beta * kldivergence:  0.14425\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35437\n",
      "kldivergence:   1625.13\n",
      "variational_beta * kldivergence:  0.16251\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34691\n",
      "kldivergence:   1634.95\n",
      "variational_beta * kldivergence:  0.16350\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31628\n",
      "kldivergence:   1259.28\n",
      "variational_beta * kldivergence:  0.12593\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37039\n",
      "kldivergence:   1675.16\n",
      "variational_beta * kldivergence:  0.16752\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30096\n",
      "kldivergence:   1512.93\n",
      "variational_beta * kldivergence:  0.15129\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29097\n",
      "kldivergence:   1376.13\n",
      "variational_beta * kldivergence:  0.13761\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38049\n",
      "kldivergence:   1684.92\n",
      "variational_beta * kldivergence:  0.16849\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32659\n",
      "kldivergence:   1676.25\n",
      "variational_beta * kldivergence:  0.16763\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30599\n",
      "kldivergence:   1584.33\n",
      "variational_beta * kldivergence:  0.15843\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.27094\n",
      "kldivergence:   1468.86\n",
      "variational_beta * kldivergence:  0.14689\n",
      "batch accuracy: 91.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34703\n",
      "kldivergence:   1538.08\n",
      "variational_beta * kldivergence:  0.15381\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.27238\n",
      "kldivergence:   1447.58\n",
      "variational_beta * kldivergence:  0.14476\n",
      "batch accuracy: 90.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38776\n",
      "kldivergence:   1660.33\n",
      "variational_beta * kldivergence:  0.16603\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32574\n",
      "kldivergence:   1607.57\n",
      "variational_beta * kldivergence:  0.16076\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30082\n",
      "kldivergence:   1503.21\n",
      "variational_beta * kldivergence:  0.15032\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31764\n",
      "kldivergence:   1495.60\n",
      "variational_beta * kldivergence:  0.14956\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38076\n",
      "kldivergence:   1510.33\n",
      "variational_beta * kldivergence:  0.15103\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30664\n",
      "kldivergence:   1417.05\n",
      "variational_beta * kldivergence:  0.14171\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33971\n",
      "kldivergence:   1500.82\n",
      "variational_beta * kldivergence:  0.15008\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34175\n",
      "kldivergence:   1651.13\n",
      "variational_beta * kldivergence:  0.16511\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31095\n",
      "kldivergence:   1546.12\n",
      "variational_beta * kldivergence:  0.15461\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38911\n",
      "kldivergence:   1563.39\n",
      "variational_beta * kldivergence:  0.15634\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35128\n",
      "kldivergence:   1585.13\n",
      "variational_beta * kldivergence:  0.15851\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32138\n",
      "kldivergence:   1546.87\n",
      "variational_beta * kldivergence:  0.15469\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34176\n",
      "kldivergence:   1744.05\n",
      "variational_beta * kldivergence:  0.17441\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30031\n",
      "kldivergence:   1588.71\n",
      "variational_beta * kldivergence:  0.15887\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29566\n",
      "kldivergence:   1371.97\n",
      "variational_beta * kldivergence:  0.13720\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33507\n",
      "kldivergence:   1660.92\n",
      "variational_beta * kldivergence:  0.16609\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36204\n",
      "kldivergence:   1544.55\n",
      "variational_beta * kldivergence:  0.15445\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29842\n",
      "kldivergence:   1434.41\n",
      "variational_beta * kldivergence:  0.14344\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35177\n",
      "kldivergence:   1511.71\n",
      "variational_beta * kldivergence:  0.15117\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.39818\n",
      "kldivergence:   1663.59\n",
      "variational_beta * kldivergence:  0.16636\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33574\n",
      "kldivergence:   1501.63\n",
      "variational_beta * kldivergence:  0.15016\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30768\n",
      "kldivergence:   1518.53\n",
      "variational_beta * kldivergence:  0.15185\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34830\n",
      "kldivergence:   1595.85\n",
      "variational_beta * kldivergence:  0.15959\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32194\n",
      "kldivergence:   1506.16\n",
      "variational_beta * kldivergence:  0.15062\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36519\n",
      "kldivergence:   1844.90\n",
      "variational_beta * kldivergence:  0.18449\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37126\n",
      "kldivergence:   1727.47\n",
      "variational_beta * kldivergence:  0.17275\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38066\n",
      "kldivergence:   1595.96\n",
      "variational_beta * kldivergence:  0.15960\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31417\n",
      "kldivergence:   1781.01\n",
      "variational_beta * kldivergence:  0.17810\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33091\n",
      "kldivergence:   1570.96\n",
      "variational_beta * kldivergence:  0.15710\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31628\n",
      "kldivergence:   1657.25\n",
      "variational_beta * kldivergence:  0.16573\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30512\n",
      "kldivergence:   1586.69\n",
      "variational_beta * kldivergence:  0.15867\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.27363\n",
      "kldivergence:   1750.50\n",
      "variational_beta * kldivergence:  0.17505\n",
      "batch accuracy: 90.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34974\n",
      "kldivergence:   1621.94\n",
      "variational_beta * kldivergence:  0.16219\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31977\n",
      "kldivergence:   1334.05\n",
      "variational_beta * kldivergence:  0.13340\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33137\n",
      "kldivergence:   1799.69\n",
      "variational_beta * kldivergence:  0.17997\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29736\n",
      "kldivergence:   1444.61\n",
      "variational_beta * kldivergence:  0.14446\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34069\n",
      "kldivergence:   1784.06\n",
      "variational_beta * kldivergence:  0.17841\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30102\n",
      "kldivergence:   1488.29\n",
      "variational_beta * kldivergence:  0.14883\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.27697\n",
      "kldivergence:   1417.15\n",
      "variational_beta * kldivergence:  0.14171\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31497\n",
      "kldivergence:   1573.62\n",
      "variational_beta * kldivergence:  0.15736\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31636\n",
      "kldivergence:   1476.30\n",
      "variational_beta * kldivergence:  0.14763\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35383\n",
      "kldivergence:   1774.94\n",
      "variational_beta * kldivergence:  0.17749\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36589\n",
      "kldivergence:   1970.27\n",
      "variational_beta * kldivergence:  0.19703\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31754\n",
      "kldivergence:   1609.71\n",
      "variational_beta * kldivergence:  0.16097\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.39250\n",
      "kldivergence:   1465.92\n",
      "variational_beta * kldivergence:  0.14659\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33855\n",
      "kldivergence:   1532.39\n",
      "variational_beta * kldivergence:  0.15324\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31338\n",
      "kldivergence:   1618.04\n",
      "variational_beta * kldivergence:  0.16180\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.41653\n",
      "kldivergence:   1772.96\n",
      "variational_beta * kldivergence:  0.17730\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35869\n",
      "kldivergence:   1474.85\n",
      "variational_beta * kldivergence:  0.14749\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32012\n",
      "kldivergence:   1461.52\n",
      "variational_beta * kldivergence:  0.14615\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32808\n",
      "kldivergence:   1458.68\n",
      "variational_beta * kldivergence:  0.14587\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34927\n",
      "kldivergence:   1489.95\n",
      "variational_beta * kldivergence:  0.14900\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34462\n",
      "kldivergence:   1608.75\n",
      "variational_beta * kldivergence:  0.16088\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33771\n",
      "kldivergence:   1565.25\n",
      "variational_beta * kldivergence:  0.15653\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35207\n",
      "kldivergence:   1639.77\n",
      "variational_beta * kldivergence:  0.16398\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33628\n",
      "kldivergence:   1641.70\n",
      "variational_beta * kldivergence:  0.16417\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30947\n",
      "kldivergence:   1724.74\n",
      "variational_beta * kldivergence:  0.17247\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31841\n",
      "kldivergence:   1642.87\n",
      "variational_beta * kldivergence:  0.16429\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31551\n",
      "kldivergence:   1622.78\n",
      "variational_beta * kldivergence:  0.16228\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33187\n",
      "kldivergence:   1610.24\n",
      "variational_beta * kldivergence:  0.16102\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36498\n",
      "kldivergence:   1493.95\n",
      "variational_beta * kldivergence:  0.14940\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35411\n",
      "kldivergence:   1593.43\n",
      "variational_beta * kldivergence:  0.15934\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33605\n",
      "kldivergence:   1662.63\n",
      "variational_beta * kldivergence:  0.16626\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33338\n",
      "kldivergence:   1474.14\n",
      "variational_beta * kldivergence:  0.14741\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36093\n",
      "kldivergence:   1460.47\n",
      "variational_beta * kldivergence:  0.14605\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.38494\n",
      "kldivergence:   1748.21\n",
      "variational_beta * kldivergence:  0.17482\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35433\n",
      "kldivergence:   1658.76\n",
      "variational_beta * kldivergence:  0.16588\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37289\n",
      "kldivergence:   1544.51\n",
      "variational_beta * kldivergence:  0.15445\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30077\n",
      "kldivergence:   1380.39\n",
      "variational_beta * kldivergence:  0.13804\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37080\n",
      "kldivergence:   1597.14\n",
      "variational_beta * kldivergence:  0.15971\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31995\n",
      "kldivergence:   1519.45\n",
      "variational_beta * kldivergence:  0.15195\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33417\n",
      "kldivergence:   1671.54\n",
      "variational_beta * kldivergence:  0.16715\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34098\n",
      "kldivergence:   1531.67\n",
      "variational_beta * kldivergence:  0.15317\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34046\n",
      "kldivergence:   1558.51\n",
      "variational_beta * kldivergence:  0.15585\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32260\n",
      "kldivergence:   1470.41\n",
      "variational_beta * kldivergence:  0.14704\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32727\n",
      "kldivergence:   1749.66\n",
      "variational_beta * kldivergence:  0.17497\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32350\n",
      "kldivergence:   1513.64\n",
      "variational_beta * kldivergence:  0.15136\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35448\n",
      "kldivergence:   1711.92\n",
      "variational_beta * kldivergence:  0.17119\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33452\n",
      "kldivergence:   1453.50\n",
      "variational_beta * kldivergence:  0.14535\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35488\n",
      "kldivergence:   1542.79\n",
      "variational_beta * kldivergence:  0.15428\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34237\n",
      "kldivergence:   1614.38\n",
      "variational_beta * kldivergence:  0.16144\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34132\n",
      "kldivergence:   1658.76\n",
      "variational_beta * kldivergence:  0.16588\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29969\n",
      "kldivergence:   1892.54\n",
      "variational_beta * kldivergence:  0.18925\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36805\n",
      "kldivergence:   1617.73\n",
      "variational_beta * kldivergence:  0.16177\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32940\n",
      "kldivergence:   1454.51\n",
      "variational_beta * kldivergence:  0.14545\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30698\n",
      "kldivergence:   2383.17\n",
      "variational_beta * kldivergence:  0.23832\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33905\n",
      "kldivergence:   1498.33\n",
      "variational_beta * kldivergence:  0.14983\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33370\n",
      "kldivergence:   1514.72\n",
      "variational_beta * kldivergence:  0.15147\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31808\n",
      "kldivergence:   1497.97\n",
      "variational_beta * kldivergence:  0.14980\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31196\n",
      "kldivergence:   1496.49\n",
      "variational_beta * kldivergence:  0.14965\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31776\n",
      "kldivergence:   1474.62\n",
      "variational_beta * kldivergence:  0.14746\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34648\n",
      "kldivergence:   1460.97\n",
      "variational_beta * kldivergence:  0.14610\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32079\n",
      "kldivergence:   1455.19\n",
      "variational_beta * kldivergence:  0.14552\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34680\n",
      "kldivergence:   1598.87\n",
      "variational_beta * kldivergence:  0.15989\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30488\n",
      "kldivergence:   1522.81\n",
      "variational_beta * kldivergence:  0.15228\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35176\n",
      "kldivergence:   1652.27\n",
      "variational_beta * kldivergence:  0.16523\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32127\n",
      "kldivergence:   1473.68\n",
      "variational_beta * kldivergence:  0.14737\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37213\n",
      "kldivergence:   1636.44\n",
      "variational_beta * kldivergence:  0.16364\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31726\n",
      "kldivergence:   1450.91\n",
      "variational_beta * kldivergence:  0.14509\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31361\n",
      "kldivergence:   1623.42\n",
      "variational_beta * kldivergence:  0.16234\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31587\n",
      "kldivergence:   1377.56\n",
      "variational_beta * kldivergence:  0.13776\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31351\n",
      "kldivergence:   1339.30\n",
      "variational_beta * kldivergence:  0.13393\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30930\n",
      "kldivergence:   2480.57\n",
      "variational_beta * kldivergence:  0.24806\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35715\n",
      "kldivergence:   1793.63\n",
      "variational_beta * kldivergence:  0.17936\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.35619\n",
      "kldivergence:   1875.19\n",
      "variational_beta * kldivergence:  0.18752\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.34903\n",
      "kldivergence:   1441.74\n",
      "variational_beta * kldivergence:  0.14417\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.36915\n",
      "kldivergence:   1799.20\n",
      "variational_beta * kldivergence:  0.17992\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.29758\n",
      "kldivergence:   1421.80\n",
      "variational_beta * kldivergence:  0.14218\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.32260\n",
      "kldivergence:   1422.18\n",
      "variational_beta * kldivergence:  0.14222\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33360\n",
      "kldivergence:   1330.81\n",
      "variational_beta * kldivergence:  0.13308\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.30238\n",
      "kldivergence:   1562.67\n",
      "variational_beta * kldivergence:  0.15627\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.37842\n",
      "kldivergence:   1515.67\n",
      "variational_beta * kldivergence:  0.15157\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.33856\n",
      "kldivergence:   1583.21\n",
      "variational_beta * kldivergence:  0.15832\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #37\n",
      "reconstruction loss: 0.31744\n",
      "kldivergence:   1725.46\n",
      "variational_beta * kldivergence:  0.17255\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.43214\n",
      "kldivergence:   1439.52\n",
      "variational_beta * kldivergence:  0.14395\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.41020\n",
      "kldivergence:   1371.18\n",
      "variational_beta * kldivergence:  0.13712\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.40512\n",
      "kldivergence:   1322.14\n",
      "variational_beta * kldivergence:  0.13221\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.51786\n",
      "kldivergence:   1644.29\n",
      "variational_beta * kldivergence:  0.16443\n",
      "batch accuracy: 83.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.55690\n",
      "kldivergence:   1581.12\n",
      "variational_beta * kldivergence:  0.15811\n",
      "batch accuracy: 83.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.53652\n",
      "kldivergence:   1513.71\n",
      "variational_beta * kldivergence:  0.15137\n",
      "batch accuracy: 83.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.53378\n",
      "kldivergence:   1476.00\n",
      "variational_beta * kldivergence:  0.14760\n",
      "batch accuracy: 84.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.43931\n",
      "kldivergence:   1425.32\n",
      "variational_beta * kldivergence:  0.14253\n",
      "batch accuracy: 86.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.61810\n",
      "kldivergence:   1783.51\n",
      "variational_beta * kldivergence:  0.17835\n",
      "batch accuracy: 81.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.51007\n",
      "kldivergence:   1572.87\n",
      "variational_beta * kldivergence:  0.15729\n",
      "batch accuracy: 83.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.41302\n",
      "kldivergence:   1410.44\n",
      "variational_beta * kldivergence:  0.14104\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.42751\n",
      "kldivergence:   1408.91\n",
      "variational_beta * kldivergence:  0.14089\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.45909\n",
      "kldivergence:   1457.51\n",
      "variational_beta * kldivergence:  0.14575\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.38502\n",
      "kldivergence:   1305.54\n",
      "variational_beta * kldivergence:  0.13055\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.35456\n",
      "kldivergence:   1281.91\n",
      "variational_beta * kldivergence:  0.12819\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.49297\n",
      "kldivergence:   1443.70\n",
      "variational_beta * kldivergence:  0.14437\n",
      "batch accuracy: 85.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.40008\n",
      "kldivergence:   1388.32\n",
      "variational_beta * kldivergence:  0.13883\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.49992\n",
      "kldivergence:   1538.30\n",
      "variational_beta * kldivergence:  0.15383\n",
      "batch accuracy: 84.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.49012\n",
      "kldivergence:   1454.55\n",
      "variational_beta * kldivergence:  0.14546\n",
      "batch accuracy: 84.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.45061\n",
      "kldivergence:   1493.92\n",
      "variational_beta * kldivergence:  0.14939\n",
      "batch accuracy: 86.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.41666\n",
      "kldivergence:   1450.44\n",
      "variational_beta * kldivergence:  0.14504\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.46221\n",
      "kldivergence:   1462.74\n",
      "variational_beta * kldivergence:  0.14627\n",
      "batch accuracy: 84.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.39575\n",
      "kldivergence:   1279.41\n",
      "variational_beta * kldivergence:  0.12794\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.46889\n",
      "kldivergence:   1496.00\n",
      "variational_beta * kldivergence:  0.14960\n",
      "batch accuracy: 85.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.38221\n",
      "kldivergence:   1497.84\n",
      "variational_beta * kldivergence:  0.14978\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.42463\n",
      "kldivergence:   1411.85\n",
      "variational_beta * kldivergence:  0.14119\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.44795\n",
      "kldivergence:   1581.40\n",
      "variational_beta * kldivergence:  0.15814\n",
      "batch accuracy: 86.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.44082\n",
      "kldivergence:   1383.39\n",
      "variational_beta * kldivergence:  0.13834\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.49453\n",
      "kldivergence:   1455.01\n",
      "variational_beta * kldivergence:  0.14550\n",
      "batch accuracy: 85.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.43109\n",
      "kldivergence:   1374.45\n",
      "variational_beta * kldivergence:  0.13745\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.42489\n",
      "kldivergence:   1384.06\n",
      "variational_beta * kldivergence:  0.13841\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.41537\n",
      "kldivergence:   1386.60\n",
      "variational_beta * kldivergence:  0.13866\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.39091\n",
      "kldivergence:   1346.55\n",
      "variational_beta * kldivergence:  0.13466\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.57953\n",
      "kldivergence:   1553.12\n",
      "variational_beta * kldivergence:  0.15531\n",
      "batch accuracy: 83.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.47194\n",
      "kldivergence:   1417.73\n",
      "variational_beta * kldivergence:  0.14177\n",
      "batch accuracy: 85.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.47265\n",
      "kldivergence:   1507.16\n",
      "variational_beta * kldivergence:  0.15072\n",
      "batch accuracy: 85.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.45550\n",
      "kldivergence:   1482.00\n",
      "variational_beta * kldivergence:  0.14820\n",
      "batch accuracy: 85.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.50920\n",
      "kldivergence:   1388.53\n",
      "variational_beta * kldivergence:  0.13885\n",
      "batch accuracy: 84.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.52556\n",
      "kldivergence:   1499.55\n",
      "variational_beta * kldivergence:  0.14995\n",
      "batch accuracy: 84.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.46723\n",
      "kldivergence:   1609.51\n",
      "variational_beta * kldivergence:  0.16095\n",
      "batch accuracy: 85.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.42124\n",
      "kldivergence:   1345.04\n",
      "variational_beta * kldivergence:  0.13450\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.49717\n",
      "kldivergence:   1481.68\n",
      "variational_beta * kldivergence:  0.14817\n",
      "batch accuracy: 85.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.46966\n",
      "kldivergence:   1422.61\n",
      "variational_beta * kldivergence:  0.14226\n",
      "batch accuracy: 85.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.42803\n",
      "kldivergence:   1308.83\n",
      "variational_beta * kldivergence:  0.13088\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.45161\n",
      "kldivergence:   1475.76\n",
      "variational_beta * kldivergence:  0.14758\n",
      "batch accuracy: 86.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.40784\n",
      "kldivergence:   1465.03\n",
      "variational_beta * kldivergence:  0.14650\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.45233\n",
      "kldivergence:   1473.33\n",
      "variational_beta * kldivergence:  0.14733\n",
      "batch accuracy: 85.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.45853\n",
      "kldivergence:   1432.51\n",
      "variational_beta * kldivergence:  0.14325\n",
      "batch accuracy: 85.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.43828\n",
      "kldivergence:   1377.65\n",
      "variational_beta * kldivergence:  0.13776\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.47176\n",
      "kldivergence:   1445.49\n",
      "variational_beta * kldivergence:  0.14455\n",
      "batch accuracy: 85.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.44031\n",
      "kldivergence:   1413.56\n",
      "variational_beta * kldivergence:  0.14136\n",
      "batch accuracy: 85.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.46071\n",
      "kldivergence:   1381.01\n",
      "variational_beta * kldivergence:  0.13810\n",
      "batch accuracy: 85.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.41120\n",
      "kldivergence:   1387.84\n",
      "variational_beta * kldivergence:  0.13878\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.45856\n",
      "kldivergence:   1495.42\n",
      "variational_beta * kldivergence:  0.14954\n",
      "batch accuracy: 85.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.42740\n",
      "kldivergence:   1440.69\n",
      "variational_beta * kldivergence:  0.14407\n",
      "batch accuracy: 86.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.38841\n",
      "kldivergence:   1308.29\n",
      "variational_beta * kldivergence:  0.13083\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.48025\n",
      "kldivergence:   1391.31\n",
      "variational_beta * kldivergence:  0.13913\n",
      "batch accuracy: 85.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.36276\n",
      "kldivergence:   1307.22\n",
      "variational_beta * kldivergence:  0.13072\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.52056\n",
      "kldivergence:   1482.09\n",
      "variational_beta * kldivergence:  0.14821\n",
      "batch accuracy: 85.32\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.51871\n",
      "kldivergence:   1411.68\n",
      "variational_beta * kldivergence:  0.14117\n",
      "batch accuracy: 83.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.49359\n",
      "kldivergence:   1514.06\n",
      "variational_beta * kldivergence:  0.15141\n",
      "batch accuracy: 84.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #37\n",
      "reconstruction loss: 0.42403\n",
      "kldivergence:   1410.00\n",
      "variational_beta * kldivergence:  0.14100\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "epoch # 37 : train loss is [181.7619944284683] and validation loss is [0.10064396623303368] \n",
      "Epoch [38 / 150] average reconstruction error: 0.489925\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30956\n",
      "kldivergence:   1478.43\n",
      "variational_beta * kldivergence:  0.14784\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29409\n",
      "kldivergence:   1480.00\n",
      "variational_beta * kldivergence:  0.14800\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33621\n",
      "kldivergence:   1310.18\n",
      "variational_beta * kldivergence:  0.13102\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31911\n",
      "kldivergence:   1710.21\n",
      "variational_beta * kldivergence:  0.17102\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38340\n",
      "kldivergence:   1512.03\n",
      "variational_beta * kldivergence:  0.15120\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37276\n",
      "kldivergence:   1636.78\n",
      "variational_beta * kldivergence:  0.16368\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29566\n",
      "kldivergence:   1438.26\n",
      "variational_beta * kldivergence:  0.14383\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30977\n",
      "kldivergence:   1633.63\n",
      "variational_beta * kldivergence:  0.16336\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33952\n",
      "kldivergence:   1446.67\n",
      "variational_beta * kldivergence:  0.14467\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31068\n",
      "kldivergence:   1587.10\n",
      "variational_beta * kldivergence:  0.15871\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36197\n",
      "kldivergence:   1614.81\n",
      "variational_beta * kldivergence:  0.16148\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32611\n",
      "kldivergence:   1627.62\n",
      "variational_beta * kldivergence:  0.16276\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.27785\n",
      "kldivergence:   1384.08\n",
      "variational_beta * kldivergence:  0.13841\n",
      "batch accuracy: 90.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29672\n",
      "kldivergence:   1374.94\n",
      "variational_beta * kldivergence:  0.13749\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34608\n",
      "kldivergence:   1530.43\n",
      "variational_beta * kldivergence:  0.15304\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30483\n",
      "kldivergence:   1454.01\n",
      "variational_beta * kldivergence:  0.14540\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29034\n",
      "kldivergence:   1495.26\n",
      "variational_beta * kldivergence:  0.14953\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33765\n",
      "kldivergence:   1722.94\n",
      "variational_beta * kldivergence:  0.17229\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36287\n",
      "kldivergence:   1716.84\n",
      "variational_beta * kldivergence:  0.17168\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33422\n",
      "kldivergence:   1599.41\n",
      "variational_beta * kldivergence:  0.15994\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29431\n",
      "kldivergence:   1515.02\n",
      "variational_beta * kldivergence:  0.15150\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.39335\n",
      "kldivergence:   1568.00\n",
      "variational_beta * kldivergence:  0.15680\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31848\n",
      "kldivergence:   1429.02\n",
      "variational_beta * kldivergence:  0.14290\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36777\n",
      "kldivergence:   1628.68\n",
      "variational_beta * kldivergence:  0.16287\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29158\n",
      "kldivergence:   1528.97\n",
      "variational_beta * kldivergence:  0.15290\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.27610\n",
      "kldivergence:   1418.97\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 90.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37691\n",
      "kldivergence:   1873.34\n",
      "variational_beta * kldivergence:  0.18733\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30025\n",
      "kldivergence:   1337.75\n",
      "variational_beta * kldivergence:  0.13378\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33011\n",
      "kldivergence:   1589.50\n",
      "variational_beta * kldivergence:  0.15895\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29730\n",
      "kldivergence:   1382.70\n",
      "variational_beta * kldivergence:  0.13827\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31337\n",
      "kldivergence:   1471.54\n",
      "variational_beta * kldivergence:  0.14715\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36403\n",
      "kldivergence:   1632.14\n",
      "variational_beta * kldivergence:  0.16321\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34163\n",
      "kldivergence:   1526.49\n",
      "variational_beta * kldivergence:  0.15265\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30720\n",
      "kldivergence:   1501.34\n",
      "variational_beta * kldivergence:  0.15013\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31638\n",
      "kldivergence:   1512.53\n",
      "variational_beta * kldivergence:  0.15125\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37734\n",
      "kldivergence:   1636.43\n",
      "variational_beta * kldivergence:  0.16364\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35053\n",
      "kldivergence:   1509.04\n",
      "variational_beta * kldivergence:  0.15090\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36584\n",
      "kldivergence:   1483.67\n",
      "variational_beta * kldivergence:  0.14837\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33458\n",
      "kldivergence:   1345.37\n",
      "variational_beta * kldivergence:  0.13454\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34732\n",
      "kldivergence:   1457.54\n",
      "variational_beta * kldivergence:  0.14575\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33020\n",
      "kldivergence:   1528.33\n",
      "variational_beta * kldivergence:  0.15283\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30290\n",
      "kldivergence:   1497.86\n",
      "variational_beta * kldivergence:  0.14979\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33880\n",
      "kldivergence:   1630.96\n",
      "variational_beta * kldivergence:  0.16310\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38366\n",
      "kldivergence:   1482.05\n",
      "variational_beta * kldivergence:  0.14820\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37370\n",
      "kldivergence:   1560.63\n",
      "variational_beta * kldivergence:  0.15606\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30829\n",
      "kldivergence:   1447.54\n",
      "variational_beta * kldivergence:  0.14475\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35394\n",
      "kldivergence:   1542.19\n",
      "variational_beta * kldivergence:  0.15422\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31729\n",
      "kldivergence:   1489.37\n",
      "variational_beta * kldivergence:  0.14894\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32264\n",
      "kldivergence:   1668.66\n",
      "variational_beta * kldivergence:  0.16687\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33184\n",
      "kldivergence:   1878.44\n",
      "variational_beta * kldivergence:  0.18784\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35145\n",
      "kldivergence:   1470.66\n",
      "variational_beta * kldivergence:  0.14707\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35168\n",
      "kldivergence:   1665.56\n",
      "variational_beta * kldivergence:  0.16656\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32308\n",
      "kldivergence:   1392.60\n",
      "variational_beta * kldivergence:  0.13926\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32023\n",
      "kldivergence:   1583.12\n",
      "variational_beta * kldivergence:  0.15831\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30580\n",
      "kldivergence:   1561.82\n",
      "variational_beta * kldivergence:  0.15618\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31105\n",
      "kldivergence:   1862.26\n",
      "variational_beta * kldivergence:  0.18623\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31472\n",
      "kldivergence:   1483.32\n",
      "variational_beta * kldivergence:  0.14833\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32844\n",
      "kldivergence:   1480.20\n",
      "variational_beta * kldivergence:  0.14802\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35907\n",
      "kldivergence:   1578.02\n",
      "variational_beta * kldivergence:  0.15780\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33417\n",
      "kldivergence:   1796.62\n",
      "variational_beta * kldivergence:  0.17966\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31265\n",
      "kldivergence:   1535.03\n",
      "variational_beta * kldivergence:  0.15350\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32546\n",
      "kldivergence:   1294.77\n",
      "variational_beta * kldivergence:  0.12948\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.41589\n",
      "kldivergence:   1552.19\n",
      "variational_beta * kldivergence:  0.15522\n",
      "batch accuracy: 86.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33979\n",
      "kldivergence:   1680.36\n",
      "variational_beta * kldivergence:  0.16804\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34260\n",
      "kldivergence:   1549.75\n",
      "variational_beta * kldivergence:  0.15497\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30096\n",
      "kldivergence:   1341.88\n",
      "variational_beta * kldivergence:  0.13419\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34477\n",
      "kldivergence:   1452.13\n",
      "variational_beta * kldivergence:  0.14521\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.27452\n",
      "kldivergence:   1503.39\n",
      "variational_beta * kldivergence:  0.15034\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33906\n",
      "kldivergence:   1428.45\n",
      "variational_beta * kldivergence:  0.14284\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34912\n",
      "kldivergence:   1634.77\n",
      "variational_beta * kldivergence:  0.16348\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.39251\n",
      "kldivergence:   1699.76\n",
      "variational_beta * kldivergence:  0.16998\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30529\n",
      "kldivergence:   1697.70\n",
      "variational_beta * kldivergence:  0.16977\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36123\n",
      "kldivergence:   1571.69\n",
      "variational_beta * kldivergence:  0.15717\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31077\n",
      "kldivergence:   1492.59\n",
      "variational_beta * kldivergence:  0.14926\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37287\n",
      "kldivergence:   1503.96\n",
      "variational_beta * kldivergence:  0.15040\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34402\n",
      "kldivergence:   1584.81\n",
      "variational_beta * kldivergence:  0.15848\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35096\n",
      "kldivergence:   1543.52\n",
      "variational_beta * kldivergence:  0.15435\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30859\n",
      "kldivergence:   1595.53\n",
      "variational_beta * kldivergence:  0.15955\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.44254\n",
      "kldivergence:   1735.81\n",
      "variational_beta * kldivergence:  0.17358\n",
      "batch accuracy: 85.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33909\n",
      "kldivergence:   1736.13\n",
      "variational_beta * kldivergence:  0.17361\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35098\n",
      "kldivergence:   1658.12\n",
      "variational_beta * kldivergence:  0.16581\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32142\n",
      "kldivergence:   1773.94\n",
      "variational_beta * kldivergence:  0.17739\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32161\n",
      "kldivergence:   1849.21\n",
      "variational_beta * kldivergence:  0.18492\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34907\n",
      "kldivergence:   1632.98\n",
      "variational_beta * kldivergence:  0.16330\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29042\n",
      "kldivergence:   1440.09\n",
      "variational_beta * kldivergence:  0.14401\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32193\n",
      "kldivergence:   1726.45\n",
      "variational_beta * kldivergence:  0.17264\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35761\n",
      "kldivergence:   1697.91\n",
      "variational_beta * kldivergence:  0.16979\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31808\n",
      "kldivergence:   1696.79\n",
      "variational_beta * kldivergence:  0.16968\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34923\n",
      "kldivergence:   1596.04\n",
      "variational_beta * kldivergence:  0.15960\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31146\n",
      "kldivergence:   1525.19\n",
      "variational_beta * kldivergence:  0.15252\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35542\n",
      "kldivergence:   1686.40\n",
      "variational_beta * kldivergence:  0.16864\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30918\n",
      "kldivergence:   1622.28\n",
      "variational_beta * kldivergence:  0.16223\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30094\n",
      "kldivergence:   1316.87\n",
      "variational_beta * kldivergence:  0.13169\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29152\n",
      "kldivergence:   1431.72\n",
      "variational_beta * kldivergence:  0.14317\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35682\n",
      "kldivergence:   1524.99\n",
      "variational_beta * kldivergence:  0.15250\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32893\n",
      "kldivergence:   1617.74\n",
      "variational_beta * kldivergence:  0.16177\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35625\n",
      "kldivergence:   1588.78\n",
      "variational_beta * kldivergence:  0.15888\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34876\n",
      "kldivergence:   1766.88\n",
      "variational_beta * kldivergence:  0.17669\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33657\n",
      "kldivergence:   1662.87\n",
      "variational_beta * kldivergence:  0.16629\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30734\n",
      "kldivergence:   1495.26\n",
      "variational_beta * kldivergence:  0.14953\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28323\n",
      "kldivergence:   1532.87\n",
      "variational_beta * kldivergence:  0.15329\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35456\n",
      "kldivergence:   2116.57\n",
      "variational_beta * kldivergence:  0.21166\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.39103\n",
      "kldivergence:   1747.57\n",
      "variational_beta * kldivergence:  0.17476\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31850\n",
      "kldivergence:   1546.59\n",
      "variational_beta * kldivergence:  0.15466\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.26739\n",
      "kldivergence:   1439.35\n",
      "variational_beta * kldivergence:  0.14393\n",
      "batch accuracy: 90.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31837\n",
      "kldivergence:   1432.47\n",
      "variational_beta * kldivergence:  0.14325\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28120\n",
      "kldivergence:   1600.55\n",
      "variational_beta * kldivergence:  0.16006\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33027\n",
      "kldivergence:   1737.62\n",
      "variational_beta * kldivergence:  0.17376\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28522\n",
      "kldivergence:   1549.01\n",
      "variational_beta * kldivergence:  0.15490\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36218\n",
      "kldivergence:   1543.19\n",
      "variational_beta * kldivergence:  0.15432\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30196\n",
      "kldivergence:   1684.28\n",
      "variational_beta * kldivergence:  0.16843\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28970\n",
      "kldivergence:   1439.65\n",
      "variational_beta * kldivergence:  0.14396\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32522\n",
      "kldivergence:   1403.85\n",
      "variational_beta * kldivergence:  0.14038\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.39839\n",
      "kldivergence:   1607.47\n",
      "variational_beta * kldivergence:  0.16075\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33779\n",
      "kldivergence:   1510.89\n",
      "variational_beta * kldivergence:  0.15109\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37638\n",
      "kldivergence:   1621.11\n",
      "variational_beta * kldivergence:  0.16211\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.39112\n",
      "kldivergence:   1725.69\n",
      "variational_beta * kldivergence:  0.17257\n",
      "batch accuracy: 86.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.40256\n",
      "kldivergence:   1739.87\n",
      "variational_beta * kldivergence:  0.17399\n",
      "batch accuracy: 86.36\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30836\n",
      "kldivergence:   1503.95\n",
      "variational_beta * kldivergence:  0.15040\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31133\n",
      "kldivergence:   1599.19\n",
      "variational_beta * kldivergence:  0.15992\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31204\n",
      "kldivergence:   1459.61\n",
      "variational_beta * kldivergence:  0.14596\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33671\n",
      "kldivergence:   1490.09\n",
      "variational_beta * kldivergence:  0.14901\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34097\n",
      "kldivergence:   1693.91\n",
      "variational_beta * kldivergence:  0.16939\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30923\n",
      "kldivergence:   1577.44\n",
      "variational_beta * kldivergence:  0.15774\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32171\n",
      "kldivergence:   1352.17\n",
      "variational_beta * kldivergence:  0.13522\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31495\n",
      "kldivergence:   1339.24\n",
      "variational_beta * kldivergence:  0.13392\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33763\n",
      "kldivergence:   1491.09\n",
      "variational_beta * kldivergence:  0.14911\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30155\n",
      "kldivergence:   1618.73\n",
      "variational_beta * kldivergence:  0.16187\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38818\n",
      "kldivergence:   1483.96\n",
      "variational_beta * kldivergence:  0.14840\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32998\n",
      "kldivergence:   1451.28\n",
      "variational_beta * kldivergence:  0.14513\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.26630\n",
      "kldivergence:   1449.47\n",
      "variational_beta * kldivergence:  0.14495\n",
      "batch accuracy: 91.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28693\n",
      "kldivergence:   1329.96\n",
      "variational_beta * kldivergence:  0.13300\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.27342\n",
      "kldivergence:   1392.67\n",
      "variational_beta * kldivergence:  0.13927\n",
      "batch accuracy: 91.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30898\n",
      "kldivergence:   1431.91\n",
      "variational_beta * kldivergence:  0.14319\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31239\n",
      "kldivergence:   1323.30\n",
      "variational_beta * kldivergence:  0.13233\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34294\n",
      "kldivergence:   1547.59\n",
      "variational_beta * kldivergence:  0.15476\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33351\n",
      "kldivergence:   1552.10\n",
      "variational_beta * kldivergence:  0.15521\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32037\n",
      "kldivergence:   1587.62\n",
      "variational_beta * kldivergence:  0.15876\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37194\n",
      "kldivergence:   1647.25\n",
      "variational_beta * kldivergence:  0.16473\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30306\n",
      "kldivergence:   1568.79\n",
      "variational_beta * kldivergence:  0.15688\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35327\n",
      "kldivergence:   1734.34\n",
      "variational_beta * kldivergence:  0.17343\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38643\n",
      "kldivergence:   1460.56\n",
      "variational_beta * kldivergence:  0.14606\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33280\n",
      "kldivergence:   1590.37\n",
      "variational_beta * kldivergence:  0.15904\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38613\n",
      "kldivergence:   1474.48\n",
      "variational_beta * kldivergence:  0.14745\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37464\n",
      "kldivergence:   1491.33\n",
      "variational_beta * kldivergence:  0.14913\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33804\n",
      "kldivergence:   1955.11\n",
      "variational_beta * kldivergence:  0.19551\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35917\n",
      "kldivergence:   1512.69\n",
      "variational_beta * kldivergence:  0.15127\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32011\n",
      "kldivergence:   1529.86\n",
      "variational_beta * kldivergence:  0.15299\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31758\n",
      "kldivergence:   1530.64\n",
      "variational_beta * kldivergence:  0.15306\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34008\n",
      "kldivergence:   1624.86\n",
      "variational_beta * kldivergence:  0.16249\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35622\n",
      "kldivergence:   1599.18\n",
      "variational_beta * kldivergence:  0.15992\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33790\n",
      "kldivergence:   1721.28\n",
      "variational_beta * kldivergence:  0.17213\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34752\n",
      "kldivergence:   1562.61\n",
      "variational_beta * kldivergence:  0.15626\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31088\n",
      "kldivergence:   1453.78\n",
      "variational_beta * kldivergence:  0.14538\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37136\n",
      "kldivergence:   1396.45\n",
      "variational_beta * kldivergence:  0.13965\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31273\n",
      "kldivergence:   1554.00\n",
      "variational_beta * kldivergence:  0.15540\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28945\n",
      "kldivergence:   1495.68\n",
      "variational_beta * kldivergence:  0.14957\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37103\n",
      "kldivergence:   1499.79\n",
      "variational_beta * kldivergence:  0.14998\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35620\n",
      "kldivergence:   1600.28\n",
      "variational_beta * kldivergence:  0.16003\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28376\n",
      "kldivergence:   1430.54\n",
      "variational_beta * kldivergence:  0.14305\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30639\n",
      "kldivergence:   1586.57\n",
      "variational_beta * kldivergence:  0.15866\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33723\n",
      "kldivergence:   1573.46\n",
      "variational_beta * kldivergence:  0.15735\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31305\n",
      "kldivergence:   1465.09\n",
      "variational_beta * kldivergence:  0.14651\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32638\n",
      "kldivergence:   1453.17\n",
      "variational_beta * kldivergence:  0.14532\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35199\n",
      "kldivergence:   1524.65\n",
      "variational_beta * kldivergence:  0.15247\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31470\n",
      "kldivergence:   1596.45\n",
      "variational_beta * kldivergence:  0.15964\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36834\n",
      "kldivergence:   1441.26\n",
      "variational_beta * kldivergence:  0.14413\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32961\n",
      "kldivergence:   1471.61\n",
      "variational_beta * kldivergence:  0.14716\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28052\n",
      "kldivergence:   1452.65\n",
      "variational_beta * kldivergence:  0.14527\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33404\n",
      "kldivergence:   1640.80\n",
      "variational_beta * kldivergence:  0.16408\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36616\n",
      "kldivergence:   1638.84\n",
      "variational_beta * kldivergence:  0.16388\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31353\n",
      "kldivergence:   1529.96\n",
      "variational_beta * kldivergence:  0.15300\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28358\n",
      "kldivergence:   1374.47\n",
      "variational_beta * kldivergence:  0.13745\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32739\n",
      "kldivergence:   1426.23\n",
      "variational_beta * kldivergence:  0.14262\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35338\n",
      "kldivergence:   1617.33\n",
      "variational_beta * kldivergence:  0.16173\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30022\n",
      "kldivergence:   1364.06\n",
      "variational_beta * kldivergence:  0.13641\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38919\n",
      "kldivergence:   1541.62\n",
      "variational_beta * kldivergence:  0.15416\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34592\n",
      "kldivergence:   1503.61\n",
      "variational_beta * kldivergence:  0.15036\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37230\n",
      "kldivergence:   1598.32\n",
      "variational_beta * kldivergence:  0.15983\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31684\n",
      "kldivergence:   1507.97\n",
      "variational_beta * kldivergence:  0.15080\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37803\n",
      "kldivergence:   1641.65\n",
      "variational_beta * kldivergence:  0.16417\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29042\n",
      "kldivergence:   1584.09\n",
      "variational_beta * kldivergence:  0.15841\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33131\n",
      "kldivergence:   1559.84\n",
      "variational_beta * kldivergence:  0.15598\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34978\n",
      "kldivergence:   1580.46\n",
      "variational_beta * kldivergence:  0.15805\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34055\n",
      "kldivergence:   1535.53\n",
      "variational_beta * kldivergence:  0.15355\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31666\n",
      "kldivergence:   2242.48\n",
      "variational_beta * kldivergence:  0.22425\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33465\n",
      "kldivergence:   1569.74\n",
      "variational_beta * kldivergence:  0.15697\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32923\n",
      "kldivergence:   1918.75\n",
      "variational_beta * kldivergence:  0.19188\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31285\n",
      "kldivergence:   1492.79\n",
      "variational_beta * kldivergence:  0.14928\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.39674\n",
      "kldivergence:   1618.33\n",
      "variational_beta * kldivergence:  0.16183\n",
      "batch accuracy: 86.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37187\n",
      "kldivergence:   1624.68\n",
      "variational_beta * kldivergence:  0.16247\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34502\n",
      "kldivergence:   1602.85\n",
      "variational_beta * kldivergence:  0.16029\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33095\n",
      "kldivergence:   1766.33\n",
      "variational_beta * kldivergence:  0.17663\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30561\n",
      "kldivergence:   1277.89\n",
      "variational_beta * kldivergence:  0.12779\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33439\n",
      "kldivergence:   1557.69\n",
      "variational_beta * kldivergence:  0.15577\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35601\n",
      "kldivergence:   1719.34\n",
      "variational_beta * kldivergence:  0.17193\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32880\n",
      "kldivergence:   1486.17\n",
      "variational_beta * kldivergence:  0.14862\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37459\n",
      "kldivergence:   1531.58\n",
      "variational_beta * kldivergence:  0.15316\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38915\n",
      "kldivergence:   1568.20\n",
      "variational_beta * kldivergence:  0.15682\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31336\n",
      "kldivergence:   1320.22\n",
      "variational_beta * kldivergence:  0.13202\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31470\n",
      "kldivergence:   1432.83\n",
      "variational_beta * kldivergence:  0.14328\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30486\n",
      "kldivergence:   1439.19\n",
      "variational_beta * kldivergence:  0.14392\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30903\n",
      "kldivergence:   1451.33\n",
      "variational_beta * kldivergence:  0.14513\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30956\n",
      "kldivergence:   1288.16\n",
      "variational_beta * kldivergence:  0.12882\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.27212\n",
      "kldivergence:   1477.75\n",
      "variational_beta * kldivergence:  0.14777\n",
      "batch accuracy: 90.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.39454\n",
      "kldivergence:   1619.78\n",
      "variational_beta * kldivergence:  0.16198\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35182\n",
      "kldivergence:   1822.60\n",
      "variational_beta * kldivergence:  0.18226\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38920\n",
      "kldivergence:   1725.41\n",
      "variational_beta * kldivergence:  0.17254\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31398\n",
      "kldivergence:   1384.55\n",
      "variational_beta * kldivergence:  0.13845\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38003\n",
      "kldivergence:   1546.49\n",
      "variational_beta * kldivergence:  0.15465\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33501\n",
      "kldivergence:   1543.30\n",
      "variational_beta * kldivergence:  0.15433\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34921\n",
      "kldivergence:   1513.84\n",
      "variational_beta * kldivergence:  0.15138\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33201\n",
      "kldivergence:   1474.39\n",
      "variational_beta * kldivergence:  0.14744\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34036\n",
      "kldivergence:   1551.81\n",
      "variational_beta * kldivergence:  0.15518\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32404\n",
      "kldivergence:   1589.16\n",
      "variational_beta * kldivergence:  0.15892\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32650\n",
      "kldivergence:   1434.26\n",
      "variational_beta * kldivergence:  0.14343\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34763\n",
      "kldivergence:   1523.47\n",
      "variational_beta * kldivergence:  0.15235\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33639\n",
      "kldivergence:   1557.05\n",
      "variational_beta * kldivergence:  0.15570\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34338\n",
      "kldivergence:   1626.54\n",
      "variational_beta * kldivergence:  0.16265\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32613\n",
      "kldivergence:   1615.77\n",
      "variational_beta * kldivergence:  0.16158\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34404\n",
      "kldivergence:   1830.95\n",
      "variational_beta * kldivergence:  0.18309\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30810\n",
      "kldivergence:   1670.31\n",
      "variational_beta * kldivergence:  0.16703\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34733\n",
      "kldivergence:   1614.36\n",
      "variational_beta * kldivergence:  0.16144\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.46207\n",
      "kldivergence:   1764.84\n",
      "variational_beta * kldivergence:  0.17648\n",
      "batch accuracy: 84.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31869\n",
      "kldivergence:   1623.55\n",
      "variational_beta * kldivergence:  0.16235\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38105\n",
      "kldivergence:   1767.24\n",
      "variational_beta * kldivergence:  0.17672\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31452\n",
      "kldivergence:   1593.50\n",
      "variational_beta * kldivergence:  0.15935\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37314\n",
      "kldivergence:   1617.96\n",
      "variational_beta * kldivergence:  0.16180\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32814\n",
      "kldivergence:   1659.63\n",
      "variational_beta * kldivergence:  0.16596\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31178\n",
      "kldivergence:   1489.98\n",
      "variational_beta * kldivergence:  0.14900\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34707\n",
      "kldivergence:   1544.07\n",
      "variational_beta * kldivergence:  0.15441\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37500\n",
      "kldivergence:   1847.18\n",
      "variational_beta * kldivergence:  0.18472\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36011\n",
      "kldivergence:   1571.33\n",
      "variational_beta * kldivergence:  0.15713\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30706\n",
      "kldivergence:   1589.40\n",
      "variational_beta * kldivergence:  0.15894\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34903\n",
      "kldivergence:   1387.18\n",
      "variational_beta * kldivergence:  0.13872\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32535\n",
      "kldivergence:   1561.90\n",
      "variational_beta * kldivergence:  0.15619\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31642\n",
      "kldivergence:   1504.24\n",
      "variational_beta * kldivergence:  0.15042\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38011\n",
      "kldivergence:   1607.79\n",
      "variational_beta * kldivergence:  0.16078\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32322\n",
      "kldivergence:   1572.15\n",
      "variational_beta * kldivergence:  0.15722\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33929\n",
      "kldivergence:   1773.20\n",
      "variational_beta * kldivergence:  0.17732\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31471\n",
      "kldivergence:   1616.03\n",
      "variational_beta * kldivergence:  0.16160\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.40626\n",
      "kldivergence:   1833.87\n",
      "variational_beta * kldivergence:  0.18339\n",
      "batch accuracy: 86.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36587\n",
      "kldivergence:   1759.58\n",
      "variational_beta * kldivergence:  0.17596\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.39491\n",
      "kldivergence:   1737.39\n",
      "variational_beta * kldivergence:  0.17374\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36366\n",
      "kldivergence:   1605.31\n",
      "variational_beta * kldivergence:  0.16053\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30109\n",
      "kldivergence:   1533.34\n",
      "variational_beta * kldivergence:  0.15333\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34975\n",
      "kldivergence:   1755.57\n",
      "variational_beta * kldivergence:  0.17556\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35153\n",
      "kldivergence:   1415.98\n",
      "variational_beta * kldivergence:  0.14160\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37337\n",
      "kldivergence:   1731.60\n",
      "variational_beta * kldivergence:  0.17316\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36743\n",
      "kldivergence:   1655.88\n",
      "variational_beta * kldivergence:  0.16559\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28940\n",
      "kldivergence:   1451.55\n",
      "variational_beta * kldivergence:  0.14515\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31125\n",
      "kldivergence:   1426.91\n",
      "variational_beta * kldivergence:  0.14269\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.41723\n",
      "kldivergence:   1630.83\n",
      "variational_beta * kldivergence:  0.16308\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.25920\n",
      "kldivergence:   1458.43\n",
      "variational_beta * kldivergence:  0.14584\n",
      "batch accuracy: 91.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.39780\n",
      "kldivergence:   1814.34\n",
      "variational_beta * kldivergence:  0.18143\n",
      "batch accuracy: 86.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.25683\n",
      "kldivergence:   1969.38\n",
      "variational_beta * kldivergence:  0.19694\n",
      "batch accuracy: 91.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35053\n",
      "kldivergence:   1584.72\n",
      "variational_beta * kldivergence:  0.15847\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37144\n",
      "kldivergence:   1751.79\n",
      "variational_beta * kldivergence:  0.17518\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37877\n",
      "kldivergence:   1818.09\n",
      "variational_beta * kldivergence:  0.18181\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34002\n",
      "kldivergence:   1827.17\n",
      "variational_beta * kldivergence:  0.18272\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.27290\n",
      "kldivergence:   1591.76\n",
      "variational_beta * kldivergence:  0.15918\n",
      "batch accuracy: 90.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34797\n",
      "kldivergence:   1499.66\n",
      "variational_beta * kldivergence:  0.14997\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35996\n",
      "kldivergence:   1534.61\n",
      "variational_beta * kldivergence:  0.15346\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33194\n",
      "kldivergence:   1738.68\n",
      "variational_beta * kldivergence:  0.17387\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32267\n",
      "kldivergence:   1631.19\n",
      "variational_beta * kldivergence:  0.16312\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34934\n",
      "kldivergence:   1640.26\n",
      "variational_beta * kldivergence:  0.16403\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.42472\n",
      "kldivergence:   1752.89\n",
      "variational_beta * kldivergence:  0.17529\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37935\n",
      "kldivergence:   1567.45\n",
      "variational_beta * kldivergence:  0.15674\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31533\n",
      "kldivergence:   1393.82\n",
      "variational_beta * kldivergence:  0.13938\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38387\n",
      "kldivergence:   1789.80\n",
      "variational_beta * kldivergence:  0.17898\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30537\n",
      "kldivergence:   1507.03\n",
      "variational_beta * kldivergence:  0.15070\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33649\n",
      "kldivergence:   1551.87\n",
      "variational_beta * kldivergence:  0.15519\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31749\n",
      "kldivergence:   1349.44\n",
      "variational_beta * kldivergence:  0.13494\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29730\n",
      "kldivergence:   1588.15\n",
      "variational_beta * kldivergence:  0.15882\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28778\n",
      "kldivergence:   1489.67\n",
      "variational_beta * kldivergence:  0.14897\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28999\n",
      "kldivergence:   1429.44\n",
      "variational_beta * kldivergence:  0.14294\n",
      "batch accuracy: 90.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33557\n",
      "kldivergence:   1390.49\n",
      "variational_beta * kldivergence:  0.13905\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35326\n",
      "kldivergence:   1647.90\n",
      "variational_beta * kldivergence:  0.16479\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30606\n",
      "kldivergence:   1501.18\n",
      "variational_beta * kldivergence:  0.15012\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30558\n",
      "kldivergence:   1297.28\n",
      "variational_beta * kldivergence:  0.12973\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35710\n",
      "kldivergence:   1545.52\n",
      "variational_beta * kldivergence:  0.15455\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35497\n",
      "kldivergence:   1619.44\n",
      "variational_beta * kldivergence:  0.16194\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33738\n",
      "kldivergence:   1416.06\n",
      "variational_beta * kldivergence:  0.14161\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33784\n",
      "kldivergence:   1832.97\n",
      "variational_beta * kldivergence:  0.18330\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37943\n",
      "kldivergence:   1709.39\n",
      "variational_beta * kldivergence:  0.17094\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30441\n",
      "kldivergence:   1514.60\n",
      "variational_beta * kldivergence:  0.15146\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30255\n",
      "kldivergence:   1546.36\n",
      "variational_beta * kldivergence:  0.15464\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28885\n",
      "kldivergence:   1408.87\n",
      "variational_beta * kldivergence:  0.14089\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32004\n",
      "kldivergence:   1468.07\n",
      "variational_beta * kldivergence:  0.14681\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31559\n",
      "kldivergence:   1485.68\n",
      "variational_beta * kldivergence:  0.14857\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.27982\n",
      "kldivergence:   1480.14\n",
      "variational_beta * kldivergence:  0.14801\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32251\n",
      "kldivergence:   1462.07\n",
      "variational_beta * kldivergence:  0.14621\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35250\n",
      "kldivergence:   1612.47\n",
      "variational_beta * kldivergence:  0.16125\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29694\n",
      "kldivergence:   1605.21\n",
      "variational_beta * kldivergence:  0.16052\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33141\n",
      "kldivergence:   1460.01\n",
      "variational_beta * kldivergence:  0.14600\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28425\n",
      "kldivergence:   1340.91\n",
      "variational_beta * kldivergence:  0.13409\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31615\n",
      "kldivergence:   1480.42\n",
      "variational_beta * kldivergence:  0.14804\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29859\n",
      "kldivergence:   1553.84\n",
      "variational_beta * kldivergence:  0.15538\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35864\n",
      "kldivergence:   1472.32\n",
      "variational_beta * kldivergence:  0.14723\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32243\n",
      "kldivergence:   1405.78\n",
      "variational_beta * kldivergence:  0.14058\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30252\n",
      "kldivergence:   1377.42\n",
      "variational_beta * kldivergence:  0.13774\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35190\n",
      "kldivergence:   1582.89\n",
      "variational_beta * kldivergence:  0.15829\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36003\n",
      "kldivergence:   1683.35\n",
      "variational_beta * kldivergence:  0.16834\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28828\n",
      "kldivergence:   1414.91\n",
      "variational_beta * kldivergence:  0.14149\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35536\n",
      "kldivergence:   1786.49\n",
      "variational_beta * kldivergence:  0.17865\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32632\n",
      "kldivergence:   1509.71\n",
      "variational_beta * kldivergence:  0.15097\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29034\n",
      "kldivergence:   1403.14\n",
      "variational_beta * kldivergence:  0.14031\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33486\n",
      "kldivergence:   1312.08\n",
      "variational_beta * kldivergence:  0.13121\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30809\n",
      "kldivergence:   1487.97\n",
      "variational_beta * kldivergence:  0.14880\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36764\n",
      "kldivergence:   1803.19\n",
      "variational_beta * kldivergence:  0.18032\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34289\n",
      "kldivergence:   1570.90\n",
      "variational_beta * kldivergence:  0.15709\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35306\n",
      "kldivergence:   1572.55\n",
      "variational_beta * kldivergence:  0.15726\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38425\n",
      "kldivergence:   1746.21\n",
      "variational_beta * kldivergence:  0.17462\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30546\n",
      "kldivergence:   1406.81\n",
      "variational_beta * kldivergence:  0.14068\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33073\n",
      "kldivergence:   1477.21\n",
      "variational_beta * kldivergence:  0.14772\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29745\n",
      "kldivergence:   1475.07\n",
      "variational_beta * kldivergence:  0.14751\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34722\n",
      "kldivergence:   1551.96\n",
      "variational_beta * kldivergence:  0.15520\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31110\n",
      "kldivergence:   1361.35\n",
      "variational_beta * kldivergence:  0.13613\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34983\n",
      "kldivergence:   1496.44\n",
      "variational_beta * kldivergence:  0.14964\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28802\n",
      "kldivergence:   1375.76\n",
      "variational_beta * kldivergence:  0.13758\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.27498\n",
      "kldivergence:   1400.41\n",
      "variational_beta * kldivergence:  0.14004\n",
      "batch accuracy: 90.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36341\n",
      "kldivergence:   1571.58\n",
      "variational_beta * kldivergence:  0.15716\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38051\n",
      "kldivergence:   1597.04\n",
      "variational_beta * kldivergence:  0.15970\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31447\n",
      "kldivergence:   1584.77\n",
      "variational_beta * kldivergence:  0.15848\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28806\n",
      "kldivergence:   1406.89\n",
      "variational_beta * kldivergence:  0.14069\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29723\n",
      "kldivergence:   1576.78\n",
      "variational_beta * kldivergence:  0.15768\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.27639\n",
      "kldivergence:   1685.30\n",
      "variational_beta * kldivergence:  0.16853\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32160\n",
      "kldivergence:   1401.77\n",
      "variational_beta * kldivergence:  0.14018\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28035\n",
      "kldivergence:   1339.12\n",
      "variational_beta * kldivergence:  0.13391\n",
      "batch accuracy: 91.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.26078\n",
      "kldivergence:   1217.96\n",
      "variational_beta * kldivergence:  0.12180\n",
      "batch accuracy: 91.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32761\n",
      "kldivergence:   1791.13\n",
      "variational_beta * kldivergence:  0.17911\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31871\n",
      "kldivergence:   1332.50\n",
      "variational_beta * kldivergence:  0.13325\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38125\n",
      "kldivergence:   1539.63\n",
      "variational_beta * kldivergence:  0.15396\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32939\n",
      "kldivergence:   1476.62\n",
      "variational_beta * kldivergence:  0.14766\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30744\n",
      "kldivergence:   1374.85\n",
      "variational_beta * kldivergence:  0.13749\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32328\n",
      "kldivergence:   1497.38\n",
      "variational_beta * kldivergence:  0.14974\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30766\n",
      "kldivergence:   1550.18\n",
      "variational_beta * kldivergence:  0.15502\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37080\n",
      "kldivergence:   1666.21\n",
      "variational_beta * kldivergence:  0.16662\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33292\n",
      "kldivergence:   1462.06\n",
      "variational_beta * kldivergence:  0.14621\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34042\n",
      "kldivergence:   1838.20\n",
      "variational_beta * kldivergence:  0.18382\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32009\n",
      "kldivergence:   1504.85\n",
      "variational_beta * kldivergence:  0.15049\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29684\n",
      "kldivergence:   1352.62\n",
      "variational_beta * kldivergence:  0.13526\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.38525\n",
      "kldivergence:   1510.03\n",
      "variational_beta * kldivergence:  0.15100\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32931\n",
      "kldivergence:   1474.96\n",
      "variational_beta * kldivergence:  0.14750\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.31967\n",
      "kldivergence:   1484.65\n",
      "variational_beta * kldivergence:  0.14846\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33026\n",
      "kldivergence:   1729.34\n",
      "variational_beta * kldivergence:  0.17293\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30769\n",
      "kldivergence:   1564.15\n",
      "variational_beta * kldivergence:  0.15641\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32132\n",
      "kldivergence:   1497.82\n",
      "variational_beta * kldivergence:  0.14978\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33240\n",
      "kldivergence:   1597.50\n",
      "variational_beta * kldivergence:  0.15975\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36669\n",
      "kldivergence:   1750.24\n",
      "variational_beta * kldivergence:  0.17502\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.37675\n",
      "kldivergence:   1661.35\n",
      "variational_beta * kldivergence:  0.16614\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30263\n",
      "kldivergence:   1415.60\n",
      "variational_beta * kldivergence:  0.14156\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.36799\n",
      "kldivergence:   1620.06\n",
      "variational_beta * kldivergence:  0.16201\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32050\n",
      "kldivergence:   1523.39\n",
      "variational_beta * kldivergence:  0.15234\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30607\n",
      "kldivergence:   1522.65\n",
      "variational_beta * kldivergence:  0.15226\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30095\n",
      "kldivergence:   1483.98\n",
      "variational_beta * kldivergence:  0.14840\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30542\n",
      "kldivergence:   1542.18\n",
      "variational_beta * kldivergence:  0.15422\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30710\n",
      "kldivergence:   1395.21\n",
      "variational_beta * kldivergence:  0.13952\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30318\n",
      "kldivergence:   1492.86\n",
      "variational_beta * kldivergence:  0.14929\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.28883\n",
      "kldivergence:   1398.88\n",
      "variational_beta * kldivergence:  0.13989\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29591\n",
      "kldivergence:   1499.03\n",
      "variational_beta * kldivergence:  0.14990\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34292\n",
      "kldivergence:   1637.83\n",
      "variational_beta * kldivergence:  0.16378\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.30911\n",
      "kldivergence:   1555.77\n",
      "variational_beta * kldivergence:  0.15558\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32709\n",
      "kldivergence:   1444.15\n",
      "variational_beta * kldivergence:  0.14441\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34115\n",
      "kldivergence:   1749.42\n",
      "variational_beta * kldivergence:  0.17494\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.33324\n",
      "kldivergence:   1654.32\n",
      "variational_beta * kldivergence:  0.16543\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.29325\n",
      "kldivergence:   1503.09\n",
      "variational_beta * kldivergence:  0.15031\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.35413\n",
      "kldivergence:   1583.61\n",
      "variational_beta * kldivergence:  0.15836\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.41647\n",
      "kldivergence:   1792.24\n",
      "variational_beta * kldivergence:  0.17922\n",
      "batch accuracy: 86.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.34303\n",
      "kldivergence:   1481.37\n",
      "variational_beta * kldivergence:  0.14814\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #38\n",
      "reconstruction loss: 0.32990\n",
      "kldivergence:   1483.01\n",
      "variational_beta * kldivergence:  0.14830\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.42329\n",
      "kldivergence:   1475.18\n",
      "variational_beta * kldivergence:  0.14752\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.44015\n",
      "kldivergence:   1566.94\n",
      "variational_beta * kldivergence:  0.15669\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.55327\n",
      "kldivergence:   1549.85\n",
      "variational_beta * kldivergence:  0.15499\n",
      "batch accuracy: 83.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.54404\n",
      "kldivergence:   1528.15\n",
      "variational_beta * kldivergence:  0.15281\n",
      "batch accuracy: 83.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.43694\n",
      "kldivergence:   1385.20\n",
      "variational_beta * kldivergence:  0.13852\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.44664\n",
      "kldivergence:   1490.99\n",
      "variational_beta * kldivergence:  0.14910\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.50028\n",
      "kldivergence:   1514.59\n",
      "variational_beta * kldivergence:  0.15146\n",
      "batch accuracy: 84.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.47178\n",
      "kldivergence:   1566.43\n",
      "variational_beta * kldivergence:  0.15664\n",
      "batch accuracy: 85.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.46664\n",
      "kldivergence:   1426.40\n",
      "variational_beta * kldivergence:  0.14264\n",
      "batch accuracy: 86.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.39858\n",
      "kldivergence:   1348.70\n",
      "variational_beta * kldivergence:  0.13487\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.39114\n",
      "kldivergence:   1431.31\n",
      "variational_beta * kldivergence:  0.14313\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.47056\n",
      "kldivergence:   1548.45\n",
      "variational_beta * kldivergence:  0.15484\n",
      "batch accuracy: 86.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.44506\n",
      "kldivergence:   1439.91\n",
      "variational_beta * kldivergence:  0.14399\n",
      "batch accuracy: 85.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.48144\n",
      "kldivergence:   1553.38\n",
      "variational_beta * kldivergence:  0.15534\n",
      "batch accuracy: 85.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.44572\n",
      "kldivergence:   1404.31\n",
      "variational_beta * kldivergence:  0.14043\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.51184\n",
      "kldivergence:   1698.40\n",
      "variational_beta * kldivergence:  0.16984\n",
      "batch accuracy: 84.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.43142\n",
      "kldivergence:   1440.54\n",
      "variational_beta * kldivergence:  0.14405\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.48036\n",
      "kldivergence:   1520.35\n",
      "variational_beta * kldivergence:  0.15203\n",
      "batch accuracy: 85.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.46935\n",
      "kldivergence:   1599.21\n",
      "variational_beta * kldivergence:  0.15992\n",
      "batch accuracy: 85.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.45395\n",
      "kldivergence:   1503.13\n",
      "variational_beta * kldivergence:  0.15031\n",
      "batch accuracy: 86.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.49233\n",
      "kldivergence:   1445.57\n",
      "variational_beta * kldivergence:  0.14456\n",
      "batch accuracy: 85.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.44814\n",
      "kldivergence:   1481.18\n",
      "variational_beta * kldivergence:  0.14812\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.46587\n",
      "kldivergence:   1413.01\n",
      "variational_beta * kldivergence:  0.14130\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.49892\n",
      "kldivergence:   1526.06\n",
      "variational_beta * kldivergence:  0.15261\n",
      "batch accuracy: 84.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.40487\n",
      "kldivergence:   1436.95\n",
      "variational_beta * kldivergence:  0.14370\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.52068\n",
      "kldivergence:   1575.30\n",
      "variational_beta * kldivergence:  0.15753\n",
      "batch accuracy: 85.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.44525\n",
      "kldivergence:   1428.82\n",
      "variational_beta * kldivergence:  0.14288\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.42358\n",
      "kldivergence:   1392.77\n",
      "variational_beta * kldivergence:  0.13928\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.40600\n",
      "kldivergence:   1377.86\n",
      "variational_beta * kldivergence:  0.13779\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.36771\n",
      "kldivergence:   1391.56\n",
      "variational_beta * kldivergence:  0.13916\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.47051\n",
      "kldivergence:   1488.52\n",
      "variational_beta * kldivergence:  0.14885\n",
      "batch accuracy: 85.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.39240\n",
      "kldivergence:   1451.62\n",
      "variational_beta * kldivergence:  0.14516\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.44604\n",
      "kldivergence:   1485.66\n",
      "variational_beta * kldivergence:  0.14857\n",
      "batch accuracy: 85.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.48381\n",
      "kldivergence:   1412.42\n",
      "variational_beta * kldivergence:  0.14124\n",
      "batch accuracy: 85.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.42340\n",
      "kldivergence:   1510.66\n",
      "variational_beta * kldivergence:  0.15107\n",
      "batch accuracy: 86.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.48524\n",
      "kldivergence:   1512.38\n",
      "variational_beta * kldivergence:  0.15124\n",
      "batch accuracy: 84.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.47430\n",
      "kldivergence:   1578.87\n",
      "variational_beta * kldivergence:  0.15789\n",
      "batch accuracy: 85.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.43077\n",
      "kldivergence:   1465.07\n",
      "variational_beta * kldivergence:  0.14651\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.51678\n",
      "kldivergence:   1524.06\n",
      "variational_beta * kldivergence:  0.15241\n",
      "batch accuracy: 84.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.43190\n",
      "kldivergence:   1539.04\n",
      "variational_beta * kldivergence:  0.15390\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.38136\n",
      "kldivergence:   1352.06\n",
      "variational_beta * kldivergence:  0.13521\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.35954\n",
      "kldivergence:   1338.91\n",
      "variational_beta * kldivergence:  0.13389\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.49223\n",
      "kldivergence:   1593.64\n",
      "variational_beta * kldivergence:  0.15936\n",
      "batch accuracy: 85.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.45026\n",
      "kldivergence:   1551.97\n",
      "variational_beta * kldivergence:  0.15520\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.43745\n",
      "kldivergence:   1406.23\n",
      "variational_beta * kldivergence:  0.14062\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.46192\n",
      "kldivergence:   1450.63\n",
      "variational_beta * kldivergence:  0.14506\n",
      "batch accuracy: 85.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.43675\n",
      "kldivergence:   1503.97\n",
      "variational_beta * kldivergence:  0.15040\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.44631\n",
      "kldivergence:   1504.78\n",
      "variational_beta * kldivergence:  0.15048\n",
      "batch accuracy: 85.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.46400\n",
      "kldivergence:   1503.40\n",
      "variational_beta * kldivergence:  0.15034\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.42738\n",
      "kldivergence:   1369.61\n",
      "variational_beta * kldivergence:  0.13696\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.39329\n",
      "kldivergence:   1342.47\n",
      "variational_beta * kldivergence:  0.13425\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.53125\n",
      "kldivergence:   1636.12\n",
      "variational_beta * kldivergence:  0.16361\n",
      "batch accuracy: 84.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.47390\n",
      "kldivergence:   1412.60\n",
      "variational_beta * kldivergence:  0.14126\n",
      "batch accuracy: 85.96\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.51440\n",
      "kldivergence:   1545.81\n",
      "variational_beta * kldivergence:  0.15458\n",
      "batch accuracy: 84.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.45352\n",
      "kldivergence:   1602.01\n",
      "variational_beta * kldivergence:  0.16020\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.51337\n",
      "kldivergence:   1654.34\n",
      "variational_beta * kldivergence:  0.16543\n",
      "batch accuracy: 83.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.57791\n",
      "kldivergence:   1637.18\n",
      "variational_beta * kldivergence:  0.16372\n",
      "batch accuracy: 82.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.54999\n",
      "kldivergence:   1569.88\n",
      "variational_beta * kldivergence:  0.15699\n",
      "batch accuracy: 84.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.49229\n",
      "kldivergence:   1490.70\n",
      "variational_beta * kldivergence:  0.14907\n",
      "batch accuracy: 84.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.39752\n",
      "kldivergence:   1440.55\n",
      "variational_beta * kldivergence:  0.14405\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.50872\n",
      "kldivergence:   1535.71\n",
      "variational_beta * kldivergence:  0.15357\n",
      "batch accuracy: 84.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #38\n",
      "reconstruction loss: 0.39961\n",
      "kldivergence:   1409.80\n",
      "variational_beta * kldivergence:  0.14098\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "epoch # 38 : train loss is [181.78681781191023] and validation loss is [0.10184005297428649] \n",
      "Epoch [39 / 150] average reconstruction error: 0.489991\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31184\n",
      "kldivergence:   1634.39\n",
      "variational_beta * kldivergence:  0.16344\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38393\n",
      "kldivergence:   1776.05\n",
      "variational_beta * kldivergence:  0.17760\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27798\n",
      "kldivergence:   1708.18\n",
      "variational_beta * kldivergence:  0.17082\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29648\n",
      "kldivergence:   1815.95\n",
      "variational_beta * kldivergence:  0.18159\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31467\n",
      "kldivergence:   1381.18\n",
      "variational_beta * kldivergence:  0.13812\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29553\n",
      "kldivergence:   1499.63\n",
      "variational_beta * kldivergence:  0.14996\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35972\n",
      "kldivergence:   1698.29\n",
      "variational_beta * kldivergence:  0.16983\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29163\n",
      "kldivergence:   1559.36\n",
      "variational_beta * kldivergence:  0.15594\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31060\n",
      "kldivergence:   1389.32\n",
      "variational_beta * kldivergence:  0.13893\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29813\n",
      "kldivergence:   1719.71\n",
      "variational_beta * kldivergence:  0.17197\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32656\n",
      "kldivergence:   1679.47\n",
      "variational_beta * kldivergence:  0.16795\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31927\n",
      "kldivergence:   1507.62\n",
      "variational_beta * kldivergence:  0.15076\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29374\n",
      "kldivergence:   1537.48\n",
      "variational_beta * kldivergence:  0.15375\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32452\n",
      "kldivergence:   1462.56\n",
      "variational_beta * kldivergence:  0.14626\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32478\n",
      "kldivergence:   1646.55\n",
      "variational_beta * kldivergence:  0.16466\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36945\n",
      "kldivergence:   1881.42\n",
      "variational_beta * kldivergence:  0.18814\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31684\n",
      "kldivergence:   1590.35\n",
      "variational_beta * kldivergence:  0.15904\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35271\n",
      "kldivergence:   1547.25\n",
      "variational_beta * kldivergence:  0.15473\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29809\n",
      "kldivergence:   1577.43\n",
      "variational_beta * kldivergence:  0.15774\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32538\n",
      "kldivergence:   1472.35\n",
      "variational_beta * kldivergence:  0.14723\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33302\n",
      "kldivergence:   1561.21\n",
      "variational_beta * kldivergence:  0.15612\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34266\n",
      "kldivergence:   1625.05\n",
      "variational_beta * kldivergence:  0.16250\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31894\n",
      "kldivergence:   1528.40\n",
      "variational_beta * kldivergence:  0.15284\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33531\n",
      "kldivergence:   1622.19\n",
      "variational_beta * kldivergence:  0.16222\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.42640\n",
      "kldivergence:   1766.78\n",
      "variational_beta * kldivergence:  0.17668\n",
      "batch accuracy: 86.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36833\n",
      "kldivergence:   1618.30\n",
      "variational_beta * kldivergence:  0.16183\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34714\n",
      "kldivergence:   1639.93\n",
      "variational_beta * kldivergence:  0.16399\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34895\n",
      "kldivergence:   1524.44\n",
      "variational_beta * kldivergence:  0.15244\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31250\n",
      "kldivergence:   1396.24\n",
      "variational_beta * kldivergence:  0.13962\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35256\n",
      "kldivergence:   1600.87\n",
      "variational_beta * kldivergence:  0.16009\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27226\n",
      "kldivergence:   2139.18\n",
      "variational_beta * kldivergence:  0.21392\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32813\n",
      "kldivergence:   1631.29\n",
      "variational_beta * kldivergence:  0.16313\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28360\n",
      "kldivergence:   1528.96\n",
      "variational_beta * kldivergence:  0.15290\n",
      "batch accuracy: 90.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31413\n",
      "kldivergence:   1549.13\n",
      "variational_beta * kldivergence:  0.15491\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37460\n",
      "kldivergence:   1659.71\n",
      "variational_beta * kldivergence:  0.16597\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28951\n",
      "kldivergence:   1671.89\n",
      "variational_beta * kldivergence:  0.16719\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34357\n",
      "kldivergence:   1674.10\n",
      "variational_beta * kldivergence:  0.16741\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32382\n",
      "kldivergence:   1532.40\n",
      "variational_beta * kldivergence:  0.15324\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33307\n",
      "kldivergence:   1572.69\n",
      "variational_beta * kldivergence:  0.15727\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31970\n",
      "kldivergence:   1469.29\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34399\n",
      "kldivergence:   1555.81\n",
      "variational_beta * kldivergence:  0.15558\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36205\n",
      "kldivergence:   1761.06\n",
      "variational_beta * kldivergence:  0.17611\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31019\n",
      "kldivergence:   1594.07\n",
      "variational_beta * kldivergence:  0.15941\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38588\n",
      "kldivergence:   1578.93\n",
      "variational_beta * kldivergence:  0.15789\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35766\n",
      "kldivergence:   1575.36\n",
      "variational_beta * kldivergence:  0.15754\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34197\n",
      "kldivergence:   1583.46\n",
      "variational_beta * kldivergence:  0.15835\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36478\n",
      "kldivergence:   1766.91\n",
      "variational_beta * kldivergence:  0.17669\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31409\n",
      "kldivergence:   1866.35\n",
      "variational_beta * kldivergence:  0.18664\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33468\n",
      "kldivergence:   1520.83\n",
      "variational_beta * kldivergence:  0.15208\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35605\n",
      "kldivergence:   1543.89\n",
      "variational_beta * kldivergence:  0.15439\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32341\n",
      "kldivergence:   1588.52\n",
      "variational_beta * kldivergence:  0.15885\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35631\n",
      "kldivergence:   1727.97\n",
      "variational_beta * kldivergence:  0.17280\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35715\n",
      "kldivergence:   1864.99\n",
      "variational_beta * kldivergence:  0.18650\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34407\n",
      "kldivergence:   1444.28\n",
      "variational_beta * kldivergence:  0.14443\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34712\n",
      "kldivergence:   1546.96\n",
      "variational_beta * kldivergence:  0.15470\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33236\n",
      "kldivergence:   1493.33\n",
      "variational_beta * kldivergence:  0.14933\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34511\n",
      "kldivergence:   1679.13\n",
      "variational_beta * kldivergence:  0.16791\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36251\n",
      "kldivergence:   1658.45\n",
      "variational_beta * kldivergence:  0.16585\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38029\n",
      "kldivergence:   1740.22\n",
      "variational_beta * kldivergence:  0.17402\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32318\n",
      "kldivergence:   1449.12\n",
      "variational_beta * kldivergence:  0.14491\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31416\n",
      "kldivergence:   1623.88\n",
      "variational_beta * kldivergence:  0.16239\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27788\n",
      "kldivergence:   1637.38\n",
      "variational_beta * kldivergence:  0.16374\n",
      "batch accuracy: 90.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29595\n",
      "kldivergence:   1372.06\n",
      "variational_beta * kldivergence:  0.13721\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34632\n",
      "kldivergence:   1646.13\n",
      "variational_beta * kldivergence:  0.16461\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31911\n",
      "kldivergence:   1503.77\n",
      "variational_beta * kldivergence:  0.15038\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37336\n",
      "kldivergence:   1798.11\n",
      "variational_beta * kldivergence:  0.17981\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32637\n",
      "kldivergence:   1624.05\n",
      "variational_beta * kldivergence:  0.16241\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33979\n",
      "kldivergence:   1506.27\n",
      "variational_beta * kldivergence:  0.15063\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.41554\n",
      "kldivergence:   1623.21\n",
      "variational_beta * kldivergence:  0.16232\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33141\n",
      "kldivergence:   1748.46\n",
      "variational_beta * kldivergence:  0.17485\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31065\n",
      "kldivergence:   1422.69\n",
      "variational_beta * kldivergence:  0.14227\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36336\n",
      "kldivergence:   1495.98\n",
      "variational_beta * kldivergence:  0.14960\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.39468\n",
      "kldivergence:   1538.71\n",
      "variational_beta * kldivergence:  0.15387\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.41073\n",
      "kldivergence:   1915.91\n",
      "variational_beta * kldivergence:  0.19159\n",
      "batch accuracy: 85.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28553\n",
      "kldivergence:   1685.68\n",
      "variational_beta * kldivergence:  0.16857\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32700\n",
      "kldivergence:   1551.14\n",
      "variational_beta * kldivergence:  0.15511\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37322\n",
      "kldivergence:   1878.66\n",
      "variational_beta * kldivergence:  0.18787\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30067\n",
      "kldivergence:   1323.40\n",
      "variational_beta * kldivergence:  0.13234\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34401\n",
      "kldivergence:   1566.62\n",
      "variational_beta * kldivergence:  0.15666\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33214\n",
      "kldivergence:   1543.09\n",
      "variational_beta * kldivergence:  0.15431\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28434\n",
      "kldivergence:   1421.87\n",
      "variational_beta * kldivergence:  0.14219\n",
      "batch accuracy: 90.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31466\n",
      "kldivergence:   1430.69\n",
      "variational_beta * kldivergence:  0.14307\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34636\n",
      "kldivergence:   1534.85\n",
      "variational_beta * kldivergence:  0.15348\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29041\n",
      "kldivergence:   1527.71\n",
      "variational_beta * kldivergence:  0.15277\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30603\n",
      "kldivergence:   1514.96\n",
      "variational_beta * kldivergence:  0.15150\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29505\n",
      "kldivergence:   1562.28\n",
      "variational_beta * kldivergence:  0.15623\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29969\n",
      "kldivergence:   1603.61\n",
      "variational_beta * kldivergence:  0.16036\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27552\n",
      "kldivergence:   1383.10\n",
      "variational_beta * kldivergence:  0.13831\n",
      "batch accuracy: 90.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.23805\n",
      "kldivergence:   1332.48\n",
      "variational_beta * kldivergence:  0.13325\n",
      "batch accuracy: 91.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27976\n",
      "kldivergence:   1479.94\n",
      "variational_beta * kldivergence:  0.14799\n",
      "batch accuracy: 90.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36128\n",
      "kldivergence:   1774.02\n",
      "variational_beta * kldivergence:  0.17740\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34536\n",
      "kldivergence:   1796.84\n",
      "variational_beta * kldivergence:  0.17968\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33285\n",
      "kldivergence:   1576.35\n",
      "variational_beta * kldivergence:  0.15764\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33951\n",
      "kldivergence:   1703.45\n",
      "variational_beta * kldivergence:  0.17035\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36775\n",
      "kldivergence:   1660.07\n",
      "variational_beta * kldivergence:  0.16601\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31917\n",
      "kldivergence:   1539.17\n",
      "variational_beta * kldivergence:  0.15392\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31624\n",
      "kldivergence:   1542.08\n",
      "variational_beta * kldivergence:  0.15421\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31401\n",
      "kldivergence:   1561.99\n",
      "variational_beta * kldivergence:  0.15620\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36259\n",
      "kldivergence:   1662.40\n",
      "variational_beta * kldivergence:  0.16624\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33996\n",
      "kldivergence:   1747.26\n",
      "variational_beta * kldivergence:  0.17473\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32734\n",
      "kldivergence:   1646.81\n",
      "variational_beta * kldivergence:  0.16468\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31265\n",
      "kldivergence:   1593.47\n",
      "variational_beta * kldivergence:  0.15935\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35855\n",
      "kldivergence:   1572.34\n",
      "variational_beta * kldivergence:  0.15723\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33633\n",
      "kldivergence:   1573.63\n",
      "variational_beta * kldivergence:  0.15736\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36183\n",
      "kldivergence:   1531.96\n",
      "variational_beta * kldivergence:  0.15320\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33895\n",
      "kldivergence:   1476.56\n",
      "variational_beta * kldivergence:  0.14766\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34582\n",
      "kldivergence:   1582.85\n",
      "variational_beta * kldivergence:  0.15829\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34449\n",
      "kldivergence:   1556.11\n",
      "variational_beta * kldivergence:  0.15561\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34656\n",
      "kldivergence:   1462.17\n",
      "variational_beta * kldivergence:  0.14622\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32591\n",
      "kldivergence:   1600.32\n",
      "variational_beta * kldivergence:  0.16003\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35126\n",
      "kldivergence:   1542.18\n",
      "variational_beta * kldivergence:  0.15422\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35237\n",
      "kldivergence:   1605.19\n",
      "variational_beta * kldivergence:  0.16052\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36838\n",
      "kldivergence:   1710.34\n",
      "variational_beta * kldivergence:  0.17103\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35637\n",
      "kldivergence:   1550.31\n",
      "variational_beta * kldivergence:  0.15503\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33386\n",
      "kldivergence:   1423.54\n",
      "variational_beta * kldivergence:  0.14235\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32972\n",
      "kldivergence:   1795.53\n",
      "variational_beta * kldivergence:  0.17955\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.26992\n",
      "kldivergence:   1461.36\n",
      "variational_beta * kldivergence:  0.14614\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.39108\n",
      "kldivergence:   1848.34\n",
      "variational_beta * kldivergence:  0.18483\n",
      "batch accuracy: 86.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29420\n",
      "kldivergence:   1503.47\n",
      "variational_beta * kldivergence:  0.15035\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31488\n",
      "kldivergence:   1545.18\n",
      "variational_beta * kldivergence:  0.15452\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29407\n",
      "kldivergence:   1569.10\n",
      "variational_beta * kldivergence:  0.15691\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35380\n",
      "kldivergence:   1593.10\n",
      "variational_beta * kldivergence:  0.15931\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38701\n",
      "kldivergence:   1668.15\n",
      "variational_beta * kldivergence:  0.16682\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33816\n",
      "kldivergence:   1586.24\n",
      "variational_beta * kldivergence:  0.15862\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29615\n",
      "kldivergence:   1400.04\n",
      "variational_beta * kldivergence:  0.14000\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29380\n",
      "kldivergence:   1475.01\n",
      "variational_beta * kldivergence:  0.14750\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37202\n",
      "kldivergence:   1734.71\n",
      "variational_beta * kldivergence:  0.17347\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31503\n",
      "kldivergence:   1484.57\n",
      "variational_beta * kldivergence:  0.14846\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30486\n",
      "kldivergence:   1516.66\n",
      "variational_beta * kldivergence:  0.15167\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32873\n",
      "kldivergence:   1902.51\n",
      "variational_beta * kldivergence:  0.19025\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31815\n",
      "kldivergence:   1637.96\n",
      "variational_beta * kldivergence:  0.16380\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34773\n",
      "kldivergence:   1400.02\n",
      "variational_beta * kldivergence:  0.14000\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31562\n",
      "kldivergence:   1282.92\n",
      "variational_beta * kldivergence:  0.12829\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32038\n",
      "kldivergence:   1290.47\n",
      "variational_beta * kldivergence:  0.12905\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32280\n",
      "kldivergence:   1500.41\n",
      "variational_beta * kldivergence:  0.15004\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29016\n",
      "kldivergence:   1445.61\n",
      "variational_beta * kldivergence:  0.14456\n",
      "batch accuracy: 90.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37341\n",
      "kldivergence:   1637.65\n",
      "variational_beta * kldivergence:  0.16377\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34534\n",
      "kldivergence:   1678.48\n",
      "variational_beta * kldivergence:  0.16785\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31489\n",
      "kldivergence:   1428.26\n",
      "variational_beta * kldivergence:  0.14283\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37338\n",
      "kldivergence:   1491.60\n",
      "variational_beta * kldivergence:  0.14916\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31981\n",
      "kldivergence:   1533.63\n",
      "variational_beta * kldivergence:  0.15336\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34778\n",
      "kldivergence:   1530.04\n",
      "variational_beta * kldivergence:  0.15300\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29880\n",
      "kldivergence:   1363.14\n",
      "variational_beta * kldivergence:  0.13631\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29401\n",
      "kldivergence:   1640.20\n",
      "variational_beta * kldivergence:  0.16402\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31486\n",
      "kldivergence:   1573.56\n",
      "variational_beta * kldivergence:  0.15736\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31965\n",
      "kldivergence:   1437.38\n",
      "variational_beta * kldivergence:  0.14374\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30299\n",
      "kldivergence:   1789.56\n",
      "variational_beta * kldivergence:  0.17896\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28273\n",
      "kldivergence:   1250.94\n",
      "variational_beta * kldivergence:  0.12509\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31241\n",
      "kldivergence:   1506.43\n",
      "variational_beta * kldivergence:  0.15064\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35909\n",
      "kldivergence:   1531.56\n",
      "variational_beta * kldivergence:  0.15316\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36024\n",
      "kldivergence:   1698.12\n",
      "variational_beta * kldivergence:  0.16981\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.39418\n",
      "kldivergence:   1465.51\n",
      "variational_beta * kldivergence:  0.14655\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33349\n",
      "kldivergence:   1423.68\n",
      "variational_beta * kldivergence:  0.14237\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30438\n",
      "kldivergence:   1290.05\n",
      "variational_beta * kldivergence:  0.12900\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31192\n",
      "kldivergence:   1642.64\n",
      "variational_beta * kldivergence:  0.16426\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33709\n",
      "kldivergence:   1546.75\n",
      "variational_beta * kldivergence:  0.15468\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34100\n",
      "kldivergence:   1498.32\n",
      "variational_beta * kldivergence:  0.14983\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.26118\n",
      "kldivergence:   1312.95\n",
      "variational_beta * kldivergence:  0.13130\n",
      "batch accuracy: 91.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31479\n",
      "kldivergence:   1370.63\n",
      "variational_beta * kldivergence:  0.13706\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35494\n",
      "kldivergence:   1593.12\n",
      "variational_beta * kldivergence:  0.15931\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.39184\n",
      "kldivergence:   1586.19\n",
      "variational_beta * kldivergence:  0.15862\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30983\n",
      "kldivergence:   1397.25\n",
      "variational_beta * kldivergence:  0.13972\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34586\n",
      "kldivergence:   1391.78\n",
      "variational_beta * kldivergence:  0.13918\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34439\n",
      "kldivergence:   1715.15\n",
      "variational_beta * kldivergence:  0.17151\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32197\n",
      "kldivergence:   1528.34\n",
      "variational_beta * kldivergence:  0.15283\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31387\n",
      "kldivergence:   1423.56\n",
      "variational_beta * kldivergence:  0.14236\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37605\n",
      "kldivergence:   1631.90\n",
      "variational_beta * kldivergence:  0.16319\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29297\n",
      "kldivergence:   1349.45\n",
      "variational_beta * kldivergence:  0.13494\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35563\n",
      "kldivergence:   1494.86\n",
      "variational_beta * kldivergence:  0.14949\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35012\n",
      "kldivergence:   1620.39\n",
      "variational_beta * kldivergence:  0.16204\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36508\n",
      "kldivergence:   1685.95\n",
      "variational_beta * kldivergence:  0.16860\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34980\n",
      "kldivergence:   1693.10\n",
      "variational_beta * kldivergence:  0.16931\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28979\n",
      "kldivergence:   1509.67\n",
      "variational_beta * kldivergence:  0.15097\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32126\n",
      "kldivergence:   1449.36\n",
      "variational_beta * kldivergence:  0.14494\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32362\n",
      "kldivergence:   1397.51\n",
      "variational_beta * kldivergence:  0.13975\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31281\n",
      "kldivergence:   1414.78\n",
      "variational_beta * kldivergence:  0.14148\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31179\n",
      "kldivergence:   1366.86\n",
      "variational_beta * kldivergence:  0.13669\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38383\n",
      "kldivergence:   1555.13\n",
      "variational_beta * kldivergence:  0.15551\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30699\n",
      "kldivergence:   1396.50\n",
      "variational_beta * kldivergence:  0.13965\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35842\n",
      "kldivergence:   1509.97\n",
      "variational_beta * kldivergence:  0.15100\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31834\n",
      "kldivergence:   1467.09\n",
      "variational_beta * kldivergence:  0.14671\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29466\n",
      "kldivergence:   1332.44\n",
      "variational_beta * kldivergence:  0.13324\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35919\n",
      "kldivergence:   1718.42\n",
      "variational_beta * kldivergence:  0.17184\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30855\n",
      "kldivergence:   1483.05\n",
      "variational_beta * kldivergence:  0.14831\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33538\n",
      "kldivergence:   1623.33\n",
      "variational_beta * kldivergence:  0.16233\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27754\n",
      "kldivergence:   1550.84\n",
      "variational_beta * kldivergence:  0.15508\n",
      "batch accuracy: 91.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37746\n",
      "kldivergence:   1975.46\n",
      "variational_beta * kldivergence:  0.19755\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32075\n",
      "kldivergence:   1420.87\n",
      "variational_beta * kldivergence:  0.14209\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33292\n",
      "kldivergence:   1292.68\n",
      "variational_beta * kldivergence:  0.12927\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32717\n",
      "kldivergence:   1425.85\n",
      "variational_beta * kldivergence:  0.14258\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34391\n",
      "kldivergence:   1584.83\n",
      "variational_beta * kldivergence:  0.15848\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34166\n",
      "kldivergence:   1529.12\n",
      "variational_beta * kldivergence:  0.15291\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34992\n",
      "kldivergence:   1645.22\n",
      "variational_beta * kldivergence:  0.16452\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27638\n",
      "kldivergence:   1430.74\n",
      "variational_beta * kldivergence:  0.14307\n",
      "batch accuracy: 90.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30493\n",
      "kldivergence:   1589.89\n",
      "variational_beta * kldivergence:  0.15899\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29921\n",
      "kldivergence:   1459.47\n",
      "variational_beta * kldivergence:  0.14595\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27308\n",
      "kldivergence:   1614.32\n",
      "variational_beta * kldivergence:  0.16143\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34011\n",
      "kldivergence:   1611.42\n",
      "variational_beta * kldivergence:  0.16114\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36812\n",
      "kldivergence:   1738.53\n",
      "variational_beta * kldivergence:  0.17385\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29870\n",
      "kldivergence:   1471.63\n",
      "variational_beta * kldivergence:  0.14716\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35439\n",
      "kldivergence:   1441.61\n",
      "variational_beta * kldivergence:  0.14416\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35785\n",
      "kldivergence:   1431.81\n",
      "variational_beta * kldivergence:  0.14318\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29031\n",
      "kldivergence:   1276.52\n",
      "variational_beta * kldivergence:  0.12765\n",
      "batch accuracy: 90.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33838\n",
      "kldivergence:   1367.71\n",
      "variational_beta * kldivergence:  0.13677\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38131\n",
      "kldivergence:   1766.13\n",
      "variational_beta * kldivergence:  0.17661\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32758\n",
      "kldivergence:   1474.20\n",
      "variational_beta * kldivergence:  0.14742\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31138\n",
      "kldivergence:   1535.32\n",
      "variational_beta * kldivergence:  0.15353\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.39794\n",
      "kldivergence:   1601.38\n",
      "variational_beta * kldivergence:  0.16014\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30295\n",
      "kldivergence:   1717.84\n",
      "variational_beta * kldivergence:  0.17178\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36040\n",
      "kldivergence:   1708.53\n",
      "variational_beta * kldivergence:  0.17085\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33057\n",
      "kldivergence:   1382.47\n",
      "variational_beta * kldivergence:  0.13825\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28715\n",
      "kldivergence:   1487.26\n",
      "variational_beta * kldivergence:  0.14873\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36658\n",
      "kldivergence:   1372.46\n",
      "variational_beta * kldivergence:  0.13725\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36264\n",
      "kldivergence:   1487.63\n",
      "variational_beta * kldivergence:  0.14876\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32785\n",
      "kldivergence:   1653.11\n",
      "variational_beta * kldivergence:  0.16531\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31902\n",
      "kldivergence:   1420.40\n",
      "variational_beta * kldivergence:  0.14204\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32374\n",
      "kldivergence:   1416.21\n",
      "variational_beta * kldivergence:  0.14162\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30072\n",
      "kldivergence:   1645.16\n",
      "variational_beta * kldivergence:  0.16452\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35157\n",
      "kldivergence:   1676.57\n",
      "variational_beta * kldivergence:  0.16766\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33678\n",
      "kldivergence:   1517.12\n",
      "variational_beta * kldivergence:  0.15171\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33629\n",
      "kldivergence:   1565.64\n",
      "variational_beta * kldivergence:  0.15656\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32325\n",
      "kldivergence:   1580.22\n",
      "variational_beta * kldivergence:  0.15802\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29558\n",
      "kldivergence:   1429.97\n",
      "variational_beta * kldivergence:  0.14300\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35062\n",
      "kldivergence:   1676.41\n",
      "variational_beta * kldivergence:  0.16764\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33573\n",
      "kldivergence:   1479.23\n",
      "variational_beta * kldivergence:  0.14792\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30792\n",
      "kldivergence:   1598.48\n",
      "variational_beta * kldivergence:  0.15985\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31459\n",
      "kldivergence:   1435.53\n",
      "variational_beta * kldivergence:  0.14355\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30828\n",
      "kldivergence:   1501.62\n",
      "variational_beta * kldivergence:  0.15016\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31156\n",
      "kldivergence:   1795.48\n",
      "variational_beta * kldivergence:  0.17955\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29978\n",
      "kldivergence:   1404.21\n",
      "variational_beta * kldivergence:  0.14042\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38808\n",
      "kldivergence:   1622.12\n",
      "variational_beta * kldivergence:  0.16221\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33727\n",
      "kldivergence:   1517.11\n",
      "variational_beta * kldivergence:  0.15171\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28351\n",
      "kldivergence:   1480.00\n",
      "variational_beta * kldivergence:  0.14800\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31971\n",
      "kldivergence:   1718.14\n",
      "variational_beta * kldivergence:  0.17181\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28945\n",
      "kldivergence:   1369.05\n",
      "variational_beta * kldivergence:  0.13690\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32918\n",
      "kldivergence:   1458.58\n",
      "variational_beta * kldivergence:  0.14586\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34868\n",
      "kldivergence:   1538.92\n",
      "variational_beta * kldivergence:  0.15389\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31097\n",
      "kldivergence:   1530.01\n",
      "variational_beta * kldivergence:  0.15300\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34754\n",
      "kldivergence:   1384.35\n",
      "variational_beta * kldivergence:  0.13844\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38667\n",
      "kldivergence:   1577.91\n",
      "variational_beta * kldivergence:  0.15779\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32385\n",
      "kldivergence:   1429.22\n",
      "variational_beta * kldivergence:  0.14292\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33398\n",
      "kldivergence:   1430.51\n",
      "variational_beta * kldivergence:  0.14305\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33639\n",
      "kldivergence:   1585.98\n",
      "variational_beta * kldivergence:  0.15860\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30152\n",
      "kldivergence:   1525.25\n",
      "variational_beta * kldivergence:  0.15252\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34302\n",
      "kldivergence:   1424.49\n",
      "variational_beta * kldivergence:  0.14245\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33488\n",
      "kldivergence:   2048.58\n",
      "variational_beta * kldivergence:  0.20486\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28002\n",
      "kldivergence:   1422.21\n",
      "variational_beta * kldivergence:  0.14222\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36700\n",
      "kldivergence:   1907.08\n",
      "variational_beta * kldivergence:  0.19071\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33071\n",
      "kldivergence:   1465.41\n",
      "variational_beta * kldivergence:  0.14654\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29550\n",
      "kldivergence:   1395.49\n",
      "variational_beta * kldivergence:  0.13955\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37092\n",
      "kldivergence:   1634.17\n",
      "variational_beta * kldivergence:  0.16342\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29119\n",
      "kldivergence:   1527.35\n",
      "variational_beta * kldivergence:  0.15273\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38766\n",
      "kldivergence:   1468.77\n",
      "variational_beta * kldivergence:  0.14688\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27484\n",
      "kldivergence:   1246.87\n",
      "variational_beta * kldivergence:  0.12469\n",
      "batch accuracy: 90.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30840\n",
      "kldivergence:   1470.53\n",
      "variational_beta * kldivergence:  0.14705\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36281\n",
      "kldivergence:   1583.40\n",
      "variational_beta * kldivergence:  0.15834\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38619\n",
      "kldivergence:   1618.72\n",
      "variational_beta * kldivergence:  0.16187\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31590\n",
      "kldivergence:   1590.23\n",
      "variational_beta * kldivergence:  0.15902\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31004\n",
      "kldivergence:   1457.68\n",
      "variational_beta * kldivergence:  0.14577\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38386\n",
      "kldivergence:   1593.89\n",
      "variational_beta * kldivergence:  0.15939\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31650\n",
      "kldivergence:   1429.40\n",
      "variational_beta * kldivergence:  0.14294\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34526\n",
      "kldivergence:   1425.38\n",
      "variational_beta * kldivergence:  0.14254\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32247\n",
      "kldivergence:   1512.50\n",
      "variational_beta * kldivergence:  0.15125\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35541\n",
      "kldivergence:   1597.09\n",
      "variational_beta * kldivergence:  0.15971\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35847\n",
      "kldivergence:   1681.29\n",
      "variational_beta * kldivergence:  0.16813\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33392\n",
      "kldivergence:   1647.76\n",
      "variational_beta * kldivergence:  0.16478\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30868\n",
      "kldivergence:   1489.08\n",
      "variational_beta * kldivergence:  0.14891\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28950\n",
      "kldivergence:   1440.89\n",
      "variational_beta * kldivergence:  0.14409\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.39997\n",
      "kldivergence:   1695.12\n",
      "variational_beta * kldivergence:  0.16951\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27118\n",
      "kldivergence:   1317.63\n",
      "variational_beta * kldivergence:  0.13176\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32920\n",
      "kldivergence:   1480.49\n",
      "variational_beta * kldivergence:  0.14805\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33737\n",
      "kldivergence:   1511.31\n",
      "variational_beta * kldivergence:  0.15113\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35799\n",
      "kldivergence:   1667.96\n",
      "variational_beta * kldivergence:  0.16680\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33649\n",
      "kldivergence:   1805.97\n",
      "variational_beta * kldivergence:  0.18060\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28638\n",
      "kldivergence:   1452.45\n",
      "variational_beta * kldivergence:  0.14524\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33511\n",
      "kldivergence:   1460.13\n",
      "variational_beta * kldivergence:  0.14601\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29759\n",
      "kldivergence:   1742.93\n",
      "variational_beta * kldivergence:  0.17429\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31491\n",
      "kldivergence:   1595.96\n",
      "variational_beta * kldivergence:  0.15960\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36236\n",
      "kldivergence:   1504.19\n",
      "variational_beta * kldivergence:  0.15042\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30459\n",
      "kldivergence:   1363.22\n",
      "variational_beta * kldivergence:  0.13632\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31153\n",
      "kldivergence:   1628.81\n",
      "variational_beta * kldivergence:  0.16288\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30252\n",
      "kldivergence:   1437.80\n",
      "variational_beta * kldivergence:  0.14378\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35641\n",
      "kldivergence:   1500.49\n",
      "variational_beta * kldivergence:  0.15005\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30821\n",
      "kldivergence:   1552.46\n",
      "variational_beta * kldivergence:  0.15525\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32424\n",
      "kldivergence:   1453.25\n",
      "variational_beta * kldivergence:  0.14533\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37778\n",
      "kldivergence:   1542.49\n",
      "variational_beta * kldivergence:  0.15425\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29632\n",
      "kldivergence:   1414.89\n",
      "variational_beta * kldivergence:  0.14149\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32044\n",
      "kldivergence:   1620.30\n",
      "variational_beta * kldivergence:  0.16203\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34516\n",
      "kldivergence:   1902.27\n",
      "variational_beta * kldivergence:  0.19023\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31435\n",
      "kldivergence:   1514.89\n",
      "variational_beta * kldivergence:  0.15149\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29979\n",
      "kldivergence:   1491.10\n",
      "variational_beta * kldivergence:  0.14911\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36083\n",
      "kldivergence:   1653.78\n",
      "variational_beta * kldivergence:  0.16538\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36236\n",
      "kldivergence:   1804.58\n",
      "variational_beta * kldivergence:  0.18046\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35034\n",
      "kldivergence:   1392.82\n",
      "variational_beta * kldivergence:  0.13928\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30766\n",
      "kldivergence:   1489.92\n",
      "variational_beta * kldivergence:  0.14899\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33390\n",
      "kldivergence:   1500.39\n",
      "variational_beta * kldivergence:  0.15004\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32460\n",
      "kldivergence:   1486.58\n",
      "variational_beta * kldivergence:  0.14866\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36470\n",
      "kldivergence:   1681.41\n",
      "variational_beta * kldivergence:  0.16814\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35674\n",
      "kldivergence:   1496.55\n",
      "variational_beta * kldivergence:  0.14966\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31302\n",
      "kldivergence:   1536.75\n",
      "variational_beta * kldivergence:  0.15367\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33694\n",
      "kldivergence:   1529.24\n",
      "variational_beta * kldivergence:  0.15292\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34459\n",
      "kldivergence:   1508.60\n",
      "variational_beta * kldivergence:  0.15086\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36776\n",
      "kldivergence:   1449.74\n",
      "variational_beta * kldivergence:  0.14497\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28497\n",
      "kldivergence:   1553.23\n",
      "variational_beta * kldivergence:  0.15532\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29630\n",
      "kldivergence:   1499.56\n",
      "variational_beta * kldivergence:  0.14996\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35373\n",
      "kldivergence:   1588.28\n",
      "variational_beta * kldivergence:  0.15883\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38091\n",
      "kldivergence:   1659.91\n",
      "variational_beta * kldivergence:  0.16599\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33316\n",
      "kldivergence:   1489.14\n",
      "variational_beta * kldivergence:  0.14891\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31776\n",
      "kldivergence:   1359.31\n",
      "variational_beta * kldivergence:  0.13593\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34613\n",
      "kldivergence:   1513.62\n",
      "variational_beta * kldivergence:  0.15136\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31424\n",
      "kldivergence:   1539.16\n",
      "variational_beta * kldivergence:  0.15392\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30741\n",
      "kldivergence:   1485.75\n",
      "variational_beta * kldivergence:  0.14857\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29612\n",
      "kldivergence:   1626.87\n",
      "variational_beta * kldivergence:  0.16269\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31799\n",
      "kldivergence:   1616.59\n",
      "variational_beta * kldivergence:  0.16166\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32455\n",
      "kldivergence:   1650.16\n",
      "variational_beta * kldivergence:  0.16502\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33035\n",
      "kldivergence:   1661.47\n",
      "variational_beta * kldivergence:  0.16615\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30108\n",
      "kldivergence:   1483.49\n",
      "variational_beta * kldivergence:  0.14835\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34729\n",
      "kldivergence:   2047.37\n",
      "variational_beta * kldivergence:  0.20474\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.28846\n",
      "kldivergence:   1339.78\n",
      "variational_beta * kldivergence:  0.13398\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29272\n",
      "kldivergence:   1501.35\n",
      "variational_beta * kldivergence:  0.15013\n",
      "batch accuracy: 90.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31835\n",
      "kldivergence:   1532.74\n",
      "variational_beta * kldivergence:  0.15327\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31792\n",
      "kldivergence:   1395.46\n",
      "variational_beta * kldivergence:  0.13955\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38618\n",
      "kldivergence:   1695.10\n",
      "variational_beta * kldivergence:  0.16951\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32671\n",
      "kldivergence:   1414.31\n",
      "variational_beta * kldivergence:  0.14143\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.27815\n",
      "kldivergence:   1379.19\n",
      "variational_beta * kldivergence:  0.13792\n",
      "batch accuracy: 90.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33895\n",
      "kldivergence:   1622.06\n",
      "variational_beta * kldivergence:  0.16221\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31235\n",
      "kldivergence:   1582.99\n",
      "variational_beta * kldivergence:  0.15830\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31470\n",
      "kldivergence:   1524.51\n",
      "variational_beta * kldivergence:  0.15245\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.38771\n",
      "kldivergence:   1652.99\n",
      "variational_beta * kldivergence:  0.16530\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.40115\n",
      "kldivergence:   1802.49\n",
      "variational_beta * kldivergence:  0.18025\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31413\n",
      "kldivergence:   1291.21\n",
      "variational_beta * kldivergence:  0.12912\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33682\n",
      "kldivergence:   1560.24\n",
      "variational_beta * kldivergence:  0.15602\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31769\n",
      "kldivergence:   1450.44\n",
      "variational_beta * kldivergence:  0.14504\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32862\n",
      "kldivergence:   1610.87\n",
      "variational_beta * kldivergence:  0.16109\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29207\n",
      "kldivergence:   1303.42\n",
      "variational_beta * kldivergence:  0.13034\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35976\n",
      "kldivergence:   1525.08\n",
      "variational_beta * kldivergence:  0.15251\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29608\n",
      "kldivergence:   1696.63\n",
      "variational_beta * kldivergence:  0.16966\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30240\n",
      "kldivergence:   1479.06\n",
      "variational_beta * kldivergence:  0.14791\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31446\n",
      "kldivergence:   1595.16\n",
      "variational_beta * kldivergence:  0.15952\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32882\n",
      "kldivergence:   1574.47\n",
      "variational_beta * kldivergence:  0.15745\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37575\n",
      "kldivergence:   1646.42\n",
      "variational_beta * kldivergence:  0.16464\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36150\n",
      "kldivergence:   1473.31\n",
      "variational_beta * kldivergence:  0.14733\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29006\n",
      "kldivergence:   1436.17\n",
      "variational_beta * kldivergence:  0.14362\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32236\n",
      "kldivergence:   1407.21\n",
      "variational_beta * kldivergence:  0.14072\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31770\n",
      "kldivergence:   1571.37\n",
      "variational_beta * kldivergence:  0.15714\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32507\n",
      "kldivergence:   1505.85\n",
      "variational_beta * kldivergence:  0.15058\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29311\n",
      "kldivergence:   1485.31\n",
      "variational_beta * kldivergence:  0.14853\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30846\n",
      "kldivergence:   1308.28\n",
      "variational_beta * kldivergence:  0.13083\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35581\n",
      "kldivergence:   1491.00\n",
      "variational_beta * kldivergence:  0.14910\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36454\n",
      "kldivergence:   1434.60\n",
      "variational_beta * kldivergence:  0.14346\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37552\n",
      "kldivergence:   1480.58\n",
      "variational_beta * kldivergence:  0.14806\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.29687\n",
      "kldivergence:   1505.02\n",
      "variational_beta * kldivergence:  0.15050\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34915\n",
      "kldivergence:   1757.21\n",
      "variational_beta * kldivergence:  0.17572\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.36804\n",
      "kldivergence:   1496.00\n",
      "variational_beta * kldivergence:  0.14960\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35665\n",
      "kldivergence:   1654.44\n",
      "variational_beta * kldivergence:  0.16544\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33668\n",
      "kldivergence:   1518.02\n",
      "variational_beta * kldivergence:  0.15180\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33277\n",
      "kldivergence:   1734.02\n",
      "variational_beta * kldivergence:  0.17340\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31032\n",
      "kldivergence:   1711.28\n",
      "variational_beta * kldivergence:  0.17113\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31191\n",
      "kldivergence:   1564.94\n",
      "variational_beta * kldivergence:  0.15649\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.32978\n",
      "kldivergence:   1508.60\n",
      "variational_beta * kldivergence:  0.15086\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.39391\n",
      "kldivergence:   1634.20\n",
      "variational_beta * kldivergence:  0.16342\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33031\n",
      "kldivergence:   1691.93\n",
      "variational_beta * kldivergence:  0.16919\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33466\n",
      "kldivergence:   1478.11\n",
      "variational_beta * kldivergence:  0.14781\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34036\n",
      "kldivergence:   1525.78\n",
      "variational_beta * kldivergence:  0.15258\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.34504\n",
      "kldivergence:   1501.70\n",
      "variational_beta * kldivergence:  0.15017\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33316\n",
      "kldivergence:   1595.60\n",
      "variational_beta * kldivergence:  0.15956\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.35804\n",
      "kldivergence:   1570.71\n",
      "variational_beta * kldivergence:  0.15707\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.33497\n",
      "kldivergence:   1628.89\n",
      "variational_beta * kldivergence:  0.16289\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.37590\n",
      "kldivergence:   1717.53\n",
      "variational_beta * kldivergence:  0.17175\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.31374\n",
      "kldivergence:   1488.48\n",
      "variational_beta * kldivergence:  0.14885\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #39\n",
      "reconstruction loss: 0.30769\n",
      "kldivergence:   1517.32\n",
      "variational_beta * kldivergence:  0.15173\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.38556\n",
      "kldivergence:   1290.75\n",
      "variational_beta * kldivergence:  0.12908\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.45437\n",
      "kldivergence:   1438.43\n",
      "variational_beta * kldivergence:  0.14384\n",
      "batch accuracy: 85.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.50013\n",
      "kldivergence:   1583.06\n",
      "variational_beta * kldivergence:  0.15831\n",
      "batch accuracy: 84.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.49398\n",
      "kldivergence:   1513.57\n",
      "variational_beta * kldivergence:  0.15136\n",
      "batch accuracy: 84.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.41455\n",
      "kldivergence:   1404.44\n",
      "variational_beta * kldivergence:  0.14044\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.49376\n",
      "kldivergence:   1586.05\n",
      "variational_beta * kldivergence:  0.15861\n",
      "batch accuracy: 85.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.49544\n",
      "kldivergence:   1542.11\n",
      "variational_beta * kldivergence:  0.15421\n",
      "batch accuracy: 84.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.39259\n",
      "kldivergence:   1446.09\n",
      "variational_beta * kldivergence:  0.14461\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.41828\n",
      "kldivergence:   1490.15\n",
      "variational_beta * kldivergence:  0.14901\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.52874\n",
      "kldivergence:   1578.24\n",
      "variational_beta * kldivergence:  0.15782\n",
      "batch accuracy: 83.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.45249\n",
      "kldivergence:   1438.27\n",
      "variational_beta * kldivergence:  0.14383\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.48119\n",
      "kldivergence:   1409.09\n",
      "variational_beta * kldivergence:  0.14091\n",
      "batch accuracy: 85.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.41570\n",
      "kldivergence:   1392.08\n",
      "variational_beta * kldivergence:  0.13921\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.44791\n",
      "kldivergence:   1559.61\n",
      "variational_beta * kldivergence:  0.15596\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.46036\n",
      "kldivergence:   1437.83\n",
      "variational_beta * kldivergence:  0.14378\n",
      "batch accuracy: 85.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.49057\n",
      "kldivergence:   1428.56\n",
      "variational_beta * kldivergence:  0.14286\n",
      "batch accuracy: 85.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.49958\n",
      "kldivergence:   1550.32\n",
      "variational_beta * kldivergence:  0.15503\n",
      "batch accuracy: 84.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.51167\n",
      "kldivergence:   1485.07\n",
      "variational_beta * kldivergence:  0.14851\n",
      "batch accuracy: 84.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.50229\n",
      "kldivergence:   1601.04\n",
      "variational_beta * kldivergence:  0.16010\n",
      "batch accuracy: 84.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.44835\n",
      "kldivergence:   1492.07\n",
      "variational_beta * kldivergence:  0.14921\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.40533\n",
      "kldivergence:   1345.48\n",
      "variational_beta * kldivergence:  0.13455\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.47375\n",
      "kldivergence:   1427.61\n",
      "variational_beta * kldivergence:  0.14276\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.46050\n",
      "kldivergence:   1431.79\n",
      "variational_beta * kldivergence:  0.14318\n",
      "batch accuracy: 85.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.38490\n",
      "kldivergence:   1480.43\n",
      "variational_beta * kldivergence:  0.14804\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.46044\n",
      "kldivergence:   1516.42\n",
      "variational_beta * kldivergence:  0.15164\n",
      "batch accuracy: 85.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.41680\n",
      "kldivergence:   1429.42\n",
      "variational_beta * kldivergence:  0.14294\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.38451\n",
      "kldivergence:   1373.45\n",
      "variational_beta * kldivergence:  0.13734\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.41651\n",
      "kldivergence:   1357.39\n",
      "variational_beta * kldivergence:  0.13574\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.39482\n",
      "kldivergence:   1329.86\n",
      "variational_beta * kldivergence:  0.13299\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.47471\n",
      "kldivergence:   1569.51\n",
      "variational_beta * kldivergence:  0.15695\n",
      "batch accuracy: 85.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.48294\n",
      "kldivergence:   1538.41\n",
      "variational_beta * kldivergence:  0.15384\n",
      "batch accuracy: 85.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.38794\n",
      "kldivergence:   1458.84\n",
      "variational_beta * kldivergence:  0.14588\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.45803\n",
      "kldivergence:   1422.07\n",
      "variational_beta * kldivergence:  0.14221\n",
      "batch accuracy: 85.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.53530\n",
      "kldivergence:   1528.33\n",
      "variational_beta * kldivergence:  0.15283\n",
      "batch accuracy: 84.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.39311\n",
      "kldivergence:   1488.40\n",
      "variational_beta * kldivergence:  0.14884\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.40679\n",
      "kldivergence:   1339.40\n",
      "variational_beta * kldivergence:  0.13394\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.49789\n",
      "kldivergence:   1510.24\n",
      "variational_beta * kldivergence:  0.15102\n",
      "batch accuracy: 84.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.44372\n",
      "kldivergence:   1312.99\n",
      "variational_beta * kldivergence:  0.13130\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.43263\n",
      "kldivergence:   1422.13\n",
      "variational_beta * kldivergence:  0.14221\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.52956\n",
      "kldivergence:   1522.33\n",
      "variational_beta * kldivergence:  0.15223\n",
      "batch accuracy: 84.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.41100\n",
      "kldivergence:   1404.36\n",
      "variational_beta * kldivergence:  0.14044\n",
      "batch accuracy: 86.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.47289\n",
      "kldivergence:   1405.62\n",
      "variational_beta * kldivergence:  0.14056\n",
      "batch accuracy: 86.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.40725\n",
      "kldivergence:   1294.09\n",
      "variational_beta * kldivergence:  0.12941\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.40837\n",
      "kldivergence:   1424.06\n",
      "variational_beta * kldivergence:  0.14241\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.43219\n",
      "kldivergence:   1457.05\n",
      "variational_beta * kldivergence:  0.14570\n",
      "batch accuracy: 87.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.44477\n",
      "kldivergence:   1451.84\n",
      "variational_beta * kldivergence:  0.14518\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.52813\n",
      "kldivergence:   1532.97\n",
      "variational_beta * kldivergence:  0.15330\n",
      "batch accuracy: 84.04\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.54610\n",
      "kldivergence:   1565.85\n",
      "variational_beta * kldivergence:  0.15659\n",
      "batch accuracy: 83.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.48416\n",
      "kldivergence:   1518.65\n",
      "variational_beta * kldivergence:  0.15186\n",
      "batch accuracy: 85.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.42034\n",
      "kldivergence:   1408.77\n",
      "variational_beta * kldivergence:  0.14088\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.47038\n",
      "kldivergence:   1553.20\n",
      "variational_beta * kldivergence:  0.15532\n",
      "batch accuracy: 85.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.48139\n",
      "kldivergence:   1528.33\n",
      "variational_beta * kldivergence:  0.15283\n",
      "batch accuracy: 85.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.44726\n",
      "kldivergence:   1469.58\n",
      "variational_beta * kldivergence:  0.14696\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.41854\n",
      "kldivergence:   1479.19\n",
      "variational_beta * kldivergence:  0.14792\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.47220\n",
      "kldivergence:   1497.72\n",
      "variational_beta * kldivergence:  0.14977\n",
      "batch accuracy: 85.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.45217\n",
      "kldivergence:   1488.08\n",
      "variational_beta * kldivergence:  0.14881\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.45260\n",
      "kldivergence:   1464.07\n",
      "variational_beta * kldivergence:  0.14641\n",
      "batch accuracy: 85.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.40165\n",
      "kldivergence:   1455.02\n",
      "variational_beta * kldivergence:  0.14550\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.38945\n",
      "kldivergence:   1372.13\n",
      "variational_beta * kldivergence:  0.13721\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.40352\n",
      "kldivergence:   1314.01\n",
      "variational_beta * kldivergence:  0.13140\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.42630\n",
      "kldivergence:   1397.85\n",
      "variational_beta * kldivergence:  0.13978\n",
      "batch accuracy: 86.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #39\n",
      "reconstruction loss: 0.46262\n",
      "kldivergence:   1500.61\n",
      "variational_beta * kldivergence:  0.15006\n",
      "batch accuracy: 85.58\n",
      "\n",
      "\n",
      "epoch # 39 : train loss is [180.9310228190626] and validation loss is [0.10002225791125943] \n",
      "saved samples\n",
      "Epoch [40 / 150] average reconstruction error: 0.487685\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.38933\n",
      "kldivergence:   1605.89\n",
      "variational_beta * kldivergence:  0.16059\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34409\n",
      "kldivergence:   1458.24\n",
      "variational_beta * kldivergence:  0.14582\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32833\n",
      "kldivergence:   1620.81\n",
      "variational_beta * kldivergence:  0.16208\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35744\n",
      "kldivergence:   1674.52\n",
      "variational_beta * kldivergence:  0.16745\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33784\n",
      "kldivergence:   1549.02\n",
      "variational_beta * kldivergence:  0.15490\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30285\n",
      "kldivergence:   1535.80\n",
      "variational_beta * kldivergence:  0.15358\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33344\n",
      "kldivergence:   1400.76\n",
      "variational_beta * kldivergence:  0.14008\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30805\n",
      "kldivergence:   1493.37\n",
      "variational_beta * kldivergence:  0.14934\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29587\n",
      "kldivergence:   1525.81\n",
      "variational_beta * kldivergence:  0.15258\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36359\n",
      "kldivergence:   1944.80\n",
      "variational_beta * kldivergence:  0.19448\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33916\n",
      "kldivergence:   1753.36\n",
      "variational_beta * kldivergence:  0.17534\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30334\n",
      "kldivergence:   1443.93\n",
      "variational_beta * kldivergence:  0.14439\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31181\n",
      "kldivergence:   1437.01\n",
      "variational_beta * kldivergence:  0.14370\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37512\n",
      "kldivergence:   1675.23\n",
      "variational_beta * kldivergence:  0.16752\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32323\n",
      "kldivergence:   1385.14\n",
      "variational_beta * kldivergence:  0.13851\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29723\n",
      "kldivergence:   1423.28\n",
      "variational_beta * kldivergence:  0.14233\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33220\n",
      "kldivergence:   1554.17\n",
      "variational_beta * kldivergence:  0.15542\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37533\n",
      "kldivergence:   1489.66\n",
      "variational_beta * kldivergence:  0.14897\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32739\n",
      "kldivergence:   1458.41\n",
      "variational_beta * kldivergence:  0.14584\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34547\n",
      "kldivergence:   1458.56\n",
      "variational_beta * kldivergence:  0.14586\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32334\n",
      "kldivergence:   1397.76\n",
      "variational_beta * kldivergence:  0.13978\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33639\n",
      "kldivergence:   1525.67\n",
      "variational_beta * kldivergence:  0.15257\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30538\n",
      "kldivergence:   1472.85\n",
      "variational_beta * kldivergence:  0.14728\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36879\n",
      "kldivergence:   1673.54\n",
      "variational_beta * kldivergence:  0.16735\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34098\n",
      "kldivergence:   1487.99\n",
      "variational_beta * kldivergence:  0.14880\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31840\n",
      "kldivergence:   1426.53\n",
      "variational_beta * kldivergence:  0.14265\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33275\n",
      "kldivergence:   1497.50\n",
      "variational_beta * kldivergence:  0.14975\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34218\n",
      "kldivergence:   1613.83\n",
      "variational_beta * kldivergence:  0.16138\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30339\n",
      "kldivergence:   1480.45\n",
      "variational_beta * kldivergence:  0.14804\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30353\n",
      "kldivergence:   1549.77\n",
      "variational_beta * kldivergence:  0.15498\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28312\n",
      "kldivergence:   1286.71\n",
      "variational_beta * kldivergence:  0.12867\n",
      "batch accuracy: 90.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29092\n",
      "kldivergence:   1479.55\n",
      "variational_beta * kldivergence:  0.14796\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36970\n",
      "kldivergence:   1832.29\n",
      "variational_beta * kldivergence:  0.18323\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29588\n",
      "kldivergence:   1551.69\n",
      "variational_beta * kldivergence:  0.15517\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29809\n",
      "kldivergence:   1601.52\n",
      "variational_beta * kldivergence:  0.16015\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34233\n",
      "kldivergence:   1674.12\n",
      "variational_beta * kldivergence:  0.16741\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32609\n",
      "kldivergence:   1453.01\n",
      "variational_beta * kldivergence:  0.14530\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31124\n",
      "kldivergence:   1356.50\n",
      "variational_beta * kldivergence:  0.13565\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33730\n",
      "kldivergence:   1587.91\n",
      "variational_beta * kldivergence:  0.15879\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30819\n",
      "kldivergence:   1396.50\n",
      "variational_beta * kldivergence:  0.13965\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.27733\n",
      "kldivergence:   1850.08\n",
      "variational_beta * kldivergence:  0.18501\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34402\n",
      "kldivergence:   1515.27\n",
      "variational_beta * kldivergence:  0.15153\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33759\n",
      "kldivergence:   1563.45\n",
      "variational_beta * kldivergence:  0.15634\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33262\n",
      "kldivergence:   1665.14\n",
      "variational_beta * kldivergence:  0.16651\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34880\n",
      "kldivergence:   1559.97\n",
      "variational_beta * kldivergence:  0.15600\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34651\n",
      "kldivergence:   1788.93\n",
      "variational_beta * kldivergence:  0.17889\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31005\n",
      "kldivergence:   1472.78\n",
      "variational_beta * kldivergence:  0.14728\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33430\n",
      "kldivergence:   1398.02\n",
      "variational_beta * kldivergence:  0.13980\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28329\n",
      "kldivergence:   1488.75\n",
      "variational_beta * kldivergence:  0.14888\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35366\n",
      "kldivergence:   1717.77\n",
      "variational_beta * kldivergence:  0.17178\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37011\n",
      "kldivergence:   1484.62\n",
      "variational_beta * kldivergence:  0.14846\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.38855\n",
      "kldivergence:   1745.40\n",
      "variational_beta * kldivergence:  0.17454\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31483\n",
      "kldivergence:   1471.80\n",
      "variational_beta * kldivergence:  0.14718\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32926\n",
      "kldivergence:   1437.06\n",
      "variational_beta * kldivergence:  0.14371\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33062\n",
      "kldivergence:   1430.90\n",
      "variational_beta * kldivergence:  0.14309\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37057\n",
      "kldivergence:   1673.37\n",
      "variational_beta * kldivergence:  0.16734\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31969\n",
      "kldivergence:   1608.46\n",
      "variational_beta * kldivergence:  0.16085\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31823\n",
      "kldivergence:   1655.85\n",
      "variational_beta * kldivergence:  0.16559\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32720\n",
      "kldivergence:   1765.64\n",
      "variational_beta * kldivergence:  0.17656\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.26293\n",
      "kldivergence:   1559.72\n",
      "variational_beta * kldivergence:  0.15597\n",
      "batch accuracy: 91.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37400\n",
      "kldivergence:   1607.41\n",
      "variational_beta * kldivergence:  0.16074\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.26485\n",
      "kldivergence:   1400.19\n",
      "variational_beta * kldivergence:  0.14002\n",
      "batch accuracy: 91.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29617\n",
      "kldivergence:   1610.41\n",
      "variational_beta * kldivergence:  0.16104\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33001\n",
      "kldivergence:   1465.85\n",
      "variational_beta * kldivergence:  0.14658\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35779\n",
      "kldivergence:   1664.72\n",
      "variational_beta * kldivergence:  0.16647\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32320\n",
      "kldivergence:   1932.16\n",
      "variational_beta * kldivergence:  0.19322\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35006\n",
      "kldivergence:   1592.02\n",
      "variational_beta * kldivergence:  0.15920\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31258\n",
      "kldivergence:   1394.32\n",
      "variational_beta * kldivergence:  0.13943\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31411\n",
      "kldivergence:   1697.64\n",
      "variational_beta * kldivergence:  0.16976\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32856\n",
      "kldivergence:   1396.28\n",
      "variational_beta * kldivergence:  0.13963\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36666\n",
      "kldivergence:   1569.42\n",
      "variational_beta * kldivergence:  0.15694\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33659\n",
      "kldivergence:   1774.45\n",
      "variational_beta * kldivergence:  0.17745\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37197\n",
      "kldivergence:   1589.24\n",
      "variational_beta * kldivergence:  0.15892\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37614\n",
      "kldivergence:   1682.90\n",
      "variational_beta * kldivergence:  0.16829\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.27650\n",
      "kldivergence:   1204.05\n",
      "variational_beta * kldivergence:  0.12041\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32269\n",
      "kldivergence:   1365.39\n",
      "variational_beta * kldivergence:  0.13654\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28442\n",
      "kldivergence:   1483.40\n",
      "variational_beta * kldivergence:  0.14834\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29423\n",
      "kldivergence:   1509.12\n",
      "variational_beta * kldivergence:  0.15091\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29580\n",
      "kldivergence:   1742.85\n",
      "variational_beta * kldivergence:  0.17428\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29951\n",
      "kldivergence:   1493.34\n",
      "variational_beta * kldivergence:  0.14933\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28964\n",
      "kldivergence:   1517.79\n",
      "variational_beta * kldivergence:  0.15178\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32395\n",
      "kldivergence:   1595.30\n",
      "variational_beta * kldivergence:  0.15953\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34733\n",
      "kldivergence:   1684.83\n",
      "variational_beta * kldivergence:  0.16848\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34924\n",
      "kldivergence:   1632.50\n",
      "variational_beta * kldivergence:  0.16325\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34845\n",
      "kldivergence:   1505.67\n",
      "variational_beta * kldivergence:  0.15057\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34490\n",
      "kldivergence:   1604.15\n",
      "variational_beta * kldivergence:  0.16042\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31052\n",
      "kldivergence:   1641.48\n",
      "variational_beta * kldivergence:  0.16415\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32695\n",
      "kldivergence:   1512.28\n",
      "variational_beta * kldivergence:  0.15123\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32548\n",
      "kldivergence:   1552.34\n",
      "variational_beta * kldivergence:  0.15523\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.40735\n",
      "kldivergence:   1632.34\n",
      "variational_beta * kldivergence:  0.16323\n",
      "batch accuracy: 86.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33347\n",
      "kldivergence:   1537.79\n",
      "variational_beta * kldivergence:  0.15378\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36475\n",
      "kldivergence:   1632.46\n",
      "variational_beta * kldivergence:  0.16325\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34574\n",
      "kldivergence:   1601.86\n",
      "variational_beta * kldivergence:  0.16019\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34485\n",
      "kldivergence:   1553.88\n",
      "variational_beta * kldivergence:  0.15539\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32250\n",
      "kldivergence:   1675.73\n",
      "variational_beta * kldivergence:  0.16757\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31865\n",
      "kldivergence:   1533.49\n",
      "variational_beta * kldivergence:  0.15335\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34031\n",
      "kldivergence:   1428.83\n",
      "variational_beta * kldivergence:  0.14288\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32746\n",
      "kldivergence:   1615.38\n",
      "variational_beta * kldivergence:  0.16154\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32606\n",
      "kldivergence:   1500.23\n",
      "variational_beta * kldivergence:  0.15002\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34360\n",
      "kldivergence:   1742.07\n",
      "variational_beta * kldivergence:  0.17421\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34347\n",
      "kldivergence:   1561.21\n",
      "variational_beta * kldivergence:  0.15612\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33273\n",
      "kldivergence:   1338.56\n",
      "variational_beta * kldivergence:  0.13386\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33837\n",
      "kldivergence:   1493.28\n",
      "variational_beta * kldivergence:  0.14933\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.38840\n",
      "kldivergence:   1715.60\n",
      "variational_beta * kldivergence:  0.17156\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35011\n",
      "kldivergence:   1461.51\n",
      "variational_beta * kldivergence:  0.14615\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34830\n",
      "kldivergence:   1573.08\n",
      "variational_beta * kldivergence:  0.15731\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36110\n",
      "kldivergence:   1418.59\n",
      "variational_beta * kldivergence:  0.14186\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32197\n",
      "kldivergence:   1558.53\n",
      "variational_beta * kldivergence:  0.15585\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30531\n",
      "kldivergence:   1918.15\n",
      "variational_beta * kldivergence:  0.19182\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.38230\n",
      "kldivergence:   1686.92\n",
      "variational_beta * kldivergence:  0.16869\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.38082\n",
      "kldivergence:   1504.93\n",
      "variational_beta * kldivergence:  0.15049\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31624\n",
      "kldivergence:   1473.22\n",
      "variational_beta * kldivergence:  0.14732\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33187\n",
      "kldivergence:   1401.26\n",
      "variational_beta * kldivergence:  0.14013\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30027\n",
      "kldivergence:   1488.08\n",
      "variational_beta * kldivergence:  0.14881\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29769\n",
      "kldivergence:   1330.94\n",
      "variational_beta * kldivergence:  0.13309\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36581\n",
      "kldivergence:   1447.82\n",
      "variational_beta * kldivergence:  0.14478\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29769\n",
      "kldivergence:   1338.59\n",
      "variational_beta * kldivergence:  0.13386\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33142\n",
      "kldivergence:   1527.15\n",
      "variational_beta * kldivergence:  0.15272\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30335\n",
      "kldivergence:   1517.67\n",
      "variational_beta * kldivergence:  0.15177\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29294\n",
      "kldivergence:   1405.40\n",
      "variational_beta * kldivergence:  0.14054\n",
      "batch accuracy: 90.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34081\n",
      "kldivergence:   1466.32\n",
      "variational_beta * kldivergence:  0.14663\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31294\n",
      "kldivergence:   1512.85\n",
      "variational_beta * kldivergence:  0.15128\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28989\n",
      "kldivergence:   1561.26\n",
      "variational_beta * kldivergence:  0.15613\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34036\n",
      "kldivergence:   1732.62\n",
      "variational_beta * kldivergence:  0.17326\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34203\n",
      "kldivergence:   1646.93\n",
      "variational_beta * kldivergence:  0.16469\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36614\n",
      "kldivergence:   1640.54\n",
      "variational_beta * kldivergence:  0.16405\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.38512\n",
      "kldivergence:   1722.57\n",
      "variational_beta * kldivergence:  0.17226\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37556\n",
      "kldivergence:   1611.07\n",
      "variational_beta * kldivergence:  0.16111\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34005\n",
      "kldivergence:   1636.06\n",
      "variational_beta * kldivergence:  0.16361\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30368\n",
      "kldivergence:   1405.52\n",
      "variational_beta * kldivergence:  0.14055\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34607\n",
      "kldivergence:   1388.98\n",
      "variational_beta * kldivergence:  0.13890\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35735\n",
      "kldivergence:   1639.00\n",
      "variational_beta * kldivergence:  0.16390\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33242\n",
      "kldivergence:   1626.07\n",
      "variational_beta * kldivergence:  0.16261\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33172\n",
      "kldivergence:   1487.11\n",
      "variational_beta * kldivergence:  0.14871\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30269\n",
      "kldivergence:   1617.50\n",
      "variational_beta * kldivergence:  0.16175\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.27969\n",
      "kldivergence:   1877.63\n",
      "variational_beta * kldivergence:  0.18776\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33513\n",
      "kldivergence:   1643.04\n",
      "variational_beta * kldivergence:  0.16430\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30442\n",
      "kldivergence:   1571.58\n",
      "variational_beta * kldivergence:  0.15716\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35486\n",
      "kldivergence:   1589.84\n",
      "variational_beta * kldivergence:  0.15898\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32286\n",
      "kldivergence:   1457.59\n",
      "variational_beta * kldivergence:  0.14576\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33456\n",
      "kldivergence:   1500.52\n",
      "variational_beta * kldivergence:  0.15005\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35298\n",
      "kldivergence:   1570.84\n",
      "variational_beta * kldivergence:  0.15708\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35282\n",
      "kldivergence:   1600.36\n",
      "variational_beta * kldivergence:  0.16004\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32002\n",
      "kldivergence:   1480.39\n",
      "variational_beta * kldivergence:  0.14804\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30649\n",
      "kldivergence:   1341.45\n",
      "variational_beta * kldivergence:  0.13414\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29830\n",
      "kldivergence:   1422.84\n",
      "variational_beta * kldivergence:  0.14228\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30382\n",
      "kldivergence:   1419.89\n",
      "variational_beta * kldivergence:  0.14199\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35339\n",
      "kldivergence:   1544.83\n",
      "variational_beta * kldivergence:  0.15448\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30869\n",
      "kldivergence:   1608.14\n",
      "variational_beta * kldivergence:  0.16081\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33454\n",
      "kldivergence:   1511.20\n",
      "variational_beta * kldivergence:  0.15112\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37441\n",
      "kldivergence:   1428.67\n",
      "variational_beta * kldivergence:  0.14287\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.41654\n",
      "kldivergence:   1548.53\n",
      "variational_beta * kldivergence:  0.15485\n",
      "batch accuracy: 86.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33468\n",
      "kldivergence:   1444.52\n",
      "variational_beta * kldivergence:  0.14445\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29306\n",
      "kldivergence:   1433.76\n",
      "variational_beta * kldivergence:  0.14338\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31993\n",
      "kldivergence:   1641.57\n",
      "variational_beta * kldivergence:  0.16416\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29828\n",
      "kldivergence:   1652.32\n",
      "variational_beta * kldivergence:  0.16523\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29467\n",
      "kldivergence:   1560.51\n",
      "variational_beta * kldivergence:  0.15605\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34994\n",
      "kldivergence:   1963.03\n",
      "variational_beta * kldivergence:  0.19630\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.39211\n",
      "kldivergence:   2005.92\n",
      "variational_beta * kldivergence:  0.20059\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29664\n",
      "kldivergence:   1944.89\n",
      "variational_beta * kldivergence:  0.19449\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33562\n",
      "kldivergence:   1479.20\n",
      "variational_beta * kldivergence:  0.14792\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29639\n",
      "kldivergence:   1416.77\n",
      "variational_beta * kldivergence:  0.14168\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35192\n",
      "kldivergence:   1555.62\n",
      "variational_beta * kldivergence:  0.15556\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34732\n",
      "kldivergence:   1550.75\n",
      "variational_beta * kldivergence:  0.15507\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31961\n",
      "kldivergence:   1469.14\n",
      "variational_beta * kldivergence:  0.14691\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36677\n",
      "kldivergence:   1736.28\n",
      "variational_beta * kldivergence:  0.17363\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28551\n",
      "kldivergence:   1376.17\n",
      "variational_beta * kldivergence:  0.13762\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32690\n",
      "kldivergence:   1586.12\n",
      "variational_beta * kldivergence:  0.15861\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37014\n",
      "kldivergence:   1618.88\n",
      "variational_beta * kldivergence:  0.16189\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.25319\n",
      "kldivergence:   1297.04\n",
      "variational_beta * kldivergence:  0.12970\n",
      "batch accuracy: 91.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34504\n",
      "kldivergence:   1450.47\n",
      "variational_beta * kldivergence:  0.14505\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31014\n",
      "kldivergence:   1335.75\n",
      "variational_beta * kldivergence:  0.13357\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32934\n",
      "kldivergence:   1487.96\n",
      "variational_beta * kldivergence:  0.14880\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34640\n",
      "kldivergence:   1465.53\n",
      "variational_beta * kldivergence:  0.14655\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35269\n",
      "kldivergence:   1664.60\n",
      "variational_beta * kldivergence:  0.16646\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35671\n",
      "kldivergence:   1776.46\n",
      "variational_beta * kldivergence:  0.17765\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.39019\n",
      "kldivergence:   1571.53\n",
      "variational_beta * kldivergence:  0.15715\n",
      "batch accuracy: 87.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32226\n",
      "kldivergence:   1390.60\n",
      "variational_beta * kldivergence:  0.13906\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30324\n",
      "kldivergence:   1283.07\n",
      "variational_beta * kldivergence:  0.12831\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31370\n",
      "kldivergence:   1481.89\n",
      "variational_beta * kldivergence:  0.14819\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37511\n",
      "kldivergence:   1546.59\n",
      "variational_beta * kldivergence:  0.15466\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34756\n",
      "kldivergence:   1429.59\n",
      "variational_beta * kldivergence:  0.14296\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32055\n",
      "kldivergence:   1504.91\n",
      "variational_beta * kldivergence:  0.15049\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30850\n",
      "kldivergence:   1468.10\n",
      "variational_beta * kldivergence:  0.14681\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.27609\n",
      "kldivergence:   1513.08\n",
      "variational_beta * kldivergence:  0.15131\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33838\n",
      "kldivergence:   1394.96\n",
      "variational_beta * kldivergence:  0.13950\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31246\n",
      "kldivergence:   1647.93\n",
      "variational_beta * kldivergence:  0.16479\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34034\n",
      "kldivergence:   1659.57\n",
      "variational_beta * kldivergence:  0.16596\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34391\n",
      "kldivergence:   1443.77\n",
      "variational_beta * kldivergence:  0.14438\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28592\n",
      "kldivergence:   1326.05\n",
      "variational_beta * kldivergence:  0.13260\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36322\n",
      "kldivergence:   1636.97\n",
      "variational_beta * kldivergence:  0.16370\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34685\n",
      "kldivergence:   1655.53\n",
      "variational_beta * kldivergence:  0.16555\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28141\n",
      "kldivergence:   1408.39\n",
      "variational_beta * kldivergence:  0.14084\n",
      "batch accuracy: 90.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.27633\n",
      "kldivergence:   1321.02\n",
      "variational_beta * kldivergence:  0.13210\n",
      "batch accuracy: 90.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29132\n",
      "kldivergence:   1652.62\n",
      "variational_beta * kldivergence:  0.16526\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33558\n",
      "kldivergence:   1504.80\n",
      "variational_beta * kldivergence:  0.15048\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34471\n",
      "kldivergence:   1682.49\n",
      "variational_beta * kldivergence:  0.16825\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35438\n",
      "kldivergence:   1563.98\n",
      "variational_beta * kldivergence:  0.15640\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28918\n",
      "kldivergence:   1637.06\n",
      "variational_beta * kldivergence:  0.16371\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35693\n",
      "kldivergence:   1628.03\n",
      "variational_beta * kldivergence:  0.16280\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35848\n",
      "kldivergence:   1586.17\n",
      "variational_beta * kldivergence:  0.15862\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31186\n",
      "kldivergence:   1765.52\n",
      "variational_beta * kldivergence:  0.17655\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34831\n",
      "kldivergence:   1799.33\n",
      "variational_beta * kldivergence:  0.17993\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29669\n",
      "kldivergence:   1453.22\n",
      "variational_beta * kldivergence:  0.14532\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31051\n",
      "kldivergence:   1442.98\n",
      "variational_beta * kldivergence:  0.14430\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30389\n",
      "kldivergence:   1478.59\n",
      "variational_beta * kldivergence:  0.14786\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28808\n",
      "kldivergence:   1407.10\n",
      "variational_beta * kldivergence:  0.14071\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33261\n",
      "kldivergence:   1440.61\n",
      "variational_beta * kldivergence:  0.14406\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33229\n",
      "kldivergence:   1489.64\n",
      "variational_beta * kldivergence:  0.14896\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29331\n",
      "kldivergence:   1476.90\n",
      "variational_beta * kldivergence:  0.14769\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31364\n",
      "kldivergence:   1412.85\n",
      "variational_beta * kldivergence:  0.14129\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32278\n",
      "kldivergence:   1422.95\n",
      "variational_beta * kldivergence:  0.14229\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36397\n",
      "kldivergence:   1726.49\n",
      "variational_beta * kldivergence:  0.17265\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32866\n",
      "kldivergence:   1469.33\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34191\n",
      "kldivergence:   1482.40\n",
      "variational_beta * kldivergence:  0.14824\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35825\n",
      "kldivergence:   1527.82\n",
      "variational_beta * kldivergence:  0.15278\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29375\n",
      "kldivergence:   1326.21\n",
      "variational_beta * kldivergence:  0.13262\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31670\n",
      "kldivergence:   1298.79\n",
      "variational_beta * kldivergence:  0.12988\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32563\n",
      "kldivergence:   1394.08\n",
      "variational_beta * kldivergence:  0.13941\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32504\n",
      "kldivergence:   1509.80\n",
      "variational_beta * kldivergence:  0.15098\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37071\n",
      "kldivergence:   1588.70\n",
      "variational_beta * kldivergence:  0.15887\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35165\n",
      "kldivergence:   1582.41\n",
      "variational_beta * kldivergence:  0.15824\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31644\n",
      "kldivergence:   1520.85\n",
      "variational_beta * kldivergence:  0.15209\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33335\n",
      "kldivergence:   1568.05\n",
      "variational_beta * kldivergence:  0.15681\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37463\n",
      "kldivergence:   1689.90\n",
      "variational_beta * kldivergence:  0.16899\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34214\n",
      "kldivergence:   1770.82\n",
      "variational_beta * kldivergence:  0.17708\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31926\n",
      "kldivergence:   1639.89\n",
      "variational_beta * kldivergence:  0.16399\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33256\n",
      "kldivergence:   1558.00\n",
      "variational_beta * kldivergence:  0.15580\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30947\n",
      "kldivergence:   1488.05\n",
      "variational_beta * kldivergence:  0.14880\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31062\n",
      "kldivergence:   1460.35\n",
      "variational_beta * kldivergence:  0.14603\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32174\n",
      "kldivergence:   1627.78\n",
      "variational_beta * kldivergence:  0.16278\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30344\n",
      "kldivergence:   1575.24\n",
      "variational_beta * kldivergence:  0.15752\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33617\n",
      "kldivergence:   1575.12\n",
      "variational_beta * kldivergence:  0.15751\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32463\n",
      "kldivergence:   1634.02\n",
      "variational_beta * kldivergence:  0.16340\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33474\n",
      "kldivergence:   1484.75\n",
      "variational_beta * kldivergence:  0.14847\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31971\n",
      "kldivergence:   1438.45\n",
      "variational_beta * kldivergence:  0.14384\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34972\n",
      "kldivergence:   1494.09\n",
      "variational_beta * kldivergence:  0.14941\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.37183\n",
      "kldivergence:   1608.41\n",
      "variational_beta * kldivergence:  0.16084\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31851\n",
      "kldivergence:   1525.34\n",
      "variational_beta * kldivergence:  0.15253\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28952\n",
      "kldivergence:   1644.73\n",
      "variational_beta * kldivergence:  0.16447\n",
      "batch accuracy: 90.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31481\n",
      "kldivergence:   1427.51\n",
      "variational_beta * kldivergence:  0.14275\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33961\n",
      "kldivergence:   1510.71\n",
      "variational_beta * kldivergence:  0.15107\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34399\n",
      "kldivergence:   1551.58\n",
      "variational_beta * kldivergence:  0.15516\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30044\n",
      "kldivergence:   1419.03\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33556\n",
      "kldivergence:   1395.78\n",
      "variational_beta * kldivergence:  0.13958\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32963\n",
      "kldivergence:   1537.30\n",
      "variational_beta * kldivergence:  0.15373\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30944\n",
      "kldivergence:   1709.99\n",
      "variational_beta * kldivergence:  0.17100\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29217\n",
      "kldivergence:   1296.12\n",
      "variational_beta * kldivergence:  0.12961\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34136\n",
      "kldivergence:   1589.34\n",
      "variational_beta * kldivergence:  0.15893\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.41148\n",
      "kldivergence:   1831.21\n",
      "variational_beta * kldivergence:  0.18312\n",
      "batch accuracy: 86.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36710\n",
      "kldivergence:   1626.44\n",
      "variational_beta * kldivergence:  0.16264\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30075\n",
      "kldivergence:   1437.56\n",
      "variational_beta * kldivergence:  0.14376\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.23383\n",
      "kldivergence:   1173.84\n",
      "variational_beta * kldivergence:  0.11738\n",
      "batch accuracy: 92.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33401\n",
      "kldivergence:   1504.27\n",
      "variational_beta * kldivergence:  0.15043\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32389\n",
      "kldivergence:   1528.69\n",
      "variational_beta * kldivergence:  0.15287\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31111\n",
      "kldivergence:   1635.54\n",
      "variational_beta * kldivergence:  0.16355\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32168\n",
      "kldivergence:   1483.34\n",
      "variational_beta * kldivergence:  0.14833\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35176\n",
      "kldivergence:   1511.09\n",
      "variational_beta * kldivergence:  0.15111\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35880\n",
      "kldivergence:   1540.05\n",
      "variational_beta * kldivergence:  0.15401\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32652\n",
      "kldivergence:   1585.02\n",
      "variational_beta * kldivergence:  0.15850\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32668\n",
      "kldivergence:   1468.92\n",
      "variational_beta * kldivergence:  0.14689\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34373\n",
      "kldivergence:   1469.22\n",
      "variational_beta * kldivergence:  0.14692\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33051\n",
      "kldivergence:   1901.07\n",
      "variational_beta * kldivergence:  0.19011\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35516\n",
      "kldivergence:   1697.28\n",
      "variational_beta * kldivergence:  0.16973\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31422\n",
      "kldivergence:   1610.33\n",
      "variational_beta * kldivergence:  0.16103\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36341\n",
      "kldivergence:   1869.12\n",
      "variational_beta * kldivergence:  0.18691\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32474\n",
      "kldivergence:   1660.28\n",
      "variational_beta * kldivergence:  0.16603\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36284\n",
      "kldivergence:   1697.72\n",
      "variational_beta * kldivergence:  0.16977\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.33568\n",
      "kldivergence:   1451.82\n",
      "variational_beta * kldivergence:  0.14518\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.26602\n",
      "kldivergence:   1379.73\n",
      "variational_beta * kldivergence:  0.13797\n",
      "batch accuracy: 90.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29294\n",
      "kldivergence:   1575.95\n",
      "variational_beta * kldivergence:  0.15760\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36647\n",
      "kldivergence:   1597.84\n",
      "variational_beta * kldivergence:  0.15978\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.36549\n",
      "kldivergence:   1539.93\n",
      "variational_beta * kldivergence:  0.15399\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29833\n",
      "kldivergence:   1922.92\n",
      "variational_beta * kldivergence:  0.19229\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34554\n",
      "kldivergence:   1659.05\n",
      "variational_beta * kldivergence:  0.16591\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.30560\n",
      "kldivergence:   1388.09\n",
      "variational_beta * kldivergence:  0.13881\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.28382\n",
      "kldivergence:   1498.36\n",
      "variational_beta * kldivergence:  0.14984\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.31875\n",
      "kldivergence:   1605.26\n",
      "variational_beta * kldivergence:  0.16053\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.34348\n",
      "kldivergence:   1641.09\n",
      "variational_beta * kldivergence:  0.16411\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.29654\n",
      "kldivergence:   1478.99\n",
      "variational_beta * kldivergence:  0.14790\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.35105\n",
      "kldivergence:   1673.90\n",
      "variational_beta * kldivergence:  0.16739\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #40\n",
      "reconstruction loss: 0.32498\n",
      "kldivergence:   1414.85\n",
      "variational_beta * kldivergence:  0.14148\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30995\n",
      "kldivergence:   1372.10\n",
      "variational_beta * kldivergence:  0.13721\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32416\n",
      "kldivergence:   1537.22\n",
      "variational_beta * kldivergence:  0.15372\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.38272\n",
      "kldivergence:   1600.78\n",
      "variational_beta * kldivergence:  0.16008\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33066\n",
      "kldivergence:   1744.21\n",
      "variational_beta * kldivergence:  0.17442\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36238\n",
      "kldivergence:   1604.48\n",
      "variational_beta * kldivergence:  0.16045\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35402\n",
      "kldivergence:   1515.91\n",
      "variational_beta * kldivergence:  0.15159\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.38165\n",
      "kldivergence:   1671.15\n",
      "variational_beta * kldivergence:  0.16712\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35682\n",
      "kldivergence:   1705.94\n",
      "variational_beta * kldivergence:  0.17059\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.39636\n",
      "kldivergence:   1603.46\n",
      "variational_beta * kldivergence:  0.16035\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34260\n",
      "kldivergence:   1682.78\n",
      "variational_beta * kldivergence:  0.16828\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.38211\n",
      "kldivergence:   1786.73\n",
      "variational_beta * kldivergence:  0.17867\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31256\n",
      "kldivergence:   1573.84\n",
      "variational_beta * kldivergence:  0.15738\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32304\n",
      "kldivergence:   1337.96\n",
      "variational_beta * kldivergence:  0.13380\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32695\n",
      "kldivergence:   1580.77\n",
      "variational_beta * kldivergence:  0.15808\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28743\n",
      "kldivergence:   1583.94\n",
      "variational_beta * kldivergence:  0.15839\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36498\n",
      "kldivergence:   1686.92\n",
      "variational_beta * kldivergence:  0.16869\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28120\n",
      "kldivergence:   1491.04\n",
      "variational_beta * kldivergence:  0.14910\n",
      "batch accuracy: 90.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34254\n",
      "kldivergence:   1454.42\n",
      "variational_beta * kldivergence:  0.14544\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28784\n",
      "kldivergence:   1431.13\n",
      "variational_beta * kldivergence:  0.14311\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32717\n",
      "kldivergence:   1528.03\n",
      "variational_beta * kldivergence:  0.15280\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34539\n",
      "kldivergence:   1670.64\n",
      "variational_beta * kldivergence:  0.16706\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34648\n",
      "kldivergence:   1730.60\n",
      "variational_beta * kldivergence:  0.17306\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33433\n",
      "kldivergence:   1786.03\n",
      "variational_beta * kldivergence:  0.17860\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32617\n",
      "kldivergence:   1658.98\n",
      "variational_beta * kldivergence:  0.16590\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33045\n",
      "kldivergence:   1614.55\n",
      "variational_beta * kldivergence:  0.16146\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32172\n",
      "kldivergence:   1622.42\n",
      "variational_beta * kldivergence:  0.16224\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.39371\n",
      "kldivergence:   1595.20\n",
      "variational_beta * kldivergence:  0.15952\n",
      "batch accuracy: 86.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29846\n",
      "kldivergence:   1434.30\n",
      "variational_beta * kldivergence:  0.14343\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36844\n",
      "kldivergence:   1655.63\n",
      "variational_beta * kldivergence:  0.16556\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29237\n",
      "kldivergence:   1434.49\n",
      "variational_beta * kldivergence:  0.14345\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34742\n",
      "kldivergence:   1800.02\n",
      "variational_beta * kldivergence:  0.18000\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35732\n",
      "kldivergence:   1507.83\n",
      "variational_beta * kldivergence:  0.15078\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28407\n",
      "kldivergence:   1475.00\n",
      "variational_beta * kldivergence:  0.14750\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.27401\n",
      "kldivergence:   1667.57\n",
      "variational_beta * kldivergence:  0.16676\n",
      "batch accuracy: 90.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.38728\n",
      "kldivergence:   1693.85\n",
      "variational_beta * kldivergence:  0.16939\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30171\n",
      "kldivergence:   1553.03\n",
      "variational_beta * kldivergence:  0.15530\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.27888\n",
      "kldivergence:   1454.76\n",
      "variational_beta * kldivergence:  0.14548\n",
      "batch accuracy: 90.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31715\n",
      "kldivergence:   1487.77\n",
      "variational_beta * kldivergence:  0.14878\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35316\n",
      "kldivergence:   1697.17\n",
      "variational_beta * kldivergence:  0.16972\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34532\n",
      "kldivergence:   1623.67\n",
      "variational_beta * kldivergence:  0.16237\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.41352\n",
      "kldivergence:   1719.75\n",
      "variational_beta * kldivergence:  0.17197\n",
      "batch accuracy: 85.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33848\n",
      "kldivergence:   1620.24\n",
      "variational_beta * kldivergence:  0.16202\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35809\n",
      "kldivergence:   1439.85\n",
      "variational_beta * kldivergence:  0.14399\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32050\n",
      "kldivergence:   1398.69\n",
      "variational_beta * kldivergence:  0.13987\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31143\n",
      "kldivergence:   1717.51\n",
      "variational_beta * kldivergence:  0.17175\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36748\n",
      "kldivergence:   1712.92\n",
      "variational_beta * kldivergence:  0.17129\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31957\n",
      "kldivergence:   1559.65\n",
      "variational_beta * kldivergence:  0.15596\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31180\n",
      "kldivergence:   1451.68\n",
      "variational_beta * kldivergence:  0.14517\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.38108\n",
      "kldivergence:   1590.47\n",
      "variational_beta * kldivergence:  0.15905\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31920\n",
      "kldivergence:   1469.42\n",
      "variational_beta * kldivergence:  0.14694\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30741\n",
      "kldivergence:   1428.65\n",
      "variational_beta * kldivergence:  0.14287\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28455\n",
      "kldivergence:   1660.55\n",
      "variational_beta * kldivergence:  0.16605\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30797\n",
      "kldivergence:   1680.43\n",
      "variational_beta * kldivergence:  0.16804\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31881\n",
      "kldivergence:   1868.68\n",
      "variational_beta * kldivergence:  0.18687\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30209\n",
      "kldivergence:   1483.37\n",
      "variational_beta * kldivergence:  0.14834\n",
      "batch accuracy: 90.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33309\n",
      "kldivergence:   1524.43\n",
      "variational_beta * kldivergence:  0.15244\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28420\n",
      "kldivergence:   1363.91\n",
      "variational_beta * kldivergence:  0.13639\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.37790\n",
      "kldivergence:   1696.58\n",
      "variational_beta * kldivergence:  0.16966\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34560\n",
      "kldivergence:   1617.42\n",
      "variational_beta * kldivergence:  0.16174\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32793\n",
      "kldivergence:   1467.79\n",
      "variational_beta * kldivergence:  0.14678\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34861\n",
      "kldivergence:   1456.08\n",
      "variational_beta * kldivergence:  0.14561\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28271\n",
      "kldivergence:   1497.84\n",
      "variational_beta * kldivergence:  0.14978\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32413\n",
      "kldivergence:   1737.49\n",
      "variational_beta * kldivergence:  0.17375\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33117\n",
      "kldivergence:   1615.30\n",
      "variational_beta * kldivergence:  0.16153\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30789\n",
      "kldivergence:   1508.53\n",
      "variational_beta * kldivergence:  0.15085\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35463\n",
      "kldivergence:   1669.39\n",
      "variational_beta * kldivergence:  0.16694\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29691\n",
      "kldivergence:   1415.50\n",
      "variational_beta * kldivergence:  0.14155\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33062\n",
      "kldivergence:   1422.27\n",
      "variational_beta * kldivergence:  0.14223\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35093\n",
      "kldivergence:   1422.33\n",
      "variational_beta * kldivergence:  0.14223\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28563\n",
      "kldivergence:   1412.77\n",
      "variational_beta * kldivergence:  0.14128\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31969\n",
      "kldivergence:   1542.45\n",
      "variational_beta * kldivergence:  0.15425\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36456\n",
      "kldivergence:   2101.36\n",
      "variational_beta * kldivergence:  0.21014\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36793\n",
      "kldivergence:   1501.64\n",
      "variational_beta * kldivergence:  0.15016\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34097\n",
      "kldivergence:   1571.17\n",
      "variational_beta * kldivergence:  0.15712\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34691\n",
      "kldivergence:   1740.45\n",
      "variational_beta * kldivergence:  0.17404\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30023\n",
      "kldivergence:   1726.87\n",
      "variational_beta * kldivergence:  0.17269\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29680\n",
      "kldivergence:   1594.74\n",
      "variational_beta * kldivergence:  0.15947\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34998\n",
      "kldivergence:   1731.78\n",
      "variational_beta * kldivergence:  0.17318\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33009\n",
      "kldivergence:   1482.65\n",
      "variational_beta * kldivergence:  0.14826\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.24784\n",
      "kldivergence:   1270.27\n",
      "variational_beta * kldivergence:  0.12703\n",
      "batch accuracy: 91.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29799\n",
      "kldivergence:   1692.92\n",
      "variational_beta * kldivergence:  0.16929\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33607\n",
      "kldivergence:   1573.26\n",
      "variational_beta * kldivergence:  0.15733\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36204\n",
      "kldivergence:   1569.77\n",
      "variational_beta * kldivergence:  0.15698\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34907\n",
      "kldivergence:   1459.67\n",
      "variational_beta * kldivergence:  0.14597\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.38497\n",
      "kldivergence:   1380.59\n",
      "variational_beta * kldivergence:  0.13806\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33757\n",
      "kldivergence:   1377.91\n",
      "variational_beta * kldivergence:  0.13779\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28547\n",
      "kldivergence:   1401.28\n",
      "variational_beta * kldivergence:  0.14013\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35846\n",
      "kldivergence:   1437.83\n",
      "variational_beta * kldivergence:  0.14378\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31139\n",
      "kldivergence:   1354.48\n",
      "variational_beta * kldivergence:  0.13545\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30457\n",
      "kldivergence:   1383.27\n",
      "variational_beta * kldivergence:  0.13833\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34510\n",
      "kldivergence:   1645.72\n",
      "variational_beta * kldivergence:  0.16457\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28898\n",
      "kldivergence:   1508.97\n",
      "variational_beta * kldivergence:  0.15090\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30769\n",
      "kldivergence:   1445.13\n",
      "variational_beta * kldivergence:  0.14451\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.26864\n",
      "kldivergence:   1267.71\n",
      "variational_beta * kldivergence:  0.12677\n",
      "batch accuracy: 90.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31683\n",
      "kldivergence:   1620.16\n",
      "variational_beta * kldivergence:  0.16202\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.37170\n",
      "kldivergence:   1707.25\n",
      "variational_beta * kldivergence:  0.17073\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.27509\n",
      "kldivergence:   1931.39\n",
      "variational_beta * kldivergence:  0.19314\n",
      "batch accuracy: 90.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33921\n",
      "kldivergence:   1456.24\n",
      "variational_beta * kldivergence:  0.14562\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29554\n",
      "kldivergence:   1695.05\n",
      "variational_beta * kldivergence:  0.16951\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30340\n",
      "kldivergence:   1397.49\n",
      "variational_beta * kldivergence:  0.13975\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34114\n",
      "kldivergence:   1788.37\n",
      "variational_beta * kldivergence:  0.17884\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32409\n",
      "kldivergence:   1436.97\n",
      "variational_beta * kldivergence:  0.14370\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32011\n",
      "kldivergence:   1586.18\n",
      "variational_beta * kldivergence:  0.15862\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29470\n",
      "kldivergence:   1431.13\n",
      "variational_beta * kldivergence:  0.14311\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32610\n",
      "kldivergence:   1443.87\n",
      "variational_beta * kldivergence:  0.14439\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33674\n",
      "kldivergence:   1510.81\n",
      "variational_beta * kldivergence:  0.15108\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31248\n",
      "kldivergence:   1303.78\n",
      "variational_beta * kldivergence:  0.13038\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34314\n",
      "kldivergence:   1365.56\n",
      "variational_beta * kldivergence:  0.13656\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.27719\n",
      "kldivergence:   1670.23\n",
      "variational_beta * kldivergence:  0.16702\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33388\n",
      "kldivergence:   1526.02\n",
      "variational_beta * kldivergence:  0.15260\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31259\n",
      "kldivergence:   1545.97\n",
      "variational_beta * kldivergence:  0.15460\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35470\n",
      "kldivergence:   1435.01\n",
      "variational_beta * kldivergence:  0.14350\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.37128\n",
      "kldivergence:   1530.21\n",
      "variational_beta * kldivergence:  0.15302\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32179\n",
      "kldivergence:   1356.14\n",
      "variational_beta * kldivergence:  0.13561\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33023\n",
      "kldivergence:   1340.12\n",
      "variational_beta * kldivergence:  0.13401\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36627\n",
      "kldivergence:   1575.98\n",
      "variational_beta * kldivergence:  0.15760\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30832\n",
      "kldivergence:   2026.23\n",
      "variational_beta * kldivergence:  0.20262\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31449\n",
      "kldivergence:   1353.77\n",
      "variational_beta * kldivergence:  0.13538\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32776\n",
      "kldivergence:   1675.22\n",
      "variational_beta * kldivergence:  0.16752\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36782\n",
      "kldivergence:   1450.06\n",
      "variational_beta * kldivergence:  0.14501\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33126\n",
      "kldivergence:   1396.80\n",
      "variational_beta * kldivergence:  0.13968\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32190\n",
      "kldivergence:   1595.81\n",
      "variational_beta * kldivergence:  0.15958\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.38504\n",
      "kldivergence:   1540.43\n",
      "variational_beta * kldivergence:  0.15404\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31549\n",
      "kldivergence:   1458.01\n",
      "variational_beta * kldivergence:  0.14580\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34057\n",
      "kldivergence:   1333.86\n",
      "variational_beta * kldivergence:  0.13339\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28630\n",
      "kldivergence:   1436.78\n",
      "variational_beta * kldivergence:  0.14368\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33077\n",
      "kldivergence:   1522.96\n",
      "variational_beta * kldivergence:  0.15230\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.37808\n",
      "kldivergence:   1552.15\n",
      "variational_beta * kldivergence:  0.15521\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31353\n",
      "kldivergence:   1368.44\n",
      "variational_beta * kldivergence:  0.13684\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33640\n",
      "kldivergence:   1458.90\n",
      "variational_beta * kldivergence:  0.14589\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33521\n",
      "kldivergence:   1599.53\n",
      "variational_beta * kldivergence:  0.15995\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36374\n",
      "kldivergence:   1633.26\n",
      "variational_beta * kldivergence:  0.16333\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.37286\n",
      "kldivergence:   1622.44\n",
      "variational_beta * kldivergence:  0.16224\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33557\n",
      "kldivergence:   1495.59\n",
      "variational_beta * kldivergence:  0.14956\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32486\n",
      "kldivergence:   1474.89\n",
      "variational_beta * kldivergence:  0.14749\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32701\n",
      "kldivergence:   1433.82\n",
      "variational_beta * kldivergence:  0.14338\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.26378\n",
      "kldivergence:   1312.02\n",
      "variational_beta * kldivergence:  0.13120\n",
      "batch accuracy: 91.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.37286\n",
      "kldivergence:   1719.05\n",
      "variational_beta * kldivergence:  0.17190\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32709\n",
      "kldivergence:   1499.96\n",
      "variational_beta * kldivergence:  0.15000\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28815\n",
      "kldivergence:   1485.26\n",
      "variational_beta * kldivergence:  0.14853\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33695\n",
      "kldivergence:   1527.30\n",
      "variational_beta * kldivergence:  0.15273\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.27632\n",
      "kldivergence:   1292.63\n",
      "variational_beta * kldivergence:  0.12926\n",
      "batch accuracy: 90.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34043\n",
      "kldivergence:   1422.83\n",
      "variational_beta * kldivergence:  0.14228\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35605\n",
      "kldivergence:   1528.82\n",
      "variational_beta * kldivergence:  0.15288\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35333\n",
      "kldivergence:   1644.01\n",
      "variational_beta * kldivergence:  0.16440\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30212\n",
      "kldivergence:   1495.40\n",
      "variational_beta * kldivergence:  0.14954\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36985\n",
      "kldivergence:   1562.49\n",
      "variational_beta * kldivergence:  0.15625\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34110\n",
      "kldivergence:   1625.60\n",
      "variational_beta * kldivergence:  0.16256\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29661\n",
      "kldivergence:   1379.14\n",
      "variational_beta * kldivergence:  0.13791\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35057\n",
      "kldivergence:   1802.22\n",
      "variational_beta * kldivergence:  0.18022\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35235\n",
      "kldivergence:   1573.85\n",
      "variational_beta * kldivergence:  0.15738\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30999\n",
      "kldivergence:   1364.78\n",
      "variational_beta * kldivergence:  0.13648\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31447\n",
      "kldivergence:   1386.29\n",
      "variational_beta * kldivergence:  0.13863\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35817\n",
      "kldivergence:   1794.28\n",
      "variational_beta * kldivergence:  0.17943\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29699\n",
      "kldivergence:   1419.51\n",
      "variational_beta * kldivergence:  0.14195\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31126\n",
      "kldivergence:   1427.66\n",
      "variational_beta * kldivergence:  0.14277\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29824\n",
      "kldivergence:   1385.96\n",
      "variational_beta * kldivergence:  0.13860\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33371\n",
      "kldivergence:   1525.37\n",
      "variational_beta * kldivergence:  0.15254\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36746\n",
      "kldivergence:   1491.73\n",
      "variational_beta * kldivergence:  0.14917\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34868\n",
      "kldivergence:   1578.33\n",
      "variational_beta * kldivergence:  0.15783\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31701\n",
      "kldivergence:   1376.51\n",
      "variational_beta * kldivergence:  0.13765\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.28811\n",
      "kldivergence:   1263.80\n",
      "variational_beta * kldivergence:  0.12638\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.38554\n",
      "kldivergence:   1707.96\n",
      "variational_beta * kldivergence:  0.17080\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35290\n",
      "kldivergence:   1744.75\n",
      "variational_beta * kldivergence:  0.17447\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31883\n",
      "kldivergence:   1452.08\n",
      "variational_beta * kldivergence:  0.14521\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.36891\n",
      "kldivergence:   1784.78\n",
      "variational_beta * kldivergence:  0.17848\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33652\n",
      "kldivergence:   1361.99\n",
      "variational_beta * kldivergence:  0.13620\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29796\n",
      "kldivergence:   1480.61\n",
      "variational_beta * kldivergence:  0.14806\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.29277\n",
      "kldivergence:   1371.52\n",
      "variational_beta * kldivergence:  0.13715\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.31306\n",
      "kldivergence:   1508.83\n",
      "variational_beta * kldivergence:  0.15088\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34094\n",
      "kldivergence:   1547.73\n",
      "variational_beta * kldivergence:  0.15477\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34314\n",
      "kldivergence:   1433.95\n",
      "variational_beta * kldivergence:  0.14340\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.33584\n",
      "kldivergence:   1586.09\n",
      "variational_beta * kldivergence:  0.15861\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32849\n",
      "kldivergence:   1369.18\n",
      "variational_beta * kldivergence:  0.13692\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.35683\n",
      "kldivergence:   1537.67\n",
      "variational_beta * kldivergence:  0.15377\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.32645\n",
      "kldivergence:   1452.90\n",
      "variational_beta * kldivergence:  0.14529\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.34743\n",
      "kldivergence:   1482.27\n",
      "variational_beta * kldivergence:  0.14823\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.45888\n",
      "kldivergence:   1797.75\n",
      "variational_beta * kldivergence:  0.17978\n",
      "batch accuracy: 84.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #49\n",
      "reconstruction loss: 0.30330\n",
      "kldivergence:   1433.22\n",
      "variational_beta * kldivergence:  0.14332\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.43199\n",
      "kldivergence:   1382.54\n",
      "variational_beta * kldivergence:  0.13825\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.48982\n",
      "kldivergence:   1410.59\n",
      "variational_beta * kldivergence:  0.14106\n",
      "batch accuracy: 85.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.50023\n",
      "kldivergence:   1407.00\n",
      "variational_beta * kldivergence:  0.14070\n",
      "batch accuracy: 85.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.48842\n",
      "kldivergence:   1430.95\n",
      "variational_beta * kldivergence:  0.14310\n",
      "batch accuracy: 85.92\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.43126\n",
      "kldivergence:   1304.42\n",
      "variational_beta * kldivergence:  0.13044\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.44906\n",
      "kldivergence:   1349.96\n",
      "variational_beta * kldivergence:  0.13500\n",
      "batch accuracy: 85.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.50357\n",
      "kldivergence:   1470.66\n",
      "variational_beta * kldivergence:  0.14707\n",
      "batch accuracy: 84.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.46861\n",
      "kldivergence:   1495.22\n",
      "variational_beta * kldivergence:  0.14952\n",
      "batch accuracy: 86.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.50676\n",
      "kldivergence:   1431.82\n",
      "variational_beta * kldivergence:  0.14318\n",
      "batch accuracy: 84.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.47363\n",
      "kldivergence:   1357.19\n",
      "variational_beta * kldivergence:  0.13572\n",
      "batch accuracy: 85.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.43093\n",
      "kldivergence:   1372.81\n",
      "variational_beta * kldivergence:  0.13728\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.38050\n",
      "kldivergence:   1317.65\n",
      "variational_beta * kldivergence:  0.13176\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.45353\n",
      "kldivergence:   1307.94\n",
      "variational_beta * kldivergence:  0.13079\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.54616\n",
      "kldivergence:   1470.46\n",
      "variational_beta * kldivergence:  0.14705\n",
      "batch accuracy: 83.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.45258\n",
      "kldivergence:   1370.44\n",
      "variational_beta * kldivergence:  0.13704\n",
      "batch accuracy: 85.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.48442\n",
      "kldivergence:   1480.44\n",
      "variational_beta * kldivergence:  0.14804\n",
      "batch accuracy: 85.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.48913\n",
      "kldivergence:   1340.78\n",
      "variational_beta * kldivergence:  0.13408\n",
      "batch accuracy: 85.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.38577\n",
      "kldivergence:   1233.58\n",
      "variational_beta * kldivergence:  0.12336\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.53276\n",
      "kldivergence:   1530.37\n",
      "variational_beta * kldivergence:  0.15304\n",
      "batch accuracy: 83.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.47366\n",
      "kldivergence:   1405.32\n",
      "variational_beta * kldivergence:  0.14053\n",
      "batch accuracy: 85.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.44553\n",
      "kldivergence:   1467.51\n",
      "variational_beta * kldivergence:  0.14675\n",
      "batch accuracy: 86.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.40378\n",
      "kldivergence:   1267.28\n",
      "variational_beta * kldivergence:  0.12673\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.45743\n",
      "kldivergence:   1563.26\n",
      "variational_beta * kldivergence:  0.15633\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.41621\n",
      "kldivergence:   1352.81\n",
      "variational_beta * kldivergence:  0.13528\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.40133\n",
      "kldivergence:   1272.94\n",
      "variational_beta * kldivergence:  0.12729\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.47280\n",
      "kldivergence:   1376.88\n",
      "variational_beta * kldivergence:  0.13769\n",
      "batch accuracy: 85.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.45031\n",
      "kldivergence:   1460.87\n",
      "variational_beta * kldivergence:  0.14609\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.40608\n",
      "kldivergence:   1296.06\n",
      "variational_beta * kldivergence:  0.12961\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.46866\n",
      "kldivergence:   1353.24\n",
      "variational_beta * kldivergence:  0.13532\n",
      "batch accuracy: 85.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.50046\n",
      "kldivergence:   1385.34\n",
      "variational_beta * kldivergence:  0.13853\n",
      "batch accuracy: 85.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.37876\n",
      "kldivergence:   1287.21\n",
      "variational_beta * kldivergence:  0.12872\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.37867\n",
      "kldivergence:   1275.17\n",
      "variational_beta * kldivergence:  0.12752\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.54000\n",
      "kldivergence:   1469.56\n",
      "variational_beta * kldivergence:  0.14696\n",
      "batch accuracy: 84.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.51797\n",
      "kldivergence:   1418.90\n",
      "variational_beta * kldivergence:  0.14189\n",
      "batch accuracy: 84.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.45643\n",
      "kldivergence:   1302.15\n",
      "variational_beta * kldivergence:  0.13022\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.42504\n",
      "kldivergence:   1402.83\n",
      "variational_beta * kldivergence:  0.14028\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.45644\n",
      "kldivergence:   1389.86\n",
      "variational_beta * kldivergence:  0.13899\n",
      "batch accuracy: 85.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.45961\n",
      "kldivergence:   1420.32\n",
      "variational_beta * kldivergence:  0.14203\n",
      "batch accuracy: 85.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.48909\n",
      "kldivergence:   1367.21\n",
      "variational_beta * kldivergence:  0.13672\n",
      "batch accuracy: 85.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.38019\n",
      "kldivergence:   1277.25\n",
      "variational_beta * kldivergence:  0.12773\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.38605\n",
      "kldivergence:   1258.75\n",
      "variational_beta * kldivergence:  0.12587\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.43662\n",
      "kldivergence:   1267.44\n",
      "variational_beta * kldivergence:  0.12674\n",
      "batch accuracy: 86.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.49256\n",
      "kldivergence:   1444.59\n",
      "variational_beta * kldivergence:  0.14446\n",
      "batch accuracy: 84.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.32449\n",
      "kldivergence:   1219.48\n",
      "variational_beta * kldivergence:  0.12195\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.38903\n",
      "kldivergence:   1306.00\n",
      "variational_beta * kldivergence:  0.13060\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.51225\n",
      "kldivergence:   1516.85\n",
      "variational_beta * kldivergence:  0.15168\n",
      "batch accuracy: 84.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.42972\n",
      "kldivergence:   1268.31\n",
      "variational_beta * kldivergence:  0.12683\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.51623\n",
      "kldivergence:   1478.75\n",
      "variational_beta * kldivergence:  0.14788\n",
      "batch accuracy: 84.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.41290\n",
      "kldivergence:   1334.50\n",
      "variational_beta * kldivergence:  0.13345\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.45964\n",
      "kldivergence:   1315.36\n",
      "variational_beta * kldivergence:  0.13154\n",
      "batch accuracy: 85.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.45375\n",
      "kldivergence:   1234.12\n",
      "variational_beta * kldivergence:  0.12341\n",
      "batch accuracy: 86.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.59687\n",
      "kldivergence:   1603.22\n",
      "variational_beta * kldivergence:  0.16032\n",
      "batch accuracy: 82.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.46713\n",
      "kldivergence:   1360.20\n",
      "variational_beta * kldivergence:  0.13602\n",
      "batch accuracy: 85.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.48485\n",
      "kldivergence:   1418.99\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 84.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.36947\n",
      "kldivergence:   1216.64\n",
      "variational_beta * kldivergence:  0.12166\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.46523\n",
      "kldivergence:   1398.67\n",
      "variational_beta * kldivergence:  0.13987\n",
      "batch accuracy: 85.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.55827\n",
      "kldivergence:   1459.37\n",
      "variational_beta * kldivergence:  0.14594\n",
      "batch accuracy: 83.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.46618\n",
      "kldivergence:   1439.73\n",
      "variational_beta * kldivergence:  0.14397\n",
      "batch accuracy: 85.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.45113\n",
      "kldivergence:   1355.15\n",
      "variational_beta * kldivergence:  0.13552\n",
      "batch accuracy: 85.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.41432\n",
      "kldivergence:   1432.92\n",
      "variational_beta * kldivergence:  0.14329\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.42178\n",
      "kldivergence:   1275.29\n",
      "variational_beta * kldivergence:  0.12753\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #49\n",
      "reconstruction loss: 0.39603\n",
      "kldivergence:   1265.24\n",
      "variational_beta * kldivergence:  0.12652\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "epoch # 49 : train loss is [178.16707507333533] and validation loss is [0.09918334753442455] \n",
      "Epoch [50 / 150] average reconstruction error: 0.480235\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.40475\n",
      "kldivergence:   1725.66\n",
      "variational_beta * kldivergence:  0.17257\n",
      "batch accuracy: 86.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28433\n",
      "kldivergence:   1351.07\n",
      "variational_beta * kldivergence:  0.13511\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36419\n",
      "kldivergence:   1488.90\n",
      "variational_beta * kldivergence:  0.14889\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36601\n",
      "kldivergence:   1490.26\n",
      "variational_beta * kldivergence:  0.14903\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33389\n",
      "kldivergence:   1484.30\n",
      "variational_beta * kldivergence:  0.14843\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.27636\n",
      "kldivergence:   1390.79\n",
      "variational_beta * kldivergence:  0.13908\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36636\n",
      "kldivergence:   1688.14\n",
      "variational_beta * kldivergence:  0.16881\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29735\n",
      "kldivergence:   1609.14\n",
      "variational_beta * kldivergence:  0.16091\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34464\n",
      "kldivergence:   1550.33\n",
      "variational_beta * kldivergence:  0.15503\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29039\n",
      "kldivergence:   1514.24\n",
      "variational_beta * kldivergence:  0.15142\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.27320\n",
      "kldivergence:   1469.01\n",
      "variational_beta * kldivergence:  0.14690\n",
      "batch accuracy: 91.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32940\n",
      "kldivergence:   1425.86\n",
      "variational_beta * kldivergence:  0.14259\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32222\n",
      "kldivergence:   1439.47\n",
      "variational_beta * kldivergence:  0.14395\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.26491\n",
      "kldivergence:   1446.85\n",
      "variational_beta * kldivergence:  0.14469\n",
      "batch accuracy: 91.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36083\n",
      "kldivergence:   1627.39\n",
      "variational_beta * kldivergence:  0.16274\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31222\n",
      "kldivergence:   1396.60\n",
      "variational_beta * kldivergence:  0.13966\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33736\n",
      "kldivergence:   1358.72\n",
      "variational_beta * kldivergence:  0.13587\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28656\n",
      "kldivergence:   1461.92\n",
      "variational_beta * kldivergence:  0.14619\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33781\n",
      "kldivergence:   1471.91\n",
      "variational_beta * kldivergence:  0.14719\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31561\n",
      "kldivergence:   1426.68\n",
      "variational_beta * kldivergence:  0.14267\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31507\n",
      "kldivergence:   1395.39\n",
      "variational_beta * kldivergence:  0.13954\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30870\n",
      "kldivergence:   1474.34\n",
      "variational_beta * kldivergence:  0.14743\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29085\n",
      "kldivergence:   1330.03\n",
      "variational_beta * kldivergence:  0.13300\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30485\n",
      "kldivergence:   1565.63\n",
      "variational_beta * kldivergence:  0.15656\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28293\n",
      "kldivergence:   1403.92\n",
      "variational_beta * kldivergence:  0.14039\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.38256\n",
      "kldivergence:   1664.88\n",
      "variational_beta * kldivergence:  0.16649\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33966\n",
      "kldivergence:   1304.15\n",
      "variational_beta * kldivergence:  0.13041\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31904\n",
      "kldivergence:   1515.66\n",
      "variational_beta * kldivergence:  0.15157\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32258\n",
      "kldivergence:   1502.74\n",
      "variational_beta * kldivergence:  0.15027\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29285\n",
      "kldivergence:   1637.68\n",
      "variational_beta * kldivergence:  0.16377\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31117\n",
      "kldivergence:   1442.07\n",
      "variational_beta * kldivergence:  0.14421\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30920\n",
      "kldivergence:   1456.48\n",
      "variational_beta * kldivergence:  0.14565\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.38228\n",
      "kldivergence:   1548.73\n",
      "variational_beta * kldivergence:  0.15487\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28842\n",
      "kldivergence:   1406.59\n",
      "variational_beta * kldivergence:  0.14066\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29219\n",
      "kldivergence:   1479.62\n",
      "variational_beta * kldivergence:  0.14796\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32851\n",
      "kldivergence:   1379.81\n",
      "variational_beta * kldivergence:  0.13798\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32841\n",
      "kldivergence:   1481.20\n",
      "variational_beta * kldivergence:  0.14812\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34391\n",
      "kldivergence:   1673.54\n",
      "variational_beta * kldivergence:  0.16735\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30816\n",
      "kldivergence:   1374.50\n",
      "variational_beta * kldivergence:  0.13745\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35900\n",
      "kldivergence:   1676.52\n",
      "variational_beta * kldivergence:  0.16765\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.27801\n",
      "kldivergence:   1455.40\n",
      "variational_beta * kldivergence:  0.14554\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.26881\n",
      "kldivergence:   1363.27\n",
      "variational_beta * kldivergence:  0.13633\n",
      "batch accuracy: 91.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36054\n",
      "kldivergence:   1484.84\n",
      "variational_beta * kldivergence:  0.14848\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32850\n",
      "kldivergence:   1248.76\n",
      "variational_beta * kldivergence:  0.12488\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29623\n",
      "kldivergence:   1506.75\n",
      "variational_beta * kldivergence:  0.15068\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30186\n",
      "kldivergence:   1425.39\n",
      "variational_beta * kldivergence:  0.14254\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32384\n",
      "kldivergence:   1545.25\n",
      "variational_beta * kldivergence:  0.15453\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31846\n",
      "kldivergence:   1597.60\n",
      "variational_beta * kldivergence:  0.15976\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34300\n",
      "kldivergence:   1697.66\n",
      "variational_beta * kldivergence:  0.16977\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28941\n",
      "kldivergence:   1377.88\n",
      "variational_beta * kldivergence:  0.13779\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29963\n",
      "kldivergence:   1581.12\n",
      "variational_beta * kldivergence:  0.15811\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32296\n",
      "kldivergence:   1577.10\n",
      "variational_beta * kldivergence:  0.15771\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31377\n",
      "kldivergence:   1467.99\n",
      "variational_beta * kldivergence:  0.14680\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35698\n",
      "kldivergence:   1540.92\n",
      "variational_beta * kldivergence:  0.15409\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29446\n",
      "kldivergence:   1367.41\n",
      "variational_beta * kldivergence:  0.13674\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28652\n",
      "kldivergence:   1445.69\n",
      "variational_beta * kldivergence:  0.14457\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28574\n",
      "kldivergence:   1430.98\n",
      "variational_beta * kldivergence:  0.14310\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31307\n",
      "kldivergence:   1551.26\n",
      "variational_beta * kldivergence:  0.15513\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31927\n",
      "kldivergence:   1744.35\n",
      "variational_beta * kldivergence:  0.17444\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35510\n",
      "kldivergence:   1682.92\n",
      "variational_beta * kldivergence:  0.16829\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31962\n",
      "kldivergence:   1650.34\n",
      "variational_beta * kldivergence:  0.16503\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33341\n",
      "kldivergence:   1560.23\n",
      "variational_beta * kldivergence:  0.15602\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36054\n",
      "kldivergence:   1694.69\n",
      "variational_beta * kldivergence:  0.16947\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28604\n",
      "kldivergence:   1430.97\n",
      "variational_beta * kldivergence:  0.14310\n",
      "batch accuracy: 90.73\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34316\n",
      "kldivergence:   1626.43\n",
      "variational_beta * kldivergence:  0.16264\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31845\n",
      "kldivergence:   1430.17\n",
      "variational_beta * kldivergence:  0.14302\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34131\n",
      "kldivergence:   1499.59\n",
      "variational_beta * kldivergence:  0.14996\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31957\n",
      "kldivergence:   1535.40\n",
      "variational_beta * kldivergence:  0.15354\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31658\n",
      "kldivergence:   1657.80\n",
      "variational_beta * kldivergence:  0.16578\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.38270\n",
      "kldivergence:   1523.25\n",
      "variational_beta * kldivergence:  0.15232\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30572\n",
      "kldivergence:   1493.40\n",
      "variational_beta * kldivergence:  0.14934\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36574\n",
      "kldivergence:   1350.52\n",
      "variational_beta * kldivergence:  0.13505\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33931\n",
      "kldivergence:   1743.75\n",
      "variational_beta * kldivergence:  0.17437\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32822\n",
      "kldivergence:   1522.10\n",
      "variational_beta * kldivergence:  0.15221\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.39002\n",
      "kldivergence:   1488.46\n",
      "variational_beta * kldivergence:  0.14885\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31719\n",
      "kldivergence:   1436.69\n",
      "variational_beta * kldivergence:  0.14367\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31958\n",
      "kldivergence:   1452.34\n",
      "variational_beta * kldivergence:  0.14523\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35227\n",
      "kldivergence:   1617.50\n",
      "variational_beta * kldivergence:  0.16175\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28645\n",
      "kldivergence:   1247.86\n",
      "variational_beta * kldivergence:  0.12479\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32416\n",
      "kldivergence:   1427.64\n",
      "variational_beta * kldivergence:  0.14276\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28191\n",
      "kldivergence:   1421.28\n",
      "variational_beta * kldivergence:  0.14213\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30774\n",
      "kldivergence:   1416.51\n",
      "variational_beta * kldivergence:  0.14165\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28400\n",
      "kldivergence:   1466.37\n",
      "variational_beta * kldivergence:  0.14664\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35061\n",
      "kldivergence:   1630.46\n",
      "variational_beta * kldivergence:  0.16305\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32586\n",
      "kldivergence:   1646.59\n",
      "variational_beta * kldivergence:  0.16466\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36788\n",
      "kldivergence:   1689.90\n",
      "variational_beta * kldivergence:  0.16899\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32314\n",
      "kldivergence:   1641.68\n",
      "variational_beta * kldivergence:  0.16417\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30079\n",
      "kldivergence:   1451.60\n",
      "variational_beta * kldivergence:  0.14516\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31800\n",
      "kldivergence:   1441.16\n",
      "variational_beta * kldivergence:  0.14412\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30434\n",
      "kldivergence:   1474.26\n",
      "variational_beta * kldivergence:  0.14743\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36521\n",
      "kldivergence:   1670.50\n",
      "variational_beta * kldivergence:  0.16705\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28679\n",
      "kldivergence:   1470.76\n",
      "variational_beta * kldivergence:  0.14708\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29550\n",
      "kldivergence:   1456.34\n",
      "variational_beta * kldivergence:  0.14563\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29414\n",
      "kldivergence:   1395.85\n",
      "variational_beta * kldivergence:  0.13959\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36187\n",
      "kldivergence:   1587.25\n",
      "variational_beta * kldivergence:  0.15872\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29682\n",
      "kldivergence:   1485.30\n",
      "variational_beta * kldivergence:  0.14853\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.26852\n",
      "kldivergence:   1384.71\n",
      "variational_beta * kldivergence:  0.13847\n",
      "batch accuracy: 91.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31159\n",
      "kldivergence:   1536.80\n",
      "variational_beta * kldivergence:  0.15368\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30594\n",
      "kldivergence:   1463.40\n",
      "variational_beta * kldivergence:  0.14634\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30736\n",
      "kldivergence:   1520.38\n",
      "variational_beta * kldivergence:  0.15204\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.27612\n",
      "kldivergence:   1386.02\n",
      "variational_beta * kldivergence:  0.13860\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32969\n",
      "kldivergence:   1607.04\n",
      "variational_beta * kldivergence:  0.16070\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33434\n",
      "kldivergence:   1574.42\n",
      "variational_beta * kldivergence:  0.15744\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29153\n",
      "kldivergence:   1495.50\n",
      "variational_beta * kldivergence:  0.14955\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30569\n",
      "kldivergence:   1605.00\n",
      "variational_beta * kldivergence:  0.16050\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29747\n",
      "kldivergence:   1407.13\n",
      "variational_beta * kldivergence:  0.14071\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30210\n",
      "kldivergence:   1395.97\n",
      "variational_beta * kldivergence:  0.13960\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.38592\n",
      "kldivergence:   1627.98\n",
      "variational_beta * kldivergence:  0.16280\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34250\n",
      "kldivergence:   1517.14\n",
      "variational_beta * kldivergence:  0.15171\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.38545\n",
      "kldivergence:   1499.31\n",
      "variational_beta * kldivergence:  0.14993\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34186\n",
      "kldivergence:   1403.57\n",
      "variational_beta * kldivergence:  0.14036\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33529\n",
      "kldivergence:   1515.91\n",
      "variational_beta * kldivergence:  0.15159\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32762\n",
      "kldivergence:   1484.40\n",
      "variational_beta * kldivergence:  0.14844\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32733\n",
      "kldivergence:   1683.73\n",
      "variational_beta * kldivergence:  0.16837\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31026\n",
      "kldivergence:   1434.48\n",
      "variational_beta * kldivergence:  0.14345\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29080\n",
      "kldivergence:   1435.31\n",
      "variational_beta * kldivergence:  0.14353\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32750\n",
      "kldivergence:   1501.00\n",
      "variational_beta * kldivergence:  0.15010\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33403\n",
      "kldivergence:   1647.19\n",
      "variational_beta * kldivergence:  0.16472\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.39586\n",
      "kldivergence:   1567.14\n",
      "variational_beta * kldivergence:  0.15671\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33045\n",
      "kldivergence:   1498.94\n",
      "variational_beta * kldivergence:  0.14989\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30697\n",
      "kldivergence:   1389.24\n",
      "variational_beta * kldivergence:  0.13892\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30613\n",
      "kldivergence:   1633.36\n",
      "variational_beta * kldivergence:  0.16334\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30534\n",
      "kldivergence:   1517.08\n",
      "variational_beta * kldivergence:  0.15171\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29257\n",
      "kldivergence:   1661.15\n",
      "variational_beta * kldivergence:  0.16611\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35207\n",
      "kldivergence:   1636.86\n",
      "variational_beta * kldivergence:  0.16369\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32134\n",
      "kldivergence:   1438.39\n",
      "variational_beta * kldivergence:  0.14384\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34415\n",
      "kldivergence:   1724.88\n",
      "variational_beta * kldivergence:  0.17249\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34621\n",
      "kldivergence:   1648.80\n",
      "variational_beta * kldivergence:  0.16488\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33626\n",
      "kldivergence:   1550.13\n",
      "variational_beta * kldivergence:  0.15501\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32344\n",
      "kldivergence:   1591.82\n",
      "variational_beta * kldivergence:  0.15918\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.37502\n",
      "kldivergence:   1709.48\n",
      "variational_beta * kldivergence:  0.17095\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28596\n",
      "kldivergence:   1329.23\n",
      "variational_beta * kldivergence:  0.13292\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34360\n",
      "kldivergence:   1801.43\n",
      "variational_beta * kldivergence:  0.18014\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35503\n",
      "kldivergence:   1471.74\n",
      "variational_beta * kldivergence:  0.14717\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34655\n",
      "kldivergence:   1723.25\n",
      "variational_beta * kldivergence:  0.17232\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30541\n",
      "kldivergence:   1334.40\n",
      "variational_beta * kldivergence:  0.13344\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29359\n",
      "kldivergence:   1422.13\n",
      "variational_beta * kldivergence:  0.14221\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32858\n",
      "kldivergence:   1501.38\n",
      "variational_beta * kldivergence:  0.15014\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.39503\n",
      "kldivergence:   1461.85\n",
      "variational_beta * kldivergence:  0.14619\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35927\n",
      "kldivergence:   1407.50\n",
      "variational_beta * kldivergence:  0.14075\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31795\n",
      "kldivergence:   1287.46\n",
      "variational_beta * kldivergence:  0.12875\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30717\n",
      "kldivergence:   1458.24\n",
      "variational_beta * kldivergence:  0.14582\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33561\n",
      "kldivergence:   1532.56\n",
      "variational_beta * kldivergence:  0.15326\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31155\n",
      "kldivergence:   1658.90\n",
      "variational_beta * kldivergence:  0.16589\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34195\n",
      "kldivergence:   1586.87\n",
      "variational_beta * kldivergence:  0.15869\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30896\n",
      "kldivergence:   1791.17\n",
      "variational_beta * kldivergence:  0.17912\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33591\n",
      "kldivergence:   1690.89\n",
      "variational_beta * kldivergence:  0.16909\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30165\n",
      "kldivergence:   1499.50\n",
      "variational_beta * kldivergence:  0.14995\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32244\n",
      "kldivergence:   1686.68\n",
      "variational_beta * kldivergence:  0.16867\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30806\n",
      "kldivergence:   1463.87\n",
      "variational_beta * kldivergence:  0.14639\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32711\n",
      "kldivergence:   1621.75\n",
      "variational_beta * kldivergence:  0.16217\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35564\n",
      "kldivergence:   1621.17\n",
      "variational_beta * kldivergence:  0.16212\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.27680\n",
      "kldivergence:   1350.38\n",
      "variational_beta * kldivergence:  0.13504\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30012\n",
      "kldivergence:   1584.99\n",
      "variational_beta * kldivergence:  0.15850\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32602\n",
      "kldivergence:   1494.73\n",
      "variational_beta * kldivergence:  0.14947\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34556\n",
      "kldivergence:   1694.68\n",
      "variational_beta * kldivergence:  0.16947\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32460\n",
      "kldivergence:   1449.75\n",
      "variational_beta * kldivergence:  0.14497\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31834\n",
      "kldivergence:   1567.92\n",
      "variational_beta * kldivergence:  0.15679\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31975\n",
      "kldivergence:   1423.98\n",
      "variational_beta * kldivergence:  0.14240\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31180\n",
      "kldivergence:   1370.53\n",
      "variational_beta * kldivergence:  0.13705\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.27337\n",
      "kldivergence:   1440.09\n",
      "variational_beta * kldivergence:  0.14401\n",
      "batch accuracy: 90.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31488\n",
      "kldivergence:   1533.91\n",
      "variational_beta * kldivergence:  0.15339\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.26257\n",
      "kldivergence:   1479.79\n",
      "variational_beta * kldivergence:  0.14798\n",
      "batch accuracy: 90.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33736\n",
      "kldivergence:   1577.19\n",
      "variational_beta * kldivergence:  0.15772\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29513\n",
      "kldivergence:   1366.60\n",
      "variational_beta * kldivergence:  0.13666\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29115\n",
      "kldivergence:   1471.21\n",
      "variational_beta * kldivergence:  0.14712\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31173\n",
      "kldivergence:   1578.52\n",
      "variational_beta * kldivergence:  0.15785\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33247\n",
      "kldivergence:   1412.31\n",
      "variational_beta * kldivergence:  0.14123\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31404\n",
      "kldivergence:   1357.60\n",
      "variational_beta * kldivergence:  0.13576\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32422\n",
      "kldivergence:   1501.31\n",
      "variational_beta * kldivergence:  0.15013\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31467\n",
      "kldivergence:   1401.50\n",
      "variational_beta * kldivergence:  0.14015\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.27961\n",
      "kldivergence:   1435.88\n",
      "variational_beta * kldivergence:  0.14359\n",
      "batch accuracy: 91.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29843\n",
      "kldivergence:   1362.37\n",
      "variational_beta * kldivergence:  0.13624\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32476\n",
      "kldivergence:   1580.92\n",
      "variational_beta * kldivergence:  0.15809\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32873\n",
      "kldivergence:   1443.33\n",
      "variational_beta * kldivergence:  0.14433\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33617\n",
      "kldivergence:   1496.55\n",
      "variational_beta * kldivergence:  0.14965\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28476\n",
      "kldivergence:   1552.75\n",
      "variational_beta * kldivergence:  0.15528\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30301\n",
      "kldivergence:   1302.64\n",
      "variational_beta * kldivergence:  0.13026\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34446\n",
      "kldivergence:   1538.99\n",
      "variational_beta * kldivergence:  0.15390\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.37720\n",
      "kldivergence:   1607.60\n",
      "variational_beta * kldivergence:  0.16076\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.26931\n",
      "kldivergence:   1494.20\n",
      "variational_beta * kldivergence:  0.14942\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36456\n",
      "kldivergence:   1642.89\n",
      "variational_beta * kldivergence:  0.16429\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33806\n",
      "kldivergence:   1462.70\n",
      "variational_beta * kldivergence:  0.14627\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31055\n",
      "kldivergence:   1519.61\n",
      "variational_beta * kldivergence:  0.15196\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34445\n",
      "kldivergence:   1439.14\n",
      "variational_beta * kldivergence:  0.14391\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30691\n",
      "kldivergence:   1684.87\n",
      "variational_beta * kldivergence:  0.16849\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.37457\n",
      "kldivergence:   1484.47\n",
      "variational_beta * kldivergence:  0.14845\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.40172\n",
      "kldivergence:   1500.47\n",
      "variational_beta * kldivergence:  0.15005\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35150\n",
      "kldivergence:   1476.37\n",
      "variational_beta * kldivergence:  0.14764\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28874\n",
      "kldivergence:   1480.33\n",
      "variational_beta * kldivergence:  0.14803\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31096\n",
      "kldivergence:   1422.38\n",
      "variational_beta * kldivergence:  0.14224\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32017\n",
      "kldivergence:   1447.32\n",
      "variational_beta * kldivergence:  0.14473\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36884\n",
      "kldivergence:   1480.98\n",
      "variational_beta * kldivergence:  0.14810\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.38447\n",
      "kldivergence:   1632.48\n",
      "variational_beta * kldivergence:  0.16325\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31656\n",
      "kldivergence:   1406.31\n",
      "variational_beta * kldivergence:  0.14063\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31792\n",
      "kldivergence:   1472.23\n",
      "variational_beta * kldivergence:  0.14722\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35103\n",
      "kldivergence:   1491.71\n",
      "variational_beta * kldivergence:  0.14917\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29484\n",
      "kldivergence:   1389.89\n",
      "variational_beta * kldivergence:  0.13899\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31583\n",
      "kldivergence:   1485.37\n",
      "variational_beta * kldivergence:  0.14854\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31848\n",
      "kldivergence:   1437.52\n",
      "variational_beta * kldivergence:  0.14375\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31333\n",
      "kldivergence:   1548.03\n",
      "variational_beta * kldivergence:  0.15480\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32442\n",
      "kldivergence:   1486.35\n",
      "variational_beta * kldivergence:  0.14864\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32403\n",
      "kldivergence:   1516.84\n",
      "variational_beta * kldivergence:  0.15168\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33661\n",
      "kldivergence:   1596.12\n",
      "variational_beta * kldivergence:  0.15961\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33807\n",
      "kldivergence:   1437.27\n",
      "variational_beta * kldivergence:  0.14373\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.26994\n",
      "kldivergence:   1524.61\n",
      "variational_beta * kldivergence:  0.15246\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33881\n",
      "kldivergence:   1562.05\n",
      "variational_beta * kldivergence:  0.15620\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.27529\n",
      "kldivergence:   1433.75\n",
      "variational_beta * kldivergence:  0.14338\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.37534\n",
      "kldivergence:   1718.41\n",
      "variational_beta * kldivergence:  0.17184\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30654\n",
      "kldivergence:   1547.63\n",
      "variational_beta * kldivergence:  0.15476\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35017\n",
      "kldivergence:   1715.30\n",
      "variational_beta * kldivergence:  0.17153\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29473\n",
      "kldivergence:   1648.21\n",
      "variational_beta * kldivergence:  0.16482\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33775\n",
      "kldivergence:   1539.77\n",
      "variational_beta * kldivergence:  0.15398\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33254\n",
      "kldivergence:   1545.02\n",
      "variational_beta * kldivergence:  0.15450\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33717\n",
      "kldivergence:   1671.27\n",
      "variational_beta * kldivergence:  0.16713\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31833\n",
      "kldivergence:   1465.98\n",
      "variational_beta * kldivergence:  0.14660\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31004\n",
      "kldivergence:   1499.68\n",
      "variational_beta * kldivergence:  0.14997\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.37456\n",
      "kldivergence:   1760.28\n",
      "variational_beta * kldivergence:  0.17603\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35888\n",
      "kldivergence:   1572.77\n",
      "variational_beta * kldivergence:  0.15728\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29353\n",
      "kldivergence:   1485.82\n",
      "variational_beta * kldivergence:  0.14858\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35565\n",
      "kldivergence:   1498.15\n",
      "variational_beta * kldivergence:  0.14982\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29000\n",
      "kldivergence:   1311.76\n",
      "variational_beta * kldivergence:  0.13118\n",
      "batch accuracy: 90.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33521\n",
      "kldivergence:   1435.13\n",
      "variational_beta * kldivergence:  0.14351\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30872\n",
      "kldivergence:   1347.23\n",
      "variational_beta * kldivergence:  0.13472\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36357\n",
      "kldivergence:   1666.66\n",
      "variational_beta * kldivergence:  0.16667\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34546\n",
      "kldivergence:   1633.12\n",
      "variational_beta * kldivergence:  0.16331\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32972\n",
      "kldivergence:   1569.63\n",
      "variational_beta * kldivergence:  0.15696\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.40194\n",
      "kldivergence:   1545.13\n",
      "variational_beta * kldivergence:  0.15451\n",
      "batch accuracy: 86.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31090\n",
      "kldivergence:   1403.05\n",
      "variational_beta * kldivergence:  0.14031\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35584\n",
      "kldivergence:   1700.47\n",
      "variational_beta * kldivergence:  0.17005\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29764\n",
      "kldivergence:   1344.31\n",
      "variational_beta * kldivergence:  0.13443\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32805\n",
      "kldivergence:   1452.75\n",
      "variational_beta * kldivergence:  0.14528\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.39872\n",
      "kldivergence:   1871.23\n",
      "variational_beta * kldivergence:  0.18712\n",
      "batch accuracy: 86.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32943\n",
      "kldivergence:   1495.26\n",
      "variational_beta * kldivergence:  0.14953\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33613\n",
      "kldivergence:   1691.95\n",
      "variational_beta * kldivergence:  0.16919\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33673\n",
      "kldivergence:   1572.23\n",
      "variational_beta * kldivergence:  0.15722\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30790\n",
      "kldivergence:   1469.56\n",
      "variational_beta * kldivergence:  0.14696\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30615\n",
      "kldivergence:   1474.89\n",
      "variational_beta * kldivergence:  0.14749\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29474\n",
      "kldivergence:   1343.01\n",
      "variational_beta * kldivergence:  0.13430\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35752\n",
      "kldivergence:   1500.97\n",
      "variational_beta * kldivergence:  0.15010\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.41554\n",
      "kldivergence:   1700.27\n",
      "variational_beta * kldivergence:  0.17003\n",
      "batch accuracy: 85.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34124\n",
      "kldivergence:   1397.40\n",
      "variational_beta * kldivergence:  0.13974\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33110\n",
      "kldivergence:   1825.89\n",
      "variational_beta * kldivergence:  0.18259\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33140\n",
      "kldivergence:   1856.65\n",
      "variational_beta * kldivergence:  0.18566\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33065\n",
      "kldivergence:   1517.68\n",
      "variational_beta * kldivergence:  0.15177\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32587\n",
      "kldivergence:   1417.06\n",
      "variational_beta * kldivergence:  0.14171\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33842\n",
      "kldivergence:   1426.16\n",
      "variational_beta * kldivergence:  0.14262\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30239\n",
      "kldivergence:   1384.87\n",
      "variational_beta * kldivergence:  0.13849\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29682\n",
      "kldivergence:   1447.12\n",
      "variational_beta * kldivergence:  0.14471\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36709\n",
      "kldivergence:   1681.51\n",
      "variational_beta * kldivergence:  0.16815\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32807\n",
      "kldivergence:   1355.73\n",
      "variational_beta * kldivergence:  0.13557\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.41297\n",
      "kldivergence:   1619.34\n",
      "variational_beta * kldivergence:  0.16193\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35625\n",
      "kldivergence:   1649.26\n",
      "variational_beta * kldivergence:  0.16493\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30471\n",
      "kldivergence:   1391.53\n",
      "variational_beta * kldivergence:  0.13915\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31621\n",
      "kldivergence:   1467.74\n",
      "variational_beta * kldivergence:  0.14677\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35629\n",
      "kldivergence:   1766.69\n",
      "variational_beta * kldivergence:  0.17667\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29158\n",
      "kldivergence:   1371.38\n",
      "variational_beta * kldivergence:  0.13714\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33770\n",
      "kldivergence:   1640.57\n",
      "variational_beta * kldivergence:  0.16406\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33386\n",
      "kldivergence:   1641.21\n",
      "variational_beta * kldivergence:  0.16412\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33298\n",
      "kldivergence:   1356.97\n",
      "variational_beta * kldivergence:  0.13570\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.41695\n",
      "kldivergence:   1859.36\n",
      "variational_beta * kldivergence:  0.18594\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32028\n",
      "kldivergence:   1443.10\n",
      "variational_beta * kldivergence:  0.14431\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31609\n",
      "kldivergence:   1580.59\n",
      "variational_beta * kldivergence:  0.15806\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30473\n",
      "kldivergence:   1496.53\n",
      "variational_beta * kldivergence:  0.14965\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29588\n",
      "kldivergence:   1539.68\n",
      "variational_beta * kldivergence:  0.15397\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28195\n",
      "kldivergence:   1694.03\n",
      "variational_beta * kldivergence:  0.16940\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30162\n",
      "kldivergence:   1379.11\n",
      "variational_beta * kldivergence:  0.13791\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35384\n",
      "kldivergence:   1513.90\n",
      "variational_beta * kldivergence:  0.15139\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31138\n",
      "kldivergence:   1445.86\n",
      "variational_beta * kldivergence:  0.14459\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.27127\n",
      "kldivergence:   1469.72\n",
      "variational_beta * kldivergence:  0.14697\n",
      "batch accuracy: 90.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.39386\n",
      "kldivergence:   1813.68\n",
      "variational_beta * kldivergence:  0.18137\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32381\n",
      "kldivergence:   1428.61\n",
      "variational_beta * kldivergence:  0.14286\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32390\n",
      "kldivergence:   1537.53\n",
      "variational_beta * kldivergence:  0.15375\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31963\n",
      "kldivergence:   1766.37\n",
      "variational_beta * kldivergence:  0.17664\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34762\n",
      "kldivergence:   1691.21\n",
      "variational_beta * kldivergence:  0.16912\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29888\n",
      "kldivergence:   1570.74\n",
      "variational_beta * kldivergence:  0.15707\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32562\n",
      "kldivergence:   1718.93\n",
      "variational_beta * kldivergence:  0.17189\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34379\n",
      "kldivergence:   1472.27\n",
      "variational_beta * kldivergence:  0.14723\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33209\n",
      "kldivergence:   1505.32\n",
      "variational_beta * kldivergence:  0.15053\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29551\n",
      "kldivergence:   1317.87\n",
      "variational_beta * kldivergence:  0.13179\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34386\n",
      "kldivergence:   1678.71\n",
      "variational_beta * kldivergence:  0.16787\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34476\n",
      "kldivergence:   1501.93\n",
      "variational_beta * kldivergence:  0.15019\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32825\n",
      "kldivergence:   1622.60\n",
      "variational_beta * kldivergence:  0.16226\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34499\n",
      "kldivergence:   1687.26\n",
      "variational_beta * kldivergence:  0.16873\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36920\n",
      "kldivergence:   1585.89\n",
      "variational_beta * kldivergence:  0.15859\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35609\n",
      "kldivergence:   1572.17\n",
      "variational_beta * kldivergence:  0.15722\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33359\n",
      "kldivergence:   1431.83\n",
      "variational_beta * kldivergence:  0.14318\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33950\n",
      "kldivergence:   1665.99\n",
      "variational_beta * kldivergence:  0.16660\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35550\n",
      "kldivergence:   1395.51\n",
      "variational_beta * kldivergence:  0.13955\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34798\n",
      "kldivergence:   1507.63\n",
      "variational_beta * kldivergence:  0.15076\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35405\n",
      "kldivergence:   1546.12\n",
      "variational_beta * kldivergence:  0.15461\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33669\n",
      "kldivergence:   1458.32\n",
      "variational_beta * kldivergence:  0.14583\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29674\n",
      "kldivergence:   1575.49\n",
      "variational_beta * kldivergence:  0.15755\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36150\n",
      "kldivergence:   1697.61\n",
      "variational_beta * kldivergence:  0.16976\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31277\n",
      "kldivergence:   1641.44\n",
      "variational_beta * kldivergence:  0.16414\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35419\n",
      "kldivergence:   2096.08\n",
      "variational_beta * kldivergence:  0.20961\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34486\n",
      "kldivergence:   1496.45\n",
      "variational_beta * kldivergence:  0.14965\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32876\n",
      "kldivergence:   2014.83\n",
      "variational_beta * kldivergence:  0.20148\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35298\n",
      "kldivergence:   1567.72\n",
      "variational_beta * kldivergence:  0.15677\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31727\n",
      "kldivergence:   1763.94\n",
      "variational_beta * kldivergence:  0.17639\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33638\n",
      "kldivergence:   1415.54\n",
      "variational_beta * kldivergence:  0.14155\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29042\n",
      "kldivergence:   1492.75\n",
      "variational_beta * kldivergence:  0.14928\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28206\n",
      "kldivergence:   1380.89\n",
      "variational_beta * kldivergence:  0.13809\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35928\n",
      "kldivergence:   1634.22\n",
      "variational_beta * kldivergence:  0.16342\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35189\n",
      "kldivergence:   1651.92\n",
      "variational_beta * kldivergence:  0.16519\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29789\n",
      "kldivergence:   1613.92\n",
      "variational_beta * kldivergence:  0.16139\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35251\n",
      "kldivergence:   1565.90\n",
      "variational_beta * kldivergence:  0.15659\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30879\n",
      "kldivergence:   1580.68\n",
      "variational_beta * kldivergence:  0.15807\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29701\n",
      "kldivergence:   1338.15\n",
      "variational_beta * kldivergence:  0.13381\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.25855\n",
      "kldivergence:   1283.74\n",
      "variational_beta * kldivergence:  0.12837\n",
      "batch accuracy: 91.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32963\n",
      "kldivergence:   1406.65\n",
      "variational_beta * kldivergence:  0.14066\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34829\n",
      "kldivergence:   1474.69\n",
      "variational_beta * kldivergence:  0.14747\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35599\n",
      "kldivergence:   1416.40\n",
      "variational_beta * kldivergence:  0.14164\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32528\n",
      "kldivergence:   1477.70\n",
      "variational_beta * kldivergence:  0.14777\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31283\n",
      "kldivergence:   1413.70\n",
      "variational_beta * kldivergence:  0.14137\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33991\n",
      "kldivergence:   1535.57\n",
      "variational_beta * kldivergence:  0.15356\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.41486\n",
      "kldivergence:   1658.59\n",
      "variational_beta * kldivergence:  0.16586\n",
      "batch accuracy: 85.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35392\n",
      "kldivergence:   1645.04\n",
      "variational_beta * kldivergence:  0.16450\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.39847\n",
      "kldivergence:   1690.24\n",
      "variational_beta * kldivergence:  0.16902\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.40541\n",
      "kldivergence:   1886.41\n",
      "variational_beta * kldivergence:  0.18864\n",
      "batch accuracy: 86.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30645\n",
      "kldivergence:   1457.22\n",
      "variational_beta * kldivergence:  0.14572\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36940\n",
      "kldivergence:   1742.51\n",
      "variational_beta * kldivergence:  0.17425\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30886\n",
      "kldivergence:   1388.90\n",
      "variational_beta * kldivergence:  0.13889\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29240\n",
      "kldivergence:   1421.30\n",
      "variational_beta * kldivergence:  0.14213\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36079\n",
      "kldivergence:   1602.30\n",
      "variational_beta * kldivergence:  0.16023\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33464\n",
      "kldivergence:   1523.01\n",
      "variational_beta * kldivergence:  0.15230\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30432\n",
      "kldivergence:   1441.93\n",
      "variational_beta * kldivergence:  0.14419\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32584\n",
      "kldivergence:   1790.45\n",
      "variational_beta * kldivergence:  0.17905\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29262\n",
      "kldivergence:   1367.33\n",
      "variational_beta * kldivergence:  0.13673\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29526\n",
      "kldivergence:   1397.00\n",
      "variational_beta * kldivergence:  0.13970\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30307\n",
      "kldivergence:   1787.62\n",
      "variational_beta * kldivergence:  0.17876\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28312\n",
      "kldivergence:   1513.51\n",
      "variational_beta * kldivergence:  0.15135\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33402\n",
      "kldivergence:   1683.18\n",
      "variational_beta * kldivergence:  0.16832\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35358\n",
      "kldivergence:   1515.15\n",
      "variational_beta * kldivergence:  0.15152\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36863\n",
      "kldivergence:   1938.51\n",
      "variational_beta * kldivergence:  0.19385\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36019\n",
      "kldivergence:   1727.03\n",
      "variational_beta * kldivergence:  0.17270\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35950\n",
      "kldivergence:   1538.18\n",
      "variational_beta * kldivergence:  0.15382\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33781\n",
      "kldivergence:   1608.82\n",
      "variational_beta * kldivergence:  0.16088\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32083\n",
      "kldivergence:   1637.80\n",
      "variational_beta * kldivergence:  0.16378\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35904\n",
      "kldivergence:   1784.30\n",
      "variational_beta * kldivergence:  0.17843\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34646\n",
      "kldivergence:   1516.55\n",
      "variational_beta * kldivergence:  0.15166\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30953\n",
      "kldivergence:   1443.69\n",
      "variational_beta * kldivergence:  0.14437\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34393\n",
      "kldivergence:   1486.19\n",
      "variational_beta * kldivergence:  0.14862\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32821\n",
      "kldivergence:   1435.22\n",
      "variational_beta * kldivergence:  0.14352\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35263\n",
      "kldivergence:   1486.79\n",
      "variational_beta * kldivergence:  0.14868\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29591\n",
      "kldivergence:   1535.46\n",
      "variational_beta * kldivergence:  0.15355\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.26881\n",
      "kldivergence:   1552.52\n",
      "variational_beta * kldivergence:  0.15525\n",
      "batch accuracy: 90.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.36401\n",
      "kldivergence:   1438.64\n",
      "variational_beta * kldivergence:  0.14386\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32049\n",
      "kldivergence:   1453.98\n",
      "variational_beta * kldivergence:  0.14540\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28129\n",
      "kldivergence:   1386.40\n",
      "variational_beta * kldivergence:  0.13864\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35023\n",
      "kldivergence:   1497.26\n",
      "variational_beta * kldivergence:  0.14973\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29969\n",
      "kldivergence:   1556.00\n",
      "variational_beta * kldivergence:  0.15560\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33303\n",
      "kldivergence:   1405.45\n",
      "variational_beta * kldivergence:  0.14055\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29475\n",
      "kldivergence:   1258.77\n",
      "variational_beta * kldivergence:  0.12588\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.28495\n",
      "kldivergence:   1563.88\n",
      "variational_beta * kldivergence:  0.15639\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.38392\n",
      "kldivergence:   1499.72\n",
      "variational_beta * kldivergence:  0.14997\n",
      "batch accuracy: 87.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31766\n",
      "kldivergence:   1549.02\n",
      "variational_beta * kldivergence:  0.15490\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34203\n",
      "kldivergence:   1548.06\n",
      "variational_beta * kldivergence:  0.15481\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30113\n",
      "kldivergence:   1691.52\n",
      "variational_beta * kldivergence:  0.16915\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.39260\n",
      "kldivergence:   1500.46\n",
      "variational_beta * kldivergence:  0.15005\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.34079\n",
      "kldivergence:   1384.63\n",
      "variational_beta * kldivergence:  0.13846\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.30430\n",
      "kldivergence:   1455.81\n",
      "variational_beta * kldivergence:  0.14558\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29890\n",
      "kldivergence:   1650.12\n",
      "variational_beta * kldivergence:  0.16501\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31523\n",
      "kldivergence:   1616.12\n",
      "variational_beta * kldivergence:  0.16161\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.31325\n",
      "kldivergence:   1516.80\n",
      "variational_beta * kldivergence:  0.15168\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29771\n",
      "kldivergence:   1494.06\n",
      "variational_beta * kldivergence:  0.14941\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.32624\n",
      "kldivergence:   1437.48\n",
      "variational_beta * kldivergence:  0.14375\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.26874\n",
      "kldivergence:   1387.40\n",
      "variational_beta * kldivergence:  0.13874\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.35237\n",
      "kldivergence:   1473.14\n",
      "variational_beta * kldivergence:  0.14731\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.29973\n",
      "kldivergence:   1281.43\n",
      "variational_beta * kldivergence:  0.12814\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #50\n",
      "reconstruction loss: 0.33949\n",
      "kldivergence:   1577.07\n",
      "variational_beta * kldivergence:  0.15771\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.41538\n",
      "kldivergence:   1400.98\n",
      "variational_beta * kldivergence:  0.14010\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.34299\n",
      "kldivergence:   1408.76\n",
      "variational_beta * kldivergence:  0.14088\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.43788\n",
      "kldivergence:   1463.35\n",
      "variational_beta * kldivergence:  0.14634\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.55433\n",
      "kldivergence:   1507.51\n",
      "variational_beta * kldivergence:  0.15075\n",
      "batch accuracy: 84.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.43017\n",
      "kldivergence:   1481.63\n",
      "variational_beta * kldivergence:  0.14816\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.46186\n",
      "kldivergence:   1581.36\n",
      "variational_beta * kldivergence:  0.15814\n",
      "batch accuracy: 85.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.55634\n",
      "kldivergence:   1533.78\n",
      "variational_beta * kldivergence:  0.15338\n",
      "batch accuracy: 83.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.37121\n",
      "kldivergence:   1181.82\n",
      "variational_beta * kldivergence:  0.11818\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.44490\n",
      "kldivergence:   1453.99\n",
      "variational_beta * kldivergence:  0.14540\n",
      "batch accuracy: 85.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.45180\n",
      "kldivergence:   1390.11\n",
      "variational_beta * kldivergence:  0.13901\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.42731\n",
      "kldivergence:   1408.47\n",
      "variational_beta * kldivergence:  0.14085\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.42587\n",
      "kldivergence:   1424.28\n",
      "variational_beta * kldivergence:  0.14243\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.41680\n",
      "kldivergence:   1324.93\n",
      "variational_beta * kldivergence:  0.13249\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.38252\n",
      "kldivergence:   1401.92\n",
      "variational_beta * kldivergence:  0.14019\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.49179\n",
      "kldivergence:   1468.84\n",
      "variational_beta * kldivergence:  0.14688\n",
      "batch accuracy: 85.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.44781\n",
      "kldivergence:   1352.43\n",
      "variational_beta * kldivergence:  0.13524\n",
      "batch accuracy: 86.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.45502\n",
      "kldivergence:   1460.95\n",
      "variational_beta * kldivergence:  0.14610\n",
      "batch accuracy: 85.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.50020\n",
      "kldivergence:   1450.96\n",
      "variational_beta * kldivergence:  0.14510\n",
      "batch accuracy: 85.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.50028\n",
      "kldivergence:   1518.39\n",
      "variational_beta * kldivergence:  0.15184\n",
      "batch accuracy: 85.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.57113\n",
      "kldivergence:   1531.46\n",
      "variational_beta * kldivergence:  0.15315\n",
      "batch accuracy: 83.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.39047\n",
      "kldivergence:   1356.49\n",
      "variational_beta * kldivergence:  0.13565\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.34825\n",
      "kldivergence:   1324.52\n",
      "variational_beta * kldivergence:  0.13245\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.49750\n",
      "kldivergence:   1556.43\n",
      "variational_beta * kldivergence:  0.15564\n",
      "batch accuracy: 85.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.41508\n",
      "kldivergence:   1452.23\n",
      "variational_beta * kldivergence:  0.14522\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.47435\n",
      "kldivergence:   1476.91\n",
      "variational_beta * kldivergence:  0.14769\n",
      "batch accuracy: 84.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.41353\n",
      "kldivergence:   1343.12\n",
      "variational_beta * kldivergence:  0.13431\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.46091\n",
      "kldivergence:   1419.19\n",
      "variational_beta * kldivergence:  0.14192\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.50414\n",
      "kldivergence:   1395.75\n",
      "variational_beta * kldivergence:  0.13957\n",
      "batch accuracy: 85.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.42410\n",
      "kldivergence:   1331.84\n",
      "variational_beta * kldivergence:  0.13318\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.48475\n",
      "kldivergence:   1478.91\n",
      "variational_beta * kldivergence:  0.14789\n",
      "batch accuracy: 85.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.43647\n",
      "kldivergence:   1405.82\n",
      "variational_beta * kldivergence:  0.14058\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.46652\n",
      "kldivergence:   1359.01\n",
      "variational_beta * kldivergence:  0.13590\n",
      "batch accuracy: 86.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.49327\n",
      "kldivergence:   1361.89\n",
      "variational_beta * kldivergence:  0.13619\n",
      "batch accuracy: 86.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.47847\n",
      "kldivergence:   1347.59\n",
      "variational_beta * kldivergence:  0.13476\n",
      "batch accuracy: 85.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.45965\n",
      "kldivergence:   1433.60\n",
      "variational_beta * kldivergence:  0.14336\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.41544\n",
      "kldivergence:   1417.26\n",
      "variational_beta * kldivergence:  0.14173\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.55117\n",
      "kldivergence:   1531.88\n",
      "variational_beta * kldivergence:  0.15319\n",
      "batch accuracy: 84.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.49554\n",
      "kldivergence:   1431.63\n",
      "variational_beta * kldivergence:  0.14316\n",
      "batch accuracy: 85.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.47348\n",
      "kldivergence:   1394.57\n",
      "variational_beta * kldivergence:  0.13946\n",
      "batch accuracy: 85.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.49473\n",
      "kldivergence:   1467.06\n",
      "variational_beta * kldivergence:  0.14671\n",
      "batch accuracy: 85.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.41180\n",
      "kldivergence:   1369.66\n",
      "variational_beta * kldivergence:  0.13697\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.43947\n",
      "kldivergence:   1386.20\n",
      "variational_beta * kldivergence:  0.13862\n",
      "batch accuracy: 85.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.47293\n",
      "kldivergence:   1363.07\n",
      "variational_beta * kldivergence:  0.13631\n",
      "batch accuracy: 86.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.46913\n",
      "kldivergence:   1458.47\n",
      "variational_beta * kldivergence:  0.14585\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.60658\n",
      "kldivergence:   1538.72\n",
      "variational_beta * kldivergence:  0.15387\n",
      "batch accuracy: 83.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.58174\n",
      "kldivergence:   1541.52\n",
      "variational_beta * kldivergence:  0.15415\n",
      "batch accuracy: 82.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.41963\n",
      "kldivergence:   1433.80\n",
      "variational_beta * kldivergence:  0.14338\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.58402\n",
      "kldivergence:   1478.43\n",
      "variational_beta * kldivergence:  0.14784\n",
      "batch accuracy: 82.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.57157\n",
      "kldivergence:   1508.79\n",
      "variational_beta * kldivergence:  0.15088\n",
      "batch accuracy: 83.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.48061\n",
      "kldivergence:   1588.25\n",
      "variational_beta * kldivergence:  0.15882\n",
      "batch accuracy: 85.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.42610\n",
      "kldivergence:   1339.06\n",
      "variational_beta * kldivergence:  0.13391\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.50080\n",
      "kldivergence:   1417.09\n",
      "variational_beta * kldivergence:  0.14171\n",
      "batch accuracy: 84.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.42671\n",
      "kldivergence:   1277.14\n",
      "variational_beta * kldivergence:  0.12771\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.40102\n",
      "kldivergence:   1367.55\n",
      "variational_beta * kldivergence:  0.13675\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.44392\n",
      "kldivergence:   1401.29\n",
      "variational_beta * kldivergence:  0.14013\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.45313\n",
      "kldivergence:   1431.68\n",
      "variational_beta * kldivergence:  0.14317\n",
      "batch accuracy: 86.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.48114\n",
      "kldivergence:   1461.85\n",
      "variational_beta * kldivergence:  0.14619\n",
      "batch accuracy: 85.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.39903\n",
      "kldivergence:   1395.94\n",
      "variational_beta * kldivergence:  0.13959\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.41357\n",
      "kldivergence:   1458.60\n",
      "variational_beta * kldivergence:  0.14586\n",
      "batch accuracy: 86.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.43817\n",
      "kldivergence:   1405.41\n",
      "variational_beta * kldivergence:  0.14054\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.44832\n",
      "kldivergence:   1537.18\n",
      "variational_beta * kldivergence:  0.15372\n",
      "batch accuracy: 85.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #50\n",
      "reconstruction loss: 0.38698\n",
      "kldivergence:   1417.41\n",
      "variational_beta * kldivergence:  0.14174\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "epoch # 50 : train loss is [178.16481702653763] and validation loss is [0.10102379610358352] \n",
      "Epoch [51 / 150] average reconstruction error: 0.480229\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31325\n",
      "kldivergence:   1451.93\n",
      "variational_beta * kldivergence:  0.14519\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37724\n",
      "kldivergence:   1889.59\n",
      "variational_beta * kldivergence:  0.18896\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35646\n",
      "kldivergence:   1558.88\n",
      "variational_beta * kldivergence:  0.15589\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27982\n",
      "kldivergence:   1315.02\n",
      "variational_beta * kldivergence:  0.13150\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31404\n",
      "kldivergence:   1368.57\n",
      "variational_beta * kldivergence:  0.13686\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33190\n",
      "kldivergence:   1365.03\n",
      "variational_beta * kldivergence:  0.13650\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37840\n",
      "kldivergence:   1696.33\n",
      "variational_beta * kldivergence:  0.16963\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27342\n",
      "kldivergence:   1458.14\n",
      "variational_beta * kldivergence:  0.14581\n",
      "batch accuracy: 90.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32257\n",
      "kldivergence:   1492.32\n",
      "variational_beta * kldivergence:  0.14923\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32907\n",
      "kldivergence:   1512.71\n",
      "variational_beta * kldivergence:  0.15127\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29738\n",
      "kldivergence:   1452.22\n",
      "variational_beta * kldivergence:  0.14522\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31188\n",
      "kldivergence:   1393.93\n",
      "variational_beta * kldivergence:  0.13939\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32820\n",
      "kldivergence:   1646.59\n",
      "variational_beta * kldivergence:  0.16466\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33940\n",
      "kldivergence:   1569.85\n",
      "variational_beta * kldivergence:  0.15698\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37283\n",
      "kldivergence:   1715.85\n",
      "variational_beta * kldivergence:  0.17159\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33380\n",
      "kldivergence:   1573.52\n",
      "variational_beta * kldivergence:  0.15735\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.39118\n",
      "kldivergence:   1770.54\n",
      "variational_beta * kldivergence:  0.17705\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31833\n",
      "kldivergence:   1436.82\n",
      "variational_beta * kldivergence:  0.14368\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32173\n",
      "kldivergence:   1517.66\n",
      "variational_beta * kldivergence:  0.15177\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.25807\n",
      "kldivergence:   1355.61\n",
      "variational_beta * kldivergence:  0.13556\n",
      "batch accuracy: 91.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33165\n",
      "kldivergence:   1834.71\n",
      "variational_beta * kldivergence:  0.18347\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34318\n",
      "kldivergence:   1683.35\n",
      "variational_beta * kldivergence:  0.16834\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.38173\n",
      "kldivergence:   1635.52\n",
      "variational_beta * kldivergence:  0.16355\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29311\n",
      "kldivergence:   1291.10\n",
      "variational_beta * kldivergence:  0.12911\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.39764\n",
      "kldivergence:   1527.54\n",
      "variational_beta * kldivergence:  0.15275\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35729\n",
      "kldivergence:   1483.43\n",
      "variational_beta * kldivergence:  0.14834\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36580\n",
      "kldivergence:   1467.41\n",
      "variational_beta * kldivergence:  0.14674\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32802\n",
      "kldivergence:   1348.41\n",
      "variational_beta * kldivergence:  0.13484\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34277\n",
      "kldivergence:   1412.50\n",
      "variational_beta * kldivergence:  0.14125\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35060\n",
      "kldivergence:   1482.88\n",
      "variational_beta * kldivergence:  0.14829\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28662\n",
      "kldivergence:   1479.56\n",
      "variational_beta * kldivergence:  0.14796\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32032\n",
      "kldivergence:   1475.31\n",
      "variational_beta * kldivergence:  0.14753\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35600\n",
      "kldivergence:   1523.69\n",
      "variational_beta * kldivergence:  0.15237\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31041\n",
      "kldivergence:   1412.46\n",
      "variational_beta * kldivergence:  0.14125\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31925\n",
      "kldivergence:   1299.08\n",
      "variational_beta * kldivergence:  0.12991\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29905\n",
      "kldivergence:   1406.29\n",
      "variational_beta * kldivergence:  0.14063\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28961\n",
      "kldivergence:   1292.77\n",
      "variational_beta * kldivergence:  0.12928\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32864\n",
      "kldivergence:   1757.83\n",
      "variational_beta * kldivergence:  0.17578\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28361\n",
      "kldivergence:   1398.02\n",
      "variational_beta * kldivergence:  0.13980\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31777\n",
      "kldivergence:   1468.01\n",
      "variational_beta * kldivergence:  0.14680\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.39190\n",
      "kldivergence:   1589.74\n",
      "variational_beta * kldivergence:  0.15897\n",
      "batch accuracy: 86.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28090\n",
      "kldivergence:   1613.06\n",
      "variational_beta * kldivergence:  0.16131\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29774\n",
      "kldivergence:   1334.03\n",
      "variational_beta * kldivergence:  0.13340\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.38743\n",
      "kldivergence:   1652.06\n",
      "variational_beta * kldivergence:  0.16521\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37329\n",
      "kldivergence:   1700.12\n",
      "variational_beta * kldivergence:  0.17001\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37102\n",
      "kldivergence:   1575.50\n",
      "variational_beta * kldivergence:  0.15755\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28054\n",
      "kldivergence:   1300.86\n",
      "variational_beta * kldivergence:  0.13009\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34864\n",
      "kldivergence:   1459.22\n",
      "variational_beta * kldivergence:  0.14592\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33337\n",
      "kldivergence:   1585.79\n",
      "variational_beta * kldivergence:  0.15858\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33647\n",
      "kldivergence:   1476.50\n",
      "variational_beta * kldivergence:  0.14765\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34436\n",
      "kldivergence:   1506.05\n",
      "variational_beta * kldivergence:  0.15061\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.38397\n",
      "kldivergence:   1526.97\n",
      "variational_beta * kldivergence:  0.15270\n",
      "batch accuracy: 87.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.38666\n",
      "kldivergence:   1633.46\n",
      "variational_beta * kldivergence:  0.16335\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27023\n",
      "kldivergence:   1355.01\n",
      "variational_beta * kldivergence:  0.13550\n",
      "batch accuracy: 91.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.43108\n",
      "kldivergence:   1662.69\n",
      "variational_beta * kldivergence:  0.16627\n",
      "batch accuracy: 85.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34171\n",
      "kldivergence:   1373.17\n",
      "variational_beta * kldivergence:  0.13732\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33567\n",
      "kldivergence:   1474.79\n",
      "variational_beta * kldivergence:  0.14748\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30340\n",
      "kldivergence:   1639.70\n",
      "variational_beta * kldivergence:  0.16397\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31525\n",
      "kldivergence:   1619.07\n",
      "variational_beta * kldivergence:  0.16191\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33122\n",
      "kldivergence:   1627.33\n",
      "variational_beta * kldivergence:  0.16273\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32727\n",
      "kldivergence:   1671.05\n",
      "variational_beta * kldivergence:  0.16710\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29326\n",
      "kldivergence:   1516.97\n",
      "variational_beta * kldivergence:  0.15170\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33685\n",
      "kldivergence:   1562.95\n",
      "variational_beta * kldivergence:  0.15630\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28552\n",
      "kldivergence:   1483.95\n",
      "variational_beta * kldivergence:  0.14840\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30483\n",
      "kldivergence:   1380.99\n",
      "variational_beta * kldivergence:  0.13810\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.25324\n",
      "kldivergence:   1258.48\n",
      "variational_beta * kldivergence:  0.12585\n",
      "batch accuracy: 91.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35906\n",
      "kldivergence:   1574.43\n",
      "variational_beta * kldivergence:  0.15744\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33601\n",
      "kldivergence:   1456.04\n",
      "variational_beta * kldivergence:  0.14560\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30535\n",
      "kldivergence:   1500.07\n",
      "variational_beta * kldivergence:  0.15001\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28121\n",
      "kldivergence:   1399.29\n",
      "variational_beta * kldivergence:  0.13993\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34812\n",
      "kldivergence:   1600.66\n",
      "variational_beta * kldivergence:  0.16007\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31376\n",
      "kldivergence:   1511.83\n",
      "variational_beta * kldivergence:  0.15118\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29515\n",
      "kldivergence:   1397.60\n",
      "variational_beta * kldivergence:  0.13976\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.25996\n",
      "kldivergence:   1327.51\n",
      "variational_beta * kldivergence:  0.13275\n",
      "batch accuracy: 91.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34932\n",
      "kldivergence:   1628.19\n",
      "variational_beta * kldivergence:  0.16282\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31370\n",
      "kldivergence:   1406.97\n",
      "variational_beta * kldivergence:  0.14070\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29577\n",
      "kldivergence:   1709.04\n",
      "variational_beta * kldivergence:  0.17090\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31731\n",
      "kldivergence:   1534.76\n",
      "variational_beta * kldivergence:  0.15348\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34315\n",
      "kldivergence:   1518.75\n",
      "variational_beta * kldivergence:  0.15188\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.25019\n",
      "kldivergence:   1397.81\n",
      "variational_beta * kldivergence:  0.13978\n",
      "batch accuracy: 91.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29023\n",
      "kldivergence:   1465.20\n",
      "variational_beta * kldivergence:  0.14652\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29930\n",
      "kldivergence:   1462.04\n",
      "variational_beta * kldivergence:  0.14620\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30473\n",
      "kldivergence:   2325.05\n",
      "variational_beta * kldivergence:  0.23251\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32273\n",
      "kldivergence:   1553.37\n",
      "variational_beta * kldivergence:  0.15534\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33824\n",
      "kldivergence:   1578.56\n",
      "variational_beta * kldivergence:  0.15786\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30054\n",
      "kldivergence:   1453.13\n",
      "variational_beta * kldivergence:  0.14531\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33150\n",
      "kldivergence:   1617.39\n",
      "variational_beta * kldivergence:  0.16174\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31661\n",
      "kldivergence:   1300.37\n",
      "variational_beta * kldivergence:  0.13004\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29347\n",
      "kldivergence:   1295.48\n",
      "variational_beta * kldivergence:  0.12955\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30955\n",
      "kldivergence:   1496.25\n",
      "variational_beta * kldivergence:  0.14962\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.26898\n",
      "kldivergence:   1448.79\n",
      "variational_beta * kldivergence:  0.14488\n",
      "batch accuracy: 91.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30753\n",
      "kldivergence:   1548.97\n",
      "variational_beta * kldivergence:  0.15490\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32406\n",
      "kldivergence:   1422.61\n",
      "variational_beta * kldivergence:  0.14226\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29197\n",
      "kldivergence:   1449.46\n",
      "variational_beta * kldivergence:  0.14495\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.26262\n",
      "kldivergence:   1230.90\n",
      "variational_beta * kldivergence:  0.12309\n",
      "batch accuracy: 91.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31216\n",
      "kldivergence:   1402.90\n",
      "variational_beta * kldivergence:  0.14029\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32619\n",
      "kldivergence:   1430.74\n",
      "variational_beta * kldivergence:  0.14307\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35245\n",
      "kldivergence:   1392.47\n",
      "variational_beta * kldivergence:  0.13925\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37305\n",
      "kldivergence:   1627.24\n",
      "variational_beta * kldivergence:  0.16272\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33336\n",
      "kldivergence:   1447.95\n",
      "variational_beta * kldivergence:  0.14480\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30058\n",
      "kldivergence:   1301.57\n",
      "variational_beta * kldivergence:  0.13016\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36500\n",
      "kldivergence:   1560.99\n",
      "variational_beta * kldivergence:  0.15610\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37815\n",
      "kldivergence:   1660.73\n",
      "variational_beta * kldivergence:  0.16607\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32575\n",
      "kldivergence:   1421.28\n",
      "variational_beta * kldivergence:  0.14213\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35353\n",
      "kldivergence:   1340.93\n",
      "variational_beta * kldivergence:  0.13409\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34488\n",
      "kldivergence:   1332.28\n",
      "variational_beta * kldivergence:  0.13323\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32552\n",
      "kldivergence:   1371.29\n",
      "variational_beta * kldivergence:  0.13713\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33105\n",
      "kldivergence:   1439.89\n",
      "variational_beta * kldivergence:  0.14399\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34686\n",
      "kldivergence:   1440.10\n",
      "variational_beta * kldivergence:  0.14401\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36110\n",
      "kldivergence:   1427.10\n",
      "variational_beta * kldivergence:  0.14271\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30061\n",
      "kldivergence:   1412.59\n",
      "variational_beta * kldivergence:  0.14126\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34798\n",
      "kldivergence:   1571.07\n",
      "variational_beta * kldivergence:  0.15711\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31147\n",
      "kldivergence:   1604.46\n",
      "variational_beta * kldivergence:  0.16045\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31727\n",
      "kldivergence:   1657.43\n",
      "variational_beta * kldivergence:  0.16574\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30050\n",
      "kldivergence:   1544.58\n",
      "variational_beta * kldivergence:  0.15446\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30339\n",
      "kldivergence:   2002.76\n",
      "variational_beta * kldivergence:  0.20028\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31865\n",
      "kldivergence:   1516.02\n",
      "variational_beta * kldivergence:  0.15160\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36113\n",
      "kldivergence:   1507.20\n",
      "variational_beta * kldivergence:  0.15072\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31407\n",
      "kldivergence:   1532.87\n",
      "variational_beta * kldivergence:  0.15329\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36178\n",
      "kldivergence:   1637.72\n",
      "variational_beta * kldivergence:  0.16377\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35669\n",
      "kldivergence:   1534.77\n",
      "variational_beta * kldivergence:  0.15348\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28595\n",
      "kldivergence:   1428.73\n",
      "variational_beta * kldivergence:  0.14287\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27923\n",
      "kldivergence:   1564.74\n",
      "variational_beta * kldivergence:  0.15647\n",
      "batch accuracy: 90.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28338\n",
      "kldivergence:   1298.11\n",
      "variational_beta * kldivergence:  0.12981\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29429\n",
      "kldivergence:   1434.54\n",
      "variational_beta * kldivergence:  0.14345\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31123\n",
      "kldivergence:   1826.62\n",
      "variational_beta * kldivergence:  0.18266\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30296\n",
      "kldivergence:   1493.50\n",
      "variational_beta * kldivergence:  0.14935\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35369\n",
      "kldivergence:   1490.25\n",
      "variational_beta * kldivergence:  0.14902\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36729\n",
      "kldivergence:   1628.24\n",
      "variational_beta * kldivergence:  0.16282\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33753\n",
      "kldivergence:   1535.51\n",
      "variational_beta * kldivergence:  0.15355\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31195\n",
      "kldivergence:   1258.17\n",
      "variational_beta * kldivergence:  0.12582\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36208\n",
      "kldivergence:   1751.43\n",
      "variational_beta * kldivergence:  0.17514\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29834\n",
      "kldivergence:   1330.39\n",
      "variational_beta * kldivergence:  0.13304\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35252\n",
      "kldivergence:   1510.07\n",
      "variational_beta * kldivergence:  0.15101\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29309\n",
      "kldivergence:   1227.61\n",
      "variational_beta * kldivergence:  0.12276\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31643\n",
      "kldivergence:   1622.26\n",
      "variational_beta * kldivergence:  0.16223\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32026\n",
      "kldivergence:   1602.87\n",
      "variational_beta * kldivergence:  0.16029\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31619\n",
      "kldivergence:   1399.73\n",
      "variational_beta * kldivergence:  0.13997\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30697\n",
      "kldivergence:   1460.21\n",
      "variational_beta * kldivergence:  0.14602\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36261\n",
      "kldivergence:   1590.83\n",
      "variational_beta * kldivergence:  0.15908\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32868\n",
      "kldivergence:   1355.10\n",
      "variational_beta * kldivergence:  0.13551\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30618\n",
      "kldivergence:   1422.52\n",
      "variational_beta * kldivergence:  0.14225\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34111\n",
      "kldivergence:   1452.47\n",
      "variational_beta * kldivergence:  0.14525\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30925\n",
      "kldivergence:   1306.89\n",
      "variational_beta * kldivergence:  0.13069\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33339\n",
      "kldivergence:   1500.34\n",
      "variational_beta * kldivergence:  0.15003\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33900\n",
      "kldivergence:   1447.85\n",
      "variational_beta * kldivergence:  0.14479\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35890\n",
      "kldivergence:   1571.95\n",
      "variational_beta * kldivergence:  0.15719\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35519\n",
      "kldivergence:   1693.45\n",
      "variational_beta * kldivergence:  0.16934\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37484\n",
      "kldivergence:   1646.40\n",
      "variational_beta * kldivergence:  0.16464\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30606\n",
      "kldivergence:   1444.44\n",
      "variational_beta * kldivergence:  0.14444\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.38617\n",
      "kldivergence:   1945.05\n",
      "variational_beta * kldivergence:  0.19450\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37480\n",
      "kldivergence:   1644.67\n",
      "variational_beta * kldivergence:  0.16447\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.39615\n",
      "kldivergence:   1348.25\n",
      "variational_beta * kldivergence:  0.13482\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37683\n",
      "kldivergence:   1786.50\n",
      "variational_beta * kldivergence:  0.17865\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33200\n",
      "kldivergence:   1409.06\n",
      "variational_beta * kldivergence:  0.14091\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29148\n",
      "kldivergence:   1274.87\n",
      "variational_beta * kldivergence:  0.12749\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34742\n",
      "kldivergence:   1650.97\n",
      "variational_beta * kldivergence:  0.16510\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36212\n",
      "kldivergence:   1475.03\n",
      "variational_beta * kldivergence:  0.14750\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33897\n",
      "kldivergence:   1514.82\n",
      "variational_beta * kldivergence:  0.15148\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31085\n",
      "kldivergence:   1455.16\n",
      "variational_beta * kldivergence:  0.14552\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27570\n",
      "kldivergence:   1294.13\n",
      "variational_beta * kldivergence:  0.12941\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37119\n",
      "kldivergence:   1653.80\n",
      "variational_beta * kldivergence:  0.16538\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29991\n",
      "kldivergence:   1297.53\n",
      "variational_beta * kldivergence:  0.12975\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33545\n",
      "kldivergence:   1549.63\n",
      "variational_beta * kldivergence:  0.15496\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30819\n",
      "kldivergence:   1445.21\n",
      "variational_beta * kldivergence:  0.14452\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33802\n",
      "kldivergence:   1565.50\n",
      "variational_beta * kldivergence:  0.15655\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34358\n",
      "kldivergence:   1529.84\n",
      "variational_beta * kldivergence:  0.15298\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35971\n",
      "kldivergence:   1565.15\n",
      "variational_beta * kldivergence:  0.15652\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32019\n",
      "kldivergence:   1463.64\n",
      "variational_beta * kldivergence:  0.14636\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32353\n",
      "kldivergence:   1515.82\n",
      "variational_beta * kldivergence:  0.15158\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27952\n",
      "kldivergence:   1307.33\n",
      "variational_beta * kldivergence:  0.13073\n",
      "batch accuracy: 90.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31234\n",
      "kldivergence:   1263.85\n",
      "variational_beta * kldivergence:  0.12639\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33650\n",
      "kldivergence:   1602.06\n",
      "variational_beta * kldivergence:  0.16021\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29554\n",
      "kldivergence:   1310.36\n",
      "variational_beta * kldivergence:  0.13104\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31221\n",
      "kldivergence:   1441.04\n",
      "variational_beta * kldivergence:  0.14410\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35288\n",
      "kldivergence:   1574.02\n",
      "variational_beta * kldivergence:  0.15740\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31421\n",
      "kldivergence:   1522.60\n",
      "variational_beta * kldivergence:  0.15226\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35589\n",
      "kldivergence:   1464.90\n",
      "variational_beta * kldivergence:  0.14649\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30207\n",
      "kldivergence:   1461.92\n",
      "variational_beta * kldivergence:  0.14619\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34782\n",
      "kldivergence:   1514.80\n",
      "variational_beta * kldivergence:  0.15148\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34014\n",
      "kldivergence:   1709.64\n",
      "variational_beta * kldivergence:  0.17096\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36016\n",
      "kldivergence:   1397.75\n",
      "variational_beta * kldivergence:  0.13977\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33045\n",
      "kldivergence:   1508.86\n",
      "variational_beta * kldivergence:  0.15089\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28941\n",
      "kldivergence:   1398.13\n",
      "variational_beta * kldivergence:  0.13981\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34945\n",
      "kldivergence:   1542.96\n",
      "variational_beta * kldivergence:  0.15430\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30887\n",
      "kldivergence:   1485.15\n",
      "variational_beta * kldivergence:  0.14852\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34527\n",
      "kldivergence:   1589.65\n",
      "variational_beta * kldivergence:  0.15896\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31025\n",
      "kldivergence:   1291.33\n",
      "variational_beta * kldivergence:  0.12913\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33227\n",
      "kldivergence:   1551.21\n",
      "variational_beta * kldivergence:  0.15512\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31212\n",
      "kldivergence:   1515.84\n",
      "variational_beta * kldivergence:  0.15158\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31358\n",
      "kldivergence:   1464.15\n",
      "variational_beta * kldivergence:  0.14641\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33410\n",
      "kldivergence:   1484.06\n",
      "variational_beta * kldivergence:  0.14841\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31078\n",
      "kldivergence:   1384.66\n",
      "variational_beta * kldivergence:  0.13847\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27195\n",
      "kldivergence:   1341.22\n",
      "variational_beta * kldivergence:  0.13412\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29609\n",
      "kldivergence:   1595.05\n",
      "variational_beta * kldivergence:  0.15951\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28738\n",
      "kldivergence:   1402.41\n",
      "variational_beta * kldivergence:  0.14024\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31561\n",
      "kldivergence:   1561.41\n",
      "variational_beta * kldivergence:  0.15614\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29559\n",
      "kldivergence:   1542.07\n",
      "variational_beta * kldivergence:  0.15421\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36279\n",
      "kldivergence:   1514.58\n",
      "variational_beta * kldivergence:  0.15146\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32846\n",
      "kldivergence:   1404.42\n",
      "variational_beta * kldivergence:  0.14044\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27626\n",
      "kldivergence:   1409.34\n",
      "variational_beta * kldivergence:  0.14093\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31350\n",
      "kldivergence:   1323.70\n",
      "variational_beta * kldivergence:  0.13237\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35035\n",
      "kldivergence:   1433.69\n",
      "variational_beta * kldivergence:  0.14337\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35152\n",
      "kldivergence:   1379.08\n",
      "variational_beta * kldivergence:  0.13791\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28007\n",
      "kldivergence:   1390.63\n",
      "variational_beta * kldivergence:  0.13906\n",
      "batch accuracy: 90.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30810\n",
      "kldivergence:   1584.56\n",
      "variational_beta * kldivergence:  0.15846\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35663\n",
      "kldivergence:   1507.76\n",
      "variational_beta * kldivergence:  0.15078\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33711\n",
      "kldivergence:   1755.13\n",
      "variational_beta * kldivergence:  0.17551\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31775\n",
      "kldivergence:   1478.16\n",
      "variational_beta * kldivergence:  0.14782\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33061\n",
      "kldivergence:   1421.21\n",
      "variational_beta * kldivergence:  0.14212\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28066\n",
      "kldivergence:   1434.73\n",
      "variational_beta * kldivergence:  0.14347\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30631\n",
      "kldivergence:   1491.59\n",
      "variational_beta * kldivergence:  0.14916\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32971\n",
      "kldivergence:   1588.68\n",
      "variational_beta * kldivergence:  0.15887\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35986\n",
      "kldivergence:   1629.94\n",
      "variational_beta * kldivergence:  0.16299\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34085\n",
      "kldivergence:   1526.05\n",
      "variational_beta * kldivergence:  0.15260\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31192\n",
      "kldivergence:   1473.94\n",
      "variational_beta * kldivergence:  0.14739\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31643\n",
      "kldivergence:   1577.30\n",
      "variational_beta * kldivergence:  0.15773\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34277\n",
      "kldivergence:   1946.55\n",
      "variational_beta * kldivergence:  0.19465\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29729\n",
      "kldivergence:   1508.78\n",
      "variational_beta * kldivergence:  0.15088\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35468\n",
      "kldivergence:   1522.29\n",
      "variational_beta * kldivergence:  0.15223\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.26945\n",
      "kldivergence:   1538.71\n",
      "variational_beta * kldivergence:  0.15387\n",
      "batch accuracy: 90.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31573\n",
      "kldivergence:   1555.91\n",
      "variational_beta * kldivergence:  0.15559\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37672\n",
      "kldivergence:   1574.93\n",
      "variational_beta * kldivergence:  0.15749\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34225\n",
      "kldivergence:   1512.89\n",
      "variational_beta * kldivergence:  0.15129\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31280\n",
      "kldivergence:   1469.46\n",
      "variational_beta * kldivergence:  0.14695\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31170\n",
      "kldivergence:   1381.80\n",
      "variational_beta * kldivergence:  0.13818\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34632\n",
      "kldivergence:   1633.34\n",
      "variational_beta * kldivergence:  0.16333\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31712\n",
      "kldivergence:   1434.94\n",
      "variational_beta * kldivergence:  0.14349\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35299\n",
      "kldivergence:   1638.83\n",
      "variational_beta * kldivergence:  0.16388\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34589\n",
      "kldivergence:   1541.31\n",
      "variational_beta * kldivergence:  0.15413\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34352\n",
      "kldivergence:   1692.19\n",
      "variational_beta * kldivergence:  0.16922\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31729\n",
      "kldivergence:   1460.22\n",
      "variational_beta * kldivergence:  0.14602\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28020\n",
      "kldivergence:   1395.86\n",
      "variational_beta * kldivergence:  0.13959\n",
      "batch accuracy: 90.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.38894\n",
      "kldivergence:   1584.81\n",
      "variational_beta * kldivergence:  0.15848\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34063\n",
      "kldivergence:   1851.85\n",
      "variational_beta * kldivergence:  0.18518\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30084\n",
      "kldivergence:   1326.43\n",
      "variational_beta * kldivergence:  0.13264\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27436\n",
      "kldivergence:   1249.86\n",
      "variational_beta * kldivergence:  0.12499\n",
      "batch accuracy: 91.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33841\n",
      "kldivergence:   1686.46\n",
      "variational_beta * kldivergence:  0.16865\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32615\n",
      "kldivergence:   1276.28\n",
      "variational_beta * kldivergence:  0.12763\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30967\n",
      "kldivergence:   1567.90\n",
      "variational_beta * kldivergence:  0.15679\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30530\n",
      "kldivergence:   1467.64\n",
      "variational_beta * kldivergence:  0.14676\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31817\n",
      "kldivergence:   1519.30\n",
      "variational_beta * kldivergence:  0.15193\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30528\n",
      "kldivergence:   1390.17\n",
      "variational_beta * kldivergence:  0.13902\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29678\n",
      "kldivergence:   1338.10\n",
      "variational_beta * kldivergence:  0.13381\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32941\n",
      "kldivergence:   1368.06\n",
      "variational_beta * kldivergence:  0.13681\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31457\n",
      "kldivergence:   1572.50\n",
      "variational_beta * kldivergence:  0.15725\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35128\n",
      "kldivergence:   1599.27\n",
      "variational_beta * kldivergence:  0.15993\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29167\n",
      "kldivergence:   1234.99\n",
      "variational_beta * kldivergence:  0.12350\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35886\n",
      "kldivergence:   1550.29\n",
      "variational_beta * kldivergence:  0.15503\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37336\n",
      "kldivergence:   1486.00\n",
      "variational_beta * kldivergence:  0.14860\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29740\n",
      "kldivergence:   1537.06\n",
      "variational_beta * kldivergence:  0.15371\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28346\n",
      "kldivergence:   1436.83\n",
      "variational_beta * kldivergence:  0.14368\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27402\n",
      "kldivergence:   1329.74\n",
      "variational_beta * kldivergence:  0.13297\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32039\n",
      "kldivergence:   1528.82\n",
      "variational_beta * kldivergence:  0.15288\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28546\n",
      "kldivergence:   1365.93\n",
      "variational_beta * kldivergence:  0.13659\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36565\n",
      "kldivergence:   1641.56\n",
      "variational_beta * kldivergence:  0.16416\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33642\n",
      "kldivergence:   1438.92\n",
      "variational_beta * kldivergence:  0.14389\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28612\n",
      "kldivergence:   1300.40\n",
      "variational_beta * kldivergence:  0.13004\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31902\n",
      "kldivergence:   1228.90\n",
      "variational_beta * kldivergence:  0.12289\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29822\n",
      "kldivergence:   1418.59\n",
      "variational_beta * kldivergence:  0.14186\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33214\n",
      "kldivergence:   1346.67\n",
      "variational_beta * kldivergence:  0.13467\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.26705\n",
      "kldivergence:   1302.31\n",
      "variational_beta * kldivergence:  0.13023\n",
      "batch accuracy: 90.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33770\n",
      "kldivergence:   1600.07\n",
      "variational_beta * kldivergence:  0.16001\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31131\n",
      "kldivergence:   1476.20\n",
      "variational_beta * kldivergence:  0.14762\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33641\n",
      "kldivergence:   1572.11\n",
      "variational_beta * kldivergence:  0.15721\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37758\n",
      "kldivergence:   1498.71\n",
      "variational_beta * kldivergence:  0.14987\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35311\n",
      "kldivergence:   1571.32\n",
      "variational_beta * kldivergence:  0.15713\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.38119\n",
      "kldivergence:   1719.75\n",
      "variational_beta * kldivergence:  0.17198\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30448\n",
      "kldivergence:   1403.60\n",
      "variational_beta * kldivergence:  0.14036\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32827\n",
      "kldivergence:   1755.73\n",
      "variational_beta * kldivergence:  0.17557\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28327\n",
      "kldivergence:   1444.30\n",
      "variational_beta * kldivergence:  0.14443\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.38963\n",
      "kldivergence:   1781.04\n",
      "variational_beta * kldivergence:  0.17810\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29352\n",
      "kldivergence:   1868.98\n",
      "variational_beta * kldivergence:  0.18690\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29238\n",
      "kldivergence:   1510.15\n",
      "variational_beta * kldivergence:  0.15101\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34306\n",
      "kldivergence:   1817.85\n",
      "variational_beta * kldivergence:  0.18179\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30820\n",
      "kldivergence:   1484.95\n",
      "variational_beta * kldivergence:  0.14850\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35030\n",
      "kldivergence:   1660.17\n",
      "variational_beta * kldivergence:  0.16602\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32304\n",
      "kldivergence:   1523.27\n",
      "variational_beta * kldivergence:  0.15233\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36272\n",
      "kldivergence:   1609.67\n",
      "variational_beta * kldivergence:  0.16097\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37551\n",
      "kldivergence:   1702.27\n",
      "variational_beta * kldivergence:  0.17023\n",
      "batch accuracy: 86.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30694\n",
      "kldivergence:   1497.19\n",
      "variational_beta * kldivergence:  0.14972\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28538\n",
      "kldivergence:   1426.46\n",
      "variational_beta * kldivergence:  0.14265\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37997\n",
      "kldivergence:   1648.46\n",
      "variational_beta * kldivergence:  0.16485\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34406\n",
      "kldivergence:   1597.49\n",
      "variational_beta * kldivergence:  0.15975\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36963\n",
      "kldivergence:   1525.32\n",
      "variational_beta * kldivergence:  0.15253\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29498\n",
      "kldivergence:   1410.77\n",
      "variational_beta * kldivergence:  0.14108\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31523\n",
      "kldivergence:   1471.43\n",
      "variational_beta * kldivergence:  0.14714\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31737\n",
      "kldivergence:   1631.01\n",
      "variational_beta * kldivergence:  0.16310\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34788\n",
      "kldivergence:   1514.57\n",
      "variational_beta * kldivergence:  0.15146\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31586\n",
      "kldivergence:   1491.32\n",
      "variational_beta * kldivergence:  0.14913\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35066\n",
      "kldivergence:   1535.56\n",
      "variational_beta * kldivergence:  0.15356\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36959\n",
      "kldivergence:   1563.66\n",
      "variational_beta * kldivergence:  0.15637\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29175\n",
      "kldivergence:   1353.77\n",
      "variational_beta * kldivergence:  0.13538\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35389\n",
      "kldivergence:   1618.70\n",
      "variational_beta * kldivergence:  0.16187\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33385\n",
      "kldivergence:   1465.62\n",
      "variational_beta * kldivergence:  0.14656\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35413\n",
      "kldivergence:   1530.28\n",
      "variational_beta * kldivergence:  0.15303\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37969\n",
      "kldivergence:   1562.59\n",
      "variational_beta * kldivergence:  0.15626\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29162\n",
      "kldivergence:   1410.41\n",
      "variational_beta * kldivergence:  0.14104\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35610\n",
      "kldivergence:   1652.86\n",
      "variational_beta * kldivergence:  0.16529\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29664\n",
      "kldivergence:   1384.86\n",
      "variational_beta * kldivergence:  0.13849\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34381\n",
      "kldivergence:   1552.80\n",
      "variational_beta * kldivergence:  0.15528\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34734\n",
      "kldivergence:   1678.59\n",
      "variational_beta * kldivergence:  0.16786\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33568\n",
      "kldivergence:   1673.43\n",
      "variational_beta * kldivergence:  0.16734\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30378\n",
      "kldivergence:   1652.69\n",
      "variational_beta * kldivergence:  0.16527\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30272\n",
      "kldivergence:   1456.14\n",
      "variational_beta * kldivergence:  0.14561\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32827\n",
      "kldivergence:   1587.47\n",
      "variational_beta * kldivergence:  0.15875\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36038\n",
      "kldivergence:   1693.58\n",
      "variational_beta * kldivergence:  0.16936\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32227\n",
      "kldivergence:   1599.99\n",
      "variational_beta * kldivergence:  0.16000\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36116\n",
      "kldivergence:   1683.27\n",
      "variational_beta * kldivergence:  0.16833\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31448\n",
      "kldivergence:   1829.39\n",
      "variational_beta * kldivergence:  0.18294\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30489\n",
      "kldivergence:   1549.91\n",
      "variational_beta * kldivergence:  0.15499\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37497\n",
      "kldivergence:   1713.51\n",
      "variational_beta * kldivergence:  0.17135\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28169\n",
      "kldivergence:   1651.82\n",
      "variational_beta * kldivergence:  0.16518\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35664\n",
      "kldivergence:   1646.05\n",
      "variational_beta * kldivergence:  0.16461\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32617\n",
      "kldivergence:   1832.63\n",
      "variational_beta * kldivergence:  0.18326\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32776\n",
      "kldivergence:   1758.43\n",
      "variational_beta * kldivergence:  0.17584\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34944\n",
      "kldivergence:   1649.79\n",
      "variational_beta * kldivergence:  0.16498\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31459\n",
      "kldivergence:   1837.87\n",
      "variational_beta * kldivergence:  0.18379\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29715\n",
      "kldivergence:   1386.05\n",
      "variational_beta * kldivergence:  0.13861\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29349\n",
      "kldivergence:   1652.65\n",
      "variational_beta * kldivergence:  0.16527\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31189\n",
      "kldivergence:   1632.55\n",
      "variational_beta * kldivergence:  0.16326\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36834\n",
      "kldivergence:   1841.87\n",
      "variational_beta * kldivergence:  0.18419\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.27745\n",
      "kldivergence:   1473.23\n",
      "variational_beta * kldivergence:  0.14732\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33149\n",
      "kldivergence:   1654.19\n",
      "variational_beta * kldivergence:  0.16542\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34063\n",
      "kldivergence:   1540.36\n",
      "variational_beta * kldivergence:  0.15404\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31492\n",
      "kldivergence:   1722.75\n",
      "variational_beta * kldivergence:  0.17227\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31635\n",
      "kldivergence:   1645.66\n",
      "variational_beta * kldivergence:  0.16457\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33439\n",
      "kldivergence:   1438.08\n",
      "variational_beta * kldivergence:  0.14381\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29115\n",
      "kldivergence:   1955.67\n",
      "variational_beta * kldivergence:  0.19557\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34108\n",
      "kldivergence:   1631.22\n",
      "variational_beta * kldivergence:  0.16312\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34258\n",
      "kldivergence:   1640.32\n",
      "variational_beta * kldivergence:  0.16403\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35171\n",
      "kldivergence:   1576.31\n",
      "variational_beta * kldivergence:  0.15763\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36754\n",
      "kldivergence:   1664.45\n",
      "variational_beta * kldivergence:  0.16645\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35389\n",
      "kldivergence:   1728.68\n",
      "variational_beta * kldivergence:  0.17287\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34030\n",
      "kldivergence:   1575.83\n",
      "variational_beta * kldivergence:  0.15758\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34318\n",
      "kldivergence:   1543.11\n",
      "variational_beta * kldivergence:  0.15431\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30510\n",
      "kldivergence:   1436.80\n",
      "variational_beta * kldivergence:  0.14368\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31890\n",
      "kldivergence:   1623.94\n",
      "variational_beta * kldivergence:  0.16239\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31055\n",
      "kldivergence:   1723.09\n",
      "variational_beta * kldivergence:  0.17231\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37657\n",
      "kldivergence:   1601.48\n",
      "variational_beta * kldivergence:  0.16015\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33358\n",
      "kldivergence:   1466.73\n",
      "variational_beta * kldivergence:  0.14667\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35425\n",
      "kldivergence:   1420.35\n",
      "variational_beta * kldivergence:  0.14203\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33231\n",
      "kldivergence:   1537.96\n",
      "variational_beta * kldivergence:  0.15380\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.37059\n",
      "kldivergence:   1643.25\n",
      "variational_beta * kldivergence:  0.16433\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35113\n",
      "kldivergence:   1506.90\n",
      "variational_beta * kldivergence:  0.15069\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31018\n",
      "kldivergence:   1820.09\n",
      "variational_beta * kldivergence:  0.18201\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.23773\n",
      "kldivergence:   1328.47\n",
      "variational_beta * kldivergence:  0.13285\n",
      "batch accuracy: 92.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34023\n",
      "kldivergence:   1609.50\n",
      "variational_beta * kldivergence:  0.16095\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32781\n",
      "kldivergence:   1333.24\n",
      "variational_beta * kldivergence:  0.13332\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31175\n",
      "kldivergence:   1536.17\n",
      "variational_beta * kldivergence:  0.15362\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31993\n",
      "kldivergence:   1779.13\n",
      "variational_beta * kldivergence:  0.17791\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34608\n",
      "kldivergence:   1938.17\n",
      "variational_beta * kldivergence:  0.19382\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31308\n",
      "kldivergence:   1574.77\n",
      "variational_beta * kldivergence:  0.15748\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36223\n",
      "kldivergence:   1729.11\n",
      "variational_beta * kldivergence:  0.17291\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34924\n",
      "kldivergence:   1528.61\n",
      "variational_beta * kldivergence:  0.15286\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.29326\n",
      "kldivergence:   1602.04\n",
      "variational_beta * kldivergence:  0.16020\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30079\n",
      "kldivergence:   1492.21\n",
      "variational_beta * kldivergence:  0.14922\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34869\n",
      "kldivergence:   1522.51\n",
      "variational_beta * kldivergence:  0.15225\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.39494\n",
      "kldivergence:   1872.81\n",
      "variational_beta * kldivergence:  0.18728\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30403\n",
      "kldivergence:   1471.38\n",
      "variational_beta * kldivergence:  0.14714\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32282\n",
      "kldivergence:   1533.66\n",
      "variational_beta * kldivergence:  0.15337\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32096\n",
      "kldivergence:   1440.50\n",
      "variational_beta * kldivergence:  0.14405\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.26399\n",
      "kldivergence:   1355.18\n",
      "variational_beta * kldivergence:  0.13552\n",
      "batch accuracy: 90.95\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.30688\n",
      "kldivergence:   1507.63\n",
      "variational_beta * kldivergence:  0.15076\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.35558\n",
      "kldivergence:   1537.00\n",
      "variational_beta * kldivergence:  0.15370\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.32596\n",
      "kldivergence:   1739.97\n",
      "variational_beta * kldivergence:  0.17400\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.33574\n",
      "kldivergence:   1389.81\n",
      "variational_beta * kldivergence:  0.13898\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.34317\n",
      "kldivergence:   1538.23\n",
      "variational_beta * kldivergence:  0.15382\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.31284\n",
      "kldivergence:   1561.95\n",
      "variational_beta * kldivergence:  0.15619\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.28943\n",
      "kldivergence:   1470.48\n",
      "variational_beta * kldivergence:  0.14705\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #51\n",
      "reconstruction loss: 0.36119\n",
      "kldivergence:   1396.17\n",
      "variational_beta * kldivergence:  0.13962\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.43583\n",
      "kldivergence:   1261.96\n",
      "variational_beta * kldivergence:  0.12620\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.55770\n",
      "kldivergence:   1594.61\n",
      "variational_beta * kldivergence:  0.15946\n",
      "batch accuracy: 83.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.44118\n",
      "kldivergence:   1478.08\n",
      "variational_beta * kldivergence:  0.14781\n",
      "batch accuracy: 86.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.44578\n",
      "kldivergence:   1455.30\n",
      "variational_beta * kldivergence:  0.14553\n",
      "batch accuracy: 86.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.58991\n",
      "kldivergence:   1536.64\n",
      "variational_beta * kldivergence:  0.15366\n",
      "batch accuracy: 84.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.42838\n",
      "kldivergence:   1353.96\n",
      "variational_beta * kldivergence:  0.13540\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.54074\n",
      "kldivergence:   1572.30\n",
      "variational_beta * kldivergence:  0.15723\n",
      "batch accuracy: 84.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.40163\n",
      "kldivergence:   1286.83\n",
      "variational_beta * kldivergence:  0.12868\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.55578\n",
      "kldivergence:   1498.00\n",
      "variational_beta * kldivergence:  0.14980\n",
      "batch accuracy: 83.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.43134\n",
      "kldivergence:   1298.70\n",
      "variational_beta * kldivergence:  0.12987\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.39779\n",
      "kldivergence:   1371.37\n",
      "variational_beta * kldivergence:  0.13714\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.50176\n",
      "kldivergence:   1359.85\n",
      "variational_beta * kldivergence:  0.13598\n",
      "batch accuracy: 84.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.57671\n",
      "kldivergence:   1455.20\n",
      "variational_beta * kldivergence:  0.14552\n",
      "batch accuracy: 83.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.50948\n",
      "kldivergence:   1555.53\n",
      "variational_beta * kldivergence:  0.15555\n",
      "batch accuracy: 84.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.45307\n",
      "kldivergence:   1485.86\n",
      "variational_beta * kldivergence:  0.14859\n",
      "batch accuracy: 85.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.54300\n",
      "kldivergence:   1480.20\n",
      "variational_beta * kldivergence:  0.14802\n",
      "batch accuracy: 83.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.42295\n",
      "kldivergence:   1313.35\n",
      "variational_beta * kldivergence:  0.13133\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.46945\n",
      "kldivergence:   1411.95\n",
      "variational_beta * kldivergence:  0.14120\n",
      "batch accuracy: 85.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.41237\n",
      "kldivergence:   1334.73\n",
      "variational_beta * kldivergence:  0.13347\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.37930\n",
      "kldivergence:   1379.16\n",
      "variational_beta * kldivergence:  0.13792\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.46953\n",
      "kldivergence:   1494.34\n",
      "variational_beta * kldivergence:  0.14943\n",
      "batch accuracy: 85.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.35844\n",
      "kldivergence:   1279.49\n",
      "variational_beta * kldivergence:  0.12795\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.46624\n",
      "kldivergence:   1448.62\n",
      "variational_beta * kldivergence:  0.14486\n",
      "batch accuracy: 85.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.38280\n",
      "kldivergence:   1356.75\n",
      "variational_beta * kldivergence:  0.13568\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.39295\n",
      "kldivergence:   1333.62\n",
      "variational_beta * kldivergence:  0.13336\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.39783\n",
      "kldivergence:   1418.94\n",
      "variational_beta * kldivergence:  0.14189\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.48914\n",
      "kldivergence:   1377.68\n",
      "variational_beta * kldivergence:  0.13777\n",
      "batch accuracy: 85.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.42969\n",
      "kldivergence:   1473.98\n",
      "variational_beta * kldivergence:  0.14740\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.47605\n",
      "kldivergence:   1417.64\n",
      "variational_beta * kldivergence:  0.14176\n",
      "batch accuracy: 86.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.47793\n",
      "kldivergence:   1491.13\n",
      "variational_beta * kldivergence:  0.14911\n",
      "batch accuracy: 85.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.45357\n",
      "kldivergence:   1518.69\n",
      "variational_beta * kldivergence:  0.15187\n",
      "batch accuracy: 86.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.50532\n",
      "kldivergence:   1483.16\n",
      "variational_beta * kldivergence:  0.14832\n",
      "batch accuracy: 84.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.49733\n",
      "kldivergence:   1612.31\n",
      "variational_beta * kldivergence:  0.16123\n",
      "batch accuracy: 84.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.31406\n",
      "kldivergence:   1204.40\n",
      "variational_beta * kldivergence:  0.12044\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.43323\n",
      "kldivergence:   1343.81\n",
      "variational_beta * kldivergence:  0.13438\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.51506\n",
      "kldivergence:   1437.02\n",
      "variational_beta * kldivergence:  0.14370\n",
      "batch accuracy: 84.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.39086\n",
      "kldivergence:   1382.91\n",
      "variational_beta * kldivergence:  0.13829\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.40051\n",
      "kldivergence:   1374.95\n",
      "variational_beta * kldivergence:  0.13750\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.48700\n",
      "kldivergence:   1529.87\n",
      "variational_beta * kldivergence:  0.15299\n",
      "batch accuracy: 85.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.41851\n",
      "kldivergence:   1469.54\n",
      "variational_beta * kldivergence:  0.14695\n",
      "batch accuracy: 86.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.39827\n",
      "kldivergence:   1478.57\n",
      "variational_beta * kldivergence:  0.14786\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.43348\n",
      "kldivergence:   1368.93\n",
      "variational_beta * kldivergence:  0.13689\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.40663\n",
      "kldivergence:   1243.07\n",
      "variational_beta * kldivergence:  0.12431\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.44347\n",
      "kldivergence:   1518.77\n",
      "variational_beta * kldivergence:  0.15188\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.41795\n",
      "kldivergence:   1386.11\n",
      "variational_beta * kldivergence:  0.13861\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.42290\n",
      "kldivergence:   1262.24\n",
      "variational_beta * kldivergence:  0.12622\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.34375\n",
      "kldivergence:   1427.50\n",
      "variational_beta * kldivergence:  0.14275\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.51120\n",
      "kldivergence:   1515.03\n",
      "variational_beta * kldivergence:  0.15150\n",
      "batch accuracy: 84.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.46408\n",
      "kldivergence:   1369.74\n",
      "variational_beta * kldivergence:  0.13697\n",
      "batch accuracy: 85.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.48234\n",
      "kldivergence:   1422.60\n",
      "variational_beta * kldivergence:  0.14226\n",
      "batch accuracy: 85.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.43942\n",
      "kldivergence:   1476.62\n",
      "variational_beta * kldivergence:  0.14766\n",
      "batch accuracy: 85.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.45281\n",
      "kldivergence:   1430.74\n",
      "variational_beta * kldivergence:  0.14307\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.50659\n",
      "kldivergence:   1582.77\n",
      "variational_beta * kldivergence:  0.15828\n",
      "batch accuracy: 84.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.42744\n",
      "kldivergence:   1374.01\n",
      "variational_beta * kldivergence:  0.13740\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.41795\n",
      "kldivergence:   1427.45\n",
      "variational_beta * kldivergence:  0.14275\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.54366\n",
      "kldivergence:   1545.04\n",
      "variational_beta * kldivergence:  0.15450\n",
      "batch accuracy: 83.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.41264\n",
      "kldivergence:   1376.22\n",
      "variational_beta * kldivergence:  0.13762\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.49535\n",
      "kldivergence:   1428.51\n",
      "variational_beta * kldivergence:  0.14285\n",
      "batch accuracy: 84.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.44905\n",
      "kldivergence:   1455.63\n",
      "variational_beta * kldivergence:  0.14556\n",
      "batch accuracy: 85.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.52794\n",
      "kldivergence:   1403.47\n",
      "variational_beta * kldivergence:  0.14035\n",
      "batch accuracy: 84.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.39316\n",
      "kldivergence:   1309.84\n",
      "variational_beta * kldivergence:  0.13098\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #51\n",
      "reconstruction loss: 0.51974\n",
      "kldivergence:   1543.48\n",
      "variational_beta * kldivergence:  0.15435\n",
      "batch accuracy: 83.69\n",
      "\n",
      "\n",
      "epoch # 51 : train loss is [178.22421140922285] and validation loss is [0.09997009524893725] \n",
      "saved samples\n",
      "Epoch [52 / 150] average reconstruction error: 0.480389\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.41972\n",
      "kldivergence:   1749.41\n",
      "variational_beta * kldivergence:  0.17494\n",
      "batch accuracy: 86.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30047\n",
      "kldivergence:   1531.57\n",
      "variational_beta * kldivergence:  0.15316\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31924\n",
      "kldivergence:   1289.83\n",
      "variational_beta * kldivergence:  0.12898\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31687\n",
      "kldivergence:   1469.73\n",
      "variational_beta * kldivergence:  0.14697\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28539\n",
      "kldivergence:   1474.48\n",
      "variational_beta * kldivergence:  0.14745\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38455\n",
      "kldivergence:   1650.29\n",
      "variational_beta * kldivergence:  0.16503\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33830\n",
      "kldivergence:   1418.76\n",
      "variational_beta * kldivergence:  0.14188\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30094\n",
      "kldivergence:   1451.14\n",
      "variational_beta * kldivergence:  0.14511\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33611\n",
      "kldivergence:   1519.22\n",
      "variational_beta * kldivergence:  0.15192\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31019\n",
      "kldivergence:   1517.84\n",
      "variational_beta * kldivergence:  0.15178\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32157\n",
      "kldivergence:   1463.66\n",
      "variational_beta * kldivergence:  0.14637\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30990\n",
      "kldivergence:   1415.82\n",
      "variational_beta * kldivergence:  0.14158\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33162\n",
      "kldivergence:   1568.18\n",
      "variational_beta * kldivergence:  0.15682\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38982\n",
      "kldivergence:   1333.22\n",
      "variational_beta * kldivergence:  0.13332\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34064\n",
      "kldivergence:   1462.73\n",
      "variational_beta * kldivergence:  0.14627\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32526\n",
      "kldivergence:   1668.75\n",
      "variational_beta * kldivergence:  0.16687\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31733\n",
      "kldivergence:   1440.02\n",
      "variational_beta * kldivergence:  0.14400\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32059\n",
      "kldivergence:   1509.64\n",
      "variational_beta * kldivergence:  0.15096\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38431\n",
      "kldivergence:   1801.86\n",
      "variational_beta * kldivergence:  0.18019\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33034\n",
      "kldivergence:   1580.12\n",
      "variational_beta * kldivergence:  0.15801\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35506\n",
      "kldivergence:   1533.97\n",
      "variational_beta * kldivergence:  0.15340\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30359\n",
      "kldivergence:   1580.10\n",
      "variational_beta * kldivergence:  0.15801\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30773\n",
      "kldivergence:   1534.61\n",
      "variational_beta * kldivergence:  0.15346\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28200\n",
      "kldivergence:   1663.86\n",
      "variational_beta * kldivergence:  0.16639\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37556\n",
      "kldivergence:   1632.00\n",
      "variational_beta * kldivergence:  0.16320\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34696\n",
      "kldivergence:   1666.29\n",
      "variational_beta * kldivergence:  0.16663\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34504\n",
      "kldivergence:   1546.34\n",
      "variational_beta * kldivergence:  0.15463\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29546\n",
      "kldivergence:   1553.30\n",
      "variational_beta * kldivergence:  0.15533\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33450\n",
      "kldivergence:   1631.46\n",
      "variational_beta * kldivergence:  0.16315\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30977\n",
      "kldivergence:   1442.30\n",
      "variational_beta * kldivergence:  0.14423\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36054\n",
      "kldivergence:   1369.34\n",
      "variational_beta * kldivergence:  0.13693\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33518\n",
      "kldivergence:   1637.33\n",
      "variational_beta * kldivergence:  0.16373\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36243\n",
      "kldivergence:   1637.18\n",
      "variational_beta * kldivergence:  0.16372\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.39285\n",
      "kldivergence:   1768.44\n",
      "variational_beta * kldivergence:  0.17684\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.40386\n",
      "kldivergence:   1800.82\n",
      "variational_beta * kldivergence:  0.18008\n",
      "batch accuracy: 86.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30471\n",
      "kldivergence:   1497.97\n",
      "variational_beta * kldivergence:  0.14980\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33741\n",
      "kldivergence:   1757.81\n",
      "variational_beta * kldivergence:  0.17578\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32068\n",
      "kldivergence:   1548.10\n",
      "variational_beta * kldivergence:  0.15481\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34744\n",
      "kldivergence:   1789.23\n",
      "variational_beta * kldivergence:  0.17892\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29246\n",
      "kldivergence:   1540.12\n",
      "variational_beta * kldivergence:  0.15401\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37065\n",
      "kldivergence:   1662.73\n",
      "variational_beta * kldivergence:  0.16627\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37625\n",
      "kldivergence:   1547.70\n",
      "variational_beta * kldivergence:  0.15477\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31542\n",
      "kldivergence:   1412.93\n",
      "variational_beta * kldivergence:  0.14129\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30968\n",
      "kldivergence:   1552.87\n",
      "variational_beta * kldivergence:  0.15529\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33588\n",
      "kldivergence:   1820.10\n",
      "variational_beta * kldivergence:  0.18201\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28314\n",
      "kldivergence:   1589.52\n",
      "variational_beta * kldivergence:  0.15895\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33733\n",
      "kldivergence:   1623.33\n",
      "variational_beta * kldivergence:  0.16233\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30721\n",
      "kldivergence:   1350.89\n",
      "variational_beta * kldivergence:  0.13509\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33514\n",
      "kldivergence:   1426.90\n",
      "variational_beta * kldivergence:  0.14269\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31995\n",
      "kldivergence:   1548.28\n",
      "variational_beta * kldivergence:  0.15483\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36006\n",
      "kldivergence:   1639.15\n",
      "variational_beta * kldivergence:  0.16391\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29522\n",
      "kldivergence:   1522.40\n",
      "variational_beta * kldivergence:  0.15224\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33660\n",
      "kldivergence:   1602.32\n",
      "variational_beta * kldivergence:  0.16023\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32160\n",
      "kldivergence:   1588.27\n",
      "variational_beta * kldivergence:  0.15883\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33692\n",
      "kldivergence:   1695.16\n",
      "variational_beta * kldivergence:  0.16952\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37305\n",
      "kldivergence:   1499.76\n",
      "variational_beta * kldivergence:  0.14998\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.39155\n",
      "kldivergence:   1731.33\n",
      "variational_beta * kldivergence:  0.17313\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36707\n",
      "kldivergence:   1420.58\n",
      "variational_beta * kldivergence:  0.14206\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32569\n",
      "kldivergence:   1508.92\n",
      "variational_beta * kldivergence:  0.15089\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31748\n",
      "kldivergence:   1328.86\n",
      "variational_beta * kldivergence:  0.13289\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31383\n",
      "kldivergence:   1517.73\n",
      "variational_beta * kldivergence:  0.15177\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31770\n",
      "kldivergence:   1659.60\n",
      "variational_beta * kldivergence:  0.16596\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32694\n",
      "kldivergence:   1522.81\n",
      "variational_beta * kldivergence:  0.15228\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34894\n",
      "kldivergence:   1956.92\n",
      "variational_beta * kldivergence:  0.19569\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28043\n",
      "kldivergence:   1483.88\n",
      "variational_beta * kldivergence:  0.14839\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34168\n",
      "kldivergence:   1516.25\n",
      "variational_beta * kldivergence:  0.15162\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31381\n",
      "kldivergence:   1475.01\n",
      "variational_beta * kldivergence:  0.14750\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29614\n",
      "kldivergence:   1830.24\n",
      "variational_beta * kldivergence:  0.18302\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31807\n",
      "kldivergence:   1691.53\n",
      "variational_beta * kldivergence:  0.16915\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34333\n",
      "kldivergence:   1612.98\n",
      "variational_beta * kldivergence:  0.16130\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33210\n",
      "kldivergence:   1456.43\n",
      "variational_beta * kldivergence:  0.14564\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32688\n",
      "kldivergence:   1478.70\n",
      "variational_beta * kldivergence:  0.14787\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32489\n",
      "kldivergence:   1589.96\n",
      "variational_beta * kldivergence:  0.15900\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32990\n",
      "kldivergence:   1513.44\n",
      "variational_beta * kldivergence:  0.15134\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32667\n",
      "kldivergence:   1594.12\n",
      "variational_beta * kldivergence:  0.15941\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.40806\n",
      "kldivergence:   1615.54\n",
      "variational_beta * kldivergence:  0.16155\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30224\n",
      "kldivergence:   1571.82\n",
      "variational_beta * kldivergence:  0.15718\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31817\n",
      "kldivergence:   1486.37\n",
      "variational_beta * kldivergence:  0.14864\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32010\n",
      "kldivergence:   1496.80\n",
      "variational_beta * kldivergence:  0.14968\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.24885\n",
      "kldivergence:   1347.87\n",
      "variational_beta * kldivergence:  0.13479\n",
      "batch accuracy: 91.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30978\n",
      "kldivergence:   1328.59\n",
      "variational_beta * kldivergence:  0.13286\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32548\n",
      "kldivergence:   1610.54\n",
      "variational_beta * kldivergence:  0.16105\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34131\n",
      "kldivergence:   1563.82\n",
      "variational_beta * kldivergence:  0.15638\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33109\n",
      "kldivergence:   1490.71\n",
      "variational_beta * kldivergence:  0.14907\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34827\n",
      "kldivergence:   1568.38\n",
      "variational_beta * kldivergence:  0.15684\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32777\n",
      "kldivergence:   1346.16\n",
      "variational_beta * kldivergence:  0.13462\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31834\n",
      "kldivergence:   1247.17\n",
      "variational_beta * kldivergence:  0.12472\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32707\n",
      "kldivergence:   1433.36\n",
      "variational_beta * kldivergence:  0.14334\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29860\n",
      "kldivergence:   1427.36\n",
      "variational_beta * kldivergence:  0.14274\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34471\n",
      "kldivergence:   1421.33\n",
      "variational_beta * kldivergence:  0.14213\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31227\n",
      "kldivergence:   1466.51\n",
      "variational_beta * kldivergence:  0.14665\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33902\n",
      "kldivergence:   1487.34\n",
      "variational_beta * kldivergence:  0.14873\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30826\n",
      "kldivergence:   1385.82\n",
      "variational_beta * kldivergence:  0.13858\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29119\n",
      "kldivergence:   1414.59\n",
      "variational_beta * kldivergence:  0.14146\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27921\n",
      "kldivergence:   1520.92\n",
      "variational_beta * kldivergence:  0.15209\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29417\n",
      "kldivergence:   1355.38\n",
      "variational_beta * kldivergence:  0.13554\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32291\n",
      "kldivergence:   1642.15\n",
      "variational_beta * kldivergence:  0.16421\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34057\n",
      "kldivergence:   1485.15\n",
      "variational_beta * kldivergence:  0.14851\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35776\n",
      "kldivergence:   1687.71\n",
      "variational_beta * kldivergence:  0.16877\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32809\n",
      "kldivergence:   1542.46\n",
      "variational_beta * kldivergence:  0.15425\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30068\n",
      "kldivergence:   1432.43\n",
      "variational_beta * kldivergence:  0.14324\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31296\n",
      "kldivergence:   1394.36\n",
      "variational_beta * kldivergence:  0.13944\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31625\n",
      "kldivergence:   1580.65\n",
      "variational_beta * kldivergence:  0.15807\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36268\n",
      "kldivergence:   1817.24\n",
      "variational_beta * kldivergence:  0.18172\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31615\n",
      "kldivergence:   1447.00\n",
      "variational_beta * kldivergence:  0.14470\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33149\n",
      "kldivergence:   1428.33\n",
      "variational_beta * kldivergence:  0.14283\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34478\n",
      "kldivergence:   1437.64\n",
      "variational_beta * kldivergence:  0.14376\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29317\n",
      "kldivergence:   1393.29\n",
      "variational_beta * kldivergence:  0.13933\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32053\n",
      "kldivergence:   1460.03\n",
      "variational_beta * kldivergence:  0.14600\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34938\n",
      "kldivergence:   1474.73\n",
      "variational_beta * kldivergence:  0.14747\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34219\n",
      "kldivergence:   1751.93\n",
      "variational_beta * kldivergence:  0.17519\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30979\n",
      "kldivergence:   1461.39\n",
      "variational_beta * kldivergence:  0.14614\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32323\n",
      "kldivergence:   1507.55\n",
      "variational_beta * kldivergence:  0.15075\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31121\n",
      "kldivergence:   1542.45\n",
      "variational_beta * kldivergence:  0.15424\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38053\n",
      "kldivergence:   1700.24\n",
      "variational_beta * kldivergence:  0.17002\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28065\n",
      "kldivergence:   1248.23\n",
      "variational_beta * kldivergence:  0.12482\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35221\n",
      "kldivergence:   1643.11\n",
      "variational_beta * kldivergence:  0.16431\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34339\n",
      "kldivergence:   1511.63\n",
      "variational_beta * kldivergence:  0.15116\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31275\n",
      "kldivergence:   1286.50\n",
      "variational_beta * kldivergence:  0.12865\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27645\n",
      "kldivergence:   1486.34\n",
      "variational_beta * kldivergence:  0.14863\n",
      "batch accuracy: 91.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27746\n",
      "kldivergence:   1466.62\n",
      "variational_beta * kldivergence:  0.14666\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32935\n",
      "kldivergence:   1683.98\n",
      "variational_beta * kldivergence:  0.16840\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33891\n",
      "kldivergence:   1865.81\n",
      "variational_beta * kldivergence:  0.18658\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33160\n",
      "kldivergence:   1499.37\n",
      "variational_beta * kldivergence:  0.14994\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35529\n",
      "kldivergence:   1517.90\n",
      "variational_beta * kldivergence:  0.15179\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36622\n",
      "kldivergence:   1522.99\n",
      "variational_beta * kldivergence:  0.15230\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32704\n",
      "kldivergence:   1543.60\n",
      "variational_beta * kldivergence:  0.15436\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38348\n",
      "kldivergence:   1665.23\n",
      "variational_beta * kldivergence:  0.16652\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31726\n",
      "kldivergence:   1408.04\n",
      "variational_beta * kldivergence:  0.14080\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31402\n",
      "kldivergence:   1490.00\n",
      "variational_beta * kldivergence:  0.14900\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38231\n",
      "kldivergence:   1533.57\n",
      "variational_beta * kldivergence:  0.15336\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28993\n",
      "kldivergence:   1283.13\n",
      "variational_beta * kldivergence:  0.12831\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30194\n",
      "kldivergence:   1400.92\n",
      "variational_beta * kldivergence:  0.14009\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31390\n",
      "kldivergence:   1687.40\n",
      "variational_beta * kldivergence:  0.16874\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35825\n",
      "kldivergence:   1649.08\n",
      "variational_beta * kldivergence:  0.16491\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33644\n",
      "kldivergence:   1463.98\n",
      "variational_beta * kldivergence:  0.14640\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34924\n",
      "kldivergence:   1424.60\n",
      "variational_beta * kldivergence:  0.14246\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33812\n",
      "kldivergence:   1537.56\n",
      "variational_beta * kldivergence:  0.15376\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33486\n",
      "kldivergence:   1573.51\n",
      "variational_beta * kldivergence:  0.15735\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29328\n",
      "kldivergence:   1360.89\n",
      "variational_beta * kldivergence:  0.13609\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33370\n",
      "kldivergence:   1715.50\n",
      "variational_beta * kldivergence:  0.17155\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.23732\n",
      "kldivergence:   1303.86\n",
      "variational_beta * kldivergence:  0.13039\n",
      "batch accuracy: 91.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27082\n",
      "kldivergence:   1355.39\n",
      "variational_beta * kldivergence:  0.13554\n",
      "batch accuracy: 91.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31277\n",
      "kldivergence:   1564.03\n",
      "variational_beta * kldivergence:  0.15640\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28602\n",
      "kldivergence:   1554.93\n",
      "variational_beta * kldivergence:  0.15549\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32221\n",
      "kldivergence:   1500.12\n",
      "variational_beta * kldivergence:  0.15001\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34314\n",
      "kldivergence:   1701.44\n",
      "variational_beta * kldivergence:  0.17014\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33210\n",
      "kldivergence:   1596.63\n",
      "variational_beta * kldivergence:  0.15966\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28211\n",
      "kldivergence:   1385.23\n",
      "variational_beta * kldivergence:  0.13852\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32168\n",
      "kldivergence:   1627.64\n",
      "variational_beta * kldivergence:  0.16276\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37858\n",
      "kldivergence:   1828.67\n",
      "variational_beta * kldivergence:  0.18287\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37066\n",
      "kldivergence:   1521.97\n",
      "variational_beta * kldivergence:  0.15220\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33150\n",
      "kldivergence:   1386.36\n",
      "variational_beta * kldivergence:  0.13864\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30135\n",
      "kldivergence:   1476.27\n",
      "variational_beta * kldivergence:  0.14763\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30836\n",
      "kldivergence:   1456.42\n",
      "variational_beta * kldivergence:  0.14564\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34053\n",
      "kldivergence:   1676.17\n",
      "variational_beta * kldivergence:  0.16762\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.26870\n",
      "kldivergence:   1246.02\n",
      "variational_beta * kldivergence:  0.12460\n",
      "batch accuracy: 91.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29971\n",
      "kldivergence:   1460.63\n",
      "variational_beta * kldivergence:  0.14606\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31723\n",
      "kldivergence:   1379.91\n",
      "variational_beta * kldivergence:  0.13799\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29401\n",
      "kldivergence:   1217.66\n",
      "variational_beta * kldivergence:  0.12177\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31268\n",
      "kldivergence:   1578.77\n",
      "variational_beta * kldivergence:  0.15788\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34401\n",
      "kldivergence:   1602.63\n",
      "variational_beta * kldivergence:  0.16026\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36306\n",
      "kldivergence:   1706.98\n",
      "variational_beta * kldivergence:  0.17070\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38942\n",
      "kldivergence:   1570.57\n",
      "variational_beta * kldivergence:  0.15706\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29955\n",
      "kldivergence:   1334.33\n",
      "variational_beta * kldivergence:  0.13343\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35958\n",
      "kldivergence:   1781.45\n",
      "variational_beta * kldivergence:  0.17815\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35902\n",
      "kldivergence:   1604.11\n",
      "variational_beta * kldivergence:  0.16041\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34521\n",
      "kldivergence:   1510.74\n",
      "variational_beta * kldivergence:  0.15107\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30369\n",
      "kldivergence:   1487.56\n",
      "variational_beta * kldivergence:  0.14876\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35226\n",
      "kldivergence:   1680.71\n",
      "variational_beta * kldivergence:  0.16807\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32993\n",
      "kldivergence:   1551.69\n",
      "variational_beta * kldivergence:  0.15517\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34430\n",
      "kldivergence:   1547.11\n",
      "variational_beta * kldivergence:  0.15471\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29842\n",
      "kldivergence:   1402.23\n",
      "variational_beta * kldivergence:  0.14022\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35752\n",
      "kldivergence:   1516.35\n",
      "variational_beta * kldivergence:  0.15164\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29598\n",
      "kldivergence:   1553.89\n",
      "variational_beta * kldivergence:  0.15539\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27820\n",
      "kldivergence:   1479.86\n",
      "variational_beta * kldivergence:  0.14799\n",
      "batch accuracy: 90.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35448\n",
      "kldivergence:   1426.04\n",
      "variational_beta * kldivergence:  0.14260\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38585\n",
      "kldivergence:   1874.52\n",
      "variational_beta * kldivergence:  0.18745\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31495\n",
      "kldivergence:   1448.41\n",
      "variational_beta * kldivergence:  0.14484\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.24537\n",
      "kldivergence:   1301.84\n",
      "variational_beta * kldivergence:  0.13018\n",
      "batch accuracy: 91.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28703\n",
      "kldivergence:   1546.85\n",
      "variational_beta * kldivergence:  0.15468\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33864\n",
      "kldivergence:   1371.25\n",
      "variational_beta * kldivergence:  0.13713\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28103\n",
      "kldivergence:   1549.24\n",
      "variational_beta * kldivergence:  0.15492\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27110\n",
      "kldivergence:   1715.42\n",
      "variational_beta * kldivergence:  0.17154\n",
      "batch accuracy: 90.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31528\n",
      "kldivergence:   1524.27\n",
      "variational_beta * kldivergence:  0.15243\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34617\n",
      "kldivergence:   1483.28\n",
      "variational_beta * kldivergence:  0.14833\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36704\n",
      "kldivergence:   1731.97\n",
      "variational_beta * kldivergence:  0.17320\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30931\n",
      "kldivergence:   1519.62\n",
      "variational_beta * kldivergence:  0.15196\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29319\n",
      "kldivergence:   1404.31\n",
      "variational_beta * kldivergence:  0.14043\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33429\n",
      "kldivergence:   1399.14\n",
      "variational_beta * kldivergence:  0.13991\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28526\n",
      "kldivergence:   1377.81\n",
      "variational_beta * kldivergence:  0.13778\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27641\n",
      "kldivergence:   1644.94\n",
      "variational_beta * kldivergence:  0.16449\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27897\n",
      "kldivergence:   1468.63\n",
      "variational_beta * kldivergence:  0.14686\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36526\n",
      "kldivergence:   1720.75\n",
      "variational_beta * kldivergence:  0.17208\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34494\n",
      "kldivergence:   1586.60\n",
      "variational_beta * kldivergence:  0.15866\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28606\n",
      "kldivergence:   1314.37\n",
      "variational_beta * kldivergence:  0.13144\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29740\n",
      "kldivergence:   1451.91\n",
      "variational_beta * kldivergence:  0.14519\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30312\n",
      "kldivergence:   1456.76\n",
      "variational_beta * kldivergence:  0.14568\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35217\n",
      "kldivergence:   1435.17\n",
      "variational_beta * kldivergence:  0.14352\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32884\n",
      "kldivergence:   1422.09\n",
      "variational_beta * kldivergence:  0.14221\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31913\n",
      "kldivergence:   1706.15\n",
      "variational_beta * kldivergence:  0.17062\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32043\n",
      "kldivergence:   1454.61\n",
      "variational_beta * kldivergence:  0.14546\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28262\n",
      "kldivergence:   1433.12\n",
      "variational_beta * kldivergence:  0.14331\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36700\n",
      "kldivergence:   1516.76\n",
      "variational_beta * kldivergence:  0.15168\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31118\n",
      "kldivergence:   1420.43\n",
      "variational_beta * kldivergence:  0.14204\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31534\n",
      "kldivergence:   1448.50\n",
      "variational_beta * kldivergence:  0.14485\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30003\n",
      "kldivergence:   1484.70\n",
      "variational_beta * kldivergence:  0.14847\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33015\n",
      "kldivergence:   1459.39\n",
      "variational_beta * kldivergence:  0.14594\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36321\n",
      "kldivergence:   1575.54\n",
      "variational_beta * kldivergence:  0.15755\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30675\n",
      "kldivergence:   1327.86\n",
      "variational_beta * kldivergence:  0.13279\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34806\n",
      "kldivergence:   1479.01\n",
      "variational_beta * kldivergence:  0.14790\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38071\n",
      "kldivergence:   1487.30\n",
      "variational_beta * kldivergence:  0.14873\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33364\n",
      "kldivergence:   1356.36\n",
      "variational_beta * kldivergence:  0.13564\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35476\n",
      "kldivergence:   1492.09\n",
      "variational_beta * kldivergence:  0.14921\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32198\n",
      "kldivergence:   1444.04\n",
      "variational_beta * kldivergence:  0.14440\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28041\n",
      "kldivergence:   1425.41\n",
      "variational_beta * kldivergence:  0.14254\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31905\n",
      "kldivergence:   1521.80\n",
      "variational_beta * kldivergence:  0.15218\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28842\n",
      "kldivergence:   1405.03\n",
      "variational_beta * kldivergence:  0.14050\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31367\n",
      "kldivergence:   1646.74\n",
      "variational_beta * kldivergence:  0.16467\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31110\n",
      "kldivergence:   1309.72\n",
      "variational_beta * kldivergence:  0.13097\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37276\n",
      "kldivergence:   1442.82\n",
      "variational_beta * kldivergence:  0.14428\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36040\n",
      "kldivergence:   1746.56\n",
      "variational_beta * kldivergence:  0.17466\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28773\n",
      "kldivergence:   1613.76\n",
      "variational_beta * kldivergence:  0.16138\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31734\n",
      "kldivergence:   1396.86\n",
      "variational_beta * kldivergence:  0.13969\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35987\n",
      "kldivergence:   1428.01\n",
      "variational_beta * kldivergence:  0.14280\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35790\n",
      "kldivergence:   1526.36\n",
      "variational_beta * kldivergence:  0.15264\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31563\n",
      "kldivergence:   1333.14\n",
      "variational_beta * kldivergence:  0.13331\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36445\n",
      "kldivergence:   1549.03\n",
      "variational_beta * kldivergence:  0.15490\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33461\n",
      "kldivergence:   1459.73\n",
      "variational_beta * kldivergence:  0.14597\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31587\n",
      "kldivergence:   1201.85\n",
      "variational_beta * kldivergence:  0.12019\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32218\n",
      "kldivergence:   1415.44\n",
      "variational_beta * kldivergence:  0.14154\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33007\n",
      "kldivergence:   1456.54\n",
      "variational_beta * kldivergence:  0.14565\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32721\n",
      "kldivergence:   1545.08\n",
      "variational_beta * kldivergence:  0.15451\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30211\n",
      "kldivergence:   1415.47\n",
      "variational_beta * kldivergence:  0.14155\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35384\n",
      "kldivergence:   1562.26\n",
      "variational_beta * kldivergence:  0.15623\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37533\n",
      "kldivergence:   1540.72\n",
      "variational_beta * kldivergence:  0.15407\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32494\n",
      "kldivergence:   1430.35\n",
      "variational_beta * kldivergence:  0.14304\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27957\n",
      "kldivergence:   1274.36\n",
      "variational_beta * kldivergence:  0.12744\n",
      "batch accuracy: 91.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37827\n",
      "kldivergence:   1663.02\n",
      "variational_beta * kldivergence:  0.16630\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34694\n",
      "kldivergence:   1510.24\n",
      "variational_beta * kldivergence:  0.15102\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34343\n",
      "kldivergence:   1590.81\n",
      "variational_beta * kldivergence:  0.15908\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33093\n",
      "kldivergence:   1514.75\n",
      "variational_beta * kldivergence:  0.15148\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35953\n",
      "kldivergence:   1448.34\n",
      "variational_beta * kldivergence:  0.14483\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31692\n",
      "kldivergence:   1511.26\n",
      "variational_beta * kldivergence:  0.15113\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34793\n",
      "kldivergence:   1669.14\n",
      "variational_beta * kldivergence:  0.16691\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32475\n",
      "kldivergence:   1331.60\n",
      "variational_beta * kldivergence:  0.13316\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34338\n",
      "kldivergence:   1736.24\n",
      "variational_beta * kldivergence:  0.17362\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33069\n",
      "kldivergence:   1528.35\n",
      "variational_beta * kldivergence:  0.15283\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33784\n",
      "kldivergence:   1586.13\n",
      "variational_beta * kldivergence:  0.15861\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30175\n",
      "kldivergence:   1647.05\n",
      "variational_beta * kldivergence:  0.16470\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30464\n",
      "kldivergence:   1672.98\n",
      "variational_beta * kldivergence:  0.16730\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31835\n",
      "kldivergence:   1542.25\n",
      "variational_beta * kldivergence:  0.15423\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.26113\n",
      "kldivergence:   1473.57\n",
      "variational_beta * kldivergence:  0.14736\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31442\n",
      "kldivergence:   1624.01\n",
      "variational_beta * kldivergence:  0.16240\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29500\n",
      "kldivergence:   1441.53\n",
      "variational_beta * kldivergence:  0.14415\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38522\n",
      "kldivergence:   1642.33\n",
      "variational_beta * kldivergence:  0.16423\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29551\n",
      "kldivergence:   1507.82\n",
      "variational_beta * kldivergence:  0.15078\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36785\n",
      "kldivergence:   1650.24\n",
      "variational_beta * kldivergence:  0.16502\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30844\n",
      "kldivergence:   1615.34\n",
      "variational_beta * kldivergence:  0.16153\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36058\n",
      "kldivergence:   1546.23\n",
      "variational_beta * kldivergence:  0.15462\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33929\n",
      "kldivergence:   1534.31\n",
      "variational_beta * kldivergence:  0.15343\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34041\n",
      "kldivergence:   1396.57\n",
      "variational_beta * kldivergence:  0.13966\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33549\n",
      "kldivergence:   1465.20\n",
      "variational_beta * kldivergence:  0.14652\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32217\n",
      "kldivergence:   1406.85\n",
      "variational_beta * kldivergence:  0.14068\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31792\n",
      "kldivergence:   1577.91\n",
      "variational_beta * kldivergence:  0.15779\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28106\n",
      "kldivergence:   1421.80\n",
      "variational_beta * kldivergence:  0.14218\n",
      "batch accuracy: 90.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32024\n",
      "kldivergence:   1510.61\n",
      "variational_beta * kldivergence:  0.15106\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36324\n",
      "kldivergence:   1664.35\n",
      "variational_beta * kldivergence:  0.16643\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30087\n",
      "kldivergence:   1460.21\n",
      "variational_beta * kldivergence:  0.14602\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36460\n",
      "kldivergence:   1515.80\n",
      "variational_beta * kldivergence:  0.15158\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37119\n",
      "kldivergence:   1714.55\n",
      "variational_beta * kldivergence:  0.17145\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33933\n",
      "kldivergence:   1686.43\n",
      "variational_beta * kldivergence:  0.16864\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.25106\n",
      "kldivergence:   1413.61\n",
      "variational_beta * kldivergence:  0.14136\n",
      "batch accuracy: 91.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.39945\n",
      "kldivergence:   1552.84\n",
      "variational_beta * kldivergence:  0.15528\n",
      "batch accuracy: 86.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29921\n",
      "kldivergence:   1461.50\n",
      "variational_beta * kldivergence:  0.14615\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29441\n",
      "kldivergence:   1430.11\n",
      "variational_beta * kldivergence:  0.14301\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28887\n",
      "kldivergence:   1658.37\n",
      "variational_beta * kldivergence:  0.16584\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27577\n",
      "kldivergence:   1774.13\n",
      "variational_beta * kldivergence:  0.17741\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29395\n",
      "kldivergence:   1536.71\n",
      "variational_beta * kldivergence:  0.15367\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31306\n",
      "kldivergence:   1423.70\n",
      "variational_beta * kldivergence:  0.14237\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31736\n",
      "kldivergence:   1643.21\n",
      "variational_beta * kldivergence:  0.16432\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31381\n",
      "kldivergence:   1470.24\n",
      "variational_beta * kldivergence:  0.14702\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31838\n",
      "kldivergence:   1659.17\n",
      "variational_beta * kldivergence:  0.16592\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31383\n",
      "kldivergence:   1743.79\n",
      "variational_beta * kldivergence:  0.17438\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29323\n",
      "kldivergence:   1939.01\n",
      "variational_beta * kldivergence:  0.19390\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32067\n",
      "kldivergence:   1662.07\n",
      "variational_beta * kldivergence:  0.16621\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28468\n",
      "kldivergence:   1339.10\n",
      "variational_beta * kldivergence:  0.13391\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33002\n",
      "kldivergence:   1522.36\n",
      "variational_beta * kldivergence:  0.15224\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27926\n",
      "kldivergence:   1314.21\n",
      "variational_beta * kldivergence:  0.13142\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28654\n",
      "kldivergence:   1476.76\n",
      "variational_beta * kldivergence:  0.14768\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29467\n",
      "kldivergence:   1428.32\n",
      "variational_beta * kldivergence:  0.14283\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36675\n",
      "kldivergence:   1557.69\n",
      "variational_beta * kldivergence:  0.15577\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36840\n",
      "kldivergence:   1466.28\n",
      "variational_beta * kldivergence:  0.14663\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30203\n",
      "kldivergence:   1682.71\n",
      "variational_beta * kldivergence:  0.16827\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36341\n",
      "kldivergence:   1467.61\n",
      "variational_beta * kldivergence:  0.14676\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32764\n",
      "kldivergence:   1522.68\n",
      "variational_beta * kldivergence:  0.15227\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32986\n",
      "kldivergence:   1472.64\n",
      "variational_beta * kldivergence:  0.14726\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37327\n",
      "kldivergence:   1975.31\n",
      "variational_beta * kldivergence:  0.19753\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31421\n",
      "kldivergence:   1453.36\n",
      "variational_beta * kldivergence:  0.14534\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34250\n",
      "kldivergence:   1542.24\n",
      "variational_beta * kldivergence:  0.15422\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29390\n",
      "kldivergence:   1461.63\n",
      "variational_beta * kldivergence:  0.14616\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30920\n",
      "kldivergence:   1618.87\n",
      "variational_beta * kldivergence:  0.16189\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35713\n",
      "kldivergence:   1543.68\n",
      "variational_beta * kldivergence:  0.15437\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.39983\n",
      "kldivergence:   1712.88\n",
      "variational_beta * kldivergence:  0.17129\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32911\n",
      "kldivergence:   1741.14\n",
      "variational_beta * kldivergence:  0.17411\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33409\n",
      "kldivergence:   1687.86\n",
      "variational_beta * kldivergence:  0.16879\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33295\n",
      "kldivergence:   1722.62\n",
      "variational_beta * kldivergence:  0.17226\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29241\n",
      "kldivergence:   1727.89\n",
      "variational_beta * kldivergence:  0.17279\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30789\n",
      "kldivergence:   1719.66\n",
      "variational_beta * kldivergence:  0.17197\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37299\n",
      "kldivergence:   1687.45\n",
      "variational_beta * kldivergence:  0.16874\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35322\n",
      "kldivergence:   1494.35\n",
      "variational_beta * kldivergence:  0.14944\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31357\n",
      "kldivergence:   1414.03\n",
      "variational_beta * kldivergence:  0.14140\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31501\n",
      "kldivergence:   1338.49\n",
      "variational_beta * kldivergence:  0.13385\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32598\n",
      "kldivergence:   1599.67\n",
      "variational_beta * kldivergence:  0.15997\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33733\n",
      "kldivergence:   1449.66\n",
      "variational_beta * kldivergence:  0.14497\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.40001\n",
      "kldivergence:   1578.01\n",
      "variational_beta * kldivergence:  0.15780\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33869\n",
      "kldivergence:   1633.62\n",
      "variational_beta * kldivergence:  0.16336\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30443\n",
      "kldivergence:   1619.64\n",
      "variational_beta * kldivergence:  0.16196\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36992\n",
      "kldivergence:   1800.58\n",
      "variational_beta * kldivergence:  0.18006\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.27935\n",
      "kldivergence:   1914.23\n",
      "variational_beta * kldivergence:  0.19142\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30089\n",
      "kldivergence:   1549.13\n",
      "variational_beta * kldivergence:  0.15491\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31811\n",
      "kldivergence:   1555.68\n",
      "variational_beta * kldivergence:  0.15557\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32530\n",
      "kldivergence:   1550.03\n",
      "variational_beta * kldivergence:  0.15500\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30743\n",
      "kldivergence:   1416.53\n",
      "variational_beta * kldivergence:  0.14165\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34757\n",
      "kldivergence:   1805.29\n",
      "variational_beta * kldivergence:  0.18053\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30122\n",
      "kldivergence:   1260.51\n",
      "variational_beta * kldivergence:  0.12605\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.23552\n",
      "kldivergence:   1674.86\n",
      "variational_beta * kldivergence:  0.16749\n",
      "batch accuracy: 92.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34824\n",
      "kldivergence:   1617.23\n",
      "variational_beta * kldivergence:  0.16172\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33748\n",
      "kldivergence:   1479.79\n",
      "variational_beta * kldivergence:  0.14798\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36071\n",
      "kldivergence:   1569.68\n",
      "variational_beta * kldivergence:  0.15697\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38276\n",
      "kldivergence:   1385.13\n",
      "variational_beta * kldivergence:  0.13851\n",
      "batch accuracy: 87.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35173\n",
      "kldivergence:   1468.89\n",
      "variational_beta * kldivergence:  0.14689\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31208\n",
      "kldivergence:   1304.83\n",
      "variational_beta * kldivergence:  0.13048\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30655\n",
      "kldivergence:   1335.74\n",
      "variational_beta * kldivergence:  0.13357\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30762\n",
      "kldivergence:   1323.28\n",
      "variational_beta * kldivergence:  0.13233\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28968\n",
      "kldivergence:   1321.60\n",
      "variational_beta * kldivergence:  0.13216\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37778\n",
      "kldivergence:   1528.42\n",
      "variational_beta * kldivergence:  0.15284\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31218\n",
      "kldivergence:   1552.60\n",
      "variational_beta * kldivergence:  0.15526\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30547\n",
      "kldivergence:   1443.01\n",
      "variational_beta * kldivergence:  0.14430\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.38401\n",
      "kldivergence:   1476.05\n",
      "variational_beta * kldivergence:  0.14761\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31815\n",
      "kldivergence:   1410.88\n",
      "variational_beta * kldivergence:  0.14109\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.28304\n",
      "kldivergence:   1350.62\n",
      "variational_beta * kldivergence:  0.13506\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34710\n",
      "kldivergence:   1398.62\n",
      "variational_beta * kldivergence:  0.13986\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37921\n",
      "kldivergence:   1536.35\n",
      "variational_beta * kldivergence:  0.15364\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35470\n",
      "kldivergence:   1540.58\n",
      "variational_beta * kldivergence:  0.15406\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31856\n",
      "kldivergence:   1548.33\n",
      "variational_beta * kldivergence:  0.15483\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33393\n",
      "kldivergence:   1585.45\n",
      "variational_beta * kldivergence:  0.15854\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32471\n",
      "kldivergence:   1543.26\n",
      "variational_beta * kldivergence:  0.15433\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35952\n",
      "kldivergence:   1649.87\n",
      "variational_beta * kldivergence:  0.16499\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30521\n",
      "kldivergence:   1521.22\n",
      "variational_beta * kldivergence:  0.15212\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33739\n",
      "kldivergence:   1515.39\n",
      "variational_beta * kldivergence:  0.15154\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30378\n",
      "kldivergence:   1500.32\n",
      "variational_beta * kldivergence:  0.15003\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33845\n",
      "kldivergence:   1513.73\n",
      "variational_beta * kldivergence:  0.15137\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.37452\n",
      "kldivergence:   1725.95\n",
      "variational_beta * kldivergence:  0.17259\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34793\n",
      "kldivergence:   1717.70\n",
      "variational_beta * kldivergence:  0.17177\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.30304\n",
      "kldivergence:   1445.81\n",
      "variational_beta * kldivergence:  0.14458\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31198\n",
      "kldivergence:   1447.70\n",
      "variational_beta * kldivergence:  0.14477\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29763\n",
      "kldivergence:   1490.77\n",
      "variational_beta * kldivergence:  0.14908\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34282\n",
      "kldivergence:   1570.40\n",
      "variational_beta * kldivergence:  0.15704\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34836\n",
      "kldivergence:   1497.44\n",
      "variational_beta * kldivergence:  0.14974\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32270\n",
      "kldivergence:   1446.57\n",
      "variational_beta * kldivergence:  0.14466\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.36181\n",
      "kldivergence:   1686.77\n",
      "variational_beta * kldivergence:  0.16868\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.31975\n",
      "kldivergence:   1522.79\n",
      "variational_beta * kldivergence:  0.15228\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32804\n",
      "kldivergence:   1408.58\n",
      "variational_beta * kldivergence:  0.14086\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34229\n",
      "kldivergence:   1735.97\n",
      "variational_beta * kldivergence:  0.17360\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.35579\n",
      "kldivergence:   1754.01\n",
      "variational_beta * kldivergence:  0.17540\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33395\n",
      "kldivergence:   1558.42\n",
      "variational_beta * kldivergence:  0.15584\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.33302\n",
      "kldivergence:   1560.55\n",
      "variational_beta * kldivergence:  0.15606\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.34522\n",
      "kldivergence:   1460.96\n",
      "variational_beta * kldivergence:  0.14610\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.29033\n",
      "kldivergence:   1574.99\n",
      "variational_beta * kldivergence:  0.15750\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #52\n",
      "reconstruction loss: 0.32495\n",
      "kldivergence:   1646.81\n",
      "variational_beta * kldivergence:  0.16468\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45687\n",
      "kldivergence:   1479.99\n",
      "variational_beta * kldivergence:  0.14800\n",
      "batch accuracy: 85.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.39543\n",
      "kldivergence:   1355.70\n",
      "variational_beta * kldivergence:  0.13557\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.37426\n",
      "kldivergence:   1338.08\n",
      "variational_beta * kldivergence:  0.13381\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45095\n",
      "kldivergence:   1466.26\n",
      "variational_beta * kldivergence:  0.14663\n",
      "batch accuracy: 86.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.47416\n",
      "kldivergence:   1389.94\n",
      "variational_beta * kldivergence:  0.13899\n",
      "batch accuracy: 86.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.36018\n",
      "kldivergence:   1323.98\n",
      "variational_beta * kldivergence:  0.13240\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.39797\n",
      "kldivergence:   1270.64\n",
      "variational_beta * kldivergence:  0.12706\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.47926\n",
      "kldivergence:   1506.84\n",
      "variational_beta * kldivergence:  0.15068\n",
      "batch accuracy: 84.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45764\n",
      "kldivergence:   1342.32\n",
      "variational_beta * kldivergence:  0.13423\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.44450\n",
      "kldivergence:   1472.12\n",
      "variational_beta * kldivergence:  0.14721\n",
      "batch accuracy: 85.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.46476\n",
      "kldivergence:   1394.42\n",
      "variational_beta * kldivergence:  0.13944\n",
      "batch accuracy: 85.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.52916\n",
      "kldivergence:   1459.19\n",
      "variational_beta * kldivergence:  0.14592\n",
      "batch accuracy: 84.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.46235\n",
      "kldivergence:   1457.68\n",
      "variational_beta * kldivergence:  0.14577\n",
      "batch accuracy: 86.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.44341\n",
      "kldivergence:   1379.14\n",
      "variational_beta * kldivergence:  0.13791\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.47395\n",
      "kldivergence:   1357.74\n",
      "variational_beta * kldivergence:  0.13577\n",
      "batch accuracy: 85.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.42989\n",
      "kldivergence:   1294.32\n",
      "variational_beta * kldivergence:  0.12943\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45484\n",
      "kldivergence:   1438.50\n",
      "variational_beta * kldivergence:  0.14385\n",
      "batch accuracy: 85.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45302\n",
      "kldivergence:   1407.75\n",
      "variational_beta * kldivergence:  0.14078\n",
      "batch accuracy: 85.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.37541\n",
      "kldivergence:   1260.18\n",
      "variational_beta * kldivergence:  0.12602\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.46929\n",
      "kldivergence:   1476.51\n",
      "variational_beta * kldivergence:  0.14765\n",
      "batch accuracy: 85.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.37727\n",
      "kldivergence:   1318.18\n",
      "variational_beta * kldivergence:  0.13182\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.44706\n",
      "kldivergence:   1512.93\n",
      "variational_beta * kldivergence:  0.15129\n",
      "batch accuracy: 85.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45361\n",
      "kldivergence:   1383.28\n",
      "variational_beta * kldivergence:  0.13833\n",
      "batch accuracy: 85.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.49165\n",
      "kldivergence:   1454.54\n",
      "variational_beta * kldivergence:  0.14545\n",
      "batch accuracy: 85.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.41260\n",
      "kldivergence:   1442.63\n",
      "variational_beta * kldivergence:  0.14426\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.51537\n",
      "kldivergence:   1640.32\n",
      "variational_beta * kldivergence:  0.16403\n",
      "batch accuracy: 83.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.42677\n",
      "kldivergence:   1487.41\n",
      "variational_beta * kldivergence:  0.14874\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.50640\n",
      "kldivergence:   1450.41\n",
      "variational_beta * kldivergence:  0.14504\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.38951\n",
      "kldivergence:   1337.81\n",
      "variational_beta * kldivergence:  0.13378\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.43826\n",
      "kldivergence:   1349.60\n",
      "variational_beta * kldivergence:  0.13496\n",
      "batch accuracy: 86.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.55291\n",
      "kldivergence:   1548.72\n",
      "variational_beta * kldivergence:  0.15487\n",
      "batch accuracy: 83.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45242\n",
      "kldivergence:   1395.81\n",
      "variational_beta * kldivergence:  0.13958\n",
      "batch accuracy: 86.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.47833\n",
      "kldivergence:   1441.53\n",
      "variational_beta * kldivergence:  0.14415\n",
      "batch accuracy: 85.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45068\n",
      "kldivergence:   1428.85\n",
      "variational_beta * kldivergence:  0.14288\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.42502\n",
      "kldivergence:   1364.29\n",
      "variational_beta * kldivergence:  0.13643\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.41725\n",
      "kldivergence:   1305.21\n",
      "variational_beta * kldivergence:  0.13052\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.40506\n",
      "kldivergence:   1341.44\n",
      "variational_beta * kldivergence:  0.13414\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.57072\n",
      "kldivergence:   1584.23\n",
      "variational_beta * kldivergence:  0.15842\n",
      "batch accuracy: 83.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45252\n",
      "kldivergence:   1359.94\n",
      "variational_beta * kldivergence:  0.13599\n",
      "batch accuracy: 86.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.33315\n",
      "kldivergence:   1261.50\n",
      "variational_beta * kldivergence:  0.12615\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.39180\n",
      "kldivergence:   1490.27\n",
      "variational_beta * kldivergence:  0.14903\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.46933\n",
      "kldivergence:   1392.61\n",
      "variational_beta * kldivergence:  0.13926\n",
      "batch accuracy: 86.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.41271\n",
      "kldivergence:   1385.79\n",
      "variational_beta * kldivergence:  0.13858\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45497\n",
      "kldivergence:   1413.56\n",
      "variational_beta * kldivergence:  0.14136\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.44034\n",
      "kldivergence:   1346.40\n",
      "variational_beta * kldivergence:  0.13464\n",
      "batch accuracy: 85.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.55998\n",
      "kldivergence:   1445.56\n",
      "variational_beta * kldivergence:  0.14456\n",
      "batch accuracy: 82.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45642\n",
      "kldivergence:   1436.12\n",
      "variational_beta * kldivergence:  0.14361\n",
      "batch accuracy: 85.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.49993\n",
      "kldivergence:   1464.27\n",
      "variational_beta * kldivergence:  0.14643\n",
      "batch accuracy: 84.24\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.46033\n",
      "kldivergence:   1417.24\n",
      "variational_beta * kldivergence:  0.14172\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.46464\n",
      "kldivergence:   1404.06\n",
      "variational_beta * kldivergence:  0.14041\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.38112\n",
      "kldivergence:   1347.07\n",
      "variational_beta * kldivergence:  0.13471\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.46550\n",
      "kldivergence:   1410.02\n",
      "variational_beta * kldivergence:  0.14100\n",
      "batch accuracy: 85.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.45449\n",
      "kldivergence:   1426.64\n",
      "variational_beta * kldivergence:  0.14266\n",
      "batch accuracy: 85.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.63972\n",
      "kldivergence:   1536.55\n",
      "variational_beta * kldivergence:  0.15365\n",
      "batch accuracy: 81.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.43155\n",
      "kldivergence:   1429.73\n",
      "variational_beta * kldivergence:  0.14297\n",
      "batch accuracy: 86.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.47494\n",
      "kldivergence:   1528.56\n",
      "variational_beta * kldivergence:  0.15286\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.36545\n",
      "kldivergence:   1288.82\n",
      "variational_beta * kldivergence:  0.12888\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.37598\n",
      "kldivergence:   1247.91\n",
      "variational_beta * kldivergence:  0.12479\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.49840\n",
      "kldivergence:   1528.20\n",
      "variational_beta * kldivergence:  0.15282\n",
      "batch accuracy: 84.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.49851\n",
      "kldivergence:   1485.25\n",
      "variational_beta * kldivergence:  0.14852\n",
      "batch accuracy: 85.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.51349\n",
      "kldivergence:   1455.77\n",
      "variational_beta * kldivergence:  0.14558\n",
      "batch accuracy: 85.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #52\n",
      "reconstruction loss: 0.43997\n",
      "kldivergence:   1429.64\n",
      "variational_beta * kldivergence:  0.14296\n",
      "batch accuracy: 86.12\n",
      "\n",
      "\n",
      "epoch # 52 : train loss is [178.61310688564754] and validation loss is [0.09933262844637268] \n",
      "Epoch [53 / 150] average reconstruction error: 0.481437\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30047\n",
      "kldivergence:   1445.80\n",
      "variational_beta * kldivergence:  0.14458\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30160\n",
      "kldivergence:   1923.92\n",
      "variational_beta * kldivergence:  0.19239\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35322\n",
      "kldivergence:   1624.35\n",
      "variational_beta * kldivergence:  0.16243\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30977\n",
      "kldivergence:   1539.55\n",
      "variational_beta * kldivergence:  0.15395\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33065\n",
      "kldivergence:   1577.81\n",
      "variational_beta * kldivergence:  0.15778\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35329\n",
      "kldivergence:   1614.89\n",
      "variational_beta * kldivergence:  0.16149\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.38305\n",
      "kldivergence:   1624.63\n",
      "variational_beta * kldivergence:  0.16246\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33688\n",
      "kldivergence:   1409.48\n",
      "variational_beta * kldivergence:  0.14095\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32490\n",
      "kldivergence:   1327.44\n",
      "variational_beta * kldivergence:  0.13274\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.37014\n",
      "kldivergence:   1576.06\n",
      "variational_beta * kldivergence:  0.15761\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32810\n",
      "kldivergence:   1443.98\n",
      "variational_beta * kldivergence:  0.14440\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32969\n",
      "kldivergence:   1436.22\n",
      "variational_beta * kldivergence:  0.14362\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.25503\n",
      "kldivergence:   1266.19\n",
      "variational_beta * kldivergence:  0.12662\n",
      "batch accuracy: 91.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34968\n",
      "kldivergence:   1383.21\n",
      "variational_beta * kldivergence:  0.13832\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32863\n",
      "kldivergence:   1449.63\n",
      "variational_beta * kldivergence:  0.14496\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31894\n",
      "kldivergence:   1425.02\n",
      "variational_beta * kldivergence:  0.14250\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36299\n",
      "kldivergence:   1557.56\n",
      "variational_beta * kldivergence:  0.15576\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36893\n",
      "kldivergence:   1594.37\n",
      "variational_beta * kldivergence:  0.15944\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32526\n",
      "kldivergence:   1476.65\n",
      "variational_beta * kldivergence:  0.14767\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29649\n",
      "kldivergence:   1392.28\n",
      "variational_beta * kldivergence:  0.13923\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29585\n",
      "kldivergence:   1360.73\n",
      "variational_beta * kldivergence:  0.13607\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30872\n",
      "kldivergence:   1418.96\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35262\n",
      "kldivergence:   1691.76\n",
      "variational_beta * kldivergence:  0.16918\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29147\n",
      "kldivergence:   1360.64\n",
      "variational_beta * kldivergence:  0.13606\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36131\n",
      "kldivergence:   1822.65\n",
      "variational_beta * kldivergence:  0.18227\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34549\n",
      "kldivergence:   1767.02\n",
      "variational_beta * kldivergence:  0.17670\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27294\n",
      "kldivergence:   1379.67\n",
      "variational_beta * kldivergence:  0.13797\n",
      "batch accuracy: 90.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32922\n",
      "kldivergence:   1586.51\n",
      "variational_beta * kldivergence:  0.15865\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30361\n",
      "kldivergence:   1401.02\n",
      "variational_beta * kldivergence:  0.14010\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32657\n",
      "kldivergence:   1536.93\n",
      "variational_beta * kldivergence:  0.15369\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32268\n",
      "kldivergence:   1525.11\n",
      "variational_beta * kldivergence:  0.15251\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31090\n",
      "kldivergence:   1332.42\n",
      "variational_beta * kldivergence:  0.13324\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.38640\n",
      "kldivergence:   1661.28\n",
      "variational_beta * kldivergence:  0.16613\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32781\n",
      "kldivergence:   1413.28\n",
      "variational_beta * kldivergence:  0.14133\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34162\n",
      "kldivergence:   1464.02\n",
      "variational_beta * kldivergence:  0.14640\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33344\n",
      "kldivergence:   1747.09\n",
      "variational_beta * kldivergence:  0.17471\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33276\n",
      "kldivergence:   1511.91\n",
      "variational_beta * kldivergence:  0.15119\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29157\n",
      "kldivergence:   1727.28\n",
      "variational_beta * kldivergence:  0.17273\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35517\n",
      "kldivergence:   1492.09\n",
      "variational_beta * kldivergence:  0.14921\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28152\n",
      "kldivergence:   1450.12\n",
      "variational_beta * kldivergence:  0.14501\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32951\n",
      "kldivergence:   1524.15\n",
      "variational_beta * kldivergence:  0.15242\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.26556\n",
      "kldivergence:   1541.08\n",
      "variational_beta * kldivergence:  0.15411\n",
      "batch accuracy: 91.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29323\n",
      "kldivergence:   1336.46\n",
      "variational_beta * kldivergence:  0.13365\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33656\n",
      "kldivergence:   1565.38\n",
      "variational_beta * kldivergence:  0.15654\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30479\n",
      "kldivergence:   1332.42\n",
      "variational_beta * kldivergence:  0.13324\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33669\n",
      "kldivergence:   1381.99\n",
      "variational_beta * kldivergence:  0.13820\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34035\n",
      "kldivergence:   1567.44\n",
      "variational_beta * kldivergence:  0.15674\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32906\n",
      "kldivergence:   1496.47\n",
      "variational_beta * kldivergence:  0.14965\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33788\n",
      "kldivergence:   1511.31\n",
      "variational_beta * kldivergence:  0.15113\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31537\n",
      "kldivergence:   1520.20\n",
      "variational_beta * kldivergence:  0.15202\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.37816\n",
      "kldivergence:   1574.96\n",
      "variational_beta * kldivergence:  0.15750\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.41794\n",
      "kldivergence:   1797.24\n",
      "variational_beta * kldivergence:  0.17972\n",
      "batch accuracy: 85.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30790\n",
      "kldivergence:   1681.43\n",
      "variational_beta * kldivergence:  0.16814\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29530\n",
      "kldivergence:   1404.20\n",
      "variational_beta * kldivergence:  0.14042\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.26259\n",
      "kldivergence:   1367.62\n",
      "variational_beta * kldivergence:  0.13676\n",
      "batch accuracy: 91.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29181\n",
      "kldivergence:   1466.40\n",
      "variational_beta * kldivergence:  0.14664\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35416\n",
      "kldivergence:   1624.06\n",
      "variational_beta * kldivergence:  0.16241\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33166\n",
      "kldivergence:   1542.79\n",
      "variational_beta * kldivergence:  0.15428\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31943\n",
      "kldivergence:   1543.63\n",
      "variational_beta * kldivergence:  0.15436\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33739\n",
      "kldivergence:   1537.80\n",
      "variational_beta * kldivergence:  0.15378\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34836\n",
      "kldivergence:   1585.33\n",
      "variational_beta * kldivergence:  0.15853\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31976\n",
      "kldivergence:   1555.09\n",
      "variational_beta * kldivergence:  0.15551\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33208\n",
      "kldivergence:   1482.84\n",
      "variational_beta * kldivergence:  0.14828\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29073\n",
      "kldivergence:   1346.90\n",
      "variational_beta * kldivergence:  0.13469\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30799\n",
      "kldivergence:   1667.72\n",
      "variational_beta * kldivergence:  0.16677\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34892\n",
      "kldivergence:   1674.13\n",
      "variational_beta * kldivergence:  0.16741\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36834\n",
      "kldivergence:   1625.59\n",
      "variational_beta * kldivergence:  0.16256\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36918\n",
      "kldivergence:   1682.93\n",
      "variational_beta * kldivergence:  0.16829\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.38415\n",
      "kldivergence:   1443.77\n",
      "variational_beta * kldivergence:  0.14438\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34326\n",
      "kldivergence:   1481.38\n",
      "variational_beta * kldivergence:  0.14814\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33844\n",
      "kldivergence:   1429.54\n",
      "variational_beta * kldivergence:  0.14295\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31018\n",
      "kldivergence:   1539.32\n",
      "variational_beta * kldivergence:  0.15393\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35931\n",
      "kldivergence:   1552.53\n",
      "variational_beta * kldivergence:  0.15525\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35953\n",
      "kldivergence:   1638.22\n",
      "variational_beta * kldivergence:  0.16382\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31428\n",
      "kldivergence:   1549.31\n",
      "variational_beta * kldivergence:  0.15493\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29271\n",
      "kldivergence:   1425.94\n",
      "variational_beta * kldivergence:  0.14259\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27567\n",
      "kldivergence:   1469.73\n",
      "variational_beta * kldivergence:  0.14697\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32078\n",
      "kldivergence:   1394.22\n",
      "variational_beta * kldivergence:  0.13942\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32406\n",
      "kldivergence:   1465.26\n",
      "variational_beta * kldivergence:  0.14653\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27709\n",
      "kldivergence:   1315.93\n",
      "variational_beta * kldivergence:  0.13159\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30649\n",
      "kldivergence:   1341.52\n",
      "variational_beta * kldivergence:  0.13415\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32791\n",
      "kldivergence:   1531.95\n",
      "variational_beta * kldivergence:  0.15320\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30475\n",
      "kldivergence:   1564.31\n",
      "variational_beta * kldivergence:  0.15643\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32384\n",
      "kldivergence:   1549.97\n",
      "variational_beta * kldivergence:  0.15500\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35693\n",
      "kldivergence:   1555.42\n",
      "variational_beta * kldivergence:  0.15554\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29193\n",
      "kldivergence:   1468.19\n",
      "variational_beta * kldivergence:  0.14682\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31492\n",
      "kldivergence:   1699.15\n",
      "variational_beta * kldivergence:  0.16992\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31818\n",
      "kldivergence:   1381.85\n",
      "variational_beta * kldivergence:  0.13819\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35240\n",
      "kldivergence:   1388.17\n",
      "variational_beta * kldivergence:  0.13882\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31761\n",
      "kldivergence:   1458.43\n",
      "variational_beta * kldivergence:  0.14584\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32424\n",
      "kldivergence:   1437.25\n",
      "variational_beta * kldivergence:  0.14372\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34178\n",
      "kldivergence:   1506.85\n",
      "variational_beta * kldivergence:  0.15068\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27427\n",
      "kldivergence:   1480.75\n",
      "variational_beta * kldivergence:  0.14808\n",
      "batch accuracy: 91.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28225\n",
      "kldivergence:   1448.41\n",
      "variational_beta * kldivergence:  0.14484\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34095\n",
      "kldivergence:   1464.86\n",
      "variational_beta * kldivergence:  0.14649\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34739\n",
      "kldivergence:   1509.15\n",
      "variational_beta * kldivergence:  0.15092\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30210\n",
      "kldivergence:   1279.11\n",
      "variational_beta * kldivergence:  0.12791\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34558\n",
      "kldivergence:   1544.40\n",
      "variational_beta * kldivergence:  0.15444\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36145\n",
      "kldivergence:   1482.68\n",
      "variational_beta * kldivergence:  0.14827\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35585\n",
      "kldivergence:   1527.77\n",
      "variational_beta * kldivergence:  0.15278\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27219\n",
      "kldivergence:   1338.39\n",
      "variational_beta * kldivergence:  0.13384\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30920\n",
      "kldivergence:   1701.02\n",
      "variational_beta * kldivergence:  0.17010\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31389\n",
      "kldivergence:   1557.50\n",
      "variational_beta * kldivergence:  0.15575\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29815\n",
      "kldivergence:   1372.33\n",
      "variational_beta * kldivergence:  0.13723\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29801\n",
      "kldivergence:   1416.75\n",
      "variational_beta * kldivergence:  0.14168\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30674\n",
      "kldivergence:   1457.58\n",
      "variational_beta * kldivergence:  0.14576\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36317\n",
      "kldivergence:   1560.70\n",
      "variational_beta * kldivergence:  0.15607\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36075\n",
      "kldivergence:   1452.95\n",
      "variational_beta * kldivergence:  0.14529\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29517\n",
      "kldivergence:   1501.85\n",
      "variational_beta * kldivergence:  0.15019\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32070\n",
      "kldivergence:   1597.24\n",
      "variational_beta * kldivergence:  0.15972\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33518\n",
      "kldivergence:   1532.44\n",
      "variational_beta * kldivergence:  0.15324\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31059\n",
      "kldivergence:   1549.90\n",
      "variational_beta * kldivergence:  0.15499\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34119\n",
      "kldivergence:   1603.54\n",
      "variational_beta * kldivergence:  0.16035\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33249\n",
      "kldivergence:   1575.05\n",
      "variational_beta * kldivergence:  0.15750\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27751\n",
      "kldivergence:   1565.61\n",
      "variational_beta * kldivergence:  0.15656\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29220\n",
      "kldivergence:   1599.35\n",
      "variational_beta * kldivergence:  0.15993\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34564\n",
      "kldivergence:   1641.19\n",
      "variational_beta * kldivergence:  0.16412\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.25635\n",
      "kldivergence:   1328.55\n",
      "variational_beta * kldivergence:  0.13285\n",
      "batch accuracy: 91.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30633\n",
      "kldivergence:   1449.49\n",
      "variational_beta * kldivergence:  0.14495\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32101\n",
      "kldivergence:   1427.34\n",
      "variational_beta * kldivergence:  0.14273\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30690\n",
      "kldivergence:   1496.57\n",
      "variational_beta * kldivergence:  0.14966\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29955\n",
      "kldivergence:   1571.97\n",
      "variational_beta * kldivergence:  0.15720\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34302\n",
      "kldivergence:   1482.38\n",
      "variational_beta * kldivergence:  0.14824\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29510\n",
      "kldivergence:   1350.08\n",
      "variational_beta * kldivergence:  0.13501\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33741\n",
      "kldivergence:   1470.18\n",
      "variational_beta * kldivergence:  0.14702\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33203\n",
      "kldivergence:   1701.58\n",
      "variational_beta * kldivergence:  0.17016\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29968\n",
      "kldivergence:   1486.50\n",
      "variational_beta * kldivergence:  0.14865\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32387\n",
      "kldivergence:   1528.82\n",
      "variational_beta * kldivergence:  0.15288\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31713\n",
      "kldivergence:   1555.92\n",
      "variational_beta * kldivergence:  0.15559\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31528\n",
      "kldivergence:   1366.63\n",
      "variational_beta * kldivergence:  0.13666\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32375\n",
      "kldivergence:   1362.72\n",
      "variational_beta * kldivergence:  0.13627\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28923\n",
      "kldivergence:   1359.37\n",
      "variational_beta * kldivergence:  0.13594\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28921\n",
      "kldivergence:   1380.77\n",
      "variational_beta * kldivergence:  0.13808\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33048\n",
      "kldivergence:   1292.44\n",
      "variational_beta * kldivergence:  0.12924\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34919\n",
      "kldivergence:   1393.17\n",
      "variational_beta * kldivergence:  0.13932\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32186\n",
      "kldivergence:   1621.10\n",
      "variational_beta * kldivergence:  0.16211\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35507\n",
      "kldivergence:   1401.29\n",
      "variational_beta * kldivergence:  0.14013\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33705\n",
      "kldivergence:   1529.86\n",
      "variational_beta * kldivergence:  0.15299\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33860\n",
      "kldivergence:   1530.88\n",
      "variational_beta * kldivergence:  0.15309\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27936\n",
      "kldivergence:   1445.70\n",
      "variational_beta * kldivergence:  0.14457\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30858\n",
      "kldivergence:   1458.77\n",
      "variational_beta * kldivergence:  0.14588\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36908\n",
      "kldivergence:   1405.87\n",
      "variational_beta * kldivergence:  0.14059\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35596\n",
      "kldivergence:   1564.20\n",
      "variational_beta * kldivergence:  0.15642\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28281\n",
      "kldivergence:   1326.34\n",
      "variational_beta * kldivergence:  0.13263\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36321\n",
      "kldivergence:   1712.06\n",
      "variational_beta * kldivergence:  0.17121\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32118\n",
      "kldivergence:   1826.71\n",
      "variational_beta * kldivergence:  0.18267\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30534\n",
      "kldivergence:   1611.49\n",
      "variational_beta * kldivergence:  0.16115\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.37680\n",
      "kldivergence:   1539.83\n",
      "variational_beta * kldivergence:  0.15398\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30378\n",
      "kldivergence:   1419.48\n",
      "variational_beta * kldivergence:  0.14195\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33762\n",
      "kldivergence:   1498.79\n",
      "variational_beta * kldivergence:  0.14988\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31172\n",
      "kldivergence:   1428.92\n",
      "variational_beta * kldivergence:  0.14289\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.39867\n",
      "kldivergence:   1835.57\n",
      "variational_beta * kldivergence:  0.18356\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.41301\n",
      "kldivergence:   1537.97\n",
      "variational_beta * kldivergence:  0.15380\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31320\n",
      "kldivergence:   1560.94\n",
      "variational_beta * kldivergence:  0.15609\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33504\n",
      "kldivergence:   1499.91\n",
      "variational_beta * kldivergence:  0.14999\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35837\n",
      "kldivergence:   1543.62\n",
      "variational_beta * kldivergence:  0.15436\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30626\n",
      "kldivergence:   1595.65\n",
      "variational_beta * kldivergence:  0.15956\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32813\n",
      "kldivergence:   1731.32\n",
      "variational_beta * kldivergence:  0.17313\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32369\n",
      "kldivergence:   1584.69\n",
      "variational_beta * kldivergence:  0.15847\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31863\n",
      "kldivergence:   1476.44\n",
      "variational_beta * kldivergence:  0.14764\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29812\n",
      "kldivergence:   1377.08\n",
      "variational_beta * kldivergence:  0.13771\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30376\n",
      "kldivergence:   1571.82\n",
      "variational_beta * kldivergence:  0.15718\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31537\n",
      "kldivergence:   1406.50\n",
      "variational_beta * kldivergence:  0.14065\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30173\n",
      "kldivergence:   1431.74\n",
      "variational_beta * kldivergence:  0.14317\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29401\n",
      "kldivergence:   1442.20\n",
      "variational_beta * kldivergence:  0.14422\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30581\n",
      "kldivergence:   1359.55\n",
      "variational_beta * kldivergence:  0.13596\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28797\n",
      "kldivergence:   1625.54\n",
      "variational_beta * kldivergence:  0.16255\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29176\n",
      "kldivergence:   1329.75\n",
      "variational_beta * kldivergence:  0.13298\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34701\n",
      "kldivergence:   1764.85\n",
      "variational_beta * kldivergence:  0.17649\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32802\n",
      "kldivergence:   1414.41\n",
      "variational_beta * kldivergence:  0.14144\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.24773\n",
      "kldivergence:   1396.80\n",
      "variational_beta * kldivergence:  0.13968\n",
      "batch accuracy: 91.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32606\n",
      "kldivergence:   1435.30\n",
      "variational_beta * kldivergence:  0.14353\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29235\n",
      "kldivergence:   1558.00\n",
      "variational_beta * kldivergence:  0.15580\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36372\n",
      "kldivergence:   2098.83\n",
      "variational_beta * kldivergence:  0.20988\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34144\n",
      "kldivergence:   1669.23\n",
      "variational_beta * kldivergence:  0.16692\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.40124\n",
      "kldivergence:   1455.61\n",
      "variational_beta * kldivergence:  0.14556\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33530\n",
      "kldivergence:   1503.68\n",
      "variational_beta * kldivergence:  0.15037\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28281\n",
      "kldivergence:   1458.46\n",
      "variational_beta * kldivergence:  0.14585\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34467\n",
      "kldivergence:   1500.61\n",
      "variational_beta * kldivergence:  0.15006\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29290\n",
      "kldivergence:   1410.66\n",
      "variational_beta * kldivergence:  0.14107\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28902\n",
      "kldivergence:   1293.37\n",
      "variational_beta * kldivergence:  0.12934\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29285\n",
      "kldivergence:   1381.02\n",
      "variational_beta * kldivergence:  0.13810\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36640\n",
      "kldivergence:   1538.89\n",
      "variational_beta * kldivergence:  0.15389\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34010\n",
      "kldivergence:   1410.89\n",
      "variational_beta * kldivergence:  0.14109\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31004\n",
      "kldivergence:   1321.00\n",
      "variational_beta * kldivergence:  0.13210\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30509\n",
      "kldivergence:   1195.21\n",
      "variational_beta * kldivergence:  0.11952\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34605\n",
      "kldivergence:   1524.43\n",
      "variational_beta * kldivergence:  0.15244\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35586\n",
      "kldivergence:   1653.37\n",
      "variational_beta * kldivergence:  0.16534\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32471\n",
      "kldivergence:   1522.08\n",
      "variational_beta * kldivergence:  0.15221\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31865\n",
      "kldivergence:   1593.42\n",
      "variational_beta * kldivergence:  0.15934\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32373\n",
      "kldivergence:   1471.62\n",
      "variational_beta * kldivergence:  0.14716\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35383\n",
      "kldivergence:   1436.76\n",
      "variational_beta * kldivergence:  0.14368\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31053\n",
      "kldivergence:   1528.35\n",
      "variational_beta * kldivergence:  0.15283\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30806\n",
      "kldivergence:   1501.43\n",
      "variational_beta * kldivergence:  0.15014\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31440\n",
      "kldivergence:   1486.74\n",
      "variational_beta * kldivergence:  0.14867\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33664\n",
      "kldivergence:   1434.43\n",
      "variational_beta * kldivergence:  0.14344\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.38688\n",
      "kldivergence:   1487.51\n",
      "variational_beta * kldivergence:  0.14875\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36975\n",
      "kldivergence:   1550.29\n",
      "variational_beta * kldivergence:  0.15503\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30578\n",
      "kldivergence:   1440.63\n",
      "variational_beta * kldivergence:  0.14406\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34182\n",
      "kldivergence:   1538.85\n",
      "variational_beta * kldivergence:  0.15388\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36016\n",
      "kldivergence:   1511.05\n",
      "variational_beta * kldivergence:  0.15111\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29752\n",
      "kldivergence:   1487.72\n",
      "variational_beta * kldivergence:  0.14877\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30114\n",
      "kldivergence:   1434.61\n",
      "variational_beta * kldivergence:  0.14346\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36476\n",
      "kldivergence:   2007.68\n",
      "variational_beta * kldivergence:  0.20077\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32405\n",
      "kldivergence:   1601.88\n",
      "variational_beta * kldivergence:  0.16019\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36882\n",
      "kldivergence:   1593.20\n",
      "variational_beta * kldivergence:  0.15932\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31610\n",
      "kldivergence:   1503.14\n",
      "variational_beta * kldivergence:  0.15031\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36218\n",
      "kldivergence:   1592.97\n",
      "variational_beta * kldivergence:  0.15930\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.40095\n",
      "kldivergence:   1629.96\n",
      "variational_beta * kldivergence:  0.16300\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32368\n",
      "kldivergence:   1479.36\n",
      "variational_beta * kldivergence:  0.14794\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32941\n",
      "kldivergence:   1651.11\n",
      "variational_beta * kldivergence:  0.16511\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31938\n",
      "kldivergence:   1594.16\n",
      "variational_beta * kldivergence:  0.15942\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35790\n",
      "kldivergence:   1553.36\n",
      "variational_beta * kldivergence:  0.15534\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36573\n",
      "kldivergence:   1664.51\n",
      "variational_beta * kldivergence:  0.16645\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33502\n",
      "kldivergence:   1579.26\n",
      "variational_beta * kldivergence:  0.15793\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34209\n",
      "kldivergence:   1531.88\n",
      "variational_beta * kldivergence:  0.15319\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28078\n",
      "kldivergence:   1412.49\n",
      "variational_beta * kldivergence:  0.14125\n",
      "batch accuracy: 90.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32542\n",
      "kldivergence:   1457.95\n",
      "variational_beta * kldivergence:  0.14579\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32631\n",
      "kldivergence:   1446.85\n",
      "variational_beta * kldivergence:  0.14468\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31918\n",
      "kldivergence:   1564.53\n",
      "variational_beta * kldivergence:  0.15645\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31968\n",
      "kldivergence:   1448.32\n",
      "variational_beta * kldivergence:  0.14483\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28882\n",
      "kldivergence:   1538.21\n",
      "variational_beta * kldivergence:  0.15382\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32085\n",
      "kldivergence:   1498.82\n",
      "variational_beta * kldivergence:  0.14988\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28264\n",
      "kldivergence:   1506.32\n",
      "variational_beta * kldivergence:  0.15063\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29637\n",
      "kldivergence:   1509.70\n",
      "variational_beta * kldivergence:  0.15097\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32559\n",
      "kldivergence:   1479.62\n",
      "variational_beta * kldivergence:  0.14796\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31481\n",
      "kldivergence:   1489.69\n",
      "variational_beta * kldivergence:  0.14897\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33652\n",
      "kldivergence:   1501.04\n",
      "variational_beta * kldivergence:  0.15010\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33564\n",
      "kldivergence:   1462.73\n",
      "variational_beta * kldivergence:  0.14627\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35081\n",
      "kldivergence:   1718.52\n",
      "variational_beta * kldivergence:  0.17185\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35736\n",
      "kldivergence:   1497.36\n",
      "variational_beta * kldivergence:  0.14974\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31982\n",
      "kldivergence:   1507.58\n",
      "variational_beta * kldivergence:  0.15076\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30863\n",
      "kldivergence:   1561.05\n",
      "variational_beta * kldivergence:  0.15611\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34773\n",
      "kldivergence:   1490.56\n",
      "variational_beta * kldivergence:  0.14906\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31723\n",
      "kldivergence:   1432.07\n",
      "variational_beta * kldivergence:  0.14321\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33679\n",
      "kldivergence:   1659.70\n",
      "variational_beta * kldivergence:  0.16597\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27928\n",
      "kldivergence:   1391.48\n",
      "variational_beta * kldivergence:  0.13915\n",
      "batch accuracy: 90.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32661\n",
      "kldivergence:   1543.19\n",
      "variational_beta * kldivergence:  0.15432\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29804\n",
      "kldivergence:   1474.99\n",
      "variational_beta * kldivergence:  0.14750\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28175\n",
      "kldivergence:   1614.77\n",
      "variational_beta * kldivergence:  0.16148\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.26235\n",
      "kldivergence:   1801.56\n",
      "variational_beta * kldivergence:  0.18016\n",
      "batch accuracy: 91.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33220\n",
      "kldivergence:   1699.54\n",
      "variational_beta * kldivergence:  0.16995\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32216\n",
      "kldivergence:   1503.57\n",
      "variational_beta * kldivergence:  0.15036\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35181\n",
      "kldivergence:   1394.45\n",
      "variational_beta * kldivergence:  0.13945\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36701\n",
      "kldivergence:   1517.38\n",
      "variational_beta * kldivergence:  0.15174\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29748\n",
      "kldivergence:   1392.02\n",
      "variational_beta * kldivergence:  0.13920\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30480\n",
      "kldivergence:   1599.41\n",
      "variational_beta * kldivergence:  0.15994\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30874\n",
      "kldivergence:   1567.00\n",
      "variational_beta * kldivergence:  0.15670\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34535\n",
      "kldivergence:   1645.69\n",
      "variational_beta * kldivergence:  0.16457\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36532\n",
      "kldivergence:   1425.53\n",
      "variational_beta * kldivergence:  0.14255\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29835\n",
      "kldivergence:   1491.82\n",
      "variational_beta * kldivergence:  0.14918\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33521\n",
      "kldivergence:   1508.02\n",
      "variational_beta * kldivergence:  0.15080\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34193\n",
      "kldivergence:   1417.63\n",
      "variational_beta * kldivergence:  0.14176\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32115\n",
      "kldivergence:   1438.29\n",
      "variational_beta * kldivergence:  0.14383\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33827\n",
      "kldivergence:   1400.72\n",
      "variational_beta * kldivergence:  0.14007\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29072\n",
      "kldivergence:   1258.98\n",
      "variational_beta * kldivergence:  0.12590\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.37735\n",
      "kldivergence:   1665.80\n",
      "variational_beta * kldivergence:  0.16658\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27808\n",
      "kldivergence:   1325.54\n",
      "variational_beta * kldivergence:  0.13255\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32538\n",
      "kldivergence:   1669.87\n",
      "variational_beta * kldivergence:  0.16699\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.37855\n",
      "kldivergence:   1592.52\n",
      "variational_beta * kldivergence:  0.15925\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.26260\n",
      "kldivergence:   1452.19\n",
      "variational_beta * kldivergence:  0.14522\n",
      "batch accuracy: 90.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29171\n",
      "kldivergence:   1579.38\n",
      "variational_beta * kldivergence:  0.15794\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34505\n",
      "kldivergence:   1568.88\n",
      "variational_beta * kldivergence:  0.15689\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32218\n",
      "kldivergence:   1498.17\n",
      "variational_beta * kldivergence:  0.14982\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36321\n",
      "kldivergence:   1666.51\n",
      "variational_beta * kldivergence:  0.16665\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28642\n",
      "kldivergence:   1383.70\n",
      "variational_beta * kldivergence:  0.13837\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27356\n",
      "kldivergence:   1311.56\n",
      "variational_beta * kldivergence:  0.13116\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30615\n",
      "kldivergence:   1527.87\n",
      "variational_beta * kldivergence:  0.15279\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33590\n",
      "kldivergence:   1511.85\n",
      "variational_beta * kldivergence:  0.15118\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30481\n",
      "kldivergence:   1464.66\n",
      "variational_beta * kldivergence:  0.14647\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29123\n",
      "kldivergence:   1249.63\n",
      "variational_beta * kldivergence:  0.12496\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34788\n",
      "kldivergence:   1578.55\n",
      "variational_beta * kldivergence:  0.15786\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35113\n",
      "kldivergence:   1396.43\n",
      "variational_beta * kldivergence:  0.13964\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33490\n",
      "kldivergence:   1537.83\n",
      "variational_beta * kldivergence:  0.15378\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35031\n",
      "kldivergence:   1413.10\n",
      "variational_beta * kldivergence:  0.14131\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30814\n",
      "kldivergence:   1501.51\n",
      "variational_beta * kldivergence:  0.15015\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.37154\n",
      "kldivergence:   1549.14\n",
      "variational_beta * kldivergence:  0.15491\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.26558\n",
      "kldivergence:   1393.99\n",
      "variational_beta * kldivergence:  0.13940\n",
      "batch accuracy: 91.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30430\n",
      "kldivergence:   1701.67\n",
      "variational_beta * kldivergence:  0.17017\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28975\n",
      "kldivergence:   1506.39\n",
      "variational_beta * kldivergence:  0.15064\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28696\n",
      "kldivergence:   1487.64\n",
      "variational_beta * kldivergence:  0.14876\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33207\n",
      "kldivergence:   1509.00\n",
      "variational_beta * kldivergence:  0.15090\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34937\n",
      "kldivergence:   1562.98\n",
      "variational_beta * kldivergence:  0.15630\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.25835\n",
      "kldivergence:   1420.02\n",
      "variational_beta * kldivergence:  0.14200\n",
      "batch accuracy: 91.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29252\n",
      "kldivergence:   1418.76\n",
      "variational_beta * kldivergence:  0.14188\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33795\n",
      "kldivergence:   1588.74\n",
      "variational_beta * kldivergence:  0.15887\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27898\n",
      "kldivergence:   1448.99\n",
      "variational_beta * kldivergence:  0.14490\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34699\n",
      "kldivergence:   1675.60\n",
      "variational_beta * kldivergence:  0.16756\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29531\n",
      "kldivergence:   1732.83\n",
      "variational_beta * kldivergence:  0.17328\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36176\n",
      "kldivergence:   1513.97\n",
      "variational_beta * kldivergence:  0.15140\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35544\n",
      "kldivergence:   1470.23\n",
      "variational_beta * kldivergence:  0.14702\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33785\n",
      "kldivergence:   1787.02\n",
      "variational_beta * kldivergence:  0.17870\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36278\n",
      "kldivergence:   1564.61\n",
      "variational_beta * kldivergence:  0.15646\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27380\n",
      "kldivergence:   1499.87\n",
      "variational_beta * kldivergence:  0.14999\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33376\n",
      "kldivergence:   1573.26\n",
      "variational_beta * kldivergence:  0.15733\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31211\n",
      "kldivergence:   1482.22\n",
      "variational_beta * kldivergence:  0.14822\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33962\n",
      "kldivergence:   1458.22\n",
      "variational_beta * kldivergence:  0.14582\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32152\n",
      "kldivergence:   1694.22\n",
      "variational_beta * kldivergence:  0.16942\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32149\n",
      "kldivergence:   1447.21\n",
      "variational_beta * kldivergence:  0.14472\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36243\n",
      "kldivergence:   1415.92\n",
      "variational_beta * kldivergence:  0.14159\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33230\n",
      "kldivergence:   1427.92\n",
      "variational_beta * kldivergence:  0.14279\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33459\n",
      "kldivergence:   1413.89\n",
      "variational_beta * kldivergence:  0.14139\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35412\n",
      "kldivergence:   1607.07\n",
      "variational_beta * kldivergence:  0.16071\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.46280\n",
      "kldivergence:   1487.82\n",
      "variational_beta * kldivergence:  0.14878\n",
      "batch accuracy: 86.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34428\n",
      "kldivergence:   1507.73\n",
      "variational_beta * kldivergence:  0.15077\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31255\n",
      "kldivergence:   1607.58\n",
      "variational_beta * kldivergence:  0.16076\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30584\n",
      "kldivergence:   1322.82\n",
      "variational_beta * kldivergence:  0.13228\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35565\n",
      "kldivergence:   1568.64\n",
      "variational_beta * kldivergence:  0.15686\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31118\n",
      "kldivergence:   1490.84\n",
      "variational_beta * kldivergence:  0.14908\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36496\n",
      "kldivergence:   1819.68\n",
      "variational_beta * kldivergence:  0.18197\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30922\n",
      "kldivergence:   1533.27\n",
      "variational_beta * kldivergence:  0.15333\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33763\n",
      "kldivergence:   1430.34\n",
      "variational_beta * kldivergence:  0.14303\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29690\n",
      "kldivergence:   1451.54\n",
      "variational_beta * kldivergence:  0.14515\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29075\n",
      "kldivergence:   1439.78\n",
      "variational_beta * kldivergence:  0.14398\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30122\n",
      "kldivergence:   1409.31\n",
      "variational_beta * kldivergence:  0.14093\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36733\n",
      "kldivergence:   1858.51\n",
      "variational_beta * kldivergence:  0.18585\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32135\n",
      "kldivergence:   1628.92\n",
      "variational_beta * kldivergence:  0.16289\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30250\n",
      "kldivergence:   1644.25\n",
      "variational_beta * kldivergence:  0.16442\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31841\n",
      "kldivergence:   1578.36\n",
      "variational_beta * kldivergence:  0.15784\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33134\n",
      "kldivergence:   1513.88\n",
      "variational_beta * kldivergence:  0.15139\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.42702\n",
      "kldivergence:   1638.14\n",
      "variational_beta * kldivergence:  0.16381\n",
      "batch accuracy: 85.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32693\n",
      "kldivergence:   1542.29\n",
      "variational_beta * kldivergence:  0.15423\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33873\n",
      "kldivergence:   1597.53\n",
      "variational_beta * kldivergence:  0.15975\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.39336\n",
      "kldivergence:   1869.17\n",
      "variational_beta * kldivergence:  0.18692\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31515\n",
      "kldivergence:   1345.61\n",
      "variational_beta * kldivergence:  0.13456\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28341\n",
      "kldivergence:   1444.47\n",
      "variational_beta * kldivergence:  0.14445\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33744\n",
      "kldivergence:   1601.82\n",
      "variational_beta * kldivergence:  0.16018\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32267\n",
      "kldivergence:   1439.65\n",
      "variational_beta * kldivergence:  0.14396\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33918\n",
      "kldivergence:   1460.19\n",
      "variational_beta * kldivergence:  0.14602\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.38183\n",
      "kldivergence:   1596.34\n",
      "variational_beta * kldivergence:  0.15963\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36076\n",
      "kldivergence:   1681.37\n",
      "variational_beta * kldivergence:  0.16814\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32305\n",
      "kldivergence:   1631.03\n",
      "variational_beta * kldivergence:  0.16310\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32232\n",
      "kldivergence:   1571.21\n",
      "variational_beta * kldivergence:  0.15712\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27707\n",
      "kldivergence:   1443.63\n",
      "variational_beta * kldivergence:  0.14436\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29463\n",
      "kldivergence:   1429.19\n",
      "variational_beta * kldivergence:  0.14292\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32116\n",
      "kldivergence:   1507.60\n",
      "variational_beta * kldivergence:  0.15076\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29092\n",
      "kldivergence:   1515.01\n",
      "variational_beta * kldivergence:  0.15150\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29546\n",
      "kldivergence:   1547.72\n",
      "variational_beta * kldivergence:  0.15477\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32355\n",
      "kldivergence:   1508.78\n",
      "variational_beta * kldivergence:  0.15088\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32862\n",
      "kldivergence:   1730.52\n",
      "variational_beta * kldivergence:  0.17305\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29979\n",
      "kldivergence:   1517.48\n",
      "variational_beta * kldivergence:  0.15175\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.28293\n",
      "kldivergence:   1491.93\n",
      "variational_beta * kldivergence:  0.14919\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30985\n",
      "kldivergence:   1606.34\n",
      "variational_beta * kldivergence:  0.16063\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31474\n",
      "kldivergence:   1655.72\n",
      "variational_beta * kldivergence:  0.16557\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.35911\n",
      "kldivergence:   1532.51\n",
      "variational_beta * kldivergence:  0.15325\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30530\n",
      "kldivergence:   1407.23\n",
      "variational_beta * kldivergence:  0.14072\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34115\n",
      "kldivergence:   1517.71\n",
      "variational_beta * kldivergence:  0.15177\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36706\n",
      "kldivergence:   1522.49\n",
      "variational_beta * kldivergence:  0.15225\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36229\n",
      "kldivergence:   1532.53\n",
      "variational_beta * kldivergence:  0.15325\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34588\n",
      "kldivergence:   1655.85\n",
      "variational_beta * kldivergence:  0.16559\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31102\n",
      "kldivergence:   1339.55\n",
      "variational_beta * kldivergence:  0.13396\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.40975\n",
      "kldivergence:   1677.47\n",
      "variational_beta * kldivergence:  0.16775\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33402\n",
      "kldivergence:   1365.13\n",
      "variational_beta * kldivergence:  0.13651\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.34520\n",
      "kldivergence:   1506.20\n",
      "variational_beta * kldivergence:  0.15062\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.38479\n",
      "kldivergence:   1605.65\n",
      "variational_beta * kldivergence:  0.16057\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.29956\n",
      "kldivergence:   1399.29\n",
      "variational_beta * kldivergence:  0.13993\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32196\n",
      "kldivergence:   1607.99\n",
      "variational_beta * kldivergence:  0.16080\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.36479\n",
      "kldivergence:   1809.18\n",
      "variational_beta * kldivergence:  0.18092\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32408\n",
      "kldivergence:   1468.92\n",
      "variational_beta * kldivergence:  0.14689\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30244\n",
      "kldivergence:   1484.38\n",
      "variational_beta * kldivergence:  0.14844\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32887\n",
      "kldivergence:   1485.50\n",
      "variational_beta * kldivergence:  0.14855\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30037\n",
      "kldivergence:   1400.61\n",
      "variational_beta * kldivergence:  0.14006\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30133\n",
      "kldivergence:   1458.78\n",
      "variational_beta * kldivergence:  0.14588\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.27985\n",
      "kldivergence:   1489.42\n",
      "variational_beta * kldivergence:  0.14894\n",
      "batch accuracy: 90.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.33421\n",
      "kldivergence:   1552.68\n",
      "variational_beta * kldivergence:  0.15527\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31074\n",
      "kldivergence:   1718.72\n",
      "variational_beta * kldivergence:  0.17187\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32922\n",
      "kldivergence:   1568.50\n",
      "variational_beta * kldivergence:  0.15685\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30869\n",
      "kldivergence:   1419.90\n",
      "variational_beta * kldivergence:  0.14199\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.32804\n",
      "kldivergence:   1537.53\n",
      "variational_beta * kldivergence:  0.15375\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.31120\n",
      "kldivergence:   1401.42\n",
      "variational_beta * kldivergence:  0.14014\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #53\n",
      "reconstruction loss: 0.30865\n",
      "kldivergence:   1348.17\n",
      "variational_beta * kldivergence:  0.13482\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.54321\n",
      "kldivergence:   1619.94\n",
      "variational_beta * kldivergence:  0.16199\n",
      "batch accuracy: 83.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.44126\n",
      "kldivergence:   1323.45\n",
      "variational_beta * kldivergence:  0.13235\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.51509\n",
      "kldivergence:   1651.95\n",
      "variational_beta * kldivergence:  0.16519\n",
      "batch accuracy: 84.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.39608\n",
      "kldivergence:   1329.58\n",
      "variational_beta * kldivergence:  0.13296\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.44009\n",
      "kldivergence:   1423.40\n",
      "variational_beta * kldivergence:  0.14234\n",
      "batch accuracy: 86.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.52656\n",
      "kldivergence:   1586.56\n",
      "variational_beta * kldivergence:  0.15866\n",
      "batch accuracy: 83.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.40463\n",
      "kldivergence:   1324.08\n",
      "variational_beta * kldivergence:  0.13241\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.38201\n",
      "kldivergence:   1377.50\n",
      "variational_beta * kldivergence:  0.13775\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.41337\n",
      "kldivergence:   1289.63\n",
      "variational_beta * kldivergence:  0.12896\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.40985\n",
      "kldivergence:   1370.21\n",
      "variational_beta * kldivergence:  0.13702\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.42746\n",
      "kldivergence:   1373.43\n",
      "variational_beta * kldivergence:  0.13734\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.55758\n",
      "kldivergence:   1700.68\n",
      "variational_beta * kldivergence:  0.17007\n",
      "batch accuracy: 82.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.44167\n",
      "kldivergence:   1404.02\n",
      "variational_beta * kldivergence:  0.14040\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.39678\n",
      "kldivergence:   1215.09\n",
      "variational_beta * kldivergence:  0.12151\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.45894\n",
      "kldivergence:   1464.29\n",
      "variational_beta * kldivergence:  0.14643\n",
      "batch accuracy: 85.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.47958\n",
      "kldivergence:   1542.62\n",
      "variational_beta * kldivergence:  0.15426\n",
      "batch accuracy: 84.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.39959\n",
      "kldivergence:   1347.18\n",
      "variational_beta * kldivergence:  0.13472\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.44974\n",
      "kldivergence:   1339.17\n",
      "variational_beta * kldivergence:  0.13392\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.38091\n",
      "kldivergence:   1254.48\n",
      "variational_beta * kldivergence:  0.12545\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.40486\n",
      "kldivergence:   1333.61\n",
      "variational_beta * kldivergence:  0.13336\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.36147\n",
      "kldivergence:   1264.37\n",
      "variational_beta * kldivergence:  0.12644\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.50676\n",
      "kldivergence:   1368.60\n",
      "variational_beta * kldivergence:  0.13686\n",
      "batch accuracy: 85.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.44213\n",
      "kldivergence:   1505.10\n",
      "variational_beta * kldivergence:  0.15051\n",
      "batch accuracy: 85.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.47986\n",
      "kldivergence:   1400.03\n",
      "variational_beta * kldivergence:  0.14000\n",
      "batch accuracy: 85.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.41787\n",
      "kldivergence:   1443.81\n",
      "variational_beta * kldivergence:  0.14438\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.39233\n",
      "kldivergence:   1410.32\n",
      "variational_beta * kldivergence:  0.14103\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.48259\n",
      "kldivergence:   1383.76\n",
      "variational_beta * kldivergence:  0.13838\n",
      "batch accuracy: 85.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.48905\n",
      "kldivergence:   1428.13\n",
      "variational_beta * kldivergence:  0.14281\n",
      "batch accuracy: 84.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.49461\n",
      "kldivergence:   1458.85\n",
      "variational_beta * kldivergence:  0.14588\n",
      "batch accuracy: 85.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.45653\n",
      "kldivergence:   1457.04\n",
      "variational_beta * kldivergence:  0.14570\n",
      "batch accuracy: 85.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.47868\n",
      "kldivergence:   1424.48\n",
      "variational_beta * kldivergence:  0.14245\n",
      "batch accuracy: 85.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.37449\n",
      "kldivergence:   1404.95\n",
      "variational_beta * kldivergence:  0.14049\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.47552\n",
      "kldivergence:   1507.64\n",
      "variational_beta * kldivergence:  0.15076\n",
      "batch accuracy: 84.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.54211\n",
      "kldivergence:   1554.97\n",
      "variational_beta * kldivergence:  0.15550\n",
      "batch accuracy: 83.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.57817\n",
      "kldivergence:   1482.85\n",
      "variational_beta * kldivergence:  0.14829\n",
      "batch accuracy: 83.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.47248\n",
      "kldivergence:   1475.74\n",
      "variational_beta * kldivergence:  0.14757\n",
      "batch accuracy: 84.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.43416\n",
      "kldivergence:   1430.78\n",
      "variational_beta * kldivergence:  0.14308\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.56133\n",
      "kldivergence:   1590.35\n",
      "variational_beta * kldivergence:  0.15903\n",
      "batch accuracy: 83.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.32380\n",
      "kldivergence:   1310.29\n",
      "variational_beta * kldivergence:  0.13103\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.37622\n",
      "kldivergence:   1369.64\n",
      "variational_beta * kldivergence:  0.13696\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.59332\n",
      "kldivergence:   1578.46\n",
      "variational_beta * kldivergence:  0.15785\n",
      "batch accuracy: 82.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.43364\n",
      "kldivergence:   1375.25\n",
      "variational_beta * kldivergence:  0.13753\n",
      "batch accuracy: 85.61\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.50309\n",
      "kldivergence:   1483.59\n",
      "variational_beta * kldivergence:  0.14836\n",
      "batch accuracy: 84.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.46164\n",
      "kldivergence:   1421.65\n",
      "variational_beta * kldivergence:  0.14217\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.44297\n",
      "kldivergence:   1370.47\n",
      "variational_beta * kldivergence:  0.13705\n",
      "batch accuracy: 86.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.50632\n",
      "kldivergence:   1536.51\n",
      "variational_beta * kldivergence:  0.15365\n",
      "batch accuracy: 84.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.41786\n",
      "kldivergence:   1450.31\n",
      "variational_beta * kldivergence:  0.14503\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.44622\n",
      "kldivergence:   1310.98\n",
      "variational_beta * kldivergence:  0.13110\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.39710\n",
      "kldivergence:   1225.56\n",
      "variational_beta * kldivergence:  0.12256\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.51698\n",
      "kldivergence:   1535.96\n",
      "variational_beta * kldivergence:  0.15360\n",
      "batch accuracy: 84.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.44334\n",
      "kldivergence:   1467.73\n",
      "variational_beta * kldivergence:  0.14677\n",
      "batch accuracy: 85.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.46319\n",
      "kldivergence:   1393.90\n",
      "variational_beta * kldivergence:  0.13939\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.42972\n",
      "kldivergence:   1316.07\n",
      "variational_beta * kldivergence:  0.13161\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.44499\n",
      "kldivergence:   1491.28\n",
      "variational_beta * kldivergence:  0.14913\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.46394\n",
      "kldivergence:   1424.52\n",
      "variational_beta * kldivergence:  0.14245\n",
      "batch accuracy: 86.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.39511\n",
      "kldivergence:   1337.48\n",
      "variational_beta * kldivergence:  0.13375\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.41013\n",
      "kldivergence:   1364.00\n",
      "variational_beta * kldivergence:  0.13640\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.38806\n",
      "kldivergence:   1272.49\n",
      "variational_beta * kldivergence:  0.12725\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.41227\n",
      "kldivergence:   1377.03\n",
      "variational_beta * kldivergence:  0.13770\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.42859\n",
      "kldivergence:   1367.21\n",
      "variational_beta * kldivergence:  0.13672\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.50194\n",
      "kldivergence:   1550.33\n",
      "variational_beta * kldivergence:  0.15503\n",
      "batch accuracy: 84.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #53\n",
      "reconstruction loss: 0.51663\n",
      "kldivergence:   1531.54\n",
      "variational_beta * kldivergence:  0.15315\n",
      "batch accuracy: 85.36\n",
      "\n",
      "\n",
      "epoch # 53 : train loss is [177.44025374232461] and validation loss is [0.09956406124571465] \n",
      "Epoch [54 / 150] average reconstruction error: 0.478276\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33085\n",
      "kldivergence:   1601.83\n",
      "variational_beta * kldivergence:  0.16018\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37999\n",
      "kldivergence:   1634.26\n",
      "variational_beta * kldivergence:  0.16343\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33342\n",
      "kldivergence:   1421.86\n",
      "variational_beta * kldivergence:  0.14219\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29342\n",
      "kldivergence:   1325.49\n",
      "variational_beta * kldivergence:  0.13255\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31091\n",
      "kldivergence:   1620.50\n",
      "variational_beta * kldivergence:  0.16205\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33998\n",
      "kldivergence:   1493.53\n",
      "variational_beta * kldivergence:  0.14935\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32306\n",
      "kldivergence:   1481.76\n",
      "variational_beta * kldivergence:  0.14818\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31896\n",
      "kldivergence:   1376.11\n",
      "variational_beta * kldivergence:  0.13761\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29954\n",
      "kldivergence:   1486.03\n",
      "variational_beta * kldivergence:  0.14860\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31310\n",
      "kldivergence:   1328.56\n",
      "variational_beta * kldivergence:  0.13286\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32450\n",
      "kldivergence:   1394.50\n",
      "variational_beta * kldivergence:  0.13945\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29281\n",
      "kldivergence:   1446.34\n",
      "variational_beta * kldivergence:  0.14463\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33575\n",
      "kldivergence:   1482.18\n",
      "variational_beta * kldivergence:  0.14822\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32438\n",
      "kldivergence:   1416.77\n",
      "variational_beta * kldivergence:  0.14168\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36549\n",
      "kldivergence:   1574.59\n",
      "variational_beta * kldivergence:  0.15746\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35407\n",
      "kldivergence:   1624.02\n",
      "variational_beta * kldivergence:  0.16240\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32485\n",
      "kldivergence:   1469.11\n",
      "variational_beta * kldivergence:  0.14691\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31119\n",
      "kldivergence:   1562.72\n",
      "variational_beta * kldivergence:  0.15627\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29666\n",
      "kldivergence:   1547.35\n",
      "variational_beta * kldivergence:  0.15473\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27547\n",
      "kldivergence:   1333.35\n",
      "variational_beta * kldivergence:  0.13334\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35279\n",
      "kldivergence:   1763.69\n",
      "variational_beta * kldivergence:  0.17637\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33463\n",
      "kldivergence:   1412.90\n",
      "variational_beta * kldivergence:  0.14129\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30094\n",
      "kldivergence:   1557.50\n",
      "variational_beta * kldivergence:  0.15575\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.38223\n",
      "kldivergence:   1411.86\n",
      "variational_beta * kldivergence:  0.14119\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31398\n",
      "kldivergence:   1430.79\n",
      "variational_beta * kldivergence:  0.14308\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28005\n",
      "kldivergence:   1409.19\n",
      "variational_beta * kldivergence:  0.14092\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32166\n",
      "kldivergence:   1504.58\n",
      "variational_beta * kldivergence:  0.15046\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32081\n",
      "kldivergence:   1521.14\n",
      "variational_beta * kldivergence:  0.15211\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32144\n",
      "kldivergence:   1523.16\n",
      "variational_beta * kldivergence:  0.15232\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34155\n",
      "kldivergence:   1498.11\n",
      "variational_beta * kldivergence:  0.14981\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30264\n",
      "kldivergence:   1436.24\n",
      "variational_beta * kldivergence:  0.14362\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30333\n",
      "kldivergence:   1545.31\n",
      "variational_beta * kldivergence:  0.15453\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31248\n",
      "kldivergence:   1361.67\n",
      "variational_beta * kldivergence:  0.13617\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31541\n",
      "kldivergence:   1505.52\n",
      "variational_beta * kldivergence:  0.15055\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33673\n",
      "kldivergence:   1459.13\n",
      "variational_beta * kldivergence:  0.14591\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32245\n",
      "kldivergence:   1416.09\n",
      "variational_beta * kldivergence:  0.14161\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32322\n",
      "kldivergence:   1556.77\n",
      "variational_beta * kldivergence:  0.15568\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33054\n",
      "kldivergence:   1479.14\n",
      "variational_beta * kldivergence:  0.14791\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.26242\n",
      "kldivergence:   1413.54\n",
      "variational_beta * kldivergence:  0.14135\n",
      "batch accuracy: 91.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33655\n",
      "kldivergence:   1499.80\n",
      "variational_beta * kldivergence:  0.14998\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34118\n",
      "kldivergence:   1549.96\n",
      "variational_beta * kldivergence:  0.15500\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31480\n",
      "kldivergence:   1487.44\n",
      "variational_beta * kldivergence:  0.14874\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30892\n",
      "kldivergence:   1541.76\n",
      "variational_beta * kldivergence:  0.15418\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28026\n",
      "kldivergence:   1531.97\n",
      "variational_beta * kldivergence:  0.15320\n",
      "batch accuracy: 91.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31567\n",
      "kldivergence:   1499.21\n",
      "variational_beta * kldivergence:  0.14992\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28298\n",
      "kldivergence:   1607.30\n",
      "variational_beta * kldivergence:  0.16073\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27927\n",
      "kldivergence:   1527.02\n",
      "variational_beta * kldivergence:  0.15270\n",
      "batch accuracy: 90.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34021\n",
      "kldivergence:   1608.78\n",
      "variational_beta * kldivergence:  0.16088\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36445\n",
      "kldivergence:   1554.25\n",
      "variational_beta * kldivergence:  0.15542\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32763\n",
      "kldivergence:   1422.88\n",
      "variational_beta * kldivergence:  0.14229\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32573\n",
      "kldivergence:   1449.19\n",
      "variational_beta * kldivergence:  0.14492\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31692\n",
      "kldivergence:   1504.57\n",
      "variational_beta * kldivergence:  0.15046\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35706\n",
      "kldivergence:   1615.33\n",
      "variational_beta * kldivergence:  0.16153\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29475\n",
      "kldivergence:   1341.32\n",
      "variational_beta * kldivergence:  0.13413\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32015\n",
      "kldivergence:   1454.51\n",
      "variational_beta * kldivergence:  0.14545\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30734\n",
      "kldivergence:   1662.06\n",
      "variational_beta * kldivergence:  0.16621\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36642\n",
      "kldivergence:   1656.47\n",
      "variational_beta * kldivergence:  0.16565\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28651\n",
      "kldivergence:   1366.76\n",
      "variational_beta * kldivergence:  0.13668\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30205\n",
      "kldivergence:   1342.30\n",
      "variational_beta * kldivergence:  0.13423\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30949\n",
      "kldivergence:   1515.84\n",
      "variational_beta * kldivergence:  0.15158\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31339\n",
      "kldivergence:   1413.15\n",
      "variational_beta * kldivergence:  0.14131\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35104\n",
      "kldivergence:   1468.44\n",
      "variational_beta * kldivergence:  0.14684\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29164\n",
      "kldivergence:   1457.49\n",
      "variational_beta * kldivergence:  0.14575\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27707\n",
      "kldivergence:   1318.30\n",
      "variational_beta * kldivergence:  0.13183\n",
      "batch accuracy: 90.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34796\n",
      "kldivergence:   1536.58\n",
      "variational_beta * kldivergence:  0.15366\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37927\n",
      "kldivergence:   1615.60\n",
      "variational_beta * kldivergence:  0.16156\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36437\n",
      "kldivergence:   1564.31\n",
      "variational_beta * kldivergence:  0.15643\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29316\n",
      "kldivergence:   1430.67\n",
      "variational_beta * kldivergence:  0.14307\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29278\n",
      "kldivergence:   1506.89\n",
      "variational_beta * kldivergence:  0.15069\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37560\n",
      "kldivergence:   1724.71\n",
      "variational_beta * kldivergence:  0.17247\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35741\n",
      "kldivergence:   1469.29\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32301\n",
      "kldivergence:   1416.40\n",
      "variational_beta * kldivergence:  0.14164\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27101\n",
      "kldivergence:   1346.39\n",
      "variational_beta * kldivergence:  0.13464\n",
      "batch accuracy: 91.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34827\n",
      "kldivergence:   1544.66\n",
      "variational_beta * kldivergence:  0.15447\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33466\n",
      "kldivergence:   1448.81\n",
      "variational_beta * kldivergence:  0.14488\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36717\n",
      "kldivergence:   1521.68\n",
      "variational_beta * kldivergence:  0.15217\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32383\n",
      "kldivergence:   1356.35\n",
      "variational_beta * kldivergence:  0.13563\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.26418\n",
      "kldivergence:   1240.24\n",
      "variational_beta * kldivergence:  0.12402\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28009\n",
      "kldivergence:   1569.47\n",
      "variational_beta * kldivergence:  0.15695\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30990\n",
      "kldivergence:   1467.40\n",
      "variational_beta * kldivergence:  0.14674\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.38522\n",
      "kldivergence:   1397.57\n",
      "variational_beta * kldivergence:  0.13976\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30798\n",
      "kldivergence:   1403.64\n",
      "variational_beta * kldivergence:  0.14036\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32223\n",
      "kldivergence:   1323.11\n",
      "variational_beta * kldivergence:  0.13231\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29794\n",
      "kldivergence:   1539.71\n",
      "variational_beta * kldivergence:  0.15397\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31668\n",
      "kldivergence:   1571.93\n",
      "variational_beta * kldivergence:  0.15719\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29897\n",
      "kldivergence:   1412.63\n",
      "variational_beta * kldivergence:  0.14126\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34916\n",
      "kldivergence:   1564.03\n",
      "variational_beta * kldivergence:  0.15640\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34208\n",
      "kldivergence:   1377.19\n",
      "variational_beta * kldivergence:  0.13772\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37938\n",
      "kldivergence:   1535.48\n",
      "variational_beta * kldivergence:  0.15355\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30366\n",
      "kldivergence:   1404.64\n",
      "variational_beta * kldivergence:  0.14046\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30863\n",
      "kldivergence:   1380.52\n",
      "variational_beta * kldivergence:  0.13805\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33859\n",
      "kldivergence:   1399.35\n",
      "variational_beta * kldivergence:  0.13994\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32763\n",
      "kldivergence:   1669.73\n",
      "variational_beta * kldivergence:  0.16697\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.41201\n",
      "kldivergence:   1546.47\n",
      "variational_beta * kldivergence:  0.15465\n",
      "batch accuracy: 86.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34712\n",
      "kldivergence:   1529.33\n",
      "variational_beta * kldivergence:  0.15293\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29497\n",
      "kldivergence:   1579.76\n",
      "variational_beta * kldivergence:  0.15798\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32285\n",
      "kldivergence:   1568.92\n",
      "variational_beta * kldivergence:  0.15689\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35520\n",
      "kldivergence:   1411.63\n",
      "variational_beta * kldivergence:  0.14116\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28587\n",
      "kldivergence:   1318.48\n",
      "variational_beta * kldivergence:  0.13185\n",
      "batch accuracy: 90.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31827\n",
      "kldivergence:   1498.57\n",
      "variational_beta * kldivergence:  0.14986\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35922\n",
      "kldivergence:   1488.26\n",
      "variational_beta * kldivergence:  0.14883\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34356\n",
      "kldivergence:   1431.78\n",
      "variational_beta * kldivergence:  0.14318\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36735\n",
      "kldivergence:   1572.87\n",
      "variational_beta * kldivergence:  0.15729\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28028\n",
      "kldivergence:   1555.80\n",
      "variational_beta * kldivergence:  0.15558\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31112\n",
      "kldivergence:   1596.57\n",
      "variational_beta * kldivergence:  0.15966\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35650\n",
      "kldivergence:   1689.42\n",
      "variational_beta * kldivergence:  0.16894\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35395\n",
      "kldivergence:   1655.30\n",
      "variational_beta * kldivergence:  0.16553\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31529\n",
      "kldivergence:   1457.23\n",
      "variational_beta * kldivergence:  0.14572\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31394\n",
      "kldivergence:   1411.50\n",
      "variational_beta * kldivergence:  0.14115\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28030\n",
      "kldivergence:   1470.51\n",
      "variational_beta * kldivergence:  0.14705\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31920\n",
      "kldivergence:   1532.00\n",
      "variational_beta * kldivergence:  0.15320\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36812\n",
      "kldivergence:   1489.60\n",
      "variational_beta * kldivergence:  0.14896\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33980\n",
      "kldivergence:   1552.69\n",
      "variational_beta * kldivergence:  0.15527\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28263\n",
      "kldivergence:   1398.45\n",
      "variational_beta * kldivergence:  0.13985\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30581\n",
      "kldivergence:   1433.49\n",
      "variational_beta * kldivergence:  0.14335\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33471\n",
      "kldivergence:   1609.70\n",
      "variational_beta * kldivergence:  0.16097\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27372\n",
      "kldivergence:   1233.56\n",
      "variational_beta * kldivergence:  0.12336\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37700\n",
      "kldivergence:   1647.65\n",
      "variational_beta * kldivergence:  0.16476\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.41501\n",
      "kldivergence:   1660.31\n",
      "variational_beta * kldivergence:  0.16603\n",
      "batch accuracy: 86.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30181\n",
      "kldivergence:   1538.02\n",
      "variational_beta * kldivergence:  0.15380\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30424\n",
      "kldivergence:   1634.68\n",
      "variational_beta * kldivergence:  0.16347\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36786\n",
      "kldivergence:   1832.78\n",
      "variational_beta * kldivergence:  0.18328\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.38400\n",
      "kldivergence:   1783.16\n",
      "variational_beta * kldivergence:  0.17832\n",
      "batch accuracy: 87.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36216\n",
      "kldivergence:   1724.57\n",
      "variational_beta * kldivergence:  0.17246\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28696\n",
      "kldivergence:   1454.10\n",
      "variational_beta * kldivergence:  0.14541\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31008\n",
      "kldivergence:   1382.60\n",
      "variational_beta * kldivergence:  0.13826\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30178\n",
      "kldivergence:   1411.04\n",
      "variational_beta * kldivergence:  0.14110\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31266\n",
      "kldivergence:   1577.56\n",
      "variational_beta * kldivergence:  0.15776\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35095\n",
      "kldivergence:   1553.02\n",
      "variational_beta * kldivergence:  0.15530\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.38282\n",
      "kldivergence:   1668.82\n",
      "variational_beta * kldivergence:  0.16688\n",
      "batch accuracy: 86.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29989\n",
      "kldivergence:   1518.15\n",
      "variational_beta * kldivergence:  0.15182\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32222\n",
      "kldivergence:   1453.08\n",
      "variational_beta * kldivergence:  0.14531\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32491\n",
      "kldivergence:   1617.32\n",
      "variational_beta * kldivergence:  0.16173\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30508\n",
      "kldivergence:   1416.48\n",
      "variational_beta * kldivergence:  0.14165\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34331\n",
      "kldivergence:   1569.30\n",
      "variational_beta * kldivergence:  0.15693\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32940\n",
      "kldivergence:   1622.40\n",
      "variational_beta * kldivergence:  0.16224\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31967\n",
      "kldivergence:   1584.52\n",
      "variational_beta * kldivergence:  0.15845\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.40568\n",
      "kldivergence:   1561.86\n",
      "variational_beta * kldivergence:  0.15619\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31830\n",
      "kldivergence:   1632.92\n",
      "variational_beta * kldivergence:  0.16329\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35820\n",
      "kldivergence:   1460.79\n",
      "variational_beta * kldivergence:  0.14608\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32375\n",
      "kldivergence:   1414.01\n",
      "variational_beta * kldivergence:  0.14140\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31456\n",
      "kldivergence:   1349.10\n",
      "variational_beta * kldivergence:  0.13491\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35380\n",
      "kldivergence:   1663.21\n",
      "variational_beta * kldivergence:  0.16632\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33522\n",
      "kldivergence:   1541.19\n",
      "variational_beta * kldivergence:  0.15412\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.38078\n",
      "kldivergence:   1564.20\n",
      "variational_beta * kldivergence:  0.15642\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34689\n",
      "kldivergence:   1659.23\n",
      "variational_beta * kldivergence:  0.16592\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30827\n",
      "kldivergence:   1510.46\n",
      "variational_beta * kldivergence:  0.15105\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32974\n",
      "kldivergence:   1425.16\n",
      "variational_beta * kldivergence:  0.14252\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36043\n",
      "kldivergence:   1605.73\n",
      "variational_beta * kldivergence:  0.16057\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31975\n",
      "kldivergence:   1425.14\n",
      "variational_beta * kldivergence:  0.14251\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34219\n",
      "kldivergence:   1365.55\n",
      "variational_beta * kldivergence:  0.13656\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32613\n",
      "kldivergence:   1502.64\n",
      "variational_beta * kldivergence:  0.15026\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32687\n",
      "kldivergence:   1747.83\n",
      "variational_beta * kldivergence:  0.17478\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30859\n",
      "kldivergence:   1321.17\n",
      "variational_beta * kldivergence:  0.13212\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.38837\n",
      "kldivergence:   1609.96\n",
      "variational_beta * kldivergence:  0.16100\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29493\n",
      "kldivergence:   1245.17\n",
      "variational_beta * kldivergence:  0.12452\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31852\n",
      "kldivergence:   1359.46\n",
      "variational_beta * kldivergence:  0.13595\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35250\n",
      "kldivergence:   1510.88\n",
      "variational_beta * kldivergence:  0.15109\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30349\n",
      "kldivergence:   1511.64\n",
      "variational_beta * kldivergence:  0.15116\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32810\n",
      "kldivergence:   1294.39\n",
      "variational_beta * kldivergence:  0.12944\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33237\n",
      "kldivergence:   1589.22\n",
      "variational_beta * kldivergence:  0.15892\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34782\n",
      "kldivergence:   1621.75\n",
      "variational_beta * kldivergence:  0.16217\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35051\n",
      "kldivergence:   1499.96\n",
      "variational_beta * kldivergence:  0.15000\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32550\n",
      "kldivergence:   1465.76\n",
      "variational_beta * kldivergence:  0.14658\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33017\n",
      "kldivergence:   1372.91\n",
      "variational_beta * kldivergence:  0.13729\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33913\n",
      "kldivergence:   1745.43\n",
      "variational_beta * kldivergence:  0.17454\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30264\n",
      "kldivergence:   1528.03\n",
      "variational_beta * kldivergence:  0.15280\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28896\n",
      "kldivergence:   1423.56\n",
      "variational_beta * kldivergence:  0.14236\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34069\n",
      "kldivergence:   1707.58\n",
      "variational_beta * kldivergence:  0.17076\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27174\n",
      "kldivergence:   1423.91\n",
      "variational_beta * kldivergence:  0.14239\n",
      "batch accuracy: 90.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28895\n",
      "kldivergence:   1280.35\n",
      "variational_beta * kldivergence:  0.12803\n",
      "batch accuracy: 90.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34476\n",
      "kldivergence:   1415.28\n",
      "variational_beta * kldivergence:  0.14153\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32878\n",
      "kldivergence:   1830.39\n",
      "variational_beta * kldivergence:  0.18304\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30765\n",
      "kldivergence:   1485.73\n",
      "variational_beta * kldivergence:  0.14857\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28169\n",
      "kldivergence:   1270.97\n",
      "variational_beta * kldivergence:  0.12710\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30689\n",
      "kldivergence:   1414.57\n",
      "variational_beta * kldivergence:  0.14146\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27239\n",
      "kldivergence:   1418.11\n",
      "variational_beta * kldivergence:  0.14181\n",
      "batch accuracy: 90.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31958\n",
      "kldivergence:   1348.98\n",
      "variational_beta * kldivergence:  0.13490\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31016\n",
      "kldivergence:   1388.90\n",
      "variational_beta * kldivergence:  0.13889\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30406\n",
      "kldivergence:   1429.10\n",
      "variational_beta * kldivergence:  0.14291\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36037\n",
      "kldivergence:   1560.19\n",
      "variational_beta * kldivergence:  0.15602\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37957\n",
      "kldivergence:   1519.05\n",
      "variational_beta * kldivergence:  0.15190\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29729\n",
      "kldivergence:   1478.81\n",
      "variational_beta * kldivergence:  0.14788\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34758\n",
      "kldivergence:   1364.02\n",
      "variational_beta * kldivergence:  0.13640\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32494\n",
      "kldivergence:   1432.55\n",
      "variational_beta * kldivergence:  0.14325\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28563\n",
      "kldivergence:   1337.18\n",
      "variational_beta * kldivergence:  0.13372\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31697\n",
      "kldivergence:   1501.89\n",
      "variational_beta * kldivergence:  0.15019\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34509\n",
      "kldivergence:   1712.04\n",
      "variational_beta * kldivergence:  0.17120\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.38086\n",
      "kldivergence:   1707.87\n",
      "variational_beta * kldivergence:  0.17079\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30049\n",
      "kldivergence:   1424.12\n",
      "variational_beta * kldivergence:  0.14241\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30198\n",
      "kldivergence:   1399.46\n",
      "variational_beta * kldivergence:  0.13995\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37033\n",
      "kldivergence:   1556.73\n",
      "variational_beta * kldivergence:  0.15567\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35424\n",
      "kldivergence:   1513.21\n",
      "variational_beta * kldivergence:  0.15132\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31653\n",
      "kldivergence:   1368.29\n",
      "variational_beta * kldivergence:  0.13683\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37321\n",
      "kldivergence:   1495.07\n",
      "variational_beta * kldivergence:  0.14951\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32180\n",
      "kldivergence:   1555.01\n",
      "variational_beta * kldivergence:  0.15550\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29028\n",
      "kldivergence:   1450.70\n",
      "variational_beta * kldivergence:  0.14507\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34796\n",
      "kldivergence:   1691.29\n",
      "variational_beta * kldivergence:  0.16913\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32129\n",
      "kldivergence:   1315.44\n",
      "variational_beta * kldivergence:  0.13154\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32201\n",
      "kldivergence:   1376.97\n",
      "variational_beta * kldivergence:  0.13770\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27664\n",
      "kldivergence:   1445.62\n",
      "variational_beta * kldivergence:  0.14456\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31424\n",
      "kldivergence:   1889.92\n",
      "variational_beta * kldivergence:  0.18899\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37042\n",
      "kldivergence:   1977.61\n",
      "variational_beta * kldivergence:  0.19776\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34970\n",
      "kldivergence:   1676.68\n",
      "variational_beta * kldivergence:  0.16767\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28241\n",
      "kldivergence:   1240.36\n",
      "variational_beta * kldivergence:  0.12404\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30521\n",
      "kldivergence:   1546.87\n",
      "variational_beta * kldivergence:  0.15469\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31928\n",
      "kldivergence:   1458.49\n",
      "variational_beta * kldivergence:  0.14585\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29776\n",
      "kldivergence:   1260.11\n",
      "variational_beta * kldivergence:  0.12601\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35618\n",
      "kldivergence:   1609.57\n",
      "variational_beta * kldivergence:  0.16096\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31139\n",
      "kldivergence:   1672.16\n",
      "variational_beta * kldivergence:  0.16722\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32697\n",
      "kldivergence:   1477.01\n",
      "variational_beta * kldivergence:  0.14770\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34229\n",
      "kldivergence:   1670.19\n",
      "variational_beta * kldivergence:  0.16702\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34226\n",
      "kldivergence:   1492.14\n",
      "variational_beta * kldivergence:  0.14921\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31606\n",
      "kldivergence:   1467.47\n",
      "variational_beta * kldivergence:  0.14675\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31460\n",
      "kldivergence:   1474.73\n",
      "variational_beta * kldivergence:  0.14747\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29802\n",
      "kldivergence:   1288.62\n",
      "variational_beta * kldivergence:  0.12886\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27471\n",
      "kldivergence:   1404.05\n",
      "variational_beta * kldivergence:  0.14040\n",
      "batch accuracy: 91.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31251\n",
      "kldivergence:   1401.67\n",
      "variational_beta * kldivergence:  0.14017\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33910\n",
      "kldivergence:   1444.00\n",
      "variational_beta * kldivergence:  0.14440\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32591\n",
      "kldivergence:   1433.78\n",
      "variational_beta * kldivergence:  0.14338\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33920\n",
      "kldivergence:   1289.65\n",
      "variational_beta * kldivergence:  0.12897\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30734\n",
      "kldivergence:   1455.81\n",
      "variational_beta * kldivergence:  0.14558\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37186\n",
      "kldivergence:   1429.79\n",
      "variational_beta * kldivergence:  0.14298\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30636\n",
      "kldivergence:   1506.61\n",
      "variational_beta * kldivergence:  0.15066\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29541\n",
      "kldivergence:   1378.58\n",
      "variational_beta * kldivergence:  0.13786\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29936\n",
      "kldivergence:   1431.32\n",
      "variational_beta * kldivergence:  0.14313\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33193\n",
      "kldivergence:   1532.45\n",
      "variational_beta * kldivergence:  0.15325\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31261\n",
      "kldivergence:   1396.85\n",
      "variational_beta * kldivergence:  0.13969\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27938\n",
      "kldivergence:   1368.24\n",
      "variational_beta * kldivergence:  0.13682\n",
      "batch accuracy: 90.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33073\n",
      "kldivergence:   1411.93\n",
      "variational_beta * kldivergence:  0.14119\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30342\n",
      "kldivergence:   1393.00\n",
      "variational_beta * kldivergence:  0.13930\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29421\n",
      "kldivergence:   1460.21\n",
      "variational_beta * kldivergence:  0.14602\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31423\n",
      "kldivergence:   1588.65\n",
      "variational_beta * kldivergence:  0.15886\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.26277\n",
      "kldivergence:   1418.50\n",
      "variational_beta * kldivergence:  0.14185\n",
      "batch accuracy: 91.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30055\n",
      "kldivergence:   1358.46\n",
      "variational_beta * kldivergence:  0.13585\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34683\n",
      "kldivergence:   1605.78\n",
      "variational_beta * kldivergence:  0.16058\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.24485\n",
      "kldivergence:   1326.44\n",
      "variational_beta * kldivergence:  0.13264\n",
      "batch accuracy: 91.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33664\n",
      "kldivergence:   1311.67\n",
      "variational_beta * kldivergence:  0.13117\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30563\n",
      "kldivergence:   1354.96\n",
      "variational_beta * kldivergence:  0.13550\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28768\n",
      "kldivergence:   1485.26\n",
      "variational_beta * kldivergence:  0.14853\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30450\n",
      "kldivergence:   1366.70\n",
      "variational_beta * kldivergence:  0.13667\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32930\n",
      "kldivergence:   1525.62\n",
      "variational_beta * kldivergence:  0.15256\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35400\n",
      "kldivergence:   1451.44\n",
      "variational_beta * kldivergence:  0.14514\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34828\n",
      "kldivergence:   1391.28\n",
      "variational_beta * kldivergence:  0.13913\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34645\n",
      "kldivergence:   1596.66\n",
      "variational_beta * kldivergence:  0.15967\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29464\n",
      "kldivergence:   1440.00\n",
      "variational_beta * kldivergence:  0.14400\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32744\n",
      "kldivergence:   1284.26\n",
      "variational_beta * kldivergence:  0.12843\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35483\n",
      "kldivergence:   1550.14\n",
      "variational_beta * kldivergence:  0.15501\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27655\n",
      "kldivergence:   1328.95\n",
      "variational_beta * kldivergence:  0.13289\n",
      "batch accuracy: 91.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35187\n",
      "kldivergence:   1366.43\n",
      "variational_beta * kldivergence:  0.13664\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31531\n",
      "kldivergence:   1434.66\n",
      "variational_beta * kldivergence:  0.14347\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36858\n",
      "kldivergence:   1736.27\n",
      "variational_beta * kldivergence:  0.17363\n",
      "batch accuracy: 87.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30361\n",
      "kldivergence:   1337.45\n",
      "variational_beta * kldivergence:  0.13375\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37025\n",
      "kldivergence:   1369.72\n",
      "variational_beta * kldivergence:  0.13697\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31873\n",
      "kldivergence:   1347.79\n",
      "variational_beta * kldivergence:  0.13478\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30598\n",
      "kldivergence:   1343.69\n",
      "variational_beta * kldivergence:  0.13437\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32812\n",
      "kldivergence:   1477.48\n",
      "variational_beta * kldivergence:  0.14775\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35228\n",
      "kldivergence:   1667.03\n",
      "variational_beta * kldivergence:  0.16670\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33685\n",
      "kldivergence:   1539.40\n",
      "variational_beta * kldivergence:  0.15394\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30220\n",
      "kldivergence:   1559.03\n",
      "variational_beta * kldivergence:  0.15590\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36660\n",
      "kldivergence:   1566.67\n",
      "variational_beta * kldivergence:  0.15667\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30947\n",
      "kldivergence:   1612.05\n",
      "variational_beta * kldivergence:  0.16121\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32454\n",
      "kldivergence:   1405.06\n",
      "variational_beta * kldivergence:  0.14051\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28275\n",
      "kldivergence:   1508.10\n",
      "variational_beta * kldivergence:  0.15081\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35814\n",
      "kldivergence:   1529.64\n",
      "variational_beta * kldivergence:  0.15296\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33407\n",
      "kldivergence:   1476.42\n",
      "variational_beta * kldivergence:  0.14764\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33088\n",
      "kldivergence:   1766.66\n",
      "variational_beta * kldivergence:  0.17667\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34702\n",
      "kldivergence:   1579.48\n",
      "variational_beta * kldivergence:  0.15795\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30352\n",
      "kldivergence:   1481.71\n",
      "variational_beta * kldivergence:  0.14817\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30843\n",
      "kldivergence:   1445.89\n",
      "variational_beta * kldivergence:  0.14459\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28553\n",
      "kldivergence:   1476.61\n",
      "variational_beta * kldivergence:  0.14766\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33611\n",
      "kldivergence:   1439.67\n",
      "variational_beta * kldivergence:  0.14397\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32421\n",
      "kldivergence:   1588.55\n",
      "variational_beta * kldivergence:  0.15885\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34135\n",
      "kldivergence:   1602.33\n",
      "variational_beta * kldivergence:  0.16023\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28225\n",
      "kldivergence:   1387.49\n",
      "variational_beta * kldivergence:  0.13875\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33973\n",
      "kldivergence:   1608.78\n",
      "variational_beta * kldivergence:  0.16088\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35462\n",
      "kldivergence:   1602.73\n",
      "variational_beta * kldivergence:  0.16027\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33307\n",
      "kldivergence:   1510.91\n",
      "variational_beta * kldivergence:  0.15109\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37889\n",
      "kldivergence:   1666.67\n",
      "variational_beta * kldivergence:  0.16667\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36053\n",
      "kldivergence:   1445.85\n",
      "variational_beta * kldivergence:  0.14458\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33396\n",
      "kldivergence:   1589.50\n",
      "variational_beta * kldivergence:  0.15895\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33212\n",
      "kldivergence:   1493.88\n",
      "variational_beta * kldivergence:  0.14939\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37120\n",
      "kldivergence:   1469.06\n",
      "variational_beta * kldivergence:  0.14691\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33630\n",
      "kldivergence:   1455.87\n",
      "variational_beta * kldivergence:  0.14559\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27093\n",
      "kldivergence:   1334.49\n",
      "variational_beta * kldivergence:  0.13345\n",
      "batch accuracy: 90.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36371\n",
      "kldivergence:   1489.98\n",
      "variational_beta * kldivergence:  0.14900\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33036\n",
      "kldivergence:   1496.75\n",
      "variational_beta * kldivergence:  0.14967\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32428\n",
      "kldivergence:   1493.27\n",
      "variational_beta * kldivergence:  0.14933\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32189\n",
      "kldivergence:   1329.71\n",
      "variational_beta * kldivergence:  0.13297\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31172\n",
      "kldivergence:   1632.33\n",
      "variational_beta * kldivergence:  0.16323\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28748\n",
      "kldivergence:   1358.43\n",
      "variational_beta * kldivergence:  0.13584\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28156\n",
      "kldivergence:   1426.28\n",
      "variational_beta * kldivergence:  0.14263\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28461\n",
      "kldivergence:   1463.36\n",
      "variational_beta * kldivergence:  0.14634\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33770\n",
      "kldivergence:   1596.95\n",
      "variational_beta * kldivergence:  0.15970\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34891\n",
      "kldivergence:   1559.54\n",
      "variational_beta * kldivergence:  0.15595\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30388\n",
      "kldivergence:   1368.00\n",
      "variational_beta * kldivergence:  0.13680\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33150\n",
      "kldivergence:   1371.59\n",
      "variational_beta * kldivergence:  0.13716\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36598\n",
      "kldivergence:   1788.74\n",
      "variational_beta * kldivergence:  0.17887\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32886\n",
      "kldivergence:   1297.66\n",
      "variational_beta * kldivergence:  0.12977\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27826\n",
      "kldivergence:   1289.77\n",
      "variational_beta * kldivergence:  0.12898\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30524\n",
      "kldivergence:   1382.70\n",
      "variational_beta * kldivergence:  0.13827\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33084\n",
      "kldivergence:   1612.79\n",
      "variational_beta * kldivergence:  0.16128\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32644\n",
      "kldivergence:   1490.95\n",
      "variational_beta * kldivergence:  0.14910\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37732\n",
      "kldivergence:   1614.40\n",
      "variational_beta * kldivergence:  0.16144\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34088\n",
      "kldivergence:   1490.84\n",
      "variational_beta * kldivergence:  0.14908\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36745\n",
      "kldivergence:   1421.75\n",
      "variational_beta * kldivergence:  0.14218\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31910\n",
      "kldivergence:   1665.31\n",
      "variational_beta * kldivergence:  0.16653\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34485\n",
      "kldivergence:   1464.69\n",
      "variational_beta * kldivergence:  0.14647\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33125\n",
      "kldivergence:   1304.04\n",
      "variational_beta * kldivergence:  0.13040\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32782\n",
      "kldivergence:   1500.74\n",
      "variational_beta * kldivergence:  0.15007\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35085\n",
      "kldivergence:   1522.36\n",
      "variational_beta * kldivergence:  0.15224\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37329\n",
      "kldivergence:   1638.41\n",
      "variational_beta * kldivergence:  0.16384\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31184\n",
      "kldivergence:   1410.43\n",
      "variational_beta * kldivergence:  0.14104\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27364\n",
      "kldivergence:   1919.77\n",
      "variational_beta * kldivergence:  0.19198\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31704\n",
      "kldivergence:   1460.45\n",
      "variational_beta * kldivergence:  0.14605\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36475\n",
      "kldivergence:   1528.40\n",
      "variational_beta * kldivergence:  0.15284\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34891\n",
      "kldivergence:   1545.49\n",
      "variational_beta * kldivergence:  0.15455\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34161\n",
      "kldivergence:   1567.44\n",
      "variational_beta * kldivergence:  0.15674\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33121\n",
      "kldivergence:   1467.32\n",
      "variational_beta * kldivergence:  0.14673\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32641\n",
      "kldivergence:   1552.97\n",
      "variational_beta * kldivergence:  0.15530\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34849\n",
      "kldivergence:   1498.01\n",
      "variational_beta * kldivergence:  0.14980\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.26321\n",
      "kldivergence:   1215.75\n",
      "variational_beta * kldivergence:  0.12158\n",
      "batch accuracy: 91.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31109\n",
      "kldivergence:   1494.15\n",
      "variational_beta * kldivergence:  0.14942\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29081\n",
      "kldivergence:   1511.69\n",
      "variational_beta * kldivergence:  0.15117\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29664\n",
      "kldivergence:   1314.12\n",
      "variational_beta * kldivergence:  0.13141\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32928\n",
      "kldivergence:   1493.62\n",
      "variational_beta * kldivergence:  0.14936\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32627\n",
      "kldivergence:   1390.53\n",
      "variational_beta * kldivergence:  0.13905\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.35102\n",
      "kldivergence:   1465.65\n",
      "variational_beta * kldivergence:  0.14656\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33374\n",
      "kldivergence:   1927.64\n",
      "variational_beta * kldivergence:  0.19276\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32166\n",
      "kldivergence:   1524.20\n",
      "variational_beta * kldivergence:  0.15242\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27365\n",
      "kldivergence:   1564.06\n",
      "variational_beta * kldivergence:  0.15641\n",
      "batch accuracy: 90.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33027\n",
      "kldivergence:   1455.04\n",
      "variational_beta * kldivergence:  0.14550\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31779\n",
      "kldivergence:   1383.53\n",
      "variational_beta * kldivergence:  0.13835\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27385\n",
      "kldivergence:   1324.28\n",
      "variational_beta * kldivergence:  0.13243\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30686\n",
      "kldivergence:   1456.78\n",
      "variational_beta * kldivergence:  0.14568\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36480\n",
      "kldivergence:   1660.12\n",
      "variational_beta * kldivergence:  0.16601\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34182\n",
      "kldivergence:   1418.49\n",
      "variational_beta * kldivergence:  0.14185\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30795\n",
      "kldivergence:   1523.38\n",
      "variational_beta * kldivergence:  0.15234\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.34554\n",
      "kldivergence:   1594.14\n",
      "variational_beta * kldivergence:  0.15941\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30610\n",
      "kldivergence:   1490.46\n",
      "variational_beta * kldivergence:  0.14905\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28632\n",
      "kldivergence:   1501.87\n",
      "variational_beta * kldivergence:  0.15019\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30573\n",
      "kldivergence:   1491.71\n",
      "variational_beta * kldivergence:  0.14917\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28346\n",
      "kldivergence:   1420.87\n",
      "variational_beta * kldivergence:  0.14209\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31016\n",
      "kldivergence:   1364.16\n",
      "variational_beta * kldivergence:  0.13642\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33078\n",
      "kldivergence:   1486.84\n",
      "variational_beta * kldivergence:  0.14868\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31372\n",
      "kldivergence:   1341.66\n",
      "variational_beta * kldivergence:  0.13417\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32108\n",
      "kldivergence:   1737.17\n",
      "variational_beta * kldivergence:  0.17372\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33298\n",
      "kldivergence:   1393.68\n",
      "variational_beta * kldivergence:  0.13937\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.31950\n",
      "kldivergence:   1424.72\n",
      "variational_beta * kldivergence:  0.14247\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.27831\n",
      "kldivergence:   1395.36\n",
      "variational_beta * kldivergence:  0.13954\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29664\n",
      "kldivergence:   1452.30\n",
      "variational_beta * kldivergence:  0.14523\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.38976\n",
      "kldivergence:   1649.44\n",
      "variational_beta * kldivergence:  0.16494\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32420\n",
      "kldivergence:   1499.27\n",
      "variational_beta * kldivergence:  0.14993\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32334\n",
      "kldivergence:   1390.45\n",
      "variational_beta * kldivergence:  0.13905\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.37415\n",
      "kldivergence:   1512.31\n",
      "variational_beta * kldivergence:  0.15123\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.33278\n",
      "kldivergence:   1432.87\n",
      "variational_beta * kldivergence:  0.14329\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36505\n",
      "kldivergence:   1543.24\n",
      "variational_beta * kldivergence:  0.15432\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.32538\n",
      "kldivergence:   1466.58\n",
      "variational_beta * kldivergence:  0.14666\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30379\n",
      "kldivergence:   1448.74\n",
      "variational_beta * kldivergence:  0.14487\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30930\n",
      "kldivergence:   1460.06\n",
      "variational_beta * kldivergence:  0.14601\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.38213\n",
      "kldivergence:   1449.00\n",
      "variational_beta * kldivergence:  0.14490\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.26583\n",
      "kldivergence:   1260.47\n",
      "variational_beta * kldivergence:  0.12605\n",
      "batch accuracy: 90.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.40815\n",
      "kldivergence:   1597.10\n",
      "variational_beta * kldivergence:  0.15971\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30752\n",
      "kldivergence:   1416.43\n",
      "variational_beta * kldivergence:  0.14164\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30396\n",
      "kldivergence:   1404.67\n",
      "variational_beta * kldivergence:  0.14047\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.36236\n",
      "kldivergence:   1661.03\n",
      "variational_beta * kldivergence:  0.16610\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29996\n",
      "kldivergence:   1461.05\n",
      "variational_beta * kldivergence:  0.14610\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.28474\n",
      "kldivergence:   1378.41\n",
      "variational_beta * kldivergence:  0.13784\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30379\n",
      "kldivergence:   1478.20\n",
      "variational_beta * kldivergence:  0.14782\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.30972\n",
      "kldivergence:   1629.10\n",
      "variational_beta * kldivergence:  0.16291\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #54\n",
      "reconstruction loss: 0.29447\n",
      "kldivergence:   1438.78\n",
      "variational_beta * kldivergence:  0.14388\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.43503\n",
      "kldivergence:   1361.04\n",
      "variational_beta * kldivergence:  0.13610\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.35921\n",
      "kldivergence:   1197.31\n",
      "variational_beta * kldivergence:  0.11973\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.46860\n",
      "kldivergence:   1462.61\n",
      "variational_beta * kldivergence:  0.14626\n",
      "batch accuracy: 85.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.52769\n",
      "kldivergence:   1423.72\n",
      "variational_beta * kldivergence:  0.14237\n",
      "batch accuracy: 84.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.47249\n",
      "kldivergence:   1336.51\n",
      "variational_beta * kldivergence:  0.13365\n",
      "batch accuracy: 85.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.40729\n",
      "kldivergence:   1382.69\n",
      "variational_beta * kldivergence:  0.13827\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.48815\n",
      "kldivergence:   1442.65\n",
      "variational_beta * kldivergence:  0.14426\n",
      "batch accuracy: 84.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.49166\n",
      "kldivergence:   1473.68\n",
      "variational_beta * kldivergence:  0.14737\n",
      "batch accuracy: 85.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.42989\n",
      "kldivergence:   1344.05\n",
      "variational_beta * kldivergence:  0.13440\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.41409\n",
      "kldivergence:   1395.28\n",
      "variational_beta * kldivergence:  0.13953\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.43747\n",
      "kldivergence:   1308.61\n",
      "variational_beta * kldivergence:  0.13086\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.43248\n",
      "kldivergence:   1446.17\n",
      "variational_beta * kldivergence:  0.14462\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.48444\n",
      "kldivergence:   1493.92\n",
      "variational_beta * kldivergence:  0.14939\n",
      "batch accuracy: 85.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.42694\n",
      "kldivergence:   1229.43\n",
      "variational_beta * kldivergence:  0.12294\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.47342\n",
      "kldivergence:   1334.22\n",
      "variational_beta * kldivergence:  0.13342\n",
      "batch accuracy: 85.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.44189\n",
      "kldivergence:   1469.98\n",
      "variational_beta * kldivergence:  0.14700\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.45048\n",
      "kldivergence:   1342.71\n",
      "variational_beta * kldivergence:  0.13427\n",
      "batch accuracy: 86.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.43082\n",
      "kldivergence:   1339.75\n",
      "variational_beta * kldivergence:  0.13397\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.45059\n",
      "kldivergence:   1253.72\n",
      "variational_beta * kldivergence:  0.12537\n",
      "batch accuracy: 85.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.40083\n",
      "kldivergence:   1336.64\n",
      "variational_beta * kldivergence:  0.13366\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.39246\n",
      "kldivergence:   1266.87\n",
      "variational_beta * kldivergence:  0.12669\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.43435\n",
      "kldivergence:   1448.82\n",
      "variational_beta * kldivergence:  0.14488\n",
      "batch accuracy: 86.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.40210\n",
      "kldivergence:   1357.45\n",
      "variational_beta * kldivergence:  0.13575\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.41772\n",
      "kldivergence:   1381.35\n",
      "variational_beta * kldivergence:  0.13813\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.55933\n",
      "kldivergence:   1496.34\n",
      "variational_beta * kldivergence:  0.14963\n",
      "batch accuracy: 83.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.51208\n",
      "kldivergence:   1395.83\n",
      "variational_beta * kldivergence:  0.13958\n",
      "batch accuracy: 84.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.52756\n",
      "kldivergence:   1435.39\n",
      "variational_beta * kldivergence:  0.14354\n",
      "batch accuracy: 84.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.63856\n",
      "kldivergence:   1615.29\n",
      "variational_beta * kldivergence:  0.16153\n",
      "batch accuracy: 82.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.42158\n",
      "kldivergence:   1283.30\n",
      "variational_beta * kldivergence:  0.12833\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.42370\n",
      "kldivergence:   1404.62\n",
      "variational_beta * kldivergence:  0.14046\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.44461\n",
      "kldivergence:   1470.89\n",
      "variational_beta * kldivergence:  0.14709\n",
      "batch accuracy: 86.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.52867\n",
      "kldivergence:   1451.87\n",
      "variational_beta * kldivergence:  0.14519\n",
      "batch accuracy: 84.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.45211\n",
      "kldivergence:   1446.58\n",
      "variational_beta * kldivergence:  0.14466\n",
      "batch accuracy: 85.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.43423\n",
      "kldivergence:   1393.59\n",
      "variational_beta * kldivergence:  0.13936\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.44695\n",
      "kldivergence:   1307.71\n",
      "variational_beta * kldivergence:  0.13077\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.45458\n",
      "kldivergence:   1378.54\n",
      "variational_beta * kldivergence:  0.13785\n",
      "batch accuracy: 86.61\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.44198\n",
      "kldivergence:   1355.39\n",
      "variational_beta * kldivergence:  0.13554\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.53273\n",
      "kldivergence:   1463.68\n",
      "variational_beta * kldivergence:  0.14637\n",
      "batch accuracy: 84.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.35549\n",
      "kldivergence:   1302.06\n",
      "variational_beta * kldivergence:  0.13021\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.40928\n",
      "kldivergence:   1441.96\n",
      "variational_beta * kldivergence:  0.14420\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.36453\n",
      "kldivergence:   1243.51\n",
      "variational_beta * kldivergence:  0.12435\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.36600\n",
      "kldivergence:   1258.05\n",
      "variational_beta * kldivergence:  0.12581\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.39216\n",
      "kldivergence:   1269.69\n",
      "variational_beta * kldivergence:  0.12697\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.46402\n",
      "kldivergence:   1340.39\n",
      "variational_beta * kldivergence:  0.13404\n",
      "batch accuracy: 86.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.44052\n",
      "kldivergence:   1444.65\n",
      "variational_beta * kldivergence:  0.14446\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.48802\n",
      "kldivergence:   1454.03\n",
      "variational_beta * kldivergence:  0.14540\n",
      "batch accuracy: 85.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.46452\n",
      "kldivergence:   1361.08\n",
      "variational_beta * kldivergence:  0.13611\n",
      "batch accuracy: 85.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.40799\n",
      "kldivergence:   1452.61\n",
      "variational_beta * kldivergence:  0.14526\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.56158\n",
      "kldivergence:   1531.30\n",
      "variational_beta * kldivergence:  0.15313\n",
      "batch accuracy: 83.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.45699\n",
      "kldivergence:   1335.84\n",
      "variational_beta * kldivergence:  0.13358\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.49987\n",
      "kldivergence:   1604.11\n",
      "variational_beta * kldivergence:  0.16041\n",
      "batch accuracy: 85.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.38512\n",
      "kldivergence:   1264.36\n",
      "variational_beta * kldivergence:  0.12644\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.51534\n",
      "kldivergence:   1338.89\n",
      "variational_beta * kldivergence:  0.13389\n",
      "batch accuracy: 84.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.55863\n",
      "kldivergence:   1574.17\n",
      "variational_beta * kldivergence:  0.15742\n",
      "batch accuracy: 82.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.47788\n",
      "kldivergence:   1517.15\n",
      "variational_beta * kldivergence:  0.15171\n",
      "batch accuracy: 84.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.47186\n",
      "kldivergence:   1331.36\n",
      "variational_beta * kldivergence:  0.13314\n",
      "batch accuracy: 85.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.44863\n",
      "kldivergence:   1409.45\n",
      "variational_beta * kldivergence:  0.14094\n",
      "batch accuracy: 86.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.51496\n",
      "kldivergence:   1569.92\n",
      "variational_beta * kldivergence:  0.15699\n",
      "batch accuracy: 83.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.44325\n",
      "kldivergence:   1430.93\n",
      "variational_beta * kldivergence:  0.14309\n",
      "batch accuracy: 85.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.41865\n",
      "kldivergence:   1334.16\n",
      "variational_beta * kldivergence:  0.13342\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.33349\n",
      "kldivergence:   1334.93\n",
      "variational_beta * kldivergence:  0.13349\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #54\n",
      "reconstruction loss: 0.43520\n",
      "kldivergence:   1406.75\n",
      "variational_beta * kldivergence:  0.14067\n",
      "batch accuracy: 86.52\n",
      "\n",
      "\n",
      "epoch # 54 : train loss is [176.16933162966342] and validation loss is [0.09916523544957963] \n",
      "saved samples\n",
      "Epoch [55 / 150] average reconstruction error: 0.474850\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31445\n",
      "kldivergence:   1315.66\n",
      "variational_beta * kldivergence:  0.13157\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.25422\n",
      "kldivergence:   1314.84\n",
      "variational_beta * kldivergence:  0.13148\n",
      "batch accuracy: 91.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28376\n",
      "kldivergence:   1425.28\n",
      "variational_beta * kldivergence:  0.14253\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29552\n",
      "kldivergence:   1649.55\n",
      "variational_beta * kldivergence:  0.16495\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31897\n",
      "kldivergence:   1596.94\n",
      "variational_beta * kldivergence:  0.15969\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32592\n",
      "kldivergence:   1324.40\n",
      "variational_beta * kldivergence:  0.13244\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31431\n",
      "kldivergence:   1352.18\n",
      "variational_beta * kldivergence:  0.13522\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33693\n",
      "kldivergence:   1584.51\n",
      "variational_beta * kldivergence:  0.15845\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35633\n",
      "kldivergence:   1588.96\n",
      "variational_beta * kldivergence:  0.15890\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30890\n",
      "kldivergence:   1345.55\n",
      "variational_beta * kldivergence:  0.13455\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30967\n",
      "kldivergence:   1403.74\n",
      "variational_beta * kldivergence:  0.14037\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35935\n",
      "kldivergence:   1725.62\n",
      "variational_beta * kldivergence:  0.17256\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32585\n",
      "kldivergence:   1743.70\n",
      "variational_beta * kldivergence:  0.17437\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.38236\n",
      "kldivergence:   1628.73\n",
      "variational_beta * kldivergence:  0.16287\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31345\n",
      "kldivergence:   1466.04\n",
      "variational_beta * kldivergence:  0.14660\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32158\n",
      "kldivergence:   1578.36\n",
      "variational_beta * kldivergence:  0.15784\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30429\n",
      "kldivergence:   1502.35\n",
      "variational_beta * kldivergence:  0.15023\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31686\n",
      "kldivergence:   1844.76\n",
      "variational_beta * kldivergence:  0.18448\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29163\n",
      "kldivergence:   1306.39\n",
      "variational_beta * kldivergence:  0.13064\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29817\n",
      "kldivergence:   1512.95\n",
      "variational_beta * kldivergence:  0.15130\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28387\n",
      "kldivergence:   1317.50\n",
      "variational_beta * kldivergence:  0.13175\n",
      "batch accuracy: 90.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31156\n",
      "kldivergence:   1489.09\n",
      "variational_beta * kldivergence:  0.14891\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30493\n",
      "kldivergence:   1483.30\n",
      "variational_beta * kldivergence:  0.14833\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34265\n",
      "kldivergence:   1387.37\n",
      "variational_beta * kldivergence:  0.13874\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31137\n",
      "kldivergence:   1277.77\n",
      "variational_beta * kldivergence:  0.12778\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.26075\n",
      "kldivergence:   1326.83\n",
      "variational_beta * kldivergence:  0.13268\n",
      "batch accuracy: 91.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34195\n",
      "kldivergence:   1618.81\n",
      "variational_beta * kldivergence:  0.16188\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.27851\n",
      "kldivergence:   1333.90\n",
      "variational_beta * kldivergence:  0.13339\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33885\n",
      "kldivergence:   1420.37\n",
      "variational_beta * kldivergence:  0.14204\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30861\n",
      "kldivergence:   1364.09\n",
      "variational_beta * kldivergence:  0.13641\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30308\n",
      "kldivergence:   1302.12\n",
      "variational_beta * kldivergence:  0.13021\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30316\n",
      "kldivergence:   1274.76\n",
      "variational_beta * kldivergence:  0.12748\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29578\n",
      "kldivergence:   1471.32\n",
      "variational_beta * kldivergence:  0.14713\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34354\n",
      "kldivergence:   1517.80\n",
      "variational_beta * kldivergence:  0.15178\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30759\n",
      "kldivergence:   1545.65\n",
      "variational_beta * kldivergence:  0.15457\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34476\n",
      "kldivergence:   1503.34\n",
      "variational_beta * kldivergence:  0.15033\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31111\n",
      "kldivergence:   1468.35\n",
      "variational_beta * kldivergence:  0.14684\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36270\n",
      "kldivergence:   1588.46\n",
      "variational_beta * kldivergence:  0.15885\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.25132\n",
      "kldivergence:   1244.63\n",
      "variational_beta * kldivergence:  0.12446\n",
      "batch accuracy: 91.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29967\n",
      "kldivergence:   1469.05\n",
      "variational_beta * kldivergence:  0.14690\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36263\n",
      "kldivergence:   1457.37\n",
      "variational_beta * kldivergence:  0.14574\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30832\n",
      "kldivergence:   1280.25\n",
      "variational_beta * kldivergence:  0.12803\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29084\n",
      "kldivergence:   1305.07\n",
      "variational_beta * kldivergence:  0.13051\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.25802\n",
      "kldivergence:   1319.15\n",
      "variational_beta * kldivergence:  0.13192\n",
      "batch accuracy: 91.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32047\n",
      "kldivergence:   1453.99\n",
      "variational_beta * kldivergence:  0.14540\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33104\n",
      "kldivergence:   1440.43\n",
      "variational_beta * kldivergence:  0.14404\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30501\n",
      "kldivergence:   1406.80\n",
      "variational_beta * kldivergence:  0.14068\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35355\n",
      "kldivergence:   1721.88\n",
      "variational_beta * kldivergence:  0.17219\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30402\n",
      "kldivergence:   1375.76\n",
      "variational_beta * kldivergence:  0.13758\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32673\n",
      "kldivergence:   1485.25\n",
      "variational_beta * kldivergence:  0.14853\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33566\n",
      "kldivergence:   1327.65\n",
      "variational_beta * kldivergence:  0.13276\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29929\n",
      "kldivergence:   1396.76\n",
      "variational_beta * kldivergence:  0.13968\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28293\n",
      "kldivergence:   1401.36\n",
      "variational_beta * kldivergence:  0.14014\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33350\n",
      "kldivergence:   1343.92\n",
      "variational_beta * kldivergence:  0.13439\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33396\n",
      "kldivergence:   1405.39\n",
      "variational_beta * kldivergence:  0.14054\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35980\n",
      "kldivergence:   1504.11\n",
      "variational_beta * kldivergence:  0.15041\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28539\n",
      "kldivergence:   1394.17\n",
      "variational_beta * kldivergence:  0.13942\n",
      "batch accuracy: 90.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32761\n",
      "kldivergence:   1416.32\n",
      "variational_beta * kldivergence:  0.14163\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37298\n",
      "kldivergence:   1654.90\n",
      "variational_beta * kldivergence:  0.16549\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33202\n",
      "kldivergence:   1496.45\n",
      "variational_beta * kldivergence:  0.14964\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34347\n",
      "kldivergence:   1570.70\n",
      "variational_beta * kldivergence:  0.15707\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30444\n",
      "kldivergence:   1378.40\n",
      "variational_beta * kldivergence:  0.13784\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.26511\n",
      "kldivergence:   1517.25\n",
      "variational_beta * kldivergence:  0.15172\n",
      "batch accuracy: 90.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32423\n",
      "kldivergence:   1385.93\n",
      "variational_beta * kldivergence:  0.13859\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30624\n",
      "kldivergence:   1463.12\n",
      "variational_beta * kldivergence:  0.14631\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31704\n",
      "kldivergence:   1573.77\n",
      "variational_beta * kldivergence:  0.15738\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30984\n",
      "kldivergence:   1458.36\n",
      "variational_beta * kldivergence:  0.14584\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29507\n",
      "kldivergence:   1642.58\n",
      "variational_beta * kldivergence:  0.16426\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30856\n",
      "kldivergence:   1334.33\n",
      "variational_beta * kldivergence:  0.13343\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36246\n",
      "kldivergence:   1558.92\n",
      "variational_beta * kldivergence:  0.15589\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35188\n",
      "kldivergence:   1509.84\n",
      "variational_beta * kldivergence:  0.15098\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34373\n",
      "kldivergence:   1677.28\n",
      "variational_beta * kldivergence:  0.16773\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31408\n",
      "kldivergence:   1346.51\n",
      "variational_beta * kldivergence:  0.13465\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32119\n",
      "kldivergence:   1376.41\n",
      "variational_beta * kldivergence:  0.13764\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32286\n",
      "kldivergence:   1337.02\n",
      "variational_beta * kldivergence:  0.13370\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33344\n",
      "kldivergence:   1562.18\n",
      "variational_beta * kldivergence:  0.15622\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31043\n",
      "kldivergence:   1395.66\n",
      "variational_beta * kldivergence:  0.13957\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29667\n",
      "kldivergence:   1471.41\n",
      "variational_beta * kldivergence:  0.14714\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37419\n",
      "kldivergence:   1698.19\n",
      "variational_beta * kldivergence:  0.16982\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29026\n",
      "kldivergence:   1606.59\n",
      "variational_beta * kldivergence:  0.16066\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29295\n",
      "kldivergence:   1486.57\n",
      "variational_beta * kldivergence:  0.14866\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30669\n",
      "kldivergence:   1604.47\n",
      "variational_beta * kldivergence:  0.16045\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28714\n",
      "kldivergence:   1460.76\n",
      "variational_beta * kldivergence:  0.14608\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.27694\n",
      "kldivergence:   1380.45\n",
      "variational_beta * kldivergence:  0.13804\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31167\n",
      "kldivergence:   1520.21\n",
      "variational_beta * kldivergence:  0.15202\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33643\n",
      "kldivergence:   1745.93\n",
      "variational_beta * kldivergence:  0.17459\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33707\n",
      "kldivergence:   1539.39\n",
      "variational_beta * kldivergence:  0.15394\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28209\n",
      "kldivergence:   1591.95\n",
      "variational_beta * kldivergence:  0.15920\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32688\n",
      "kldivergence:   1426.23\n",
      "variational_beta * kldivergence:  0.14262\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28022\n",
      "kldivergence:   1540.13\n",
      "variational_beta * kldivergence:  0.15401\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31331\n",
      "kldivergence:   1691.93\n",
      "variational_beta * kldivergence:  0.16919\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29970\n",
      "kldivergence:   1316.50\n",
      "variational_beta * kldivergence:  0.13165\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33417\n",
      "kldivergence:   1418.99\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36757\n",
      "kldivergence:   1538.51\n",
      "variational_beta * kldivergence:  0.15385\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.26934\n",
      "kldivergence:   1257.27\n",
      "variational_beta * kldivergence:  0.12573\n",
      "batch accuracy: 90.82\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35313\n",
      "kldivergence:   1506.58\n",
      "variational_beta * kldivergence:  0.15066\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34781\n",
      "kldivergence:   1783.23\n",
      "variational_beta * kldivergence:  0.17832\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36012\n",
      "kldivergence:   1488.62\n",
      "variational_beta * kldivergence:  0.14886\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31613\n",
      "kldivergence:   1522.13\n",
      "variational_beta * kldivergence:  0.15221\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34274\n",
      "kldivergence:   1463.46\n",
      "variational_beta * kldivergence:  0.14635\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31595\n",
      "kldivergence:   1338.01\n",
      "variational_beta * kldivergence:  0.13380\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37280\n",
      "kldivergence:   1524.00\n",
      "variational_beta * kldivergence:  0.15240\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28250\n",
      "kldivergence:   1421.19\n",
      "variational_beta * kldivergence:  0.14212\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33085\n",
      "kldivergence:   1529.75\n",
      "variational_beta * kldivergence:  0.15298\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28925\n",
      "kldivergence:   1433.49\n",
      "variational_beta * kldivergence:  0.14335\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29949\n",
      "kldivergence:   1558.78\n",
      "variational_beta * kldivergence:  0.15588\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.27669\n",
      "kldivergence:   1511.58\n",
      "variational_beta * kldivergence:  0.15116\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.23519\n",
      "kldivergence:   1423.41\n",
      "variational_beta * kldivergence:  0.14234\n",
      "batch accuracy: 92.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32850\n",
      "kldivergence:   1496.69\n",
      "variational_beta * kldivergence:  0.14967\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34328\n",
      "kldivergence:   1505.51\n",
      "variational_beta * kldivergence:  0.15055\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30826\n",
      "kldivergence:   1312.24\n",
      "variational_beta * kldivergence:  0.13122\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36278\n",
      "kldivergence:   1548.06\n",
      "variational_beta * kldivergence:  0.15481\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30498\n",
      "kldivergence:   1381.02\n",
      "variational_beta * kldivergence:  0.13810\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34487\n",
      "kldivergence:   1539.10\n",
      "variational_beta * kldivergence:  0.15391\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29874\n",
      "kldivergence:   1476.43\n",
      "variational_beta * kldivergence:  0.14764\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31571\n",
      "kldivergence:   1420.09\n",
      "variational_beta * kldivergence:  0.14201\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35219\n",
      "kldivergence:   1602.40\n",
      "variational_beta * kldivergence:  0.16024\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33607\n",
      "kldivergence:   1561.64\n",
      "variational_beta * kldivergence:  0.15616\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35120\n",
      "kldivergence:   1604.58\n",
      "variational_beta * kldivergence:  0.16046\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.38833\n",
      "kldivergence:   1638.36\n",
      "variational_beta * kldivergence:  0.16384\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34679\n",
      "kldivergence:   1481.86\n",
      "variational_beta * kldivergence:  0.14819\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32513\n",
      "kldivergence:   1444.45\n",
      "variational_beta * kldivergence:  0.14444\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36311\n",
      "kldivergence:   1633.48\n",
      "variational_beta * kldivergence:  0.16335\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34616\n",
      "kldivergence:   1704.53\n",
      "variational_beta * kldivergence:  0.17045\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29526\n",
      "kldivergence:   1605.25\n",
      "variational_beta * kldivergence:  0.16052\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35022\n",
      "kldivergence:   1416.44\n",
      "variational_beta * kldivergence:  0.14164\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34050\n",
      "kldivergence:   1366.72\n",
      "variational_beta * kldivergence:  0.13667\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32243\n",
      "kldivergence:   1474.33\n",
      "variational_beta * kldivergence:  0.14743\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33942\n",
      "kldivergence:   1590.98\n",
      "variational_beta * kldivergence:  0.15910\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29561\n",
      "kldivergence:   1285.95\n",
      "variational_beta * kldivergence:  0.12860\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29957\n",
      "kldivergence:   1496.99\n",
      "variational_beta * kldivergence:  0.14970\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31906\n",
      "kldivergence:   1461.77\n",
      "variational_beta * kldivergence:  0.14618\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36983\n",
      "kldivergence:   1676.19\n",
      "variational_beta * kldivergence:  0.16762\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32608\n",
      "kldivergence:   1379.68\n",
      "variational_beta * kldivergence:  0.13797\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31652\n",
      "kldivergence:   1622.56\n",
      "variational_beta * kldivergence:  0.16226\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28863\n",
      "kldivergence:   1543.56\n",
      "variational_beta * kldivergence:  0.15436\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28851\n",
      "kldivergence:   1580.72\n",
      "variational_beta * kldivergence:  0.15807\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28070\n",
      "kldivergence:   1535.30\n",
      "variational_beta * kldivergence:  0.15353\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36671\n",
      "kldivergence:   1460.13\n",
      "variational_beta * kldivergence:  0.14601\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34667\n",
      "kldivergence:   1487.65\n",
      "variational_beta * kldivergence:  0.14877\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33058\n",
      "kldivergence:   1607.16\n",
      "variational_beta * kldivergence:  0.16072\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34855\n",
      "kldivergence:   1410.33\n",
      "variational_beta * kldivergence:  0.14103\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31028\n",
      "kldivergence:   1446.43\n",
      "variational_beta * kldivergence:  0.14464\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33349\n",
      "kldivergence:   1535.00\n",
      "variational_beta * kldivergence:  0.15350\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32459\n",
      "kldivergence:   1535.74\n",
      "variational_beta * kldivergence:  0.15357\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36902\n",
      "kldivergence:   1554.59\n",
      "variational_beta * kldivergence:  0.15546\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32875\n",
      "kldivergence:   1484.16\n",
      "variational_beta * kldivergence:  0.14842\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33173\n",
      "kldivergence:   1392.26\n",
      "variational_beta * kldivergence:  0.13923\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32587\n",
      "kldivergence:   1465.41\n",
      "variational_beta * kldivergence:  0.14654\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31089\n",
      "kldivergence:   1562.89\n",
      "variational_beta * kldivergence:  0.15629\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30458\n",
      "kldivergence:   1519.45\n",
      "variational_beta * kldivergence:  0.15195\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.24950\n",
      "kldivergence:   1270.09\n",
      "variational_beta * kldivergence:  0.12701\n",
      "batch accuracy: 91.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35593\n",
      "kldivergence:   1627.34\n",
      "variational_beta * kldivergence:  0.16273\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28420\n",
      "kldivergence:   1672.75\n",
      "variational_beta * kldivergence:  0.16728\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32021\n",
      "kldivergence:   1510.11\n",
      "variational_beta * kldivergence:  0.15101\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31601\n",
      "kldivergence:   1551.60\n",
      "variational_beta * kldivergence:  0.15516\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34703\n",
      "kldivergence:   1386.47\n",
      "variational_beta * kldivergence:  0.13865\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37950\n",
      "kldivergence:   1498.91\n",
      "variational_beta * kldivergence:  0.14989\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.43266\n",
      "kldivergence:   1799.85\n",
      "variational_beta * kldivergence:  0.17998\n",
      "batch accuracy: 85.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36902\n",
      "kldivergence:   1641.33\n",
      "variational_beta * kldivergence:  0.16413\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35685\n",
      "kldivergence:   1465.37\n",
      "variational_beta * kldivergence:  0.14654\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34015\n",
      "kldivergence:   1628.26\n",
      "variational_beta * kldivergence:  0.16283\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30778\n",
      "kldivergence:   1533.13\n",
      "variational_beta * kldivergence:  0.15331\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37822\n",
      "kldivergence:   1772.16\n",
      "variational_beta * kldivergence:  0.17722\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34971\n",
      "kldivergence:   1604.26\n",
      "variational_beta * kldivergence:  0.16043\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28447\n",
      "kldivergence:   1331.10\n",
      "variational_beta * kldivergence:  0.13311\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33382\n",
      "kldivergence:   1527.03\n",
      "variational_beta * kldivergence:  0.15270\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32584\n",
      "kldivergence:   1468.85\n",
      "variational_beta * kldivergence:  0.14688\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28267\n",
      "kldivergence:   1410.24\n",
      "variational_beta * kldivergence:  0.14102\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31834\n",
      "kldivergence:   1451.71\n",
      "variational_beta * kldivergence:  0.14517\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34958\n",
      "kldivergence:   1596.87\n",
      "variational_beta * kldivergence:  0.15969\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33676\n",
      "kldivergence:   1393.29\n",
      "variational_beta * kldivergence:  0.13933\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30429\n",
      "kldivergence:   1566.54\n",
      "variational_beta * kldivergence:  0.15665\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32623\n",
      "kldivergence:   1436.93\n",
      "variational_beta * kldivergence:  0.14369\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.27897\n",
      "kldivergence:   1277.06\n",
      "variational_beta * kldivergence:  0.12771\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32670\n",
      "kldivergence:   1649.20\n",
      "variational_beta * kldivergence:  0.16492\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31815\n",
      "kldivergence:   1650.87\n",
      "variational_beta * kldivergence:  0.16509\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33152\n",
      "kldivergence:   1291.72\n",
      "variational_beta * kldivergence:  0.12917\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34253\n",
      "kldivergence:   1402.81\n",
      "variational_beta * kldivergence:  0.14028\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32118\n",
      "kldivergence:   1440.96\n",
      "variational_beta * kldivergence:  0.14410\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35384\n",
      "kldivergence:   1646.47\n",
      "variational_beta * kldivergence:  0.16465\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30211\n",
      "kldivergence:   1529.79\n",
      "variational_beta * kldivergence:  0.15298\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32477\n",
      "kldivergence:   1454.55\n",
      "variational_beta * kldivergence:  0.14545\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32178\n",
      "kldivergence:   1536.18\n",
      "variational_beta * kldivergence:  0.15362\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30943\n",
      "kldivergence:   1389.31\n",
      "variational_beta * kldivergence:  0.13893\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30565\n",
      "kldivergence:   1415.45\n",
      "variational_beta * kldivergence:  0.14155\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.26951\n",
      "kldivergence:   1358.10\n",
      "variational_beta * kldivergence:  0.13581\n",
      "batch accuracy: 91.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32859\n",
      "kldivergence:   1340.34\n",
      "variational_beta * kldivergence:  0.13403\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32129\n",
      "kldivergence:   1400.74\n",
      "variational_beta * kldivergence:  0.14007\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35896\n",
      "kldivergence:   1452.93\n",
      "variational_beta * kldivergence:  0.14529\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33113\n",
      "kldivergence:   1508.25\n",
      "variational_beta * kldivergence:  0.15082\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31411\n",
      "kldivergence:   1468.44\n",
      "variational_beta * kldivergence:  0.14684\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29525\n",
      "kldivergence:   1417.78\n",
      "variational_beta * kldivergence:  0.14178\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29772\n",
      "kldivergence:   1435.69\n",
      "variational_beta * kldivergence:  0.14357\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33150\n",
      "kldivergence:   1423.55\n",
      "variational_beta * kldivergence:  0.14235\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35402\n",
      "kldivergence:   1594.97\n",
      "variational_beta * kldivergence:  0.15950\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29684\n",
      "kldivergence:   1357.95\n",
      "variational_beta * kldivergence:  0.13579\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32247\n",
      "kldivergence:   1480.13\n",
      "variational_beta * kldivergence:  0.14801\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36888\n",
      "kldivergence:   1634.55\n",
      "variational_beta * kldivergence:  0.16345\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36033\n",
      "kldivergence:   1565.35\n",
      "variational_beta * kldivergence:  0.15653\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31708\n",
      "kldivergence:   1402.88\n",
      "variational_beta * kldivergence:  0.14029\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29309\n",
      "kldivergence:   1565.28\n",
      "variational_beta * kldivergence:  0.15653\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33686\n",
      "kldivergence:   1621.82\n",
      "variational_beta * kldivergence:  0.16218\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36177\n",
      "kldivergence:   1550.03\n",
      "variational_beta * kldivergence:  0.15500\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31741\n",
      "kldivergence:   1654.72\n",
      "variational_beta * kldivergence:  0.16547\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28126\n",
      "kldivergence:   1452.16\n",
      "variational_beta * kldivergence:  0.14522\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36613\n",
      "kldivergence:   1591.53\n",
      "variational_beta * kldivergence:  0.15915\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30923\n",
      "kldivergence:   1225.57\n",
      "variational_beta * kldivergence:  0.12256\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33628\n",
      "kldivergence:   1435.90\n",
      "variational_beta * kldivergence:  0.14359\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31652\n",
      "kldivergence:   1434.94\n",
      "variational_beta * kldivergence:  0.14349\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32915\n",
      "kldivergence:   1502.86\n",
      "variational_beta * kldivergence:  0.15029\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29961\n",
      "kldivergence:   1253.22\n",
      "variational_beta * kldivergence:  0.12532\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37629\n",
      "kldivergence:   1667.44\n",
      "variational_beta * kldivergence:  0.16674\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30536\n",
      "kldivergence:   1483.83\n",
      "variational_beta * kldivergence:  0.14838\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34260\n",
      "kldivergence:   1623.67\n",
      "variational_beta * kldivergence:  0.16237\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36997\n",
      "kldivergence:   1415.00\n",
      "variational_beta * kldivergence:  0.14150\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32148\n",
      "kldivergence:   1398.21\n",
      "variational_beta * kldivergence:  0.13982\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32008\n",
      "kldivergence:   1433.78\n",
      "variational_beta * kldivergence:  0.14338\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36003\n",
      "kldivergence:   1381.48\n",
      "variational_beta * kldivergence:  0.13815\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29160\n",
      "kldivergence:   1312.15\n",
      "variational_beta * kldivergence:  0.13121\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.27828\n",
      "kldivergence:   1450.93\n",
      "variational_beta * kldivergence:  0.14509\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36399\n",
      "kldivergence:   1495.70\n",
      "variational_beta * kldivergence:  0.14957\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30248\n",
      "kldivergence:   1350.84\n",
      "variational_beta * kldivergence:  0.13508\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30142\n",
      "kldivergence:   1745.60\n",
      "variational_beta * kldivergence:  0.17456\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32231\n",
      "kldivergence:   1526.92\n",
      "variational_beta * kldivergence:  0.15269\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33632\n",
      "kldivergence:   1449.99\n",
      "variational_beta * kldivergence:  0.14500\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33753\n",
      "kldivergence:   1512.15\n",
      "variational_beta * kldivergence:  0.15122\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34237\n",
      "kldivergence:   1700.79\n",
      "variational_beta * kldivergence:  0.17008\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32423\n",
      "kldivergence:   1433.40\n",
      "variational_beta * kldivergence:  0.14334\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31505\n",
      "kldivergence:   1445.63\n",
      "variational_beta * kldivergence:  0.14456\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35862\n",
      "kldivergence:   1425.24\n",
      "variational_beta * kldivergence:  0.14252\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33910\n",
      "kldivergence:   1496.86\n",
      "variational_beta * kldivergence:  0.14969\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29300\n",
      "kldivergence:   1412.59\n",
      "variational_beta * kldivergence:  0.14126\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28382\n",
      "kldivergence:   1383.06\n",
      "variational_beta * kldivergence:  0.13831\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34477\n",
      "kldivergence:   1476.11\n",
      "variational_beta * kldivergence:  0.14761\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30160\n",
      "kldivergence:   1236.54\n",
      "variational_beta * kldivergence:  0.12365\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37067\n",
      "kldivergence:   1439.66\n",
      "variational_beta * kldivergence:  0.14397\n",
      "batch accuracy: 87.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36922\n",
      "kldivergence:   1518.94\n",
      "variational_beta * kldivergence:  0.15189\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.38973\n",
      "kldivergence:   1510.16\n",
      "variational_beta * kldivergence:  0.15102\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31408\n",
      "kldivergence:   1378.24\n",
      "variational_beta * kldivergence:  0.13782\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29489\n",
      "kldivergence:   1375.11\n",
      "variational_beta * kldivergence:  0.13751\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33032\n",
      "kldivergence:   1386.42\n",
      "variational_beta * kldivergence:  0.13864\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37099\n",
      "kldivergence:   1594.12\n",
      "variational_beta * kldivergence:  0.15941\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.27829\n",
      "kldivergence:   1574.24\n",
      "variational_beta * kldivergence:  0.15742\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31995\n",
      "kldivergence:   1641.95\n",
      "variational_beta * kldivergence:  0.16420\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33249\n",
      "kldivergence:   1595.06\n",
      "variational_beta * kldivergence:  0.15951\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34316\n",
      "kldivergence:   1505.11\n",
      "variational_beta * kldivergence:  0.15051\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34931\n",
      "kldivergence:   1551.16\n",
      "variational_beta * kldivergence:  0.15512\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33027\n",
      "kldivergence:   1625.85\n",
      "variational_beta * kldivergence:  0.16258\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37260\n",
      "kldivergence:   1679.73\n",
      "variational_beta * kldivergence:  0.16797\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34582\n",
      "kldivergence:   1500.11\n",
      "variational_beta * kldivergence:  0.15001\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28309\n",
      "kldivergence:   1452.88\n",
      "variational_beta * kldivergence:  0.14529\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33752\n",
      "kldivergence:   1329.82\n",
      "variational_beta * kldivergence:  0.13298\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32285\n",
      "kldivergence:   1605.44\n",
      "variational_beta * kldivergence:  0.16054\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31800\n",
      "kldivergence:   1598.06\n",
      "variational_beta * kldivergence:  0.15981\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28574\n",
      "kldivergence:   1544.01\n",
      "variational_beta * kldivergence:  0.15440\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35907\n",
      "kldivergence:   1602.68\n",
      "variational_beta * kldivergence:  0.16027\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32135\n",
      "kldivergence:   1629.37\n",
      "variational_beta * kldivergence:  0.16294\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30079\n",
      "kldivergence:   1348.46\n",
      "variational_beta * kldivergence:  0.13485\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32805\n",
      "kldivergence:   1368.68\n",
      "variational_beta * kldivergence:  0.13687\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28965\n",
      "kldivergence:   1423.74\n",
      "variational_beta * kldivergence:  0.14237\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36835\n",
      "kldivergence:   1742.86\n",
      "variational_beta * kldivergence:  0.17429\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34476\n",
      "kldivergence:   1635.73\n",
      "variational_beta * kldivergence:  0.16357\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28456\n",
      "kldivergence:   1685.22\n",
      "variational_beta * kldivergence:  0.16852\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37638\n",
      "kldivergence:   1795.17\n",
      "variational_beta * kldivergence:  0.17952\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32918\n",
      "kldivergence:   1466.91\n",
      "variational_beta * kldivergence:  0.14669\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29227\n",
      "kldivergence:   1463.31\n",
      "variational_beta * kldivergence:  0.14633\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30048\n",
      "kldivergence:   1529.52\n",
      "variational_beta * kldivergence:  0.15295\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34855\n",
      "kldivergence:   1435.70\n",
      "variational_beta * kldivergence:  0.14357\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32428\n",
      "kldivergence:   1443.93\n",
      "variational_beta * kldivergence:  0.14439\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.25143\n",
      "kldivergence:   1464.93\n",
      "variational_beta * kldivergence:  0.14649\n",
      "batch accuracy: 91.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30896\n",
      "kldivergence:   1547.99\n",
      "variational_beta * kldivergence:  0.15480\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.27562\n",
      "kldivergence:   1422.54\n",
      "variational_beta * kldivergence:  0.14225\n",
      "batch accuracy: 91.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30281\n",
      "kldivergence:   1501.60\n",
      "variational_beta * kldivergence:  0.15016\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33951\n",
      "kldivergence:   1591.43\n",
      "variational_beta * kldivergence:  0.15914\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35192\n",
      "kldivergence:   1748.95\n",
      "variational_beta * kldivergence:  0.17490\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34959\n",
      "kldivergence:   1703.07\n",
      "variational_beta * kldivergence:  0.17031\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30277\n",
      "kldivergence:   1520.82\n",
      "variational_beta * kldivergence:  0.15208\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.39193\n",
      "kldivergence:   1809.70\n",
      "variational_beta * kldivergence:  0.18097\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37103\n",
      "kldivergence:   1515.63\n",
      "variational_beta * kldivergence:  0.15156\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33001\n",
      "kldivergence:   1685.63\n",
      "variational_beta * kldivergence:  0.16856\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33566\n",
      "kldivergence:   1547.54\n",
      "variational_beta * kldivergence:  0.15475\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33326\n",
      "kldivergence:   1597.64\n",
      "variational_beta * kldivergence:  0.15976\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30526\n",
      "kldivergence:   1525.73\n",
      "variational_beta * kldivergence:  0.15257\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34290\n",
      "kldivergence:   1507.88\n",
      "variational_beta * kldivergence:  0.15079\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33764\n",
      "kldivergence:   1581.47\n",
      "variational_beta * kldivergence:  0.15815\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30581\n",
      "kldivergence:   1458.01\n",
      "variational_beta * kldivergence:  0.14580\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33002\n",
      "kldivergence:   1318.65\n",
      "variational_beta * kldivergence:  0.13186\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33451\n",
      "kldivergence:   1562.46\n",
      "variational_beta * kldivergence:  0.15625\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31864\n",
      "kldivergence:   1422.95\n",
      "variational_beta * kldivergence:  0.14229\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32310\n",
      "kldivergence:   1472.83\n",
      "variational_beta * kldivergence:  0.14728\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35188\n",
      "kldivergence:   1764.56\n",
      "variational_beta * kldivergence:  0.17646\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34395\n",
      "kldivergence:   1629.12\n",
      "variational_beta * kldivergence:  0.16291\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.28330\n",
      "kldivergence:   1504.80\n",
      "variational_beta * kldivergence:  0.15048\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.38005\n",
      "kldivergence:   1750.80\n",
      "variational_beta * kldivergence:  0.17508\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32494\n",
      "kldivergence:   1495.74\n",
      "variational_beta * kldivergence:  0.14957\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30418\n",
      "kldivergence:   1567.89\n",
      "variational_beta * kldivergence:  0.15679\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33913\n",
      "kldivergence:   1576.16\n",
      "variational_beta * kldivergence:  0.15762\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34499\n",
      "kldivergence:   1517.55\n",
      "variational_beta * kldivergence:  0.15175\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34900\n",
      "kldivergence:   1604.16\n",
      "variational_beta * kldivergence:  0.16042\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29844\n",
      "kldivergence:   1420.16\n",
      "variational_beta * kldivergence:  0.14202\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32178\n",
      "kldivergence:   1464.54\n",
      "variational_beta * kldivergence:  0.14645\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30437\n",
      "kldivergence:   1330.01\n",
      "variational_beta * kldivergence:  0.13300\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30075\n",
      "kldivergence:   1598.36\n",
      "variational_beta * kldivergence:  0.15984\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33493\n",
      "kldivergence:   1455.43\n",
      "variational_beta * kldivergence:  0.14554\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33992\n",
      "kldivergence:   1571.75\n",
      "variational_beta * kldivergence:  0.15717\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30754\n",
      "kldivergence:   1512.63\n",
      "variational_beta * kldivergence:  0.15126\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33395\n",
      "kldivergence:   1893.25\n",
      "variational_beta * kldivergence:  0.18932\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31794\n",
      "kldivergence:   1439.57\n",
      "variational_beta * kldivergence:  0.14396\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37796\n",
      "kldivergence:   1577.09\n",
      "variational_beta * kldivergence:  0.15771\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29141\n",
      "kldivergence:   1259.42\n",
      "variational_beta * kldivergence:  0.12594\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31205\n",
      "kldivergence:   1453.76\n",
      "variational_beta * kldivergence:  0.14538\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29354\n",
      "kldivergence:   1527.66\n",
      "variational_beta * kldivergence:  0.15277\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33776\n",
      "kldivergence:   1544.00\n",
      "variational_beta * kldivergence:  0.15440\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36011\n",
      "kldivergence:   1644.61\n",
      "variational_beta * kldivergence:  0.16446\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33885\n",
      "kldivergence:   1509.43\n",
      "variational_beta * kldivergence:  0.15094\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.38225\n",
      "kldivergence:   1639.20\n",
      "variational_beta * kldivergence:  0.16392\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30148\n",
      "kldivergence:   1361.66\n",
      "variational_beta * kldivergence:  0.13617\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30453\n",
      "kldivergence:   1599.61\n",
      "variational_beta * kldivergence:  0.15996\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31130\n",
      "kldivergence:   1417.13\n",
      "variational_beta * kldivergence:  0.14171\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33557\n",
      "kldivergence:   1517.60\n",
      "variational_beta * kldivergence:  0.15176\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36085\n",
      "kldivergence:   1393.26\n",
      "variational_beta * kldivergence:  0.13933\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33887\n",
      "kldivergence:   1572.60\n",
      "variational_beta * kldivergence:  0.15726\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.36238\n",
      "kldivergence:   1495.38\n",
      "variational_beta * kldivergence:  0.14954\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31864\n",
      "kldivergence:   1574.82\n",
      "variational_beta * kldivergence:  0.15748\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31286\n",
      "kldivergence:   1367.80\n",
      "variational_beta * kldivergence:  0.13678\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30028\n",
      "kldivergence:   1540.89\n",
      "variational_beta * kldivergence:  0.15409\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29842\n",
      "kldivergence:   1341.53\n",
      "variational_beta * kldivergence:  0.13415\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32133\n",
      "kldivergence:   1461.08\n",
      "variational_beta * kldivergence:  0.14611\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35827\n",
      "kldivergence:   1598.15\n",
      "variational_beta * kldivergence:  0.15981\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37434\n",
      "kldivergence:   1694.29\n",
      "variational_beta * kldivergence:  0.16943\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35007\n",
      "kldivergence:   1561.15\n",
      "variational_beta * kldivergence:  0.15612\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32963\n",
      "kldivergence:   1501.30\n",
      "variational_beta * kldivergence:  0.15013\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29073\n",
      "kldivergence:   1708.87\n",
      "variational_beta * kldivergence:  0.17089\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34975\n",
      "kldivergence:   1560.48\n",
      "variational_beta * kldivergence:  0.15605\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33881\n",
      "kldivergence:   1472.56\n",
      "variational_beta * kldivergence:  0.14726\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29659\n",
      "kldivergence:   1546.18\n",
      "variational_beta * kldivergence:  0.15462\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34483\n",
      "kldivergence:   1610.57\n",
      "variational_beta * kldivergence:  0.16106\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29896\n",
      "kldivergence:   1397.86\n",
      "variational_beta * kldivergence:  0.13979\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31533\n",
      "kldivergence:   1658.18\n",
      "variational_beta * kldivergence:  0.16582\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31013\n",
      "kldivergence:   1543.86\n",
      "variational_beta * kldivergence:  0.15439\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31473\n",
      "kldivergence:   1483.81\n",
      "variational_beta * kldivergence:  0.14838\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29526\n",
      "kldivergence:   1429.78\n",
      "variational_beta * kldivergence:  0.14298\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32665\n",
      "kldivergence:   1657.52\n",
      "variational_beta * kldivergence:  0.16575\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33691\n",
      "kldivergence:   1474.92\n",
      "variational_beta * kldivergence:  0.14749\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30988\n",
      "kldivergence:   1504.08\n",
      "variational_beta * kldivergence:  0.15041\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.37090\n",
      "kldivergence:   1702.06\n",
      "variational_beta * kldivergence:  0.17021\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33529\n",
      "kldivergence:   1566.79\n",
      "variational_beta * kldivergence:  0.15668\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35727\n",
      "kldivergence:   1432.04\n",
      "variational_beta * kldivergence:  0.14320\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34129\n",
      "kldivergence:   1540.27\n",
      "variational_beta * kldivergence:  0.15403\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34910\n",
      "kldivergence:   1536.41\n",
      "variational_beta * kldivergence:  0.15364\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35538\n",
      "kldivergence:   1558.15\n",
      "variational_beta * kldivergence:  0.15582\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30164\n",
      "kldivergence:   1414.34\n",
      "variational_beta * kldivergence:  0.14143\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33862\n",
      "kldivergence:   1680.52\n",
      "variational_beta * kldivergence:  0.16805\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33491\n",
      "kldivergence:   1367.58\n",
      "variational_beta * kldivergence:  0.13676\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30624\n",
      "kldivergence:   1355.33\n",
      "variational_beta * kldivergence:  0.13553\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33829\n",
      "kldivergence:   1407.04\n",
      "variational_beta * kldivergence:  0.14070\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32802\n",
      "kldivergence:   1564.40\n",
      "variational_beta * kldivergence:  0.15644\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31307\n",
      "kldivergence:   1545.66\n",
      "variational_beta * kldivergence:  0.15457\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.33682\n",
      "kldivergence:   1581.70\n",
      "variational_beta * kldivergence:  0.15817\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35487\n",
      "kldivergence:   1549.57\n",
      "variational_beta * kldivergence:  0.15496\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.35042\n",
      "kldivergence:   1538.31\n",
      "variational_beta * kldivergence:  0.15383\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31274\n",
      "kldivergence:   1656.85\n",
      "variational_beta * kldivergence:  0.16569\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29270\n",
      "kldivergence:   1421.22\n",
      "variational_beta * kldivergence:  0.14212\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.31868\n",
      "kldivergence:   1470.06\n",
      "variational_beta * kldivergence:  0.14701\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30969\n",
      "kldivergence:   1478.00\n",
      "variational_beta * kldivergence:  0.14780\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.32128\n",
      "kldivergence:   1458.75\n",
      "variational_beta * kldivergence:  0.14588\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.34131\n",
      "kldivergence:   1563.85\n",
      "variational_beta * kldivergence:  0.15638\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.30661\n",
      "kldivergence:   1504.39\n",
      "variational_beta * kldivergence:  0.15044\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.27746\n",
      "kldivergence:   1384.90\n",
      "variational_beta * kldivergence:  0.13849\n",
      "batch accuracy: 90.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #55\n",
      "reconstruction loss: 0.29978\n",
      "kldivergence:   1398.97\n",
      "variational_beta * kldivergence:  0.13990\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.44362\n",
      "kldivergence:   1409.94\n",
      "variational_beta * kldivergence:  0.14099\n",
      "batch accuracy: 85.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.38964\n",
      "kldivergence:   1439.43\n",
      "variational_beta * kldivergence:  0.14394\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.45597\n",
      "kldivergence:   1470.96\n",
      "variational_beta * kldivergence:  0.14710\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.51191\n",
      "kldivergence:   1467.99\n",
      "variational_beta * kldivergence:  0.14680\n",
      "batch accuracy: 84.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.47000\n",
      "kldivergence:   1440.25\n",
      "variational_beta * kldivergence:  0.14402\n",
      "batch accuracy: 85.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.40410\n",
      "kldivergence:   1417.97\n",
      "variational_beta * kldivergence:  0.14180\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.36021\n",
      "kldivergence:   1220.55\n",
      "variational_beta * kldivergence:  0.12206\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.36229\n",
      "kldivergence:   1248.41\n",
      "variational_beta * kldivergence:  0.12484\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.42809\n",
      "kldivergence:   1333.45\n",
      "variational_beta * kldivergence:  0.13335\n",
      "batch accuracy: 86.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.39696\n",
      "kldivergence:   1254.92\n",
      "variational_beta * kldivergence:  0.12549\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.44971\n",
      "kldivergence:   1429.43\n",
      "variational_beta * kldivergence:  0.14294\n",
      "batch accuracy: 85.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.36770\n",
      "kldivergence:   1319.91\n",
      "variational_beta * kldivergence:  0.13199\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.48475\n",
      "kldivergence:   1428.66\n",
      "variational_beta * kldivergence:  0.14287\n",
      "batch accuracy: 85.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.41557\n",
      "kldivergence:   1383.58\n",
      "variational_beta * kldivergence:  0.13836\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.40673\n",
      "kldivergence:   1299.80\n",
      "variational_beta * kldivergence:  0.12998\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.49861\n",
      "kldivergence:   1492.17\n",
      "variational_beta * kldivergence:  0.14922\n",
      "batch accuracy: 84.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.54474\n",
      "kldivergence:   1511.07\n",
      "variational_beta * kldivergence:  0.15111\n",
      "batch accuracy: 83.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.47727\n",
      "kldivergence:   1613.44\n",
      "variational_beta * kldivergence:  0.16134\n",
      "batch accuracy: 84.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.45552\n",
      "kldivergence:   1521.88\n",
      "variational_beta * kldivergence:  0.15219\n",
      "batch accuracy: 85.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.48897\n",
      "kldivergence:   1463.23\n",
      "variational_beta * kldivergence:  0.14632\n",
      "batch accuracy: 84.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.52467\n",
      "kldivergence:   1561.84\n",
      "variational_beta * kldivergence:  0.15618\n",
      "batch accuracy: 83.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.43311\n",
      "kldivergence:   1321.85\n",
      "variational_beta * kldivergence:  0.13219\n",
      "batch accuracy: 86.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.48547\n",
      "kldivergence:   1405.65\n",
      "variational_beta * kldivergence:  0.14056\n",
      "batch accuracy: 85.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.35397\n",
      "kldivergence:   1242.78\n",
      "variational_beta * kldivergence:  0.12428\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.43884\n",
      "kldivergence:   1466.81\n",
      "variational_beta * kldivergence:  0.14668\n",
      "batch accuracy: 86.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.46948\n",
      "kldivergence:   1420.23\n",
      "variational_beta * kldivergence:  0.14202\n",
      "batch accuracy: 84.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.49101\n",
      "kldivergence:   1307.97\n",
      "variational_beta * kldivergence:  0.13080\n",
      "batch accuracy: 85.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.44863\n",
      "kldivergence:   1459.48\n",
      "variational_beta * kldivergence:  0.14595\n",
      "batch accuracy: 86.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.53491\n",
      "kldivergence:   1446.09\n",
      "variational_beta * kldivergence:  0.14461\n",
      "batch accuracy: 83.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.42291\n",
      "kldivergence:   1284.23\n",
      "variational_beta * kldivergence:  0.12842\n",
      "batch accuracy: 86.86\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.51443\n",
      "kldivergence:   1426.75\n",
      "variational_beta * kldivergence:  0.14268\n",
      "batch accuracy: 84.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.40231\n",
      "kldivergence:   1359.27\n",
      "variational_beta * kldivergence:  0.13593\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.40063\n",
      "kldivergence:   1347.20\n",
      "variational_beta * kldivergence:  0.13472\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.47132\n",
      "kldivergence:   1406.70\n",
      "variational_beta * kldivergence:  0.14067\n",
      "batch accuracy: 85.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.45318\n",
      "kldivergence:   1459.26\n",
      "variational_beta * kldivergence:  0.14593\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.50002\n",
      "kldivergence:   1568.38\n",
      "variational_beta * kldivergence:  0.15684\n",
      "batch accuracy: 84.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.46113\n",
      "kldivergence:   1454.76\n",
      "variational_beta * kldivergence:  0.14548\n",
      "batch accuracy: 85.45\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.47808\n",
      "kldivergence:   1428.04\n",
      "variational_beta * kldivergence:  0.14280\n",
      "batch accuracy: 85.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.35467\n",
      "kldivergence:   1265.70\n",
      "variational_beta * kldivergence:  0.12657\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.49988\n",
      "kldivergence:   1416.23\n",
      "variational_beta * kldivergence:  0.14162\n",
      "batch accuracy: 85.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.45159\n",
      "kldivergence:   1412.97\n",
      "variational_beta * kldivergence:  0.14130\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.46578\n",
      "kldivergence:   1361.34\n",
      "variational_beta * kldivergence:  0.13613\n",
      "batch accuracy: 86.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.53207\n",
      "kldivergence:   1429.36\n",
      "variational_beta * kldivergence:  0.14294\n",
      "batch accuracy: 84.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.41134\n",
      "kldivergence:   1309.88\n",
      "variational_beta * kldivergence:  0.13099\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.53156\n",
      "kldivergence:   1468.97\n",
      "variational_beta * kldivergence:  0.14690\n",
      "batch accuracy: 85.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.45691\n",
      "kldivergence:   1455.19\n",
      "variational_beta * kldivergence:  0.14552\n",
      "batch accuracy: 85.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.43117\n",
      "kldivergence:   1288.92\n",
      "variational_beta * kldivergence:  0.12889\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.39060\n",
      "kldivergence:   1396.52\n",
      "variational_beta * kldivergence:  0.13965\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.50332\n",
      "kldivergence:   1492.48\n",
      "variational_beta * kldivergence:  0.14925\n",
      "batch accuracy: 84.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.52843\n",
      "kldivergence:   1440.38\n",
      "variational_beta * kldivergence:  0.14404\n",
      "batch accuracy: 83.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.31686\n",
      "kldivergence:   1149.99\n",
      "variational_beta * kldivergence:  0.11500\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.45340\n",
      "kldivergence:   1585.66\n",
      "variational_beta * kldivergence:  0.15857\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.49720\n",
      "kldivergence:   1511.29\n",
      "variational_beta * kldivergence:  0.15113\n",
      "batch accuracy: 84.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.41317\n",
      "kldivergence:   1262.50\n",
      "variational_beta * kldivergence:  0.12625\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.37990\n",
      "kldivergence:   1409.76\n",
      "variational_beta * kldivergence:  0.14098\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.44837\n",
      "kldivergence:   1335.05\n",
      "variational_beta * kldivergence:  0.13351\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.47182\n",
      "kldivergence:   1494.61\n",
      "variational_beta * kldivergence:  0.14946\n",
      "batch accuracy: 85.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.44865\n",
      "kldivergence:   1340.73\n",
      "variational_beta * kldivergence:  0.13407\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.45298\n",
      "kldivergence:   1408.84\n",
      "variational_beta * kldivergence:  0.14088\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.43603\n",
      "kldivergence:   1421.48\n",
      "variational_beta * kldivergence:  0.14215\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.38059\n",
      "kldivergence:   1256.95\n",
      "variational_beta * kldivergence:  0.12570\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #55\n",
      "reconstruction loss: 0.50142\n",
      "kldivergence:   1337.38\n",
      "variational_beta * kldivergence:  0.13374\n",
      "batch accuracy: 85.53\n",
      "\n",
      "\n",
      "epoch # 55 : train loss is [176.39504979174518] and validation loss is [0.0987384765255529] \n",
      "Epoch [56 / 150] average reconstruction error: 0.475458\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36751\n",
      "kldivergence:   1642.94\n",
      "variational_beta * kldivergence:  0.16429\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32188\n",
      "kldivergence:   1541.76\n",
      "variational_beta * kldivergence:  0.15418\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29785\n",
      "kldivergence:   1321.40\n",
      "variational_beta * kldivergence:  0.13214\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31485\n",
      "kldivergence:   1368.94\n",
      "variational_beta * kldivergence:  0.13689\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33105\n",
      "kldivergence:   1651.87\n",
      "variational_beta * kldivergence:  0.16519\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29903\n",
      "kldivergence:   1457.43\n",
      "variational_beta * kldivergence:  0.14574\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31472\n",
      "kldivergence:   1363.09\n",
      "variational_beta * kldivergence:  0.13631\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36113\n",
      "kldivergence:   1537.04\n",
      "variational_beta * kldivergence:  0.15370\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28323\n",
      "kldivergence:   1411.43\n",
      "variational_beta * kldivergence:  0.14114\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.26716\n",
      "kldivergence:   1544.32\n",
      "variational_beta * kldivergence:  0.15443\n",
      "batch accuracy: 90.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30798\n",
      "kldivergence:   1535.36\n",
      "variational_beta * kldivergence:  0.15354\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36521\n",
      "kldivergence:   1582.09\n",
      "variational_beta * kldivergence:  0.15821\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32065\n",
      "kldivergence:   1340.63\n",
      "variational_beta * kldivergence:  0.13406\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.25605\n",
      "kldivergence:   1198.72\n",
      "variational_beta * kldivergence:  0.11987\n",
      "batch accuracy: 91.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32838\n",
      "kldivergence:   1634.87\n",
      "variational_beta * kldivergence:  0.16349\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31571\n",
      "kldivergence:   1349.92\n",
      "variational_beta * kldivergence:  0.13499\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33302\n",
      "kldivergence:   1437.16\n",
      "variational_beta * kldivergence:  0.14372\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31285\n",
      "kldivergence:   1458.87\n",
      "variational_beta * kldivergence:  0.14589\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31981\n",
      "kldivergence:   1657.59\n",
      "variational_beta * kldivergence:  0.16576\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36518\n",
      "kldivergence:   1617.23\n",
      "variational_beta * kldivergence:  0.16172\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33506\n",
      "kldivergence:   1712.94\n",
      "variational_beta * kldivergence:  0.17129\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34998\n",
      "kldivergence:   1401.16\n",
      "variational_beta * kldivergence:  0.14012\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31304\n",
      "kldivergence:   1538.48\n",
      "variational_beta * kldivergence:  0.15385\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30793\n",
      "kldivergence:   1617.00\n",
      "variational_beta * kldivergence:  0.16170\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33900\n",
      "kldivergence:   1437.15\n",
      "variational_beta * kldivergence:  0.14371\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.39561\n",
      "kldivergence:   1621.15\n",
      "variational_beta * kldivergence:  0.16212\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.40051\n",
      "kldivergence:   1756.77\n",
      "variational_beta * kldivergence:  0.17568\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35044\n",
      "kldivergence:   1587.58\n",
      "variational_beta * kldivergence:  0.15876\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31468\n",
      "kldivergence:   1569.24\n",
      "variational_beta * kldivergence:  0.15692\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28587\n",
      "kldivergence:   1350.59\n",
      "variational_beta * kldivergence:  0.13506\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30627\n",
      "kldivergence:   1468.25\n",
      "variational_beta * kldivergence:  0.14683\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36028\n",
      "kldivergence:   1598.12\n",
      "variational_beta * kldivergence:  0.15981\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32505\n",
      "kldivergence:   1503.92\n",
      "variational_beta * kldivergence:  0.15039\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36905\n",
      "kldivergence:   1821.49\n",
      "variational_beta * kldivergence:  0.18215\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36763\n",
      "kldivergence:   1656.80\n",
      "variational_beta * kldivergence:  0.16568\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35205\n",
      "kldivergence:   1490.79\n",
      "variational_beta * kldivergence:  0.14908\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29183\n",
      "kldivergence:   1525.24\n",
      "variational_beta * kldivergence:  0.15252\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.38234\n",
      "kldivergence:   1791.09\n",
      "variational_beta * kldivergence:  0.17911\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31442\n",
      "kldivergence:   1423.65\n",
      "variational_beta * kldivergence:  0.14237\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30896\n",
      "kldivergence:   1431.89\n",
      "variational_beta * kldivergence:  0.14319\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36735\n",
      "kldivergence:   1876.51\n",
      "variational_beta * kldivergence:  0.18765\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30283\n",
      "kldivergence:   1598.27\n",
      "variational_beta * kldivergence:  0.15983\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31691\n",
      "kldivergence:   1305.73\n",
      "variational_beta * kldivergence:  0.13057\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34877\n",
      "kldivergence:   1650.02\n",
      "variational_beta * kldivergence:  0.16500\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35642\n",
      "kldivergence:   1653.51\n",
      "variational_beta * kldivergence:  0.16535\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32708\n",
      "kldivergence:   1757.04\n",
      "variational_beta * kldivergence:  0.17570\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32172\n",
      "kldivergence:   1440.99\n",
      "variational_beta * kldivergence:  0.14410\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34868\n",
      "kldivergence:   1682.97\n",
      "variational_beta * kldivergence:  0.16830\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30877\n",
      "kldivergence:   1466.47\n",
      "variational_beta * kldivergence:  0.14665\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32548\n",
      "kldivergence:   1672.38\n",
      "variational_beta * kldivergence:  0.16724\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32378\n",
      "kldivergence:   1520.28\n",
      "variational_beta * kldivergence:  0.15203\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33025\n",
      "kldivergence:   1296.61\n",
      "variational_beta * kldivergence:  0.12966\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31861\n",
      "kldivergence:   1523.35\n",
      "variational_beta * kldivergence:  0.15233\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31177\n",
      "kldivergence:   1537.29\n",
      "variational_beta * kldivergence:  0.15373\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.26259\n",
      "kldivergence:   2039.48\n",
      "variational_beta * kldivergence:  0.20395\n",
      "batch accuracy: 91.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35799\n",
      "kldivergence:   1544.63\n",
      "variational_beta * kldivergence:  0.15446\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30653\n",
      "kldivergence:   1478.69\n",
      "variational_beta * kldivergence:  0.14787\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28295\n",
      "kldivergence:   1436.27\n",
      "variational_beta * kldivergence:  0.14363\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.40340\n",
      "kldivergence:   1537.37\n",
      "variational_beta * kldivergence:  0.15374\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30027\n",
      "kldivergence:   1408.36\n",
      "variational_beta * kldivergence:  0.14084\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30958\n",
      "kldivergence:   1449.19\n",
      "variational_beta * kldivergence:  0.14492\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33317\n",
      "kldivergence:   1508.55\n",
      "variational_beta * kldivergence:  0.15086\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31244\n",
      "kldivergence:   1363.97\n",
      "variational_beta * kldivergence:  0.13640\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29397\n",
      "kldivergence:   1355.85\n",
      "variational_beta * kldivergence:  0.13559\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31395\n",
      "kldivergence:   1474.46\n",
      "variational_beta * kldivergence:  0.14745\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32824\n",
      "kldivergence:   1445.42\n",
      "variational_beta * kldivergence:  0.14454\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.26838\n",
      "kldivergence:   1266.54\n",
      "variational_beta * kldivergence:  0.12665\n",
      "batch accuracy: 91.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28958\n",
      "kldivergence:   1483.58\n",
      "variational_beta * kldivergence:  0.14836\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28892\n",
      "kldivergence:   1405.32\n",
      "variational_beta * kldivergence:  0.14053\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.26774\n",
      "kldivergence:   1237.30\n",
      "variational_beta * kldivergence:  0.12373\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.26407\n",
      "kldivergence:   1210.43\n",
      "variational_beta * kldivergence:  0.12104\n",
      "batch accuracy: 91.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34887\n",
      "kldivergence:   1494.84\n",
      "variational_beta * kldivergence:  0.14948\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29147\n",
      "kldivergence:   1387.92\n",
      "variational_beta * kldivergence:  0.13879\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35194\n",
      "kldivergence:   1540.77\n",
      "variational_beta * kldivergence:  0.15408\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32539\n",
      "kldivergence:   1439.92\n",
      "variational_beta * kldivergence:  0.14399\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35167\n",
      "kldivergence:   1488.34\n",
      "variational_beta * kldivergence:  0.14883\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.37587\n",
      "kldivergence:   1540.88\n",
      "variational_beta * kldivergence:  0.15409\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33676\n",
      "kldivergence:   1535.54\n",
      "variational_beta * kldivergence:  0.15355\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28867\n",
      "kldivergence:   1531.89\n",
      "variational_beta * kldivergence:  0.15319\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34051\n",
      "kldivergence:   1572.14\n",
      "variational_beta * kldivergence:  0.15721\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29882\n",
      "kldivergence:   1342.05\n",
      "variational_beta * kldivergence:  0.13421\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32040\n",
      "kldivergence:   1723.86\n",
      "variational_beta * kldivergence:  0.17239\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33437\n",
      "kldivergence:   1593.46\n",
      "variational_beta * kldivergence:  0.15935\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31373\n",
      "kldivergence:   1511.58\n",
      "variational_beta * kldivergence:  0.15116\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36931\n",
      "kldivergence:   1446.59\n",
      "variational_beta * kldivergence:  0.14466\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31597\n",
      "kldivergence:   1555.73\n",
      "variational_beta * kldivergence:  0.15557\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30202\n",
      "kldivergence:   1561.73\n",
      "variational_beta * kldivergence:  0.15617\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30757\n",
      "kldivergence:   1555.77\n",
      "variational_beta * kldivergence:  0.15558\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29486\n",
      "kldivergence:   1497.35\n",
      "variational_beta * kldivergence:  0.14973\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29718\n",
      "kldivergence:   1418.06\n",
      "variational_beta * kldivergence:  0.14181\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36197\n",
      "kldivergence:   1621.13\n",
      "variational_beta * kldivergence:  0.16211\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33332\n",
      "kldivergence:   1496.11\n",
      "variational_beta * kldivergence:  0.14961\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34056\n",
      "kldivergence:   1518.44\n",
      "variational_beta * kldivergence:  0.15184\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32331\n",
      "kldivergence:   1561.43\n",
      "variational_beta * kldivergence:  0.15614\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34280\n",
      "kldivergence:   1885.39\n",
      "variational_beta * kldivergence:  0.18854\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33359\n",
      "kldivergence:   1521.84\n",
      "variational_beta * kldivergence:  0.15218\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33104\n",
      "kldivergence:   1745.60\n",
      "variational_beta * kldivergence:  0.17456\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35744\n",
      "kldivergence:   1478.41\n",
      "variational_beta * kldivergence:  0.14784\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.24230\n",
      "kldivergence:   1314.20\n",
      "variational_beta * kldivergence:  0.13142\n",
      "batch accuracy: 91.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31584\n",
      "kldivergence:   1559.50\n",
      "variational_beta * kldivergence:  0.15595\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29930\n",
      "kldivergence:   1414.03\n",
      "variational_beta * kldivergence:  0.14140\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31581\n",
      "kldivergence:   1580.34\n",
      "variational_beta * kldivergence:  0.15803\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.37583\n",
      "kldivergence:   1657.20\n",
      "variational_beta * kldivergence:  0.16572\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36329\n",
      "kldivergence:   1474.71\n",
      "variational_beta * kldivergence:  0.14747\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31121\n",
      "kldivergence:   1572.86\n",
      "variational_beta * kldivergence:  0.15729\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34323\n",
      "kldivergence:   1500.97\n",
      "variational_beta * kldivergence:  0.15010\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36865\n",
      "kldivergence:   1719.52\n",
      "variational_beta * kldivergence:  0.17195\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31937\n",
      "kldivergence:   1399.68\n",
      "variational_beta * kldivergence:  0.13997\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36218\n",
      "kldivergence:   1643.12\n",
      "variational_beta * kldivergence:  0.16431\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29985\n",
      "kldivergence:   1523.23\n",
      "variational_beta * kldivergence:  0.15232\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.40036\n",
      "kldivergence:   1674.08\n",
      "variational_beta * kldivergence:  0.16741\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35336\n",
      "kldivergence:   1398.90\n",
      "variational_beta * kldivergence:  0.13989\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36680\n",
      "kldivergence:   1518.58\n",
      "variational_beta * kldivergence:  0.15186\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29915\n",
      "kldivergence:   1391.38\n",
      "variational_beta * kldivergence:  0.13914\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32736\n",
      "kldivergence:   1481.56\n",
      "variational_beta * kldivergence:  0.14816\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30596\n",
      "kldivergence:   1552.53\n",
      "variational_beta * kldivergence:  0.15525\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31033\n",
      "kldivergence:   1480.66\n",
      "variational_beta * kldivergence:  0.14807\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34214\n",
      "kldivergence:   1516.56\n",
      "variational_beta * kldivergence:  0.15166\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36828\n",
      "kldivergence:   1888.34\n",
      "variational_beta * kldivergence:  0.18883\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30408\n",
      "kldivergence:   1331.73\n",
      "variational_beta * kldivergence:  0.13317\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29251\n",
      "kldivergence:   1341.37\n",
      "variational_beta * kldivergence:  0.13414\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34765\n",
      "kldivergence:   1621.96\n",
      "variational_beta * kldivergence:  0.16220\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.37419\n",
      "kldivergence:   1625.33\n",
      "variational_beta * kldivergence:  0.16253\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32257\n",
      "kldivergence:   1425.26\n",
      "variational_beta * kldivergence:  0.14253\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29334\n",
      "kldivergence:   1303.08\n",
      "variational_beta * kldivergence:  0.13031\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31340\n",
      "kldivergence:   1351.50\n",
      "variational_beta * kldivergence:  0.13515\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.41107\n",
      "kldivergence:   1584.14\n",
      "variational_beta * kldivergence:  0.15841\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30824\n",
      "kldivergence:   1435.80\n",
      "variational_beta * kldivergence:  0.14358\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36515\n",
      "kldivergence:   1629.63\n",
      "variational_beta * kldivergence:  0.16296\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33000\n",
      "kldivergence:   1408.58\n",
      "variational_beta * kldivergence:  0.14086\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33277\n",
      "kldivergence:   1446.88\n",
      "variational_beta * kldivergence:  0.14469\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33094\n",
      "kldivergence:   1444.06\n",
      "variational_beta * kldivergence:  0.14441\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33631\n",
      "kldivergence:   1542.67\n",
      "variational_beta * kldivergence:  0.15427\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33166\n",
      "kldivergence:   1527.42\n",
      "variational_beta * kldivergence:  0.15274\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35766\n",
      "kldivergence:   1725.69\n",
      "variational_beta * kldivergence:  0.17257\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31276\n",
      "kldivergence:   1473.36\n",
      "variational_beta * kldivergence:  0.14734\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35703\n",
      "kldivergence:   1578.19\n",
      "variational_beta * kldivergence:  0.15782\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27051\n",
      "kldivergence:   1412.57\n",
      "variational_beta * kldivergence:  0.14126\n",
      "batch accuracy: 90.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30713\n",
      "kldivergence:   1377.84\n",
      "variational_beta * kldivergence:  0.13778\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33520\n",
      "kldivergence:   1466.11\n",
      "variational_beta * kldivergence:  0.14661\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27086\n",
      "kldivergence:   1334.02\n",
      "variational_beta * kldivergence:  0.13340\n",
      "batch accuracy: 90.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31872\n",
      "kldivergence:   1488.02\n",
      "variational_beta * kldivergence:  0.14880\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31963\n",
      "kldivergence:   1263.29\n",
      "variational_beta * kldivergence:  0.12633\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.25772\n",
      "kldivergence:   1416.26\n",
      "variational_beta * kldivergence:  0.14163\n",
      "batch accuracy: 91.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28978\n",
      "kldivergence:   1571.02\n",
      "variational_beta * kldivergence:  0.15710\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34054\n",
      "kldivergence:   1476.98\n",
      "variational_beta * kldivergence:  0.14770\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33598\n",
      "kldivergence:   1505.77\n",
      "variational_beta * kldivergence:  0.15058\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29958\n",
      "kldivergence:   1454.84\n",
      "variational_beta * kldivergence:  0.14548\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32460\n",
      "kldivergence:   1358.80\n",
      "variational_beta * kldivergence:  0.13588\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34708\n",
      "kldivergence:   1672.79\n",
      "variational_beta * kldivergence:  0.16728\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36486\n",
      "kldivergence:   1510.68\n",
      "variational_beta * kldivergence:  0.15107\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28292\n",
      "kldivergence:   1444.30\n",
      "variational_beta * kldivergence:  0.14443\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31148\n",
      "kldivergence:   1410.35\n",
      "variational_beta * kldivergence:  0.14104\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32391\n",
      "kldivergence:   1649.89\n",
      "variational_beta * kldivergence:  0.16499\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27914\n",
      "kldivergence:   1358.70\n",
      "variational_beta * kldivergence:  0.13587\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33164\n",
      "kldivergence:   1571.42\n",
      "variational_beta * kldivergence:  0.15714\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.24383\n",
      "kldivergence:   1368.78\n",
      "variational_beta * kldivergence:  0.13688\n",
      "batch accuracy: 91.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33399\n",
      "kldivergence:   1418.91\n",
      "variational_beta * kldivergence:  0.14189\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31028\n",
      "kldivergence:   1537.07\n",
      "variational_beta * kldivergence:  0.15371\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30568\n",
      "kldivergence:   1377.57\n",
      "variational_beta * kldivergence:  0.13776\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31836\n",
      "kldivergence:   1403.51\n",
      "variational_beta * kldivergence:  0.14035\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34424\n",
      "kldivergence:   1462.83\n",
      "variational_beta * kldivergence:  0.14628\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32609\n",
      "kldivergence:   1520.35\n",
      "variational_beta * kldivergence:  0.15204\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35234\n",
      "kldivergence:   1443.53\n",
      "variational_beta * kldivergence:  0.14435\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32926\n",
      "kldivergence:   1490.39\n",
      "variational_beta * kldivergence:  0.14904\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28891\n",
      "kldivergence:   1503.73\n",
      "variational_beta * kldivergence:  0.15037\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.38620\n",
      "kldivergence:   1589.07\n",
      "variational_beta * kldivergence:  0.15891\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27315\n",
      "kldivergence:   1354.92\n",
      "variational_beta * kldivergence:  0.13549\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32972\n",
      "kldivergence:   1471.93\n",
      "variational_beta * kldivergence:  0.14719\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32070\n",
      "kldivergence:   1417.61\n",
      "variational_beta * kldivergence:  0.14176\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.37323\n",
      "kldivergence:   1625.35\n",
      "variational_beta * kldivergence:  0.16253\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31829\n",
      "kldivergence:   1313.71\n",
      "variational_beta * kldivergence:  0.13137\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35156\n",
      "kldivergence:   1627.74\n",
      "variational_beta * kldivergence:  0.16277\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28931\n",
      "kldivergence:   1552.79\n",
      "variational_beta * kldivergence:  0.15528\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.38098\n",
      "kldivergence:   1574.43\n",
      "variational_beta * kldivergence:  0.15744\n",
      "batch accuracy: 87.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32721\n",
      "kldivergence:   1372.58\n",
      "variational_beta * kldivergence:  0.13726\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31090\n",
      "kldivergence:   1566.95\n",
      "variational_beta * kldivergence:  0.15670\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27660\n",
      "kldivergence:   1503.50\n",
      "variational_beta * kldivergence:  0.15035\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36897\n",
      "kldivergence:   1553.24\n",
      "variational_beta * kldivergence:  0.15532\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27742\n",
      "kldivergence:   1328.98\n",
      "variational_beta * kldivergence:  0.13290\n",
      "batch accuracy: 91.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33642\n",
      "kldivergence:   1443.50\n",
      "variational_beta * kldivergence:  0.14435\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33915\n",
      "kldivergence:   1674.85\n",
      "variational_beta * kldivergence:  0.16749\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29362\n",
      "kldivergence:   1460.10\n",
      "variational_beta * kldivergence:  0.14601\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32237\n",
      "kldivergence:   1531.21\n",
      "variational_beta * kldivergence:  0.15312\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33500\n",
      "kldivergence:   1564.36\n",
      "variational_beta * kldivergence:  0.15644\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.37703\n",
      "kldivergence:   1743.58\n",
      "variational_beta * kldivergence:  0.17436\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34304\n",
      "kldivergence:   1530.39\n",
      "variational_beta * kldivergence:  0.15304\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32913\n",
      "kldivergence:   1503.86\n",
      "variational_beta * kldivergence:  0.15039\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30389\n",
      "kldivergence:   1621.40\n",
      "variational_beta * kldivergence:  0.16214\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30067\n",
      "kldivergence:   1523.24\n",
      "variational_beta * kldivergence:  0.15232\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29064\n",
      "kldivergence:   1340.63\n",
      "variational_beta * kldivergence:  0.13406\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35420\n",
      "kldivergence:   1395.08\n",
      "variational_beta * kldivergence:  0.13951\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31665\n",
      "kldivergence:   1543.35\n",
      "variational_beta * kldivergence:  0.15433\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35431\n",
      "kldivergence:   1455.61\n",
      "variational_beta * kldivergence:  0.14556\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29669\n",
      "kldivergence:   1314.07\n",
      "variational_beta * kldivergence:  0.13141\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27147\n",
      "kldivergence:   1361.53\n",
      "variational_beta * kldivergence:  0.13615\n",
      "batch accuracy: 90.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33367\n",
      "kldivergence:   1471.58\n",
      "variational_beta * kldivergence:  0.14716\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32168\n",
      "kldivergence:   1368.32\n",
      "variational_beta * kldivergence:  0.13683\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32137\n",
      "kldivergence:   1565.91\n",
      "variational_beta * kldivergence:  0.15659\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32731\n",
      "kldivergence:   1508.84\n",
      "variational_beta * kldivergence:  0.15088\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.37202\n",
      "kldivergence:   1607.54\n",
      "variational_beta * kldivergence:  0.16075\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34363\n",
      "kldivergence:   1332.61\n",
      "variational_beta * kldivergence:  0.13326\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30198\n",
      "kldivergence:   1426.21\n",
      "variational_beta * kldivergence:  0.14262\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32709\n",
      "kldivergence:   1636.54\n",
      "variational_beta * kldivergence:  0.16365\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34725\n",
      "kldivergence:   1472.05\n",
      "variational_beta * kldivergence:  0.14720\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28745\n",
      "kldivergence:   1549.54\n",
      "variational_beta * kldivergence:  0.15495\n",
      "batch accuracy: 90.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36264\n",
      "kldivergence:   1673.65\n",
      "variational_beta * kldivergence:  0.16736\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30546\n",
      "kldivergence:   1482.79\n",
      "variational_beta * kldivergence:  0.14828\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33761\n",
      "kldivergence:   1398.05\n",
      "variational_beta * kldivergence:  0.13980\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30253\n",
      "kldivergence:   1430.98\n",
      "variational_beta * kldivergence:  0.14310\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33022\n",
      "kldivergence:   1763.05\n",
      "variational_beta * kldivergence:  0.17631\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35687\n",
      "kldivergence:   1512.40\n",
      "variational_beta * kldivergence:  0.15124\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30820\n",
      "kldivergence:   1488.50\n",
      "variational_beta * kldivergence:  0.14885\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30957\n",
      "kldivergence:   1612.51\n",
      "variational_beta * kldivergence:  0.16125\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35576\n",
      "kldivergence:   1454.86\n",
      "variational_beta * kldivergence:  0.14549\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32812\n",
      "kldivergence:   1700.54\n",
      "variational_beta * kldivergence:  0.17005\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.38357\n",
      "kldivergence:   1555.16\n",
      "variational_beta * kldivergence:  0.15552\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34873\n",
      "kldivergence:   1741.45\n",
      "variational_beta * kldivergence:  0.17415\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28596\n",
      "kldivergence:   1487.75\n",
      "variational_beta * kldivergence:  0.14878\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29865\n",
      "kldivergence:   1430.16\n",
      "variational_beta * kldivergence:  0.14302\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29527\n",
      "kldivergence:   1377.97\n",
      "variational_beta * kldivergence:  0.13780\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28249\n",
      "kldivergence:   1344.88\n",
      "variational_beta * kldivergence:  0.13449\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32087\n",
      "kldivergence:   1489.68\n",
      "variational_beta * kldivergence:  0.14897\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30295\n",
      "kldivergence:   1521.43\n",
      "variational_beta * kldivergence:  0.15214\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30446\n",
      "kldivergence:   1405.98\n",
      "variational_beta * kldivergence:  0.14060\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.37139\n",
      "kldivergence:   1526.60\n",
      "variational_beta * kldivergence:  0.15266\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28080\n",
      "kldivergence:   1448.46\n",
      "variational_beta * kldivergence:  0.14485\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33447\n",
      "kldivergence:   1442.86\n",
      "variational_beta * kldivergence:  0.14429\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34469\n",
      "kldivergence:   1414.45\n",
      "variational_beta * kldivergence:  0.14145\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29399\n",
      "kldivergence:   1434.19\n",
      "variational_beta * kldivergence:  0.14342\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31305\n",
      "kldivergence:   1390.50\n",
      "variational_beta * kldivergence:  0.13905\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33373\n",
      "kldivergence:   1465.84\n",
      "variational_beta * kldivergence:  0.14658\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33140\n",
      "kldivergence:   1569.67\n",
      "variational_beta * kldivergence:  0.15697\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28180\n",
      "kldivergence:   1391.19\n",
      "variational_beta * kldivergence:  0.13912\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36129\n",
      "kldivergence:   1481.00\n",
      "variational_beta * kldivergence:  0.14810\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31143\n",
      "kldivergence:   1690.42\n",
      "variational_beta * kldivergence:  0.16904\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36283\n",
      "kldivergence:   1416.54\n",
      "variational_beta * kldivergence:  0.14165\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29462\n",
      "kldivergence:   1401.59\n",
      "variational_beta * kldivergence:  0.14016\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31742\n",
      "kldivergence:   1415.25\n",
      "variational_beta * kldivergence:  0.14153\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35660\n",
      "kldivergence:   1594.91\n",
      "variational_beta * kldivergence:  0.15949\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33374\n",
      "kldivergence:   1576.43\n",
      "variational_beta * kldivergence:  0.15764\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35222\n",
      "kldivergence:   1485.60\n",
      "variational_beta * kldivergence:  0.14856\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30720\n",
      "kldivergence:   1669.17\n",
      "variational_beta * kldivergence:  0.16692\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31179\n",
      "kldivergence:   1539.08\n",
      "variational_beta * kldivergence:  0.15391\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.38925\n",
      "kldivergence:   1489.51\n",
      "variational_beta * kldivergence:  0.14895\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35436\n",
      "kldivergence:   1588.64\n",
      "variational_beta * kldivergence:  0.15886\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34746\n",
      "kldivergence:   1434.75\n",
      "variational_beta * kldivergence:  0.14348\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31089\n",
      "kldivergence:   1463.77\n",
      "variational_beta * kldivergence:  0.14638\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31862\n",
      "kldivergence:   1371.75\n",
      "variational_beta * kldivergence:  0.13717\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30636\n",
      "kldivergence:   1594.30\n",
      "variational_beta * kldivergence:  0.15943\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.38079\n",
      "kldivergence:   1673.63\n",
      "variational_beta * kldivergence:  0.16736\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.39970\n",
      "kldivergence:   1583.08\n",
      "variational_beta * kldivergence:  0.15831\n",
      "batch accuracy: 86.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36912\n",
      "kldivergence:   1622.60\n",
      "variational_beta * kldivergence:  0.16226\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33462\n",
      "kldivergence:   1533.61\n",
      "variational_beta * kldivergence:  0.15336\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33071\n",
      "kldivergence:   1579.11\n",
      "variational_beta * kldivergence:  0.15791\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35882\n",
      "kldivergence:   1682.83\n",
      "variational_beta * kldivergence:  0.16828\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34500\n",
      "kldivergence:   1443.67\n",
      "variational_beta * kldivergence:  0.14437\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31262\n",
      "kldivergence:   1510.93\n",
      "variational_beta * kldivergence:  0.15109\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29641\n",
      "kldivergence:   1462.36\n",
      "variational_beta * kldivergence:  0.14624\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29846\n",
      "kldivergence:   1499.41\n",
      "variational_beta * kldivergence:  0.14994\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30319\n",
      "kldivergence:   1536.60\n",
      "variational_beta * kldivergence:  0.15366\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30939\n",
      "kldivergence:   1495.29\n",
      "variational_beta * kldivergence:  0.14953\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32798\n",
      "kldivergence:   1520.07\n",
      "variational_beta * kldivergence:  0.15201\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32921\n",
      "kldivergence:   1574.16\n",
      "variational_beta * kldivergence:  0.15742\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35714\n",
      "kldivergence:   1718.13\n",
      "variational_beta * kldivergence:  0.17181\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31761\n",
      "kldivergence:   1405.77\n",
      "variational_beta * kldivergence:  0.14058\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35865\n",
      "kldivergence:   1605.83\n",
      "variational_beta * kldivergence:  0.16058\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28165\n",
      "kldivergence:   1299.26\n",
      "variational_beta * kldivergence:  0.12993\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.25252\n",
      "kldivergence:   1350.57\n",
      "variational_beta * kldivergence:  0.13506\n",
      "batch accuracy: 91.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27812\n",
      "kldivergence:   1549.07\n",
      "variational_beta * kldivergence:  0.15491\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30245\n",
      "kldivergence:   1614.34\n",
      "variational_beta * kldivergence:  0.16143\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29413\n",
      "kldivergence:   1440.12\n",
      "variational_beta * kldivergence:  0.14401\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30807\n",
      "kldivergence:   1639.69\n",
      "variational_beta * kldivergence:  0.16397\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33092\n",
      "kldivergence:   1586.02\n",
      "variational_beta * kldivergence:  0.15860\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33470\n",
      "kldivergence:   1468.26\n",
      "variational_beta * kldivergence:  0.14683\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28307\n",
      "kldivergence:   1456.84\n",
      "variational_beta * kldivergence:  0.14568\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34648\n",
      "kldivergence:   1524.35\n",
      "variational_beta * kldivergence:  0.15244\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.38213\n",
      "kldivergence:   1743.48\n",
      "variational_beta * kldivergence:  0.17435\n",
      "batch accuracy: 87.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33285\n",
      "kldivergence:   1299.13\n",
      "variational_beta * kldivergence:  0.12991\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31223\n",
      "kldivergence:   1339.00\n",
      "variational_beta * kldivergence:  0.13390\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33531\n",
      "kldivergence:   1563.08\n",
      "variational_beta * kldivergence:  0.15631\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30242\n",
      "kldivergence:   1646.60\n",
      "variational_beta * kldivergence:  0.16466\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30124\n",
      "kldivergence:   1465.20\n",
      "variational_beta * kldivergence:  0.14652\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29901\n",
      "kldivergence:   1470.70\n",
      "variational_beta * kldivergence:  0.14707\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.39177\n",
      "kldivergence:   1456.73\n",
      "variational_beta * kldivergence:  0.14567\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31546\n",
      "kldivergence:   1391.19\n",
      "variational_beta * kldivergence:  0.13912\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32402\n",
      "kldivergence:   1444.50\n",
      "variational_beta * kldivergence:  0.14445\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34381\n",
      "kldivergence:   1408.35\n",
      "variational_beta * kldivergence:  0.14083\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31980\n",
      "kldivergence:   1427.71\n",
      "variational_beta * kldivergence:  0.14277\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31980\n",
      "kldivergence:   1748.67\n",
      "variational_beta * kldivergence:  0.17487\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30477\n",
      "kldivergence:   1359.31\n",
      "variational_beta * kldivergence:  0.13593\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31064\n",
      "kldivergence:   1541.48\n",
      "variational_beta * kldivergence:  0.15415\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29932\n",
      "kldivergence:   1455.82\n",
      "variational_beta * kldivergence:  0.14558\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31794\n",
      "kldivergence:   1191.50\n",
      "variational_beta * kldivergence:  0.11915\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34739\n",
      "kldivergence:   1582.17\n",
      "variational_beta * kldivergence:  0.15822\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32971\n",
      "kldivergence:   1265.39\n",
      "variational_beta * kldivergence:  0.12654\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33555\n",
      "kldivergence:   1464.22\n",
      "variational_beta * kldivergence:  0.14642\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28656\n",
      "kldivergence:   1396.56\n",
      "variational_beta * kldivergence:  0.13966\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27808\n",
      "kldivergence:   1474.68\n",
      "variational_beta * kldivergence:  0.14747\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31198\n",
      "kldivergence:   1511.27\n",
      "variational_beta * kldivergence:  0.15113\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30143\n",
      "kldivergence:   1384.03\n",
      "variational_beta * kldivergence:  0.13840\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34949\n",
      "kldivergence:   1641.25\n",
      "variational_beta * kldivergence:  0.16412\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32954\n",
      "kldivergence:   1426.39\n",
      "variational_beta * kldivergence:  0.14264\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32983\n",
      "kldivergence:   1572.18\n",
      "variational_beta * kldivergence:  0.15722\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36977\n",
      "kldivergence:   1643.03\n",
      "variational_beta * kldivergence:  0.16430\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29869\n",
      "kldivergence:   1371.66\n",
      "variational_beta * kldivergence:  0.13717\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31723\n",
      "kldivergence:   1486.27\n",
      "variational_beta * kldivergence:  0.14863\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.38061\n",
      "kldivergence:   1569.51\n",
      "variational_beta * kldivergence:  0.15695\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31043\n",
      "kldivergence:   1588.92\n",
      "variational_beta * kldivergence:  0.15889\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28444\n",
      "kldivergence:   1358.37\n",
      "variational_beta * kldivergence:  0.13584\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30278\n",
      "kldivergence:   1681.10\n",
      "variational_beta * kldivergence:  0.16811\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.23972\n",
      "kldivergence:   1267.16\n",
      "variational_beta * kldivergence:  0.12672\n",
      "batch accuracy: 92.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30121\n",
      "kldivergence:   1489.13\n",
      "variational_beta * kldivergence:  0.14891\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36299\n",
      "kldivergence:   1723.48\n",
      "variational_beta * kldivergence:  0.17235\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.26062\n",
      "kldivergence:   1346.18\n",
      "variational_beta * kldivergence:  0.13462\n",
      "batch accuracy: 91.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35450\n",
      "kldivergence:   1741.84\n",
      "variational_beta * kldivergence:  0.17418\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.23258\n",
      "kldivergence:   1394.28\n",
      "variational_beta * kldivergence:  0.13943\n",
      "batch accuracy: 92.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33076\n",
      "kldivergence:   1504.10\n",
      "variational_beta * kldivergence:  0.15041\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34359\n",
      "kldivergence:   1574.78\n",
      "variational_beta * kldivergence:  0.15748\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32238\n",
      "kldivergence:   1683.44\n",
      "variational_beta * kldivergence:  0.16834\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28504\n",
      "kldivergence:   1470.36\n",
      "variational_beta * kldivergence:  0.14704\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33824\n",
      "kldivergence:   1632.79\n",
      "variational_beta * kldivergence:  0.16328\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31400\n",
      "kldivergence:   1282.66\n",
      "variational_beta * kldivergence:  0.12827\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35140\n",
      "kldivergence:   1512.16\n",
      "variational_beta * kldivergence:  0.15122\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32900\n",
      "kldivergence:   1438.35\n",
      "variational_beta * kldivergence:  0.14384\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.25063\n",
      "kldivergence:   1411.57\n",
      "variational_beta * kldivergence:  0.14116\n",
      "batch accuracy: 91.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33285\n",
      "kldivergence:   1505.72\n",
      "variational_beta * kldivergence:  0.15057\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35094\n",
      "kldivergence:   1488.28\n",
      "variational_beta * kldivergence:  0.14883\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33977\n",
      "kldivergence:   1489.97\n",
      "variational_beta * kldivergence:  0.14900\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33685\n",
      "kldivergence:   1490.27\n",
      "variational_beta * kldivergence:  0.14903\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33652\n",
      "kldivergence:   1382.90\n",
      "variational_beta * kldivergence:  0.13829\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32963\n",
      "kldivergence:   1428.95\n",
      "variational_beta * kldivergence:  0.14289\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33215\n",
      "kldivergence:   1684.66\n",
      "variational_beta * kldivergence:  0.16847\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32295\n",
      "kldivergence:   1447.27\n",
      "variational_beta * kldivergence:  0.14473\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32239\n",
      "kldivergence:   1301.42\n",
      "variational_beta * kldivergence:  0.13014\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30519\n",
      "kldivergence:   1429.67\n",
      "variational_beta * kldivergence:  0.14297\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32704\n",
      "kldivergence:   1258.90\n",
      "variational_beta * kldivergence:  0.12589\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34959\n",
      "kldivergence:   1563.32\n",
      "variational_beta * kldivergence:  0.15633\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33239\n",
      "kldivergence:   1625.71\n",
      "variational_beta * kldivergence:  0.16257\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30429\n",
      "kldivergence:   1477.40\n",
      "variational_beta * kldivergence:  0.14774\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34530\n",
      "kldivergence:   1455.39\n",
      "variational_beta * kldivergence:  0.14554\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36311\n",
      "kldivergence:   1637.65\n",
      "variational_beta * kldivergence:  0.16377\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29407\n",
      "kldivergence:   1398.96\n",
      "variational_beta * kldivergence:  0.13990\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33838\n",
      "kldivergence:   1587.27\n",
      "variational_beta * kldivergence:  0.15873\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27186\n",
      "kldivergence:   1447.83\n",
      "variational_beta * kldivergence:  0.14478\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30409\n",
      "kldivergence:   1585.58\n",
      "variational_beta * kldivergence:  0.15856\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.27602\n",
      "kldivergence:   1264.77\n",
      "variational_beta * kldivergence:  0.12648\n",
      "batch accuracy: 90.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32767\n",
      "kldivergence:   1422.79\n",
      "variational_beta * kldivergence:  0.14228\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33846\n",
      "kldivergence:   1569.04\n",
      "variational_beta * kldivergence:  0.15690\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.32003\n",
      "kldivergence:   1457.60\n",
      "variational_beta * kldivergence:  0.14576\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34039\n",
      "kldivergence:   1630.55\n",
      "variational_beta * kldivergence:  0.16306\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35478\n",
      "kldivergence:   1524.02\n",
      "variational_beta * kldivergence:  0.15240\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31866\n",
      "kldivergence:   1371.54\n",
      "variational_beta * kldivergence:  0.13715\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.28669\n",
      "kldivergence:   1495.38\n",
      "variational_beta * kldivergence:  0.14954\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33335\n",
      "kldivergence:   1471.30\n",
      "variational_beta * kldivergence:  0.14713\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30059\n",
      "kldivergence:   1295.05\n",
      "variational_beta * kldivergence:  0.12951\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35553\n",
      "kldivergence:   1503.94\n",
      "variational_beta * kldivergence:  0.15039\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31132\n",
      "kldivergence:   1357.94\n",
      "variational_beta * kldivergence:  0.13579\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34750\n",
      "kldivergence:   1518.09\n",
      "variational_beta * kldivergence:  0.15181\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.29519\n",
      "kldivergence:   1524.30\n",
      "variational_beta * kldivergence:  0.15243\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30703\n",
      "kldivergence:   1255.84\n",
      "variational_beta * kldivergence:  0.12558\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.35419\n",
      "kldivergence:   1408.68\n",
      "variational_beta * kldivergence:  0.14087\n",
      "batch accuracy: 87.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30139\n",
      "kldivergence:   1302.32\n",
      "variational_beta * kldivergence:  0.13023\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31889\n",
      "kldivergence:   1442.49\n",
      "variational_beta * kldivergence:  0.14425\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30717\n",
      "kldivergence:   1483.83\n",
      "variational_beta * kldivergence:  0.14838\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.30711\n",
      "kldivergence:   1418.58\n",
      "variational_beta * kldivergence:  0.14186\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.36773\n",
      "kldivergence:   1532.66\n",
      "variational_beta * kldivergence:  0.15327\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34197\n",
      "kldivergence:   1497.68\n",
      "variational_beta * kldivergence:  0.14977\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.31962\n",
      "kldivergence:   1496.10\n",
      "variational_beta * kldivergence:  0.14961\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.33414\n",
      "kldivergence:   1604.37\n",
      "variational_beta * kldivergence:  0.16044\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #56\n",
      "reconstruction loss: 0.34828\n",
      "kldivergence:   1439.18\n",
      "variational_beta * kldivergence:  0.14392\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.45757\n",
      "kldivergence:   1320.80\n",
      "variational_beta * kldivergence:  0.13208\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.53255\n",
      "kldivergence:   1522.21\n",
      "variational_beta * kldivergence:  0.15222\n",
      "batch accuracy: 83.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.39466\n",
      "kldivergence:   1280.43\n",
      "variational_beta * kldivergence:  0.12804\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.47179\n",
      "kldivergence:   1439.53\n",
      "variational_beta * kldivergence:  0.14395\n",
      "batch accuracy: 85.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.53533\n",
      "kldivergence:   1552.52\n",
      "variational_beta * kldivergence:  0.15525\n",
      "batch accuracy: 83.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.37520\n",
      "kldivergence:   1359.82\n",
      "variational_beta * kldivergence:  0.13598\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.42414\n",
      "kldivergence:   1236.23\n",
      "variational_beta * kldivergence:  0.12362\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.50275\n",
      "kldivergence:   1385.09\n",
      "variational_beta * kldivergence:  0.13851\n",
      "batch accuracy: 85.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.46661\n",
      "kldivergence:   1421.63\n",
      "variational_beta * kldivergence:  0.14216\n",
      "batch accuracy: 85.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.57206\n",
      "kldivergence:   1387.76\n",
      "variational_beta * kldivergence:  0.13878\n",
      "batch accuracy: 82.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.40459\n",
      "kldivergence:   1228.57\n",
      "variational_beta * kldivergence:  0.12286\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.45362\n",
      "kldivergence:   1223.44\n",
      "variational_beta * kldivergence:  0.12234\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.45560\n",
      "kldivergence:   1317.50\n",
      "variational_beta * kldivergence:  0.13175\n",
      "batch accuracy: 86.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.46499\n",
      "kldivergence:   1313.07\n",
      "variational_beta * kldivergence:  0.13131\n",
      "batch accuracy: 85.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.41181\n",
      "kldivergence:   1373.22\n",
      "variational_beta * kldivergence:  0.13732\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.45363\n",
      "kldivergence:   1268.18\n",
      "variational_beta * kldivergence:  0.12682\n",
      "batch accuracy: 86.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.44968\n",
      "kldivergence:   1377.66\n",
      "variational_beta * kldivergence:  0.13777\n",
      "batch accuracy: 86.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.61675\n",
      "kldivergence:   1506.61\n",
      "variational_beta * kldivergence:  0.15066\n",
      "batch accuracy: 83.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.38847\n",
      "kldivergence:   1281.81\n",
      "variational_beta * kldivergence:  0.12818\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.53269\n",
      "kldivergence:   1515.44\n",
      "variational_beta * kldivergence:  0.15154\n",
      "batch accuracy: 83.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.44600\n",
      "kldivergence:   1270.54\n",
      "variational_beta * kldivergence:  0.12705\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.42480\n",
      "kldivergence:   1340.12\n",
      "variational_beta * kldivergence:  0.13401\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.45242\n",
      "kldivergence:   1316.57\n",
      "variational_beta * kldivergence:  0.13166\n",
      "batch accuracy: 85.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.44484\n",
      "kldivergence:   1310.02\n",
      "variational_beta * kldivergence:  0.13100\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.36379\n",
      "kldivergence:   1319.36\n",
      "variational_beta * kldivergence:  0.13194\n",
      "batch accuracy: 89.25\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.48656\n",
      "kldivergence:   1418.40\n",
      "variational_beta * kldivergence:  0.14184\n",
      "batch accuracy: 85.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.47841\n",
      "kldivergence:   1329.77\n",
      "variational_beta * kldivergence:  0.13298\n",
      "batch accuracy: 85.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.49594\n",
      "kldivergence:   1506.16\n",
      "variational_beta * kldivergence:  0.15062\n",
      "batch accuracy: 84.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.53927\n",
      "kldivergence:   1381.80\n",
      "variational_beta * kldivergence:  0.13818\n",
      "batch accuracy: 84.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.43339\n",
      "kldivergence:   1324.93\n",
      "variational_beta * kldivergence:  0.13249\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.42710\n",
      "kldivergence:   1327.03\n",
      "variational_beta * kldivergence:  0.13270\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.55628\n",
      "kldivergence:   1479.99\n",
      "variational_beta * kldivergence:  0.14800\n",
      "batch accuracy: 83.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.48591\n",
      "kldivergence:   1374.60\n",
      "variational_beta * kldivergence:  0.13746\n",
      "batch accuracy: 86.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.57572\n",
      "kldivergence:   1487.01\n",
      "variational_beta * kldivergence:  0.14870\n",
      "batch accuracy: 83.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.45826\n",
      "kldivergence:   1388.67\n",
      "variational_beta * kldivergence:  0.13887\n",
      "batch accuracy: 85.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.42197\n",
      "kldivergence:   1354.55\n",
      "variational_beta * kldivergence:  0.13545\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.40886\n",
      "kldivergence:   1210.07\n",
      "variational_beta * kldivergence:  0.12101\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.37652\n",
      "kldivergence:   1219.54\n",
      "variational_beta * kldivergence:  0.12195\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.46328\n",
      "kldivergence:   1327.99\n",
      "variational_beta * kldivergence:  0.13280\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.51763\n",
      "kldivergence:   1357.53\n",
      "variational_beta * kldivergence:  0.13575\n",
      "batch accuracy: 85.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.48880\n",
      "kldivergence:   1454.57\n",
      "variational_beta * kldivergence:  0.14546\n",
      "batch accuracy: 84.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.43061\n",
      "kldivergence:   1248.64\n",
      "variational_beta * kldivergence:  0.12486\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.46686\n",
      "kldivergence:   1420.41\n",
      "variational_beta * kldivergence:  0.14204\n",
      "batch accuracy: 85.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.41976\n",
      "kldivergence:   1273.83\n",
      "variational_beta * kldivergence:  0.12738\n",
      "batch accuracy: 86.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.36734\n",
      "kldivergence:   1269.90\n",
      "variational_beta * kldivergence:  0.12699\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.47119\n",
      "kldivergence:   1351.38\n",
      "variational_beta * kldivergence:  0.13514\n",
      "batch accuracy: 85.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.43873\n",
      "kldivergence:   1311.73\n",
      "variational_beta * kldivergence:  0.13117\n",
      "batch accuracy: 86.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.49195\n",
      "kldivergence:   1302.48\n",
      "variational_beta * kldivergence:  0.13025\n",
      "batch accuracy: 85.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.48969\n",
      "kldivergence:   1373.01\n",
      "variational_beta * kldivergence:  0.13730\n",
      "batch accuracy: 85.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.46114\n",
      "kldivergence:   1336.52\n",
      "variational_beta * kldivergence:  0.13365\n",
      "batch accuracy: 86.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.43108\n",
      "kldivergence:   1386.79\n",
      "variational_beta * kldivergence:  0.13868\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.44639\n",
      "kldivergence:   1295.43\n",
      "variational_beta * kldivergence:  0.12954\n",
      "batch accuracy: 86.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.41437\n",
      "kldivergence:   1323.93\n",
      "variational_beta * kldivergence:  0.13239\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.47272\n",
      "kldivergence:   1376.57\n",
      "variational_beta * kldivergence:  0.13766\n",
      "batch accuracy: 85.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.44274\n",
      "kldivergence:   1242.24\n",
      "variational_beta * kldivergence:  0.12422\n",
      "batch accuracy: 86.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.42034\n",
      "kldivergence:   1351.33\n",
      "variational_beta * kldivergence:  0.13513\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.45160\n",
      "kldivergence:   1222.38\n",
      "variational_beta * kldivergence:  0.12224\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.40823\n",
      "kldivergence:   1288.60\n",
      "variational_beta * kldivergence:  0.12886\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.52426\n",
      "kldivergence:   1409.94\n",
      "variational_beta * kldivergence:  0.14099\n",
      "batch accuracy: 84.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.52508\n",
      "kldivergence:   1459.48\n",
      "variational_beta * kldivergence:  0.14595\n",
      "batch accuracy: 84.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.51304\n",
      "kldivergence:   1338.72\n",
      "variational_beta * kldivergence:  0.13387\n",
      "batch accuracy: 85.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #56\n",
      "reconstruction loss: 0.42365\n",
      "kldivergence:   1371.62\n",
      "variational_beta * kldivergence:  0.13716\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "epoch # 56 : train loss is [176.4108899548508] and validation loss is [0.09999008050957461] \n",
      "Epoch [57 / 150] average reconstruction error: 0.475501\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31534\n",
      "kldivergence:   1515.36\n",
      "variational_beta * kldivergence:  0.15154\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29111\n",
      "kldivergence:   1306.79\n",
      "variational_beta * kldivergence:  0.13068\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31243\n",
      "kldivergence:   1674.04\n",
      "variational_beta * kldivergence:  0.16740\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33643\n",
      "kldivergence:   1442.99\n",
      "variational_beta * kldivergence:  0.14430\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32915\n",
      "kldivergence:   1628.15\n",
      "variational_beta * kldivergence:  0.16281\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31988\n",
      "kldivergence:   1732.99\n",
      "variational_beta * kldivergence:  0.17330\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28746\n",
      "kldivergence:   1459.53\n",
      "variational_beta * kldivergence:  0.14595\n",
      "batch accuracy: 90.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31623\n",
      "kldivergence:   1445.38\n",
      "variational_beta * kldivergence:  0.14454\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30177\n",
      "kldivergence:   1367.65\n",
      "variational_beta * kldivergence:  0.13676\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37852\n",
      "kldivergence:   1708.71\n",
      "variational_beta * kldivergence:  0.17087\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35983\n",
      "kldivergence:   1504.99\n",
      "variational_beta * kldivergence:  0.15050\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31443\n",
      "kldivergence:   1353.32\n",
      "variational_beta * kldivergence:  0.13533\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31226\n",
      "kldivergence:   1455.91\n",
      "variational_beta * kldivergence:  0.14559\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36018\n",
      "kldivergence:   1494.57\n",
      "variational_beta * kldivergence:  0.14946\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34029\n",
      "kldivergence:   1459.43\n",
      "variational_beta * kldivergence:  0.14594\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35630\n",
      "kldivergence:   1505.07\n",
      "variational_beta * kldivergence:  0.15051\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31686\n",
      "kldivergence:   1389.71\n",
      "variational_beta * kldivergence:  0.13897\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34024\n",
      "kldivergence:   1573.22\n",
      "variational_beta * kldivergence:  0.15732\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32331\n",
      "kldivergence:   1603.13\n",
      "variational_beta * kldivergence:  0.16031\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28437\n",
      "kldivergence:   1216.97\n",
      "variational_beta * kldivergence:  0.12170\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33349\n",
      "kldivergence:   1551.89\n",
      "variational_beta * kldivergence:  0.15519\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32305\n",
      "kldivergence:   1450.82\n",
      "variational_beta * kldivergence:  0.14508\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36196\n",
      "kldivergence:   1726.22\n",
      "variational_beta * kldivergence:  0.17262\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33317\n",
      "kldivergence:   1463.80\n",
      "variational_beta * kldivergence:  0.14638\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34475\n",
      "kldivergence:   1465.06\n",
      "variational_beta * kldivergence:  0.14651\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28145\n",
      "kldivergence:   1819.21\n",
      "variational_beta * kldivergence:  0.18192\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36062\n",
      "kldivergence:   1530.85\n",
      "variational_beta * kldivergence:  0.15309\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35222\n",
      "kldivergence:   1781.09\n",
      "variational_beta * kldivergence:  0.17811\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31322\n",
      "kldivergence:   1472.57\n",
      "variational_beta * kldivergence:  0.14726\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30411\n",
      "kldivergence:   1666.39\n",
      "variational_beta * kldivergence:  0.16664\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27873\n",
      "kldivergence:   1278.53\n",
      "variational_beta * kldivergence:  0.12785\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30867\n",
      "kldivergence:   1367.00\n",
      "variational_beta * kldivergence:  0.13670\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33006\n",
      "kldivergence:   1707.25\n",
      "variational_beta * kldivergence:  0.17073\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33376\n",
      "kldivergence:   1346.19\n",
      "variational_beta * kldivergence:  0.13462\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33058\n",
      "kldivergence:   1309.78\n",
      "variational_beta * kldivergence:  0.13098\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30867\n",
      "kldivergence:   1463.85\n",
      "variational_beta * kldivergence:  0.14638\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28661\n",
      "kldivergence:   1391.62\n",
      "variational_beta * kldivergence:  0.13916\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32075\n",
      "kldivergence:   1540.28\n",
      "variational_beta * kldivergence:  0.15403\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31682\n",
      "kldivergence:   1306.70\n",
      "variational_beta * kldivergence:  0.13067\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27025\n",
      "kldivergence:   1486.68\n",
      "variational_beta * kldivergence:  0.14867\n",
      "batch accuracy: 91.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28468\n",
      "kldivergence:   1651.59\n",
      "variational_beta * kldivergence:  0.16516\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30955\n",
      "kldivergence:   1642.62\n",
      "variational_beta * kldivergence:  0.16426\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29743\n",
      "kldivergence:   1404.99\n",
      "variational_beta * kldivergence:  0.14050\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33212\n",
      "kldivergence:   1462.45\n",
      "variational_beta * kldivergence:  0.14625\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33133\n",
      "kldivergence:   1490.69\n",
      "variational_beta * kldivergence:  0.14907\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34069\n",
      "kldivergence:   1454.62\n",
      "variational_beta * kldivergence:  0.14546\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31660\n",
      "kldivergence:   1437.60\n",
      "variational_beta * kldivergence:  0.14376\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35544\n",
      "kldivergence:   1524.40\n",
      "variational_beta * kldivergence:  0.15244\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32452\n",
      "kldivergence:   1493.49\n",
      "variational_beta * kldivergence:  0.14935\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32881\n",
      "kldivergence:   1572.93\n",
      "variational_beta * kldivergence:  0.15729\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35163\n",
      "kldivergence:   1464.50\n",
      "variational_beta * kldivergence:  0.14645\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29076\n",
      "kldivergence:   1331.51\n",
      "variational_beta * kldivergence:  0.13315\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30032\n",
      "kldivergence:   1340.19\n",
      "variational_beta * kldivergence:  0.13402\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34834\n",
      "kldivergence:   1581.62\n",
      "variational_beta * kldivergence:  0.15816\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32188\n",
      "kldivergence:   1555.36\n",
      "variational_beta * kldivergence:  0.15554\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26813\n",
      "kldivergence:   1336.44\n",
      "variational_beta * kldivergence:  0.13364\n",
      "batch accuracy: 90.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33458\n",
      "kldivergence:   1289.84\n",
      "variational_beta * kldivergence:  0.12898\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28366\n",
      "kldivergence:   1494.50\n",
      "variational_beta * kldivergence:  0.14945\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33837\n",
      "kldivergence:   1476.99\n",
      "variational_beta * kldivergence:  0.14770\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31674\n",
      "kldivergence:   1327.09\n",
      "variational_beta * kldivergence:  0.13271\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34154\n",
      "kldivergence:   1477.20\n",
      "variational_beta * kldivergence:  0.14772\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31916\n",
      "kldivergence:   1686.27\n",
      "variational_beta * kldivergence:  0.16863\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34278\n",
      "kldivergence:   1686.02\n",
      "variational_beta * kldivergence:  0.16860\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28608\n",
      "kldivergence:   1311.14\n",
      "variational_beta * kldivergence:  0.13111\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30660\n",
      "kldivergence:   1756.20\n",
      "variational_beta * kldivergence:  0.17562\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37831\n",
      "kldivergence:   1754.92\n",
      "variational_beta * kldivergence:  0.17549\n",
      "batch accuracy: 87.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32188\n",
      "kldivergence:   1393.50\n",
      "variational_beta * kldivergence:  0.13935\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34425\n",
      "kldivergence:   1406.35\n",
      "variational_beta * kldivergence:  0.14064\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31484\n",
      "kldivergence:   1323.94\n",
      "variational_beta * kldivergence:  0.13239\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34813\n",
      "kldivergence:   1523.26\n",
      "variational_beta * kldivergence:  0.15233\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34283\n",
      "kldivergence:   1456.18\n",
      "variational_beta * kldivergence:  0.14562\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28914\n",
      "kldivergence:   1473.65\n",
      "variational_beta * kldivergence:  0.14737\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32323\n",
      "kldivergence:   1398.70\n",
      "variational_beta * kldivergence:  0.13987\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35740\n",
      "kldivergence:   1444.42\n",
      "variational_beta * kldivergence:  0.14444\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.39447\n",
      "kldivergence:   1595.50\n",
      "variational_beta * kldivergence:  0.15955\n",
      "batch accuracy: 86.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27878\n",
      "kldivergence:   1333.86\n",
      "variational_beta * kldivergence:  0.13339\n",
      "batch accuracy: 90.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33002\n",
      "kldivergence:   1294.18\n",
      "variational_beta * kldivergence:  0.12942\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37421\n",
      "kldivergence:   1623.01\n",
      "variational_beta * kldivergence:  0.16230\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29306\n",
      "kldivergence:   1418.25\n",
      "variational_beta * kldivergence:  0.14182\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28699\n",
      "kldivergence:   1424.59\n",
      "variational_beta * kldivergence:  0.14246\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35966\n",
      "kldivergence:   1557.19\n",
      "variational_beta * kldivergence:  0.15572\n",
      "batch accuracy: 87.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29550\n",
      "kldivergence:   1348.58\n",
      "variational_beta * kldivergence:  0.13486\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28406\n",
      "kldivergence:   1541.83\n",
      "variational_beta * kldivergence:  0.15418\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36754\n",
      "kldivergence:   1679.48\n",
      "variational_beta * kldivergence:  0.16795\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33119\n",
      "kldivergence:   1525.22\n",
      "variational_beta * kldivergence:  0.15252\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33563\n",
      "kldivergence:   1631.63\n",
      "variational_beta * kldivergence:  0.16316\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30211\n",
      "kldivergence:   1312.25\n",
      "variational_beta * kldivergence:  0.13123\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37211\n",
      "kldivergence:   1637.03\n",
      "variational_beta * kldivergence:  0.16370\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30242\n",
      "kldivergence:   1552.93\n",
      "variational_beta * kldivergence:  0.15529\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36801\n",
      "kldivergence:   1815.43\n",
      "variational_beta * kldivergence:  0.18154\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33621\n",
      "kldivergence:   1465.00\n",
      "variational_beta * kldivergence:  0.14650\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27356\n",
      "kldivergence:   1356.16\n",
      "variational_beta * kldivergence:  0.13562\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30854\n",
      "kldivergence:   1464.41\n",
      "variational_beta * kldivergence:  0.14644\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31354\n",
      "kldivergence:   1496.89\n",
      "variational_beta * kldivergence:  0.14969\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28366\n",
      "kldivergence:   1352.27\n",
      "variational_beta * kldivergence:  0.13523\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35708\n",
      "kldivergence:   1558.99\n",
      "variational_beta * kldivergence:  0.15590\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37175\n",
      "kldivergence:   1657.03\n",
      "variational_beta * kldivergence:  0.16570\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29960\n",
      "kldivergence:   1363.87\n",
      "variational_beta * kldivergence:  0.13639\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31192\n",
      "kldivergence:   1382.73\n",
      "variational_beta * kldivergence:  0.13827\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30487\n",
      "kldivergence:   1427.78\n",
      "variational_beta * kldivergence:  0.14278\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31280\n",
      "kldivergence:   1236.46\n",
      "variational_beta * kldivergence:  0.12365\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32631\n",
      "kldivergence:   1678.20\n",
      "variational_beta * kldivergence:  0.16782\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34942\n",
      "kldivergence:   1636.85\n",
      "variational_beta * kldivergence:  0.16369\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32506\n",
      "kldivergence:   1728.15\n",
      "variational_beta * kldivergence:  0.17282\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29347\n",
      "kldivergence:   1429.15\n",
      "variational_beta * kldivergence:  0.14291\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32545\n",
      "kldivergence:   1522.33\n",
      "variational_beta * kldivergence:  0.15223\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31207\n",
      "kldivergence:   1553.85\n",
      "variational_beta * kldivergence:  0.15539\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29873\n",
      "kldivergence:   1738.65\n",
      "variational_beta * kldivergence:  0.17387\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30464\n",
      "kldivergence:   1482.19\n",
      "variational_beta * kldivergence:  0.14822\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33424\n",
      "kldivergence:   1489.55\n",
      "variational_beta * kldivergence:  0.14895\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.24958\n",
      "kldivergence:   1285.93\n",
      "variational_beta * kldivergence:  0.12859\n",
      "batch accuracy: 91.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30325\n",
      "kldivergence:   1461.58\n",
      "variational_beta * kldivergence:  0.14616\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32981\n",
      "kldivergence:   1553.34\n",
      "variational_beta * kldivergence:  0.15533\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29573\n",
      "kldivergence:   1462.64\n",
      "variational_beta * kldivergence:  0.14626\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32332\n",
      "kldivergence:   1585.31\n",
      "variational_beta * kldivergence:  0.15853\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35561\n",
      "kldivergence:   1540.10\n",
      "variational_beta * kldivergence:  0.15401\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34546\n",
      "kldivergence:   1459.21\n",
      "variational_beta * kldivergence:  0.14592\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30469\n",
      "kldivergence:   1201.06\n",
      "variational_beta * kldivergence:  0.12011\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33416\n",
      "kldivergence:   1599.96\n",
      "variational_beta * kldivergence:  0.16000\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35756\n",
      "kldivergence:   1668.88\n",
      "variational_beta * kldivergence:  0.16689\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31175\n",
      "kldivergence:   1389.57\n",
      "variational_beta * kldivergence:  0.13896\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31568\n",
      "kldivergence:   1571.76\n",
      "variational_beta * kldivergence:  0.15718\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32597\n",
      "kldivergence:   1539.30\n",
      "variational_beta * kldivergence:  0.15393\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35642\n",
      "kldivergence:   1531.87\n",
      "variational_beta * kldivergence:  0.15319\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32473\n",
      "kldivergence:   1477.80\n",
      "variational_beta * kldivergence:  0.14778\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35643\n",
      "kldivergence:   1571.87\n",
      "variational_beta * kldivergence:  0.15719\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28114\n",
      "kldivergence:   1314.48\n",
      "variational_beta * kldivergence:  0.13145\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30953\n",
      "kldivergence:   1444.43\n",
      "variational_beta * kldivergence:  0.14444\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31862\n",
      "kldivergence:   1463.69\n",
      "variational_beta * kldivergence:  0.14637\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33676\n",
      "kldivergence:   1525.14\n",
      "variational_beta * kldivergence:  0.15251\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27979\n",
      "kldivergence:   1295.83\n",
      "variational_beta * kldivergence:  0.12958\n",
      "batch accuracy: 90.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33974\n",
      "kldivergence:   1410.63\n",
      "variational_beta * kldivergence:  0.14106\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33391\n",
      "kldivergence:   1651.65\n",
      "variational_beta * kldivergence:  0.16517\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33008\n",
      "kldivergence:   1631.54\n",
      "variational_beta * kldivergence:  0.16315\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33047\n",
      "kldivergence:   1580.92\n",
      "variational_beta * kldivergence:  0.15809\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26981\n",
      "kldivergence:   1352.30\n",
      "variational_beta * kldivergence:  0.13523\n",
      "batch accuracy: 90.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34059\n",
      "kldivergence:   1680.03\n",
      "variational_beta * kldivergence:  0.16800\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34091\n",
      "kldivergence:   1537.42\n",
      "variational_beta * kldivergence:  0.15374\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34070\n",
      "kldivergence:   1360.93\n",
      "variational_beta * kldivergence:  0.13609\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35475\n",
      "kldivergence:   1714.14\n",
      "variational_beta * kldivergence:  0.17141\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35778\n",
      "kldivergence:   1585.83\n",
      "variational_beta * kldivergence:  0.15858\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35591\n",
      "kldivergence:   1540.55\n",
      "variational_beta * kldivergence:  0.15405\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31918\n",
      "kldivergence:   1471.91\n",
      "variational_beta * kldivergence:  0.14719\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34201\n",
      "kldivergence:   1408.77\n",
      "variational_beta * kldivergence:  0.14088\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29924\n",
      "kldivergence:   1396.69\n",
      "variational_beta * kldivergence:  0.13967\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33420\n",
      "kldivergence:   1320.88\n",
      "variational_beta * kldivergence:  0.13209\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30779\n",
      "kldivergence:   1560.10\n",
      "variational_beta * kldivergence:  0.15601\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28699\n",
      "kldivergence:   1356.66\n",
      "variational_beta * kldivergence:  0.13567\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27638\n",
      "kldivergence:   1362.34\n",
      "variational_beta * kldivergence:  0.13623\n",
      "batch accuracy: 90.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32383\n",
      "kldivergence:   1272.91\n",
      "variational_beta * kldivergence:  0.12729\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31968\n",
      "kldivergence:   1543.06\n",
      "variational_beta * kldivergence:  0.15431\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33959\n",
      "kldivergence:   1283.93\n",
      "variational_beta * kldivergence:  0.12839\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32997\n",
      "kldivergence:   1453.62\n",
      "variational_beta * kldivergence:  0.14536\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33630\n",
      "kldivergence:   1590.65\n",
      "variational_beta * kldivergence:  0.15907\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32494\n",
      "kldivergence:   1374.61\n",
      "variational_beta * kldivergence:  0.13746\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31004\n",
      "kldivergence:   1367.99\n",
      "variational_beta * kldivergence:  0.13680\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30788\n",
      "kldivergence:   1356.48\n",
      "variational_beta * kldivergence:  0.13565\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26604\n",
      "kldivergence:   1340.56\n",
      "variational_beta * kldivergence:  0.13406\n",
      "batch accuracy: 91.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34732\n",
      "kldivergence:   1669.74\n",
      "variational_beta * kldivergence:  0.16697\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31491\n",
      "kldivergence:   1528.08\n",
      "variational_beta * kldivergence:  0.15281\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31383\n",
      "kldivergence:   1642.75\n",
      "variational_beta * kldivergence:  0.16428\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35878\n",
      "kldivergence:   1543.18\n",
      "variational_beta * kldivergence:  0.15432\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32231\n",
      "kldivergence:   1309.78\n",
      "variational_beta * kldivergence:  0.13098\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29765\n",
      "kldivergence:   1488.58\n",
      "variational_beta * kldivergence:  0.14886\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35494\n",
      "kldivergence:   1602.31\n",
      "variational_beta * kldivergence:  0.16023\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30278\n",
      "kldivergence:   1530.11\n",
      "variational_beta * kldivergence:  0.15301\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26735\n",
      "kldivergence:   1384.77\n",
      "variational_beta * kldivergence:  0.13848\n",
      "batch accuracy: 91.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34717\n",
      "kldivergence:   1590.61\n",
      "variational_beta * kldivergence:  0.15906\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37027\n",
      "kldivergence:   1524.76\n",
      "variational_beta * kldivergence:  0.15248\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33606\n",
      "kldivergence:   1433.27\n",
      "variational_beta * kldivergence:  0.14333\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33931\n",
      "kldivergence:   1484.55\n",
      "variational_beta * kldivergence:  0.14845\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30107\n",
      "kldivergence:   1498.01\n",
      "variational_beta * kldivergence:  0.14980\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32185\n",
      "kldivergence:   1390.19\n",
      "variational_beta * kldivergence:  0.13902\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31194\n",
      "kldivergence:   1530.93\n",
      "variational_beta * kldivergence:  0.15309\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31860\n",
      "kldivergence:   1456.55\n",
      "variational_beta * kldivergence:  0.14565\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27894\n",
      "kldivergence:   1294.99\n",
      "variational_beta * kldivergence:  0.12950\n",
      "batch accuracy: 91.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27054\n",
      "kldivergence:   1299.30\n",
      "variational_beta * kldivergence:  0.12993\n",
      "batch accuracy: 90.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32859\n",
      "kldivergence:   1457.84\n",
      "variational_beta * kldivergence:  0.14578\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31859\n",
      "kldivergence:   1585.53\n",
      "variational_beta * kldivergence:  0.15855\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28020\n",
      "kldivergence:   1375.08\n",
      "variational_beta * kldivergence:  0.13751\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33552\n",
      "kldivergence:   1423.13\n",
      "variational_beta * kldivergence:  0.14231\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34218\n",
      "kldivergence:   1510.14\n",
      "variational_beta * kldivergence:  0.15101\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33800\n",
      "kldivergence:   1512.35\n",
      "variational_beta * kldivergence:  0.15123\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31979\n",
      "kldivergence:   1423.34\n",
      "variational_beta * kldivergence:  0.14233\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30847\n",
      "kldivergence:   1552.83\n",
      "variational_beta * kldivergence:  0.15528\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37149\n",
      "kldivergence:   1434.94\n",
      "variational_beta * kldivergence:  0.14349\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36212\n",
      "kldivergence:   1710.37\n",
      "variational_beta * kldivergence:  0.17104\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33499\n",
      "kldivergence:   1577.98\n",
      "variational_beta * kldivergence:  0.15780\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30549\n",
      "kldivergence:   1395.27\n",
      "variational_beta * kldivergence:  0.13953\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28306\n",
      "kldivergence:   1557.19\n",
      "variational_beta * kldivergence:  0.15572\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33916\n",
      "kldivergence:   1574.25\n",
      "variational_beta * kldivergence:  0.15743\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26781\n",
      "kldivergence:   1390.91\n",
      "variational_beta * kldivergence:  0.13909\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31934\n",
      "kldivergence:   1403.48\n",
      "variational_beta * kldivergence:  0.14035\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34136\n",
      "kldivergence:   1422.72\n",
      "variational_beta * kldivergence:  0.14227\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29555\n",
      "kldivergence:   1442.79\n",
      "variational_beta * kldivergence:  0.14428\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32998\n",
      "kldivergence:   1436.95\n",
      "variational_beta * kldivergence:  0.14369\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33651\n",
      "kldivergence:   1531.44\n",
      "variational_beta * kldivergence:  0.15314\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31129\n",
      "kldivergence:   1462.01\n",
      "variational_beta * kldivergence:  0.14620\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34070\n",
      "kldivergence:   1548.67\n",
      "variational_beta * kldivergence:  0.15487\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28368\n",
      "kldivergence:   1458.29\n",
      "variational_beta * kldivergence:  0.14583\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32648\n",
      "kldivergence:   1304.76\n",
      "variational_beta * kldivergence:  0.13048\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33810\n",
      "kldivergence:   1467.78\n",
      "variational_beta * kldivergence:  0.14678\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36811\n",
      "kldivergence:   1387.58\n",
      "variational_beta * kldivergence:  0.13876\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33303\n",
      "kldivergence:   1575.90\n",
      "variational_beta * kldivergence:  0.15759\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33009\n",
      "kldivergence:   1432.24\n",
      "variational_beta * kldivergence:  0.14322\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27737\n",
      "kldivergence:   1636.79\n",
      "variational_beta * kldivergence:  0.16368\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33910\n",
      "kldivergence:   1719.03\n",
      "variational_beta * kldivergence:  0.17190\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28101\n",
      "kldivergence:   1501.06\n",
      "variational_beta * kldivergence:  0.15011\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34649\n",
      "kldivergence:   1428.90\n",
      "variational_beta * kldivergence:  0.14289\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28369\n",
      "kldivergence:   1214.52\n",
      "variational_beta * kldivergence:  0.12145\n",
      "batch accuracy: 90.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32983\n",
      "kldivergence:   1665.61\n",
      "variational_beta * kldivergence:  0.16656\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34034\n",
      "kldivergence:   1431.64\n",
      "variational_beta * kldivergence:  0.14316\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28700\n",
      "kldivergence:   1453.80\n",
      "variational_beta * kldivergence:  0.14538\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29942\n",
      "kldivergence:   1418.10\n",
      "variational_beta * kldivergence:  0.14181\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33027\n",
      "kldivergence:   1516.14\n",
      "variational_beta * kldivergence:  0.15161\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28490\n",
      "kldivergence:   1425.33\n",
      "variational_beta * kldivergence:  0.14253\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30875\n",
      "kldivergence:   1383.32\n",
      "variational_beta * kldivergence:  0.13833\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32485\n",
      "kldivergence:   1644.44\n",
      "variational_beta * kldivergence:  0.16444\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26103\n",
      "kldivergence:   1481.88\n",
      "variational_beta * kldivergence:  0.14819\n",
      "batch accuracy: 90.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34642\n",
      "kldivergence:   1776.02\n",
      "variational_beta * kldivergence:  0.17760\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29916\n",
      "kldivergence:   1393.36\n",
      "variational_beta * kldivergence:  0.13934\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32810\n",
      "kldivergence:   1596.17\n",
      "variational_beta * kldivergence:  0.15962\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37921\n",
      "kldivergence:   1891.76\n",
      "variational_beta * kldivergence:  0.18918\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32069\n",
      "kldivergence:   1479.94\n",
      "variational_beta * kldivergence:  0.14799\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32329\n",
      "kldivergence:   1599.65\n",
      "variational_beta * kldivergence:  0.15996\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34864\n",
      "kldivergence:   1830.16\n",
      "variational_beta * kldivergence:  0.18302\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27611\n",
      "kldivergence:   1452.81\n",
      "variational_beta * kldivergence:  0.14528\n",
      "batch accuracy: 90.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.39292\n",
      "kldivergence:   1548.59\n",
      "variational_beta * kldivergence:  0.15486\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29199\n",
      "kldivergence:   1453.91\n",
      "variational_beta * kldivergence:  0.14539\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34722\n",
      "kldivergence:   1768.69\n",
      "variational_beta * kldivergence:  0.17687\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30766\n",
      "kldivergence:   1463.32\n",
      "variational_beta * kldivergence:  0.14633\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35337\n",
      "kldivergence:   1788.55\n",
      "variational_beta * kldivergence:  0.17886\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31608\n",
      "kldivergence:   1496.06\n",
      "variational_beta * kldivergence:  0.14961\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32555\n",
      "kldivergence:   1557.46\n",
      "variational_beta * kldivergence:  0.15575\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.38529\n",
      "kldivergence:   1481.75\n",
      "variational_beta * kldivergence:  0.14817\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.25869\n",
      "kldivergence:   1150.94\n",
      "variational_beta * kldivergence:  0.11509\n",
      "batch accuracy: 90.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34873\n",
      "kldivergence:   1512.57\n",
      "variational_beta * kldivergence:  0.15126\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28222\n",
      "kldivergence:   1303.61\n",
      "variational_beta * kldivergence:  0.13036\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.39215\n",
      "kldivergence:   1610.84\n",
      "variational_beta * kldivergence:  0.16108\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36415\n",
      "kldivergence:   1440.51\n",
      "variational_beta * kldivergence:  0.14405\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34769\n",
      "kldivergence:   1436.61\n",
      "variational_beta * kldivergence:  0.14366\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34367\n",
      "kldivergence:   1396.19\n",
      "variational_beta * kldivergence:  0.13962\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33808\n",
      "kldivergence:   1328.45\n",
      "variational_beta * kldivergence:  0.13284\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35020\n",
      "kldivergence:   1421.09\n",
      "variational_beta * kldivergence:  0.14211\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29175\n",
      "kldivergence:   1569.11\n",
      "variational_beta * kldivergence:  0.15691\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26673\n",
      "kldivergence:   1284.06\n",
      "variational_beta * kldivergence:  0.12841\n",
      "batch accuracy: 91.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.38809\n",
      "kldivergence:   1556.44\n",
      "variational_beta * kldivergence:  0.15564\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35874\n",
      "kldivergence:   1662.34\n",
      "variational_beta * kldivergence:  0.16623\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34221\n",
      "kldivergence:   1536.88\n",
      "variational_beta * kldivergence:  0.15369\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36286\n",
      "kldivergence:   1388.33\n",
      "variational_beta * kldivergence:  0.13883\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32102\n",
      "kldivergence:   1394.51\n",
      "variational_beta * kldivergence:  0.13945\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34581\n",
      "kldivergence:   1495.97\n",
      "variational_beta * kldivergence:  0.14960\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37736\n",
      "kldivergence:   1471.00\n",
      "variational_beta * kldivergence:  0.14710\n",
      "batch accuracy: 87.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33098\n",
      "kldivergence:   1713.04\n",
      "variational_beta * kldivergence:  0.17130\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33895\n",
      "kldivergence:   1501.47\n",
      "variational_beta * kldivergence:  0.15015\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33146\n",
      "kldivergence:   1430.29\n",
      "variational_beta * kldivergence:  0.14303\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32495\n",
      "kldivergence:   1371.10\n",
      "variational_beta * kldivergence:  0.13711\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34242\n",
      "kldivergence:   1412.34\n",
      "variational_beta * kldivergence:  0.14123\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33419\n",
      "kldivergence:   1483.19\n",
      "variational_beta * kldivergence:  0.14832\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.40644\n",
      "kldivergence:   1586.74\n",
      "variational_beta * kldivergence:  0.15867\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32231\n",
      "kldivergence:   1527.41\n",
      "variational_beta * kldivergence:  0.15274\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33857\n",
      "kldivergence:   1413.38\n",
      "variational_beta * kldivergence:  0.14134\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34740\n",
      "kldivergence:   1557.25\n",
      "variational_beta * kldivergence:  0.15573\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37235\n",
      "kldivergence:   1590.35\n",
      "variational_beta * kldivergence:  0.15904\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29920\n",
      "kldivergence:   1367.84\n",
      "variational_beta * kldivergence:  0.13678\n",
      "batch accuracy: 90.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34755\n",
      "kldivergence:   1486.02\n",
      "variational_beta * kldivergence:  0.14860\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36305\n",
      "kldivergence:   1581.85\n",
      "variational_beta * kldivergence:  0.15819\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35258\n",
      "kldivergence:   1390.42\n",
      "variational_beta * kldivergence:  0.13904\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33803\n",
      "kldivergence:   1540.32\n",
      "variational_beta * kldivergence:  0.15403\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32999\n",
      "kldivergence:   1460.11\n",
      "variational_beta * kldivergence:  0.14601\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30468\n",
      "kldivergence:   1548.50\n",
      "variational_beta * kldivergence:  0.15485\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35634\n",
      "kldivergence:   1400.90\n",
      "variational_beta * kldivergence:  0.14009\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36511\n",
      "kldivergence:   1655.99\n",
      "variational_beta * kldivergence:  0.16560\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27957\n",
      "kldivergence:   1328.89\n",
      "variational_beta * kldivergence:  0.13289\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33508\n",
      "kldivergence:   1482.94\n",
      "variational_beta * kldivergence:  0.14829\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32754\n",
      "kldivergence:   1814.18\n",
      "variational_beta * kldivergence:  0.18142\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31911\n",
      "kldivergence:   1688.61\n",
      "variational_beta * kldivergence:  0.16886\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31596\n",
      "kldivergence:   1599.36\n",
      "variational_beta * kldivergence:  0.15994\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31987\n",
      "kldivergence:   1508.16\n",
      "variational_beta * kldivergence:  0.15082\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32439\n",
      "kldivergence:   1310.98\n",
      "variational_beta * kldivergence:  0.13110\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35990\n",
      "kldivergence:   1433.22\n",
      "variational_beta * kldivergence:  0.14332\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31304\n",
      "kldivergence:   1560.76\n",
      "variational_beta * kldivergence:  0.15608\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.38253\n",
      "kldivergence:   1675.28\n",
      "variational_beta * kldivergence:  0.16753\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33316\n",
      "kldivergence:   1801.36\n",
      "variational_beta * kldivergence:  0.18014\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34547\n",
      "kldivergence:   1627.26\n",
      "variational_beta * kldivergence:  0.16273\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.38944\n",
      "kldivergence:   1744.47\n",
      "variational_beta * kldivergence:  0.17445\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34091\n",
      "kldivergence:   1659.84\n",
      "variational_beta * kldivergence:  0.16598\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36019\n",
      "kldivergence:   1633.62\n",
      "variational_beta * kldivergence:  0.16336\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35226\n",
      "kldivergence:   1626.28\n",
      "variational_beta * kldivergence:  0.16263\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32276\n",
      "kldivergence:   1501.90\n",
      "variational_beta * kldivergence:  0.15019\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34632\n",
      "kldivergence:   1430.40\n",
      "variational_beta * kldivergence:  0.14304\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30975\n",
      "kldivergence:   1452.27\n",
      "variational_beta * kldivergence:  0.14523\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28253\n",
      "kldivergence:   1584.47\n",
      "variational_beta * kldivergence:  0.15845\n",
      "batch accuracy: 90.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28463\n",
      "kldivergence:   1332.80\n",
      "variational_beta * kldivergence:  0.13328\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32948\n",
      "kldivergence:   1467.77\n",
      "variational_beta * kldivergence:  0.14678\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31488\n",
      "kldivergence:   1385.16\n",
      "variational_beta * kldivergence:  0.13852\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34273\n",
      "kldivergence:   1544.08\n",
      "variational_beta * kldivergence:  0.15441\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26422\n",
      "kldivergence:   1433.56\n",
      "variational_beta * kldivergence:  0.14336\n",
      "batch accuracy: 91.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32406\n",
      "kldivergence:   1531.26\n",
      "variational_beta * kldivergence:  0.15313\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35369\n",
      "kldivergence:   1426.74\n",
      "variational_beta * kldivergence:  0.14267\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34431\n",
      "kldivergence:   1608.71\n",
      "variational_beta * kldivergence:  0.16087\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31898\n",
      "kldivergence:   1335.43\n",
      "variational_beta * kldivergence:  0.13354\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34883\n",
      "kldivergence:   1549.54\n",
      "variational_beta * kldivergence:  0.15495\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37561\n",
      "kldivergence:   1694.63\n",
      "variational_beta * kldivergence:  0.16946\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31530\n",
      "kldivergence:   1372.95\n",
      "variational_beta * kldivergence:  0.13729\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32721\n",
      "kldivergence:   1296.90\n",
      "variational_beta * kldivergence:  0.12969\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30656\n",
      "kldivergence:   1439.66\n",
      "variational_beta * kldivergence:  0.14397\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31095\n",
      "kldivergence:   1658.93\n",
      "variational_beta * kldivergence:  0.16589\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33216\n",
      "kldivergence:   1677.03\n",
      "variational_beta * kldivergence:  0.16770\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30690\n",
      "kldivergence:   1675.23\n",
      "variational_beta * kldivergence:  0.16752\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32002\n",
      "kldivergence:   1691.31\n",
      "variational_beta * kldivergence:  0.16913\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33605\n",
      "kldivergence:   1510.24\n",
      "variational_beta * kldivergence:  0.15102\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35260\n",
      "kldivergence:   1650.80\n",
      "variational_beta * kldivergence:  0.16508\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31278\n",
      "kldivergence:   1561.95\n",
      "variational_beta * kldivergence:  0.15620\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31620\n",
      "kldivergence:   1526.77\n",
      "variational_beta * kldivergence:  0.15268\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33450\n",
      "kldivergence:   1504.57\n",
      "variational_beta * kldivergence:  0.15046\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33343\n",
      "kldivergence:   1328.26\n",
      "variational_beta * kldivergence:  0.13283\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35614\n",
      "kldivergence:   1585.32\n",
      "variational_beta * kldivergence:  0.15853\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.27948\n",
      "kldivergence:   1345.95\n",
      "variational_beta * kldivergence:  0.13460\n",
      "batch accuracy: 90.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32013\n",
      "kldivergence:   1505.86\n",
      "variational_beta * kldivergence:  0.15059\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36412\n",
      "kldivergence:   1379.08\n",
      "variational_beta * kldivergence:  0.13791\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26634\n",
      "kldivergence:   1361.98\n",
      "variational_beta * kldivergence:  0.13620\n",
      "batch accuracy: 90.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33454\n",
      "kldivergence:   1454.36\n",
      "variational_beta * kldivergence:  0.14544\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29777\n",
      "kldivergence:   1340.81\n",
      "variational_beta * kldivergence:  0.13408\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32792\n",
      "kldivergence:   1518.93\n",
      "variational_beta * kldivergence:  0.15189\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32283\n",
      "kldivergence:   1494.63\n",
      "variational_beta * kldivergence:  0.14946\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31536\n",
      "kldivergence:   1500.39\n",
      "variational_beta * kldivergence:  0.15004\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30441\n",
      "kldivergence:   1419.42\n",
      "variational_beta * kldivergence:  0.14194\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32800\n",
      "kldivergence:   1459.59\n",
      "variational_beta * kldivergence:  0.14596\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31145\n",
      "kldivergence:   1612.21\n",
      "variational_beta * kldivergence:  0.16122\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30711\n",
      "kldivergence:   1478.40\n",
      "variational_beta * kldivergence:  0.14784\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37423\n",
      "kldivergence:   1460.10\n",
      "variational_beta * kldivergence:  0.14601\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30151\n",
      "kldivergence:   1509.85\n",
      "variational_beta * kldivergence:  0.15098\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26432\n",
      "kldivergence:   1684.74\n",
      "variational_beta * kldivergence:  0.16847\n",
      "batch accuracy: 91.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33336\n",
      "kldivergence:   1613.28\n",
      "variational_beta * kldivergence:  0.16133\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30655\n",
      "kldivergence:   1438.60\n",
      "variational_beta * kldivergence:  0.14386\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35542\n",
      "kldivergence:   1626.22\n",
      "variational_beta * kldivergence:  0.16262\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36005\n",
      "kldivergence:   1598.61\n",
      "variational_beta * kldivergence:  0.15986\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29789\n",
      "kldivergence:   1388.86\n",
      "variational_beta * kldivergence:  0.13889\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.28839\n",
      "kldivergence:   1585.46\n",
      "variational_beta * kldivergence:  0.15855\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.33763\n",
      "kldivergence:   1552.56\n",
      "variational_beta * kldivergence:  0.15526\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.37125\n",
      "kldivergence:   1714.79\n",
      "variational_beta * kldivergence:  0.17148\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26825\n",
      "kldivergence:   1472.40\n",
      "variational_beta * kldivergence:  0.14724\n",
      "batch accuracy: 90.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32298\n",
      "kldivergence:   1469.00\n",
      "variational_beta * kldivergence:  0.14690\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.25566\n",
      "kldivergence:   1357.60\n",
      "variational_beta * kldivergence:  0.13576\n",
      "batch accuracy: 91.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34390\n",
      "kldivergence:   1570.27\n",
      "variational_beta * kldivergence:  0.15703\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29762\n",
      "kldivergence:   1570.84\n",
      "variational_beta * kldivergence:  0.15708\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31447\n",
      "kldivergence:   1590.89\n",
      "variational_beta * kldivergence:  0.15909\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.29559\n",
      "kldivergence:   1476.53\n",
      "variational_beta * kldivergence:  0.14765\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32413\n",
      "kldivergence:   1455.58\n",
      "variational_beta * kldivergence:  0.14556\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30969\n",
      "kldivergence:   1460.08\n",
      "variational_beta * kldivergence:  0.14601\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31780\n",
      "kldivergence:   1538.59\n",
      "variational_beta * kldivergence:  0.15386\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30265\n",
      "kldivergence:   1511.29\n",
      "variational_beta * kldivergence:  0.15113\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32579\n",
      "kldivergence:   1615.08\n",
      "variational_beta * kldivergence:  0.16151\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32669\n",
      "kldivergence:   1500.63\n",
      "variational_beta * kldivergence:  0.15006\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30912\n",
      "kldivergence:   1439.04\n",
      "variational_beta * kldivergence:  0.14390\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30691\n",
      "kldivergence:   1502.92\n",
      "variational_beta * kldivergence:  0.15029\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.34045\n",
      "kldivergence:   1581.83\n",
      "variational_beta * kldivergence:  0.15818\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.36370\n",
      "kldivergence:   1528.84\n",
      "variational_beta * kldivergence:  0.15288\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30986\n",
      "kldivergence:   1663.29\n",
      "variational_beta * kldivergence:  0.16633\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.35005\n",
      "kldivergence:   1579.25\n",
      "variational_beta * kldivergence:  0.15793\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30270\n",
      "kldivergence:   1546.95\n",
      "variational_beta * kldivergence:  0.15470\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31707\n",
      "kldivergence:   1437.34\n",
      "variational_beta * kldivergence:  0.14373\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30517\n",
      "kldivergence:   1369.73\n",
      "variational_beta * kldivergence:  0.13697\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32764\n",
      "kldivergence:   1677.55\n",
      "variational_beta * kldivergence:  0.16776\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32395\n",
      "kldivergence:   1489.51\n",
      "variational_beta * kldivergence:  0.14895\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.30368\n",
      "kldivergence:   1478.68\n",
      "variational_beta * kldivergence:  0.14787\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31622\n",
      "kldivergence:   1498.68\n",
      "variational_beta * kldivergence:  0.14987\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.31323\n",
      "kldivergence:   1415.59\n",
      "variational_beta * kldivergence:  0.14156\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.26202\n",
      "kldivergence:   1305.65\n",
      "variational_beta * kldivergence:  0.13057\n",
      "batch accuracy: 91.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #57\n",
      "reconstruction loss: 0.32240\n",
      "kldivergence:   1483.56\n",
      "variational_beta * kldivergence:  0.14836\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.47148\n",
      "kldivergence:   1444.97\n",
      "variational_beta * kldivergence:  0.14450\n",
      "batch accuracy: 85.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.49005\n",
      "kldivergence:   1403.70\n",
      "variational_beta * kldivergence:  0.14037\n",
      "batch accuracy: 86.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.41565\n",
      "kldivergence:   1363.25\n",
      "variational_beta * kldivergence:  0.13632\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.37908\n",
      "kldivergence:   1294.37\n",
      "variational_beta * kldivergence:  0.12944\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.50490\n",
      "kldivergence:   1388.50\n",
      "variational_beta * kldivergence:  0.13885\n",
      "batch accuracy: 85.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.45575\n",
      "kldivergence:   1455.13\n",
      "variational_beta * kldivergence:  0.14551\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.50563\n",
      "kldivergence:   1498.57\n",
      "variational_beta * kldivergence:  0.14986\n",
      "batch accuracy: 84.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.49098\n",
      "kldivergence:   1450.14\n",
      "variational_beta * kldivergence:  0.14501\n",
      "batch accuracy: 85.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.39434\n",
      "kldivergence:   1325.15\n",
      "variational_beta * kldivergence:  0.13252\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.52987\n",
      "kldivergence:   1510.41\n",
      "variational_beta * kldivergence:  0.15104\n",
      "batch accuracy: 84.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.47845\n",
      "kldivergence:   1381.85\n",
      "variational_beta * kldivergence:  0.13818\n",
      "batch accuracy: 85.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.42380\n",
      "kldivergence:   1345.53\n",
      "variational_beta * kldivergence:  0.13455\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.50361\n",
      "kldivergence:   1548.41\n",
      "variational_beta * kldivergence:  0.15484\n",
      "batch accuracy: 84.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.36847\n",
      "kldivergence:   1304.62\n",
      "variational_beta * kldivergence:  0.13046\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.43296\n",
      "kldivergence:   1370.83\n",
      "variational_beta * kldivergence:  0.13708\n",
      "batch accuracy: 86.47\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.53966\n",
      "kldivergence:   1614.94\n",
      "variational_beta * kldivergence:  0.16149\n",
      "batch accuracy: 83.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.52608\n",
      "kldivergence:   1439.01\n",
      "variational_beta * kldivergence:  0.14390\n",
      "batch accuracy: 84.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.49897\n",
      "kldivergence:   1582.17\n",
      "variational_beta * kldivergence:  0.15822\n",
      "batch accuracy: 85.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.38330\n",
      "kldivergence:   1347.89\n",
      "variational_beta * kldivergence:  0.13479\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.46394\n",
      "kldivergence:   1485.15\n",
      "variational_beta * kldivergence:  0.14851\n",
      "batch accuracy: 85.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.55038\n",
      "kldivergence:   1461.66\n",
      "variational_beta * kldivergence:  0.14617\n",
      "batch accuracy: 83.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.40802\n",
      "kldivergence:   1388.31\n",
      "variational_beta * kldivergence:  0.13883\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.45606\n",
      "kldivergence:   1412.94\n",
      "variational_beta * kldivergence:  0.14129\n",
      "batch accuracy: 85.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.37911\n",
      "kldivergence:   1308.90\n",
      "variational_beta * kldivergence:  0.13089\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.48491\n",
      "kldivergence:   1432.48\n",
      "variational_beta * kldivergence:  0.14325\n",
      "batch accuracy: 84.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.39507\n",
      "kldivergence:   1452.50\n",
      "variational_beta * kldivergence:  0.14525\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.44083\n",
      "kldivergence:   1370.84\n",
      "variational_beta * kldivergence:  0.13708\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.40798\n",
      "kldivergence:   1230.04\n",
      "variational_beta * kldivergence:  0.12300\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.40242\n",
      "kldivergence:   1329.49\n",
      "variational_beta * kldivergence:  0.13295\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.46580\n",
      "kldivergence:   1435.99\n",
      "variational_beta * kldivergence:  0.14360\n",
      "batch accuracy: 86.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.39217\n",
      "kldivergence:   1344.21\n",
      "variational_beta * kldivergence:  0.13442\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.43836\n",
      "kldivergence:   1365.55\n",
      "variational_beta * kldivergence:  0.13656\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.45783\n",
      "kldivergence:   1466.64\n",
      "variational_beta * kldivergence:  0.14666\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.40278\n",
      "kldivergence:   1377.75\n",
      "variational_beta * kldivergence:  0.13778\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.38666\n",
      "kldivergence:   1323.19\n",
      "variational_beta * kldivergence:  0.13232\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.54410\n",
      "kldivergence:   1506.87\n",
      "variational_beta * kldivergence:  0.15069\n",
      "batch accuracy: 83.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.41767\n",
      "kldivergence:   1298.76\n",
      "variational_beta * kldivergence:  0.12988\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.39921\n",
      "kldivergence:   1270.35\n",
      "variational_beta * kldivergence:  0.12703\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.46402\n",
      "kldivergence:   1367.66\n",
      "variational_beta * kldivergence:  0.13677\n",
      "batch accuracy: 85.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.37758\n",
      "kldivergence:   1317.09\n",
      "variational_beta * kldivergence:  0.13171\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.47557\n",
      "kldivergence:   1410.32\n",
      "variational_beta * kldivergence:  0.14103\n",
      "batch accuracy: 86.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.39606\n",
      "kldivergence:   1346.16\n",
      "variational_beta * kldivergence:  0.13462\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.46346\n",
      "kldivergence:   1376.62\n",
      "variational_beta * kldivergence:  0.13766\n",
      "batch accuracy: 86.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.43528\n",
      "kldivergence:   1364.84\n",
      "variational_beta * kldivergence:  0.13648\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.44270\n",
      "kldivergence:   1417.93\n",
      "variational_beta * kldivergence:  0.14179\n",
      "batch accuracy: 86.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.41299\n",
      "kldivergence:   1353.47\n",
      "variational_beta * kldivergence:  0.13535\n",
      "batch accuracy: 86.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.37870\n",
      "kldivergence:   1351.33\n",
      "variational_beta * kldivergence:  0.13513\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.44664\n",
      "kldivergence:   1328.33\n",
      "variational_beta * kldivergence:  0.13283\n",
      "batch accuracy: 86.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.37997\n",
      "kldivergence:   1298.61\n",
      "variational_beta * kldivergence:  0.12986\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.42501\n",
      "kldivergence:   1423.16\n",
      "variational_beta * kldivergence:  0.14232\n",
      "batch accuracy: 86.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.44447\n",
      "kldivergence:   1349.61\n",
      "variational_beta * kldivergence:  0.13496\n",
      "batch accuracy: 85.97\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.40536\n",
      "kldivergence:   1286.95\n",
      "variational_beta * kldivergence:  0.12870\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.50156\n",
      "kldivergence:   1461.58\n",
      "variational_beta * kldivergence:  0.14616\n",
      "batch accuracy: 84.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.48092\n",
      "kldivergence:   1535.20\n",
      "variational_beta * kldivergence:  0.15352\n",
      "batch accuracy: 85.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.46063\n",
      "kldivergence:   1445.22\n",
      "variational_beta * kldivergence:  0.14452\n",
      "batch accuracy: 85.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.48407\n",
      "kldivergence:   1472.74\n",
      "variational_beta * kldivergence:  0.14727\n",
      "batch accuracy: 84.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.43955\n",
      "kldivergence:   1367.51\n",
      "variational_beta * kldivergence:  0.13675\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.52109\n",
      "kldivergence:   1453.47\n",
      "variational_beta * kldivergence:  0.14535\n",
      "batch accuracy: 84.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.45728\n",
      "kldivergence:   1338.82\n",
      "variational_beta * kldivergence:  0.13388\n",
      "batch accuracy: 86.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.47899\n",
      "kldivergence:   1412.43\n",
      "variational_beta * kldivergence:  0.14124\n",
      "batch accuracy: 85.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.59819\n",
      "kldivergence:   1455.56\n",
      "variational_beta * kldivergence:  0.14556\n",
      "batch accuracy: 83.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #57\n",
      "reconstruction loss: 0.44288\n",
      "kldivergence:   1432.46\n",
      "variational_beta * kldivergence:  0.14325\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "epoch # 57 : train loss is [176.31640346898942] and validation loss is [0.09883846911756923] \n",
      "saved samples\n",
      "Epoch [58 / 150] average reconstruction error: 0.475246\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29191\n",
      "kldivergence:   1431.05\n",
      "variational_beta * kldivergence:  0.14311\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35955\n",
      "kldivergence:   1846.12\n",
      "variational_beta * kldivergence:  0.18461\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33516\n",
      "kldivergence:   1509.97\n",
      "variational_beta * kldivergence:  0.15100\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32929\n",
      "kldivergence:   1353.40\n",
      "variational_beta * kldivergence:  0.13534\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32506\n",
      "kldivergence:   1412.44\n",
      "variational_beta * kldivergence:  0.14124\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34787\n",
      "kldivergence:   1590.73\n",
      "variational_beta * kldivergence:  0.15907\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30706\n",
      "kldivergence:   1430.76\n",
      "variational_beta * kldivergence:  0.14308\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34673\n",
      "kldivergence:   1462.94\n",
      "variational_beta * kldivergence:  0.14629\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35929\n",
      "kldivergence:   1577.62\n",
      "variational_beta * kldivergence:  0.15776\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.25202\n",
      "kldivergence:   1483.35\n",
      "variational_beta * kldivergence:  0.14833\n",
      "batch accuracy: 91.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33691\n",
      "kldivergence:   1805.41\n",
      "variational_beta * kldivergence:  0.18054\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31502\n",
      "kldivergence:   1395.76\n",
      "variational_beta * kldivergence:  0.13958\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.40667\n",
      "kldivergence:   1482.09\n",
      "variational_beta * kldivergence:  0.14821\n",
      "batch accuracy: 86.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35746\n",
      "kldivergence:   1388.48\n",
      "variational_beta * kldivergence:  0.13885\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30764\n",
      "kldivergence:   1449.81\n",
      "variational_beta * kldivergence:  0.14498\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33275\n",
      "kldivergence:   1585.78\n",
      "variational_beta * kldivergence:  0.15858\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30584\n",
      "kldivergence:   1354.45\n",
      "variational_beta * kldivergence:  0.13545\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29435\n",
      "kldivergence:   1387.69\n",
      "variational_beta * kldivergence:  0.13877\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35404\n",
      "kldivergence:   1708.81\n",
      "variational_beta * kldivergence:  0.17088\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30406\n",
      "kldivergence:   1307.18\n",
      "variational_beta * kldivergence:  0.13072\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34431\n",
      "kldivergence:   1439.44\n",
      "variational_beta * kldivergence:  0.14394\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.38253\n",
      "kldivergence:   1618.37\n",
      "variational_beta * kldivergence:  0.16184\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33072\n",
      "kldivergence:   1437.19\n",
      "variational_beta * kldivergence:  0.14372\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30928\n",
      "kldivergence:   1459.00\n",
      "variational_beta * kldivergence:  0.14590\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30851\n",
      "kldivergence:   1439.82\n",
      "variational_beta * kldivergence:  0.14398\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30312\n",
      "kldivergence:   1454.95\n",
      "variational_beta * kldivergence:  0.14550\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36224\n",
      "kldivergence:   1628.74\n",
      "variational_beta * kldivergence:  0.16287\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32169\n",
      "kldivergence:   1654.55\n",
      "variational_beta * kldivergence:  0.16545\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29921\n",
      "kldivergence:   1418.85\n",
      "variational_beta * kldivergence:  0.14189\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29372\n",
      "kldivergence:   1414.94\n",
      "variational_beta * kldivergence:  0.14149\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29011\n",
      "kldivergence:   1335.47\n",
      "variational_beta * kldivergence:  0.13355\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34666\n",
      "kldivergence:   1472.12\n",
      "variational_beta * kldivergence:  0.14721\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35206\n",
      "kldivergence:   1603.19\n",
      "variational_beta * kldivergence:  0.16032\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32702\n",
      "kldivergence:   1441.32\n",
      "variational_beta * kldivergence:  0.14413\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30569\n",
      "kldivergence:   1485.56\n",
      "variational_beta * kldivergence:  0.14856\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36510\n",
      "kldivergence:   1629.23\n",
      "variational_beta * kldivergence:  0.16292\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35019\n",
      "kldivergence:   1551.15\n",
      "variational_beta * kldivergence:  0.15512\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33645\n",
      "kldivergence:   1545.46\n",
      "variational_beta * kldivergence:  0.15455\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33195\n",
      "kldivergence:   1517.91\n",
      "variational_beta * kldivergence:  0.15179\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35119\n",
      "kldivergence:   1537.84\n",
      "variational_beta * kldivergence:  0.15378\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36206\n",
      "kldivergence:   1533.49\n",
      "variational_beta * kldivergence:  0.15335\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32244\n",
      "kldivergence:   1420.11\n",
      "variational_beta * kldivergence:  0.14201\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35232\n",
      "kldivergence:   1748.17\n",
      "variational_beta * kldivergence:  0.17482\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30696\n",
      "kldivergence:   1381.28\n",
      "variational_beta * kldivergence:  0.13813\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36570\n",
      "kldivergence:   1523.68\n",
      "variational_beta * kldivergence:  0.15237\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33040\n",
      "kldivergence:   1326.62\n",
      "variational_beta * kldivergence:  0.13266\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34923\n",
      "kldivergence:   1703.00\n",
      "variational_beta * kldivergence:  0.17030\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30204\n",
      "kldivergence:   1621.25\n",
      "variational_beta * kldivergence:  0.16213\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35821\n",
      "kldivergence:   1502.30\n",
      "variational_beta * kldivergence:  0.15023\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37144\n",
      "kldivergence:   1630.13\n",
      "variational_beta * kldivergence:  0.16301\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27950\n",
      "kldivergence:   1248.88\n",
      "variational_beta * kldivergence:  0.12489\n",
      "batch accuracy: 90.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29397\n",
      "kldivergence:   1961.91\n",
      "variational_beta * kldivergence:  0.19619\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27471\n",
      "kldivergence:   1464.65\n",
      "variational_beta * kldivergence:  0.14647\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31492\n",
      "kldivergence:   1631.57\n",
      "variational_beta * kldivergence:  0.16316\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27679\n",
      "kldivergence:   1364.25\n",
      "variational_beta * kldivergence:  0.13642\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32378\n",
      "kldivergence:   1367.45\n",
      "variational_beta * kldivergence:  0.13674\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33134\n",
      "kldivergence:   1409.64\n",
      "variational_beta * kldivergence:  0.14096\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31727\n",
      "kldivergence:   1428.22\n",
      "variational_beta * kldivergence:  0.14282\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30779\n",
      "kldivergence:   1550.30\n",
      "variational_beta * kldivergence:  0.15503\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32183\n",
      "kldivergence:   1537.60\n",
      "variational_beta * kldivergence:  0.15376\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33221\n",
      "kldivergence:   1563.26\n",
      "variational_beta * kldivergence:  0.15633\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31395\n",
      "kldivergence:   1534.01\n",
      "variational_beta * kldivergence:  0.15340\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32936\n",
      "kldivergence:   1577.08\n",
      "variational_beta * kldivergence:  0.15771\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34823\n",
      "kldivergence:   1513.37\n",
      "variational_beta * kldivergence:  0.15134\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32303\n",
      "kldivergence:   1517.59\n",
      "variational_beta * kldivergence:  0.15176\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32716\n",
      "kldivergence:   1436.33\n",
      "variational_beta * kldivergence:  0.14363\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31034\n",
      "kldivergence:   1377.23\n",
      "variational_beta * kldivergence:  0.13772\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28908\n",
      "kldivergence:   1429.04\n",
      "variational_beta * kldivergence:  0.14290\n",
      "batch accuracy: 90.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33847\n",
      "kldivergence:   1560.45\n",
      "variational_beta * kldivergence:  0.15605\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30609\n",
      "kldivergence:   1487.38\n",
      "variational_beta * kldivergence:  0.14874\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31938\n",
      "kldivergence:   1390.92\n",
      "variational_beta * kldivergence:  0.13909\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34843\n",
      "kldivergence:   1363.23\n",
      "variational_beta * kldivergence:  0.13632\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.25597\n",
      "kldivergence:   1216.57\n",
      "variational_beta * kldivergence:  0.12166\n",
      "batch accuracy: 91.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32328\n",
      "kldivergence:   1431.17\n",
      "variational_beta * kldivergence:  0.14312\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33877\n",
      "kldivergence:   1453.24\n",
      "variational_beta * kldivergence:  0.14532\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34029\n",
      "kldivergence:   1504.13\n",
      "variational_beta * kldivergence:  0.15041\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33645\n",
      "kldivergence:   1395.87\n",
      "variational_beta * kldivergence:  0.13959\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31061\n",
      "kldivergence:   1263.40\n",
      "variational_beta * kldivergence:  0.12634\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.38063\n",
      "kldivergence:   1640.97\n",
      "variational_beta * kldivergence:  0.16410\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36555\n",
      "kldivergence:   1631.87\n",
      "variational_beta * kldivergence:  0.16319\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29718\n",
      "kldivergence:   1203.07\n",
      "variational_beta * kldivergence:  0.12031\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35897\n",
      "kldivergence:   1575.01\n",
      "variational_beta * kldivergence:  0.15750\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34207\n",
      "kldivergence:   1308.23\n",
      "variational_beta * kldivergence:  0.13082\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37234\n",
      "kldivergence:   1564.66\n",
      "variational_beta * kldivergence:  0.15647\n",
      "batch accuracy: 87.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.26306\n",
      "kldivergence:   1271.98\n",
      "variational_beta * kldivergence:  0.12720\n",
      "batch accuracy: 91.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31730\n",
      "kldivergence:   1431.98\n",
      "variational_beta * kldivergence:  0.14320\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37044\n",
      "kldivergence:   1612.03\n",
      "variational_beta * kldivergence:  0.16120\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33795\n",
      "kldivergence:   1497.58\n",
      "variational_beta * kldivergence:  0.14976\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29777\n",
      "kldivergence:   1565.54\n",
      "variational_beta * kldivergence:  0.15655\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30872\n",
      "kldivergence:   1396.66\n",
      "variational_beta * kldivergence:  0.13967\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33707\n",
      "kldivergence:   1424.17\n",
      "variational_beta * kldivergence:  0.14242\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31754\n",
      "kldivergence:   1417.33\n",
      "variational_beta * kldivergence:  0.14173\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33063\n",
      "kldivergence:   1412.18\n",
      "variational_beta * kldivergence:  0.14122\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32349\n",
      "kldivergence:   1349.15\n",
      "variational_beta * kldivergence:  0.13491\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35345\n",
      "kldivergence:   1610.92\n",
      "variational_beta * kldivergence:  0.16109\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35017\n",
      "kldivergence:   1474.29\n",
      "variational_beta * kldivergence:  0.14743\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31077\n",
      "kldivergence:   1505.12\n",
      "variational_beta * kldivergence:  0.15051\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31512\n",
      "kldivergence:   1610.46\n",
      "variational_beta * kldivergence:  0.16105\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27487\n",
      "kldivergence:   1318.23\n",
      "variational_beta * kldivergence:  0.13182\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30629\n",
      "kldivergence:   1369.32\n",
      "variational_beta * kldivergence:  0.13693\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34329\n",
      "kldivergence:   1667.30\n",
      "variational_beta * kldivergence:  0.16673\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36921\n",
      "kldivergence:   1567.07\n",
      "variational_beta * kldivergence:  0.15671\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33193\n",
      "kldivergence:   1431.54\n",
      "variational_beta * kldivergence:  0.14315\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27630\n",
      "kldivergence:   1688.84\n",
      "variational_beta * kldivergence:  0.16888\n",
      "batch accuracy: 90.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31038\n",
      "kldivergence:   1384.02\n",
      "variational_beta * kldivergence:  0.13840\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31641\n",
      "kldivergence:   1437.27\n",
      "variational_beta * kldivergence:  0.14373\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33390\n",
      "kldivergence:   1618.68\n",
      "variational_beta * kldivergence:  0.16187\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29845\n",
      "kldivergence:   1426.67\n",
      "variational_beta * kldivergence:  0.14267\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28305\n",
      "kldivergence:   1267.60\n",
      "variational_beta * kldivergence:  0.12676\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28362\n",
      "kldivergence:   1445.63\n",
      "variational_beta * kldivergence:  0.14456\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34792\n",
      "kldivergence:   1635.10\n",
      "variational_beta * kldivergence:  0.16351\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37911\n",
      "kldivergence:   1809.80\n",
      "variational_beta * kldivergence:  0.18098\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30919\n",
      "kldivergence:   1585.74\n",
      "variational_beta * kldivergence:  0.15857\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34663\n",
      "kldivergence:   1882.44\n",
      "variational_beta * kldivergence:  0.18824\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35399\n",
      "kldivergence:   1427.40\n",
      "variational_beta * kldivergence:  0.14274\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31510\n",
      "kldivergence:   1587.95\n",
      "variational_beta * kldivergence:  0.15880\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36123\n",
      "kldivergence:   1555.31\n",
      "variational_beta * kldivergence:  0.15553\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33681\n",
      "kldivergence:   1604.24\n",
      "variational_beta * kldivergence:  0.16042\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33305\n",
      "kldivergence:   1541.82\n",
      "variational_beta * kldivergence:  0.15418\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31140\n",
      "kldivergence:   1458.79\n",
      "variational_beta * kldivergence:  0.14588\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33585\n",
      "kldivergence:   1652.78\n",
      "variational_beta * kldivergence:  0.16528\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36369\n",
      "kldivergence:   1439.34\n",
      "variational_beta * kldivergence:  0.14393\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30941\n",
      "kldivergence:   1444.17\n",
      "variational_beta * kldivergence:  0.14442\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32819\n",
      "kldivergence:   1333.80\n",
      "variational_beta * kldivergence:  0.13338\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34243\n",
      "kldivergence:   1497.47\n",
      "variational_beta * kldivergence:  0.14975\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29878\n",
      "kldivergence:   1520.37\n",
      "variational_beta * kldivergence:  0.15204\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33631\n",
      "kldivergence:   1454.67\n",
      "variational_beta * kldivergence:  0.14547\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32399\n",
      "kldivergence:   1537.97\n",
      "variational_beta * kldivergence:  0.15380\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30796\n",
      "kldivergence:   1404.71\n",
      "variational_beta * kldivergence:  0.14047\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32186\n",
      "kldivergence:   1618.73\n",
      "variational_beta * kldivergence:  0.16187\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33180\n",
      "kldivergence:   1617.26\n",
      "variational_beta * kldivergence:  0.16173\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33620\n",
      "kldivergence:   1704.44\n",
      "variational_beta * kldivergence:  0.17044\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36259\n",
      "kldivergence:   1468.22\n",
      "variational_beta * kldivergence:  0.14682\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30906\n",
      "kldivergence:   1544.52\n",
      "variational_beta * kldivergence:  0.15445\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33044\n",
      "kldivergence:   1357.70\n",
      "variational_beta * kldivergence:  0.13577\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36118\n",
      "kldivergence:   1685.11\n",
      "variational_beta * kldivergence:  0.16851\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31370\n",
      "kldivergence:   1442.15\n",
      "variational_beta * kldivergence:  0.14421\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30130\n",
      "kldivergence:   1303.33\n",
      "variational_beta * kldivergence:  0.13033\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37119\n",
      "kldivergence:   1481.41\n",
      "variational_beta * kldivergence:  0.14814\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33801\n",
      "kldivergence:   1559.94\n",
      "variational_beta * kldivergence:  0.15599\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34693\n",
      "kldivergence:   1643.26\n",
      "variational_beta * kldivergence:  0.16433\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35229\n",
      "kldivergence:   1556.09\n",
      "variational_beta * kldivergence:  0.15561\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.26950\n",
      "kldivergence:   1394.10\n",
      "variational_beta * kldivergence:  0.13941\n",
      "batch accuracy: 90.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31529\n",
      "kldivergence:   1404.95\n",
      "variational_beta * kldivergence:  0.14049\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32281\n",
      "kldivergence:   1550.85\n",
      "variational_beta * kldivergence:  0.15508\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29489\n",
      "kldivergence:   1496.56\n",
      "variational_beta * kldivergence:  0.14966\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31757\n",
      "kldivergence:   1453.86\n",
      "variational_beta * kldivergence:  0.14539\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32404\n",
      "kldivergence:   1535.71\n",
      "variational_beta * kldivergence:  0.15357\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34225\n",
      "kldivergence:   1472.70\n",
      "variational_beta * kldivergence:  0.14727\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37097\n",
      "kldivergence:   1764.22\n",
      "variational_beta * kldivergence:  0.17642\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.38548\n",
      "kldivergence:   1549.69\n",
      "variational_beta * kldivergence:  0.15497\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33099\n",
      "kldivergence:   1485.02\n",
      "variational_beta * kldivergence:  0.14850\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31849\n",
      "kldivergence:   1575.47\n",
      "variational_beta * kldivergence:  0.15755\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33597\n",
      "kldivergence:   1392.68\n",
      "variational_beta * kldivergence:  0.13927\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35708\n",
      "kldivergence:   1637.60\n",
      "variational_beta * kldivergence:  0.16376\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35568\n",
      "kldivergence:   1636.88\n",
      "variational_beta * kldivergence:  0.16369\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33235\n",
      "kldivergence:   1445.88\n",
      "variational_beta * kldivergence:  0.14459\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30657\n",
      "kldivergence:   1547.60\n",
      "variational_beta * kldivergence:  0.15476\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33009\n",
      "kldivergence:   1437.20\n",
      "variational_beta * kldivergence:  0.14372\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29463\n",
      "kldivergence:   1299.26\n",
      "variational_beta * kldivergence:  0.12993\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31611\n",
      "kldivergence:   1513.19\n",
      "variational_beta * kldivergence:  0.15132\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31999\n",
      "kldivergence:   1439.41\n",
      "variational_beta * kldivergence:  0.14394\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28624\n",
      "kldivergence:   1711.64\n",
      "variational_beta * kldivergence:  0.17116\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33038\n",
      "kldivergence:   1663.99\n",
      "variational_beta * kldivergence:  0.16640\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.26383\n",
      "kldivergence:   1236.26\n",
      "variational_beta * kldivergence:  0.12363\n",
      "batch accuracy: 91.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27907\n",
      "kldivergence:   1588.28\n",
      "variational_beta * kldivergence:  0.15883\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.38309\n",
      "kldivergence:   1706.28\n",
      "variational_beta * kldivergence:  0.17063\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29010\n",
      "kldivergence:   1377.40\n",
      "variational_beta * kldivergence:  0.13774\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30692\n",
      "kldivergence:   1486.17\n",
      "variational_beta * kldivergence:  0.14862\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.26925\n",
      "kldivergence:   1416.06\n",
      "variational_beta * kldivergence:  0.14161\n",
      "batch accuracy: 90.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36667\n",
      "kldivergence:   1505.83\n",
      "variational_beta * kldivergence:  0.15058\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33992\n",
      "kldivergence:   1315.64\n",
      "variational_beta * kldivergence:  0.13156\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27485\n",
      "kldivergence:   1580.48\n",
      "variational_beta * kldivergence:  0.15805\n",
      "batch accuracy: 90.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29598\n",
      "kldivergence:   1365.49\n",
      "variational_beta * kldivergence:  0.13655\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33229\n",
      "kldivergence:   1382.41\n",
      "variational_beta * kldivergence:  0.13824\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31135\n",
      "kldivergence:   1476.15\n",
      "variational_beta * kldivergence:  0.14762\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29906\n",
      "kldivergence:   1307.76\n",
      "variational_beta * kldivergence:  0.13078\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32369\n",
      "kldivergence:   1448.50\n",
      "variational_beta * kldivergence:  0.14485\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31375\n",
      "kldivergence:   1403.99\n",
      "variational_beta * kldivergence:  0.14040\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33547\n",
      "kldivergence:   1545.06\n",
      "variational_beta * kldivergence:  0.15451\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31271\n",
      "kldivergence:   1480.56\n",
      "variational_beta * kldivergence:  0.14806\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.38265\n",
      "kldivergence:   1507.78\n",
      "variational_beta * kldivergence:  0.15078\n",
      "batch accuracy: 86.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33463\n",
      "kldivergence:   1362.75\n",
      "variational_beta * kldivergence:  0.13628\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32084\n",
      "kldivergence:   1518.20\n",
      "variational_beta * kldivergence:  0.15182\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37866\n",
      "kldivergence:   1710.79\n",
      "variational_beta * kldivergence:  0.17108\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34545\n",
      "kldivergence:   1539.37\n",
      "variational_beta * kldivergence:  0.15394\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.39742\n",
      "kldivergence:   1586.32\n",
      "variational_beta * kldivergence:  0.15863\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28967\n",
      "kldivergence:   1324.59\n",
      "variational_beta * kldivergence:  0.13246\n",
      "batch accuracy: 90.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35014\n",
      "kldivergence:   1628.42\n",
      "variational_beta * kldivergence:  0.16284\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36405\n",
      "kldivergence:   1477.18\n",
      "variational_beta * kldivergence:  0.14772\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28177\n",
      "kldivergence:   1521.38\n",
      "variational_beta * kldivergence:  0.15214\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32262\n",
      "kldivergence:   1572.74\n",
      "variational_beta * kldivergence:  0.15727\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34752\n",
      "kldivergence:   1670.62\n",
      "variational_beta * kldivergence:  0.16706\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37126\n",
      "kldivergence:   1590.11\n",
      "variational_beta * kldivergence:  0.15901\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33522\n",
      "kldivergence:   1586.08\n",
      "variational_beta * kldivergence:  0.15861\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32092\n",
      "kldivergence:   1538.49\n",
      "variational_beta * kldivergence:  0.15385\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37480\n",
      "kldivergence:   1582.33\n",
      "variational_beta * kldivergence:  0.15823\n",
      "batch accuracy: 87.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32632\n",
      "kldivergence:   1575.77\n",
      "variational_beta * kldivergence:  0.15758\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29194\n",
      "kldivergence:   1409.45\n",
      "variational_beta * kldivergence:  0.14095\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32935\n",
      "kldivergence:   1555.08\n",
      "variational_beta * kldivergence:  0.15551\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30698\n",
      "kldivergence:   1534.95\n",
      "variational_beta * kldivergence:  0.15349\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32510\n",
      "kldivergence:   1558.13\n",
      "variational_beta * kldivergence:  0.15581\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33367\n",
      "kldivergence:   1512.61\n",
      "variational_beta * kldivergence:  0.15126\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36197\n",
      "kldivergence:   1600.18\n",
      "variational_beta * kldivergence:  0.16002\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30617\n",
      "kldivergence:   1445.54\n",
      "variational_beta * kldivergence:  0.14455\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28933\n",
      "kldivergence:   1679.32\n",
      "variational_beta * kldivergence:  0.16793\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31873\n",
      "kldivergence:   1506.90\n",
      "variational_beta * kldivergence:  0.15069\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36432\n",
      "kldivergence:   1692.24\n",
      "variational_beta * kldivergence:  0.16922\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31605\n",
      "kldivergence:   1496.54\n",
      "variational_beta * kldivergence:  0.14965\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28704\n",
      "kldivergence:   1489.28\n",
      "variational_beta * kldivergence:  0.14893\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29602\n",
      "kldivergence:   1460.33\n",
      "variational_beta * kldivergence:  0.14603\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.39167\n",
      "kldivergence:   2022.48\n",
      "variational_beta * kldivergence:  0.20225\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33277\n",
      "kldivergence:   1569.36\n",
      "variational_beta * kldivergence:  0.15694\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31492\n",
      "kldivergence:   1553.85\n",
      "variational_beta * kldivergence:  0.15538\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31220\n",
      "kldivergence:   1351.10\n",
      "variational_beta * kldivergence:  0.13511\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37449\n",
      "kldivergence:   1618.24\n",
      "variational_beta * kldivergence:  0.16182\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30978\n",
      "kldivergence:   1369.50\n",
      "variational_beta * kldivergence:  0.13695\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34164\n",
      "kldivergence:   1550.87\n",
      "variational_beta * kldivergence:  0.15509\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28893\n",
      "kldivergence:   1456.53\n",
      "variational_beta * kldivergence:  0.14565\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29513\n",
      "kldivergence:   1348.71\n",
      "variational_beta * kldivergence:  0.13487\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35478\n",
      "kldivergence:   1487.19\n",
      "variational_beta * kldivergence:  0.14872\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29260\n",
      "kldivergence:   1758.07\n",
      "variational_beta * kldivergence:  0.17581\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28041\n",
      "kldivergence:   1347.08\n",
      "variational_beta * kldivergence:  0.13471\n",
      "batch accuracy: 90.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28957\n",
      "kldivergence:   1400.98\n",
      "variational_beta * kldivergence:  0.14010\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32301\n",
      "kldivergence:   1638.48\n",
      "variational_beta * kldivergence:  0.16385\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.26433\n",
      "kldivergence:   1419.20\n",
      "variational_beta * kldivergence:  0.14192\n",
      "batch accuracy: 91.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32145\n",
      "kldivergence:   1488.84\n",
      "variational_beta * kldivergence:  0.14888\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35536\n",
      "kldivergence:   1635.32\n",
      "variational_beta * kldivergence:  0.16353\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31383\n",
      "kldivergence:   1389.04\n",
      "variational_beta * kldivergence:  0.13890\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28245\n",
      "kldivergence:   1287.18\n",
      "variational_beta * kldivergence:  0.12872\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29558\n",
      "kldivergence:   1466.00\n",
      "variational_beta * kldivergence:  0.14660\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32493\n",
      "kldivergence:   1399.79\n",
      "variational_beta * kldivergence:  0.13998\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35244\n",
      "kldivergence:   1572.73\n",
      "variational_beta * kldivergence:  0.15727\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29850\n",
      "kldivergence:   1425.37\n",
      "variational_beta * kldivergence:  0.14254\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33652\n",
      "kldivergence:   1408.38\n",
      "variational_beta * kldivergence:  0.14084\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31068\n",
      "kldivergence:   1403.42\n",
      "variational_beta * kldivergence:  0.14034\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28249\n",
      "kldivergence:   1328.85\n",
      "variational_beta * kldivergence:  0.13289\n",
      "batch accuracy: 90.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.40550\n",
      "kldivergence:   1657.51\n",
      "variational_beta * kldivergence:  0.16575\n",
      "batch accuracy: 85.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36061\n",
      "kldivergence:   1409.53\n",
      "variational_beta * kldivergence:  0.14095\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29674\n",
      "kldivergence:   1602.84\n",
      "variational_beta * kldivergence:  0.16028\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29438\n",
      "kldivergence:   1507.08\n",
      "variational_beta * kldivergence:  0.15071\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29000\n",
      "kldivergence:   1414.64\n",
      "variational_beta * kldivergence:  0.14146\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32199\n",
      "kldivergence:   1715.28\n",
      "variational_beta * kldivergence:  0.17153\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34028\n",
      "kldivergence:   1483.37\n",
      "variational_beta * kldivergence:  0.14834\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33876\n",
      "kldivergence:   1436.12\n",
      "variational_beta * kldivergence:  0.14361\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27642\n",
      "kldivergence:   1373.96\n",
      "variational_beta * kldivergence:  0.13740\n",
      "batch accuracy: 90.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34980\n",
      "kldivergence:   1513.33\n",
      "variational_beta * kldivergence:  0.15133\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30564\n",
      "kldivergence:   1468.89\n",
      "variational_beta * kldivergence:  0.14689\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.24339\n",
      "kldivergence:   1189.14\n",
      "variational_beta * kldivergence:  0.11891\n",
      "batch accuracy: 91.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34221\n",
      "kldivergence:   1625.58\n",
      "variational_beta * kldivergence:  0.16256\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34483\n",
      "kldivergence:   1591.49\n",
      "variational_beta * kldivergence:  0.15915\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31784\n",
      "kldivergence:   1379.10\n",
      "variational_beta * kldivergence:  0.13791\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29493\n",
      "kldivergence:   1469.26\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.39130\n",
      "kldivergence:   1777.06\n",
      "variational_beta * kldivergence:  0.17771\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36047\n",
      "kldivergence:   1557.33\n",
      "variational_beta * kldivergence:  0.15573\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34387\n",
      "kldivergence:   1626.84\n",
      "variational_beta * kldivergence:  0.16268\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33446\n",
      "kldivergence:   1587.17\n",
      "variational_beta * kldivergence:  0.15872\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32514\n",
      "kldivergence:   1496.25\n",
      "variational_beta * kldivergence:  0.14962\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31304\n",
      "kldivergence:   1476.86\n",
      "variational_beta * kldivergence:  0.14769\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31139\n",
      "kldivergence:   1374.43\n",
      "variational_beta * kldivergence:  0.13744\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31374\n",
      "kldivergence:   1622.07\n",
      "variational_beta * kldivergence:  0.16221\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27805\n",
      "kldivergence:   1360.51\n",
      "variational_beta * kldivergence:  0.13605\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27215\n",
      "kldivergence:   1419.85\n",
      "variational_beta * kldivergence:  0.14198\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34024\n",
      "kldivergence:   1511.19\n",
      "variational_beta * kldivergence:  0.15112\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33310\n",
      "kldivergence:   1450.89\n",
      "variational_beta * kldivergence:  0.14509\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30446\n",
      "kldivergence:   1504.60\n",
      "variational_beta * kldivergence:  0.15046\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32597\n",
      "kldivergence:   1450.84\n",
      "variational_beta * kldivergence:  0.14508\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31096\n",
      "kldivergence:   1813.83\n",
      "variational_beta * kldivergence:  0.18138\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.23984\n",
      "kldivergence:   1403.67\n",
      "variational_beta * kldivergence:  0.14037\n",
      "batch accuracy: 91.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34818\n",
      "kldivergence:   1367.69\n",
      "variational_beta * kldivergence:  0.13677\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33639\n",
      "kldivergence:   1645.25\n",
      "variational_beta * kldivergence:  0.16453\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32923\n",
      "kldivergence:   1388.58\n",
      "variational_beta * kldivergence:  0.13886\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.39304\n",
      "kldivergence:   1752.88\n",
      "variational_beta * kldivergence:  0.17529\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30000\n",
      "kldivergence:   1456.16\n",
      "variational_beta * kldivergence:  0.14562\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.38109\n",
      "kldivergence:   1577.02\n",
      "variational_beta * kldivergence:  0.15770\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36137\n",
      "kldivergence:   1464.21\n",
      "variational_beta * kldivergence:  0.14642\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.25282\n",
      "kldivergence:   1230.36\n",
      "variational_beta * kldivergence:  0.12304\n",
      "batch accuracy: 91.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29319\n",
      "kldivergence:   1352.10\n",
      "variational_beta * kldivergence:  0.13521\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31101\n",
      "kldivergence:   1359.81\n",
      "variational_beta * kldivergence:  0.13598\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37895\n",
      "kldivergence:   1544.86\n",
      "variational_beta * kldivergence:  0.15449\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29905\n",
      "kldivergence:   1241.31\n",
      "variational_beta * kldivergence:  0.12413\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30479\n",
      "kldivergence:   1557.28\n",
      "variational_beta * kldivergence:  0.15573\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31186\n",
      "kldivergence:   1353.79\n",
      "variational_beta * kldivergence:  0.13538\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30019\n",
      "kldivergence:   1250.72\n",
      "variational_beta * kldivergence:  0.12507\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32840\n",
      "kldivergence:   1583.08\n",
      "variational_beta * kldivergence:  0.15831\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34017\n",
      "kldivergence:   1732.65\n",
      "variational_beta * kldivergence:  0.17327\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30753\n",
      "kldivergence:   1376.06\n",
      "variational_beta * kldivergence:  0.13761\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31193\n",
      "kldivergence:   1522.77\n",
      "variational_beta * kldivergence:  0.15228\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34335\n",
      "kldivergence:   1426.65\n",
      "variational_beta * kldivergence:  0.14267\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35224\n",
      "kldivergence:   1387.44\n",
      "variational_beta * kldivergence:  0.13874\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30583\n",
      "kldivergence:   1500.04\n",
      "variational_beta * kldivergence:  0.15000\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.25977\n",
      "kldivergence:   1576.66\n",
      "variational_beta * kldivergence:  0.15767\n",
      "batch accuracy: 90.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36660\n",
      "kldivergence:   1681.57\n",
      "variational_beta * kldivergence:  0.16816\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37103\n",
      "kldivergence:   1483.64\n",
      "variational_beta * kldivergence:  0.14836\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29764\n",
      "kldivergence:   1406.08\n",
      "variational_beta * kldivergence:  0.14061\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34040\n",
      "kldivergence:   1617.65\n",
      "variational_beta * kldivergence:  0.16176\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27507\n",
      "kldivergence:   1436.82\n",
      "variational_beta * kldivergence:  0.14368\n",
      "batch accuracy: 90.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.25930\n",
      "kldivergence:   1412.45\n",
      "variational_beta * kldivergence:  0.14125\n",
      "batch accuracy: 91.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34366\n",
      "kldivergence:   1534.02\n",
      "variational_beta * kldivergence:  0.15340\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31637\n",
      "kldivergence:   1529.80\n",
      "variational_beta * kldivergence:  0.15298\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33839\n",
      "kldivergence:   1499.59\n",
      "variational_beta * kldivergence:  0.14996\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32600\n",
      "kldivergence:   1418.89\n",
      "variational_beta * kldivergence:  0.14189\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30409\n",
      "kldivergence:   1559.89\n",
      "variational_beta * kldivergence:  0.15599\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35330\n",
      "kldivergence:   1362.48\n",
      "variational_beta * kldivergence:  0.13625\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30824\n",
      "kldivergence:   1462.21\n",
      "variational_beta * kldivergence:  0.14622\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32615\n",
      "kldivergence:   1481.12\n",
      "variational_beta * kldivergence:  0.14811\n",
      "batch accuracy: 89.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34227\n",
      "kldivergence:   1728.39\n",
      "variational_beta * kldivergence:  0.17284\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31185\n",
      "kldivergence:   1529.55\n",
      "variational_beta * kldivergence:  0.15296\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34135\n",
      "kldivergence:   1385.31\n",
      "variational_beta * kldivergence:  0.13853\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33912\n",
      "kldivergence:   1592.66\n",
      "variational_beta * kldivergence:  0.15927\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27355\n",
      "kldivergence:   1474.04\n",
      "variational_beta * kldivergence:  0.14740\n",
      "batch accuracy: 90.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31602\n",
      "kldivergence:   1451.22\n",
      "variational_beta * kldivergence:  0.14512\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29691\n",
      "kldivergence:   1359.82\n",
      "variational_beta * kldivergence:  0.13598\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33889\n",
      "kldivergence:   1471.67\n",
      "variational_beta * kldivergence:  0.14717\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28693\n",
      "kldivergence:   1576.37\n",
      "variational_beta * kldivergence:  0.15764\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30806\n",
      "kldivergence:   1463.05\n",
      "variational_beta * kldivergence:  0.14630\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37993\n",
      "kldivergence:   1529.30\n",
      "variational_beta * kldivergence:  0.15293\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30222\n",
      "kldivergence:   1654.69\n",
      "variational_beta * kldivergence:  0.16547\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32261\n",
      "kldivergence:   1307.93\n",
      "variational_beta * kldivergence:  0.13079\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.37591\n",
      "kldivergence:   1527.14\n",
      "variational_beta * kldivergence:  0.15271\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33774\n",
      "kldivergence:   1480.24\n",
      "variational_beta * kldivergence:  0.14802\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35283\n",
      "kldivergence:   1405.85\n",
      "variational_beta * kldivergence:  0.14059\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34466\n",
      "kldivergence:   1690.78\n",
      "variational_beta * kldivergence:  0.16908\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30808\n",
      "kldivergence:   1516.12\n",
      "variational_beta * kldivergence:  0.15161\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32307\n",
      "kldivergence:   1495.31\n",
      "variational_beta * kldivergence:  0.14953\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34123\n",
      "kldivergence:   1461.34\n",
      "variational_beta * kldivergence:  0.14613\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33747\n",
      "kldivergence:   1479.60\n",
      "variational_beta * kldivergence:  0.14796\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31007\n",
      "kldivergence:   1565.69\n",
      "variational_beta * kldivergence:  0.15657\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33239\n",
      "kldivergence:   1372.47\n",
      "variational_beta * kldivergence:  0.13725\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28494\n",
      "kldivergence:   1399.82\n",
      "variational_beta * kldivergence:  0.13998\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29346\n",
      "kldivergence:   1432.37\n",
      "variational_beta * kldivergence:  0.14324\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33371\n",
      "kldivergence:   1390.61\n",
      "variational_beta * kldivergence:  0.13906\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32675\n",
      "kldivergence:   1406.74\n",
      "variational_beta * kldivergence:  0.14067\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29253\n",
      "kldivergence:   1450.06\n",
      "variational_beta * kldivergence:  0.14501\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28163\n",
      "kldivergence:   1427.82\n",
      "variational_beta * kldivergence:  0.14278\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32195\n",
      "kldivergence:   1485.54\n",
      "variational_beta * kldivergence:  0.14855\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33584\n",
      "kldivergence:   1439.46\n",
      "variational_beta * kldivergence:  0.14395\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.38534\n",
      "kldivergence:   1737.41\n",
      "variational_beta * kldivergence:  0.17374\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32461\n",
      "kldivergence:   1377.03\n",
      "variational_beta * kldivergence:  0.13770\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32700\n",
      "kldivergence:   1613.65\n",
      "variational_beta * kldivergence:  0.16137\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.34276\n",
      "kldivergence:   1460.66\n",
      "variational_beta * kldivergence:  0.14607\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27060\n",
      "kldivergence:   1358.12\n",
      "variational_beta * kldivergence:  0.13581\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.38983\n",
      "kldivergence:   1746.01\n",
      "variational_beta * kldivergence:  0.17460\n",
      "batch accuracy: 86.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30497\n",
      "kldivergence:   1434.16\n",
      "variational_beta * kldivergence:  0.14342\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29722\n",
      "kldivergence:   1273.29\n",
      "variational_beta * kldivergence:  0.12733\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33552\n",
      "kldivergence:   1538.50\n",
      "variational_beta * kldivergence:  0.15385\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33976\n",
      "kldivergence:   1527.99\n",
      "variational_beta * kldivergence:  0.15280\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31297\n",
      "kldivergence:   1255.90\n",
      "variational_beta * kldivergence:  0.12559\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33660\n",
      "kldivergence:   1469.69\n",
      "variational_beta * kldivergence:  0.14697\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30989\n",
      "kldivergence:   1389.59\n",
      "variational_beta * kldivergence:  0.13896\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33966\n",
      "kldivergence:   1425.71\n",
      "variational_beta * kldivergence:  0.14257\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33716\n",
      "kldivergence:   1556.28\n",
      "variational_beta * kldivergence:  0.15563\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29716\n",
      "kldivergence:   1503.87\n",
      "variational_beta * kldivergence:  0.15039\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32927\n",
      "kldivergence:   1453.87\n",
      "variational_beta * kldivergence:  0.14539\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29516\n",
      "kldivergence:   1464.00\n",
      "variational_beta * kldivergence:  0.14640\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32652\n",
      "kldivergence:   1712.75\n",
      "variational_beta * kldivergence:  0.17127\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30423\n",
      "kldivergence:   1499.36\n",
      "variational_beta * kldivergence:  0.14994\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.30335\n",
      "kldivergence:   1445.50\n",
      "variational_beta * kldivergence:  0.14455\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.31678\n",
      "kldivergence:   1463.47\n",
      "variational_beta * kldivergence:  0.14635\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27033\n",
      "kldivergence:   1253.57\n",
      "variational_beta * kldivergence:  0.12536\n",
      "batch accuracy: 91.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.27305\n",
      "kldivergence:   1404.48\n",
      "variational_beta * kldivergence:  0.14045\n",
      "batch accuracy: 90.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29051\n",
      "kldivergence:   1540.14\n",
      "variational_beta * kldivergence:  0.15401\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29471\n",
      "kldivergence:   1407.00\n",
      "variational_beta * kldivergence:  0.14070\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.29698\n",
      "kldivergence:   1392.10\n",
      "variational_beta * kldivergence:  0.13921\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.32222\n",
      "kldivergence:   1526.28\n",
      "variational_beta * kldivergence:  0.15263\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.35056\n",
      "kldivergence:   1523.18\n",
      "variational_beta * kldivergence:  0.15232\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.36525\n",
      "kldivergence:   1767.18\n",
      "variational_beta * kldivergence:  0.17672\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33167\n",
      "kldivergence:   1363.01\n",
      "variational_beta * kldivergence:  0.13630\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33217\n",
      "kldivergence:   1477.37\n",
      "variational_beta * kldivergence:  0.14774\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.33339\n",
      "kldivergence:   1599.38\n",
      "variational_beta * kldivergence:  0.15994\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #58\n",
      "reconstruction loss: 0.28308\n",
      "kldivergence:   1372.37\n",
      "variational_beta * kldivergence:  0.13724\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.35438\n",
      "kldivergence:   1262.98\n",
      "variational_beta * kldivergence:  0.12630\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.52146\n",
      "kldivergence:   1483.97\n",
      "variational_beta * kldivergence:  0.14840\n",
      "batch accuracy: 84.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.52290\n",
      "kldivergence:   1526.36\n",
      "variational_beta * kldivergence:  0.15264\n",
      "batch accuracy: 83.87\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.38857\n",
      "kldivergence:   1206.80\n",
      "variational_beta * kldivergence:  0.12068\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.45468\n",
      "kldivergence:   1403.50\n",
      "variational_beta * kldivergence:  0.14035\n",
      "batch accuracy: 85.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.38839\n",
      "kldivergence:   1149.61\n",
      "variational_beta * kldivergence:  0.11496\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.44535\n",
      "kldivergence:   1365.69\n",
      "variational_beta * kldivergence:  0.13657\n",
      "batch accuracy: 86.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.48851\n",
      "kldivergence:   1422.94\n",
      "variational_beta * kldivergence:  0.14229\n",
      "batch accuracy: 85.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.43783\n",
      "kldivergence:   1328.65\n",
      "variational_beta * kldivergence:  0.13287\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.43395\n",
      "kldivergence:   1282.94\n",
      "variational_beta * kldivergence:  0.12829\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.49354\n",
      "kldivergence:   1497.03\n",
      "variational_beta * kldivergence:  0.14970\n",
      "batch accuracy: 85.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.42551\n",
      "kldivergence:   1439.13\n",
      "variational_beta * kldivergence:  0.14391\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.56882\n",
      "kldivergence:   1401.10\n",
      "variational_beta * kldivergence:  0.14011\n",
      "batch accuracy: 82.82\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.46428\n",
      "kldivergence:   1319.11\n",
      "variational_beta * kldivergence:  0.13191\n",
      "batch accuracy: 86.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.41850\n",
      "kldivergence:   1294.86\n",
      "variational_beta * kldivergence:  0.12949\n",
      "batch accuracy: 86.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.46606\n",
      "kldivergence:   1339.64\n",
      "variational_beta * kldivergence:  0.13396\n",
      "batch accuracy: 85.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.40573\n",
      "kldivergence:   1382.60\n",
      "variational_beta * kldivergence:  0.13826\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.44121\n",
      "kldivergence:   1364.30\n",
      "variational_beta * kldivergence:  0.13643\n",
      "batch accuracy: 86.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.57076\n",
      "kldivergence:   1431.96\n",
      "variational_beta * kldivergence:  0.14320\n",
      "batch accuracy: 82.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.43989\n",
      "kldivergence:   1365.79\n",
      "variational_beta * kldivergence:  0.13658\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.55459\n",
      "kldivergence:   1471.65\n",
      "variational_beta * kldivergence:  0.14716\n",
      "batch accuracy: 83.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.47568\n",
      "kldivergence:   1400.72\n",
      "variational_beta * kldivergence:  0.14007\n",
      "batch accuracy: 85.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.51489\n",
      "kldivergence:   1527.53\n",
      "variational_beta * kldivergence:  0.15275\n",
      "batch accuracy: 83.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.38471\n",
      "kldivergence:   1309.79\n",
      "variational_beta * kldivergence:  0.13098\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.45511\n",
      "kldivergence:   1335.36\n",
      "variational_beta * kldivergence:  0.13354\n",
      "batch accuracy: 86.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.47167\n",
      "kldivergence:   1459.73\n",
      "variational_beta * kldivergence:  0.14597\n",
      "batch accuracy: 85.27\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.43111\n",
      "kldivergence:   1321.70\n",
      "variational_beta * kldivergence:  0.13217\n",
      "batch accuracy: 86.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.48246\n",
      "kldivergence:   1323.07\n",
      "variational_beta * kldivergence:  0.13231\n",
      "batch accuracy: 85.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.45841\n",
      "kldivergence:   1350.43\n",
      "variational_beta * kldivergence:  0.13504\n",
      "batch accuracy: 85.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.53610\n",
      "kldivergence:   1443.37\n",
      "variational_beta * kldivergence:  0.14434\n",
      "batch accuracy: 84.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.45003\n",
      "kldivergence:   1386.54\n",
      "variational_beta * kldivergence:  0.13865\n",
      "batch accuracy: 85.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.48351\n",
      "kldivergence:   1422.71\n",
      "variational_beta * kldivergence:  0.14227\n",
      "batch accuracy: 85.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.43180\n",
      "kldivergence:   1282.56\n",
      "variational_beta * kldivergence:  0.12826\n",
      "batch accuracy: 86.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.45610\n",
      "kldivergence:   1453.42\n",
      "variational_beta * kldivergence:  0.14534\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.54045\n",
      "kldivergence:   1471.74\n",
      "variational_beta * kldivergence:  0.14717\n",
      "batch accuracy: 84.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.45542\n",
      "kldivergence:   1400.48\n",
      "variational_beta * kldivergence:  0.14005\n",
      "batch accuracy: 86.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.39122\n",
      "kldivergence:   1311.54\n",
      "variational_beta * kldivergence:  0.13115\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.42526\n",
      "kldivergence:   1357.68\n",
      "variational_beta * kldivergence:  0.13577\n",
      "batch accuracy: 86.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.42700\n",
      "kldivergence:   1349.17\n",
      "variational_beta * kldivergence:  0.13492\n",
      "batch accuracy: 86.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.40701\n",
      "kldivergence:   1378.95\n",
      "variational_beta * kldivergence:  0.13790\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.36158\n",
      "kldivergence:   1254.78\n",
      "variational_beta * kldivergence:  0.12548\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.47006\n",
      "kldivergence:   1454.11\n",
      "variational_beta * kldivergence:  0.14541\n",
      "batch accuracy: 85.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.55772\n",
      "kldivergence:   1478.81\n",
      "variational_beta * kldivergence:  0.14788\n",
      "batch accuracy: 84.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.50797\n",
      "kldivergence:   1321.47\n",
      "variational_beta * kldivergence:  0.13215\n",
      "batch accuracy: 84.92\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.43487\n",
      "kldivergence:   1388.20\n",
      "variational_beta * kldivergence:  0.13882\n",
      "batch accuracy: 87.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.44602\n",
      "kldivergence:   1356.68\n",
      "variational_beta * kldivergence:  0.13567\n",
      "batch accuracy: 86.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.42994\n",
      "kldivergence:   1304.15\n",
      "variational_beta * kldivergence:  0.13042\n",
      "batch accuracy: 86.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.46100\n",
      "kldivergence:   1351.43\n",
      "variational_beta * kldivergence:  0.13514\n",
      "batch accuracy: 85.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.47059\n",
      "kldivergence:   1328.30\n",
      "variational_beta * kldivergence:  0.13283\n",
      "batch accuracy: 85.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.47197\n",
      "kldivergence:   1466.87\n",
      "variational_beta * kldivergence:  0.14669\n",
      "batch accuracy: 84.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.39748\n",
      "kldivergence:   1247.13\n",
      "variational_beta * kldivergence:  0.12471\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.47739\n",
      "kldivergence:   1342.07\n",
      "variational_beta * kldivergence:  0.13421\n",
      "batch accuracy: 85.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.53125\n",
      "kldivergence:   1408.60\n",
      "variational_beta * kldivergence:  0.14086\n",
      "batch accuracy: 85.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.41932\n",
      "kldivergence:   1267.94\n",
      "variational_beta * kldivergence:  0.12679\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.44374\n",
      "kldivergence:   1360.71\n",
      "variational_beta * kldivergence:  0.13607\n",
      "batch accuracy: 86.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.46015\n",
      "kldivergence:   1308.62\n",
      "variational_beta * kldivergence:  0.13086\n",
      "batch accuracy: 86.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.42628\n",
      "kldivergence:   1260.56\n",
      "variational_beta * kldivergence:  0.12606\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.40165\n",
      "kldivergence:   1250.37\n",
      "variational_beta * kldivergence:  0.12504\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.54082\n",
      "kldivergence:   1405.30\n",
      "variational_beta * kldivergence:  0.14053\n",
      "batch accuracy: 83.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.37436\n",
      "kldivergence:   1242.93\n",
      "variational_beta * kldivergence:  0.12429\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.50601\n",
      "kldivergence:   1489.91\n",
      "variational_beta * kldivergence:  0.14899\n",
      "batch accuracy: 84.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #58\n",
      "reconstruction loss: 0.43888\n",
      "kldivergence:   1445.90\n",
      "variational_beta * kldivergence:  0.14459\n",
      "batch accuracy: 86.09\n",
      "\n",
      "\n",
      "epoch # 58 : train loss is [176.22866356442597] and validation loss is [0.09964119903570474] \n",
      "Epoch [59 / 150] average reconstruction error: 0.475010\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35003\n",
      "kldivergence:   1350.45\n",
      "variational_beta * kldivergence:  0.13505\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32042\n",
      "kldivergence:   1284.95\n",
      "variational_beta * kldivergence:  0.12849\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32187\n",
      "kldivergence:   1430.20\n",
      "variational_beta * kldivergence:  0.14302\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30538\n",
      "kldivergence:   1333.49\n",
      "variational_beta * kldivergence:  0.13335\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34596\n",
      "kldivergence:   1512.55\n",
      "variational_beta * kldivergence:  0.15126\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30037\n",
      "kldivergence:   1392.73\n",
      "variational_beta * kldivergence:  0.13927\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32228\n",
      "kldivergence:   1863.80\n",
      "variational_beta * kldivergence:  0.18638\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34300\n",
      "kldivergence:   1621.46\n",
      "variational_beta * kldivergence:  0.16215\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31047\n",
      "kldivergence:   1432.46\n",
      "variational_beta * kldivergence:  0.14325\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37781\n",
      "kldivergence:   1456.47\n",
      "variational_beta * kldivergence:  0.14565\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35254\n",
      "kldivergence:   1723.47\n",
      "variational_beta * kldivergence:  0.17235\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27961\n",
      "kldivergence:   1336.49\n",
      "variational_beta * kldivergence:  0.13365\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30111\n",
      "kldivergence:   1368.60\n",
      "variational_beta * kldivergence:  0.13686\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28572\n",
      "kldivergence:   1249.90\n",
      "variational_beta * kldivergence:  0.12499\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28373\n",
      "kldivergence:   1531.39\n",
      "variational_beta * kldivergence:  0.15314\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33425\n",
      "kldivergence:   1675.12\n",
      "variational_beta * kldivergence:  0.16751\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33412\n",
      "kldivergence:   1454.01\n",
      "variational_beta * kldivergence:  0.14540\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31153\n",
      "kldivergence:   1372.86\n",
      "variational_beta * kldivergence:  0.13729\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32113\n",
      "kldivergence:   1444.28\n",
      "variational_beta * kldivergence:  0.14443\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.26033\n",
      "kldivergence:   1235.65\n",
      "variational_beta * kldivergence:  0.12357\n",
      "batch accuracy: 91.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34917\n",
      "kldivergence:   1488.38\n",
      "variational_beta * kldivergence:  0.14884\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32112\n",
      "kldivergence:   1500.85\n",
      "variational_beta * kldivergence:  0.15008\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36667\n",
      "kldivergence:   1623.93\n",
      "variational_beta * kldivergence:  0.16239\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30272\n",
      "kldivergence:   1428.31\n",
      "variational_beta * kldivergence:  0.14283\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32502\n",
      "kldivergence:   1616.34\n",
      "variational_beta * kldivergence:  0.16163\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31001\n",
      "kldivergence:   1409.13\n",
      "variational_beta * kldivergence:  0.14091\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35523\n",
      "kldivergence:   1616.07\n",
      "variational_beta * kldivergence:  0.16161\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34421\n",
      "kldivergence:   1453.88\n",
      "variational_beta * kldivergence:  0.14539\n",
      "batch accuracy: 87.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32481\n",
      "kldivergence:   1429.99\n",
      "variational_beta * kldivergence:  0.14300\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35882\n",
      "kldivergence:   1384.52\n",
      "variational_beta * kldivergence:  0.13845\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27981\n",
      "kldivergence:   1329.31\n",
      "variational_beta * kldivergence:  0.13293\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29238\n",
      "kldivergence:   1573.84\n",
      "variational_beta * kldivergence:  0.15738\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29173\n",
      "kldivergence:   1488.63\n",
      "variational_beta * kldivergence:  0.14886\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28764\n",
      "kldivergence:   1286.83\n",
      "variational_beta * kldivergence:  0.12868\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29313\n",
      "kldivergence:   1569.96\n",
      "variational_beta * kldivergence:  0.15700\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35657\n",
      "kldivergence:   1408.89\n",
      "variational_beta * kldivergence:  0.14089\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.38580\n",
      "kldivergence:   1544.94\n",
      "variational_beta * kldivergence:  0.15449\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33195\n",
      "kldivergence:   1612.60\n",
      "variational_beta * kldivergence:  0.16126\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30880\n",
      "kldivergence:   1627.95\n",
      "variational_beta * kldivergence:  0.16279\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33103\n",
      "kldivergence:   1459.24\n",
      "variational_beta * kldivergence:  0.14592\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.24749\n",
      "kldivergence:   1188.19\n",
      "variational_beta * kldivergence:  0.11882\n",
      "batch accuracy: 91.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32384\n",
      "kldivergence:   1396.99\n",
      "variational_beta * kldivergence:  0.13970\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34112\n",
      "kldivergence:   1428.33\n",
      "variational_beta * kldivergence:  0.14283\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.39890\n",
      "kldivergence:   1738.11\n",
      "variational_beta * kldivergence:  0.17381\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32549\n",
      "kldivergence:   1552.19\n",
      "variational_beta * kldivergence:  0.15522\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30019\n",
      "kldivergence:   1473.90\n",
      "variational_beta * kldivergence:  0.14739\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34148\n",
      "kldivergence:   1674.79\n",
      "variational_beta * kldivergence:  0.16748\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36489\n",
      "kldivergence:   1760.34\n",
      "variational_beta * kldivergence:  0.17603\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36344\n",
      "kldivergence:   1639.90\n",
      "variational_beta * kldivergence:  0.16399\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32281\n",
      "kldivergence:   1468.93\n",
      "variational_beta * kldivergence:  0.14689\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29545\n",
      "kldivergence:   1426.90\n",
      "variational_beta * kldivergence:  0.14269\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31674\n",
      "kldivergence:   1441.55\n",
      "variational_beta * kldivergence:  0.14415\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28859\n",
      "kldivergence:   1403.45\n",
      "variational_beta * kldivergence:  0.14034\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29854\n",
      "kldivergence:   1405.75\n",
      "variational_beta * kldivergence:  0.14057\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29119\n",
      "kldivergence:   1458.04\n",
      "variational_beta * kldivergence:  0.14580\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28698\n",
      "kldivergence:   1365.52\n",
      "variational_beta * kldivergence:  0.13655\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31611\n",
      "kldivergence:   1615.08\n",
      "variational_beta * kldivergence:  0.16151\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27871\n",
      "kldivergence:   1399.73\n",
      "variational_beta * kldivergence:  0.13997\n",
      "batch accuracy: 90.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30849\n",
      "kldivergence:   1615.44\n",
      "variational_beta * kldivergence:  0.16154\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32484\n",
      "kldivergence:   1508.65\n",
      "variational_beta * kldivergence:  0.15087\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35207\n",
      "kldivergence:   1570.82\n",
      "variational_beta * kldivergence:  0.15708\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29896\n",
      "kldivergence:   1394.93\n",
      "variational_beta * kldivergence:  0.13949\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35302\n",
      "kldivergence:   1380.37\n",
      "variational_beta * kldivergence:  0.13804\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.41096\n",
      "kldivergence:   1633.43\n",
      "variational_beta * kldivergence:  0.16334\n",
      "batch accuracy: 86.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30967\n",
      "kldivergence:   1420.82\n",
      "variational_beta * kldivergence:  0.14208\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.40651\n",
      "kldivergence:   1584.51\n",
      "variational_beta * kldivergence:  0.15845\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29832\n",
      "kldivergence:   1369.39\n",
      "variational_beta * kldivergence:  0.13694\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29965\n",
      "kldivergence:   1557.45\n",
      "variational_beta * kldivergence:  0.15575\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35293\n",
      "kldivergence:   1672.29\n",
      "variational_beta * kldivergence:  0.16723\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32149\n",
      "kldivergence:   1710.26\n",
      "variational_beta * kldivergence:  0.17103\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34070\n",
      "kldivergence:   1418.58\n",
      "variational_beta * kldivergence:  0.14186\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.24137\n",
      "kldivergence:   1237.78\n",
      "variational_beta * kldivergence:  0.12378\n",
      "batch accuracy: 92.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33031\n",
      "kldivergence:   1781.30\n",
      "variational_beta * kldivergence:  0.17813\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35592\n",
      "kldivergence:   1460.55\n",
      "variational_beta * kldivergence:  0.14605\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32008\n",
      "kldivergence:   1809.82\n",
      "variational_beta * kldivergence:  0.18098\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27700\n",
      "kldivergence:   2082.32\n",
      "variational_beta * kldivergence:  0.20823\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33628\n",
      "kldivergence:   1680.31\n",
      "variational_beta * kldivergence:  0.16803\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35336\n",
      "kldivergence:   1608.06\n",
      "variational_beta * kldivergence:  0.16081\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33183\n",
      "kldivergence:   1671.20\n",
      "variational_beta * kldivergence:  0.16712\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34739\n",
      "kldivergence:   1530.18\n",
      "variational_beta * kldivergence:  0.15302\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33124\n",
      "kldivergence:   1594.11\n",
      "variational_beta * kldivergence:  0.15941\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30255\n",
      "kldivergence:   1558.87\n",
      "variational_beta * kldivergence:  0.15589\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28477\n",
      "kldivergence:   1374.51\n",
      "variational_beta * kldivergence:  0.13745\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31686\n",
      "kldivergence:   1343.32\n",
      "variational_beta * kldivergence:  0.13433\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27173\n",
      "kldivergence:   1236.81\n",
      "variational_beta * kldivergence:  0.12368\n",
      "batch accuracy: 91.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32054\n",
      "kldivergence:   1461.35\n",
      "variational_beta * kldivergence:  0.14614\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34460\n",
      "kldivergence:   1287.37\n",
      "variational_beta * kldivergence:  0.12874\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34584\n",
      "kldivergence:   1728.59\n",
      "variational_beta * kldivergence:  0.17286\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30364\n",
      "kldivergence:   1443.56\n",
      "variational_beta * kldivergence:  0.14436\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30763\n",
      "kldivergence:   1489.66\n",
      "variational_beta * kldivergence:  0.14897\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29664\n",
      "kldivergence:   1387.50\n",
      "variational_beta * kldivergence:  0.13875\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.39279\n",
      "kldivergence:   1344.26\n",
      "variational_beta * kldivergence:  0.13443\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31272\n",
      "kldivergence:   1493.91\n",
      "variational_beta * kldivergence:  0.14939\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35769\n",
      "kldivergence:   1573.86\n",
      "variational_beta * kldivergence:  0.15739\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27590\n",
      "kldivergence:   1101.14\n",
      "variational_beta * kldivergence:  0.11011\n",
      "batch accuracy: 90.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29085\n",
      "kldivergence:   1387.59\n",
      "variational_beta * kldivergence:  0.13876\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33486\n",
      "kldivergence:   1533.60\n",
      "variational_beta * kldivergence:  0.15336\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34928\n",
      "kldivergence:   1560.61\n",
      "variational_beta * kldivergence:  0.15606\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34031\n",
      "kldivergence:   1564.36\n",
      "variational_beta * kldivergence:  0.15644\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34975\n",
      "kldivergence:   1723.55\n",
      "variational_beta * kldivergence:  0.17236\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37026\n",
      "kldivergence:   1424.74\n",
      "variational_beta * kldivergence:  0.14247\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32715\n",
      "kldivergence:   1544.84\n",
      "variational_beta * kldivergence:  0.15448\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34548\n",
      "kldivergence:   1532.31\n",
      "variational_beta * kldivergence:  0.15323\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35662\n",
      "kldivergence:   1482.92\n",
      "variational_beta * kldivergence:  0.14829\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35294\n",
      "kldivergence:   1402.74\n",
      "variational_beta * kldivergence:  0.14027\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30525\n",
      "kldivergence:   1314.62\n",
      "variational_beta * kldivergence:  0.13146\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28031\n",
      "kldivergence:   1342.71\n",
      "variational_beta * kldivergence:  0.13427\n",
      "batch accuracy: 90.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36667\n",
      "kldivergence:   1638.22\n",
      "variational_beta * kldivergence:  0.16382\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36512\n",
      "kldivergence:   1556.76\n",
      "variational_beta * kldivergence:  0.15568\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29751\n",
      "kldivergence:   1332.86\n",
      "variational_beta * kldivergence:  0.13329\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33780\n",
      "kldivergence:   1471.12\n",
      "variational_beta * kldivergence:  0.14711\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32783\n",
      "kldivergence:   1493.32\n",
      "variational_beta * kldivergence:  0.14933\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29746\n",
      "kldivergence:   1385.33\n",
      "variational_beta * kldivergence:  0.13853\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29365\n",
      "kldivergence:   2087.44\n",
      "variational_beta * kldivergence:  0.20874\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37719\n",
      "kldivergence:   1600.71\n",
      "variational_beta * kldivergence:  0.16007\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29918\n",
      "kldivergence:   1500.35\n",
      "variational_beta * kldivergence:  0.15004\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29891\n",
      "kldivergence:   1464.40\n",
      "variational_beta * kldivergence:  0.14644\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31855\n",
      "kldivergence:   1626.04\n",
      "variational_beta * kldivergence:  0.16260\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29241\n",
      "kldivergence:   1447.27\n",
      "variational_beta * kldivergence:  0.14473\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35120\n",
      "kldivergence:   1626.82\n",
      "variational_beta * kldivergence:  0.16268\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28638\n",
      "kldivergence:   1574.86\n",
      "variational_beta * kldivergence:  0.15749\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31161\n",
      "kldivergence:   1442.31\n",
      "variational_beta * kldivergence:  0.14423\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28534\n",
      "kldivergence:   1565.25\n",
      "variational_beta * kldivergence:  0.15652\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32268\n",
      "kldivergence:   1508.40\n",
      "variational_beta * kldivergence:  0.15084\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37489\n",
      "kldivergence:   1579.93\n",
      "variational_beta * kldivergence:  0.15799\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28551\n",
      "kldivergence:   1403.65\n",
      "variational_beta * kldivergence:  0.14036\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32923\n",
      "kldivergence:   1494.95\n",
      "variational_beta * kldivergence:  0.14949\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36053\n",
      "kldivergence:   1600.50\n",
      "variational_beta * kldivergence:  0.16005\n",
      "batch accuracy: 87.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28994\n",
      "kldivergence:   1417.64\n",
      "variational_beta * kldivergence:  0.14176\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34113\n",
      "kldivergence:   1668.21\n",
      "variational_beta * kldivergence:  0.16682\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31980\n",
      "kldivergence:   1683.38\n",
      "variational_beta * kldivergence:  0.16834\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36460\n",
      "kldivergence:   1571.05\n",
      "variational_beta * kldivergence:  0.15711\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27987\n",
      "kldivergence:   1410.53\n",
      "variational_beta * kldivergence:  0.14105\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33984\n",
      "kldivergence:   1468.81\n",
      "variational_beta * kldivergence:  0.14688\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33617\n",
      "kldivergence:   1492.27\n",
      "variational_beta * kldivergence:  0.14923\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29983\n",
      "kldivergence:   1386.76\n",
      "variational_beta * kldivergence:  0.13868\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34392\n",
      "kldivergence:   1361.81\n",
      "variational_beta * kldivergence:  0.13618\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30870\n",
      "kldivergence:   1486.10\n",
      "variational_beta * kldivergence:  0.14861\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35224\n",
      "kldivergence:   1464.35\n",
      "variational_beta * kldivergence:  0.14643\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31609\n",
      "kldivergence:   1566.86\n",
      "variational_beta * kldivergence:  0.15669\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32496\n",
      "kldivergence:   1334.03\n",
      "variational_beta * kldivergence:  0.13340\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33023\n",
      "kldivergence:   1446.32\n",
      "variational_beta * kldivergence:  0.14463\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36061\n",
      "kldivergence:   1721.90\n",
      "variational_beta * kldivergence:  0.17219\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31099\n",
      "kldivergence:   1558.98\n",
      "variational_beta * kldivergence:  0.15590\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32400\n",
      "kldivergence:   1507.99\n",
      "variational_beta * kldivergence:  0.15080\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32209\n",
      "kldivergence:   1531.44\n",
      "variational_beta * kldivergence:  0.15314\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.26362\n",
      "kldivergence:   1718.00\n",
      "variational_beta * kldivergence:  0.17180\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37347\n",
      "kldivergence:   1582.67\n",
      "variational_beta * kldivergence:  0.15827\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30651\n",
      "kldivergence:   1618.25\n",
      "variational_beta * kldivergence:  0.16183\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32374\n",
      "kldivergence:   1618.48\n",
      "variational_beta * kldivergence:  0.16185\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32630\n",
      "kldivergence:   1518.66\n",
      "variational_beta * kldivergence:  0.15187\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36229\n",
      "kldivergence:   1398.80\n",
      "variational_beta * kldivergence:  0.13988\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27458\n",
      "kldivergence:   1233.44\n",
      "variational_beta * kldivergence:  0.12334\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34267\n",
      "kldivergence:   1400.75\n",
      "variational_beta * kldivergence:  0.14008\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32916\n",
      "kldivergence:   1532.16\n",
      "variational_beta * kldivergence:  0.15322\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36963\n",
      "kldivergence:   1566.07\n",
      "variational_beta * kldivergence:  0.15661\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30620\n",
      "kldivergence:   1526.27\n",
      "variational_beta * kldivergence:  0.15263\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32734\n",
      "kldivergence:   1388.91\n",
      "variational_beta * kldivergence:  0.13889\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32647\n",
      "kldivergence:   1516.75\n",
      "variational_beta * kldivergence:  0.15168\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32130\n",
      "kldivergence:   1569.18\n",
      "variational_beta * kldivergence:  0.15692\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28105\n",
      "kldivergence:   1328.88\n",
      "variational_beta * kldivergence:  0.13289\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32742\n",
      "kldivergence:   1655.18\n",
      "variational_beta * kldivergence:  0.16552\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36138\n",
      "kldivergence:   1573.55\n",
      "variational_beta * kldivergence:  0.15736\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35535\n",
      "kldivergence:   1426.96\n",
      "variational_beta * kldivergence:  0.14270\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31839\n",
      "kldivergence:   1378.39\n",
      "variational_beta * kldivergence:  0.13784\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29684\n",
      "kldivergence:   1546.11\n",
      "variational_beta * kldivergence:  0.15461\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34634\n",
      "kldivergence:   1475.39\n",
      "variational_beta * kldivergence:  0.14754\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30075\n",
      "kldivergence:   1459.11\n",
      "variational_beta * kldivergence:  0.14591\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37741\n",
      "kldivergence:   1682.70\n",
      "variational_beta * kldivergence:  0.16827\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27736\n",
      "kldivergence:   1321.68\n",
      "variational_beta * kldivergence:  0.13217\n",
      "batch accuracy: 90.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32807\n",
      "kldivergence:   1380.02\n",
      "variational_beta * kldivergence:  0.13800\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35656\n",
      "kldivergence:   1627.53\n",
      "variational_beta * kldivergence:  0.16275\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30959\n",
      "kldivergence:   1673.24\n",
      "variational_beta * kldivergence:  0.16732\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36035\n",
      "kldivergence:   1708.47\n",
      "variational_beta * kldivergence:  0.17085\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31050\n",
      "kldivergence:   1364.15\n",
      "variational_beta * kldivergence:  0.13641\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34766\n",
      "kldivergence:   1650.91\n",
      "variational_beta * kldivergence:  0.16509\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29336\n",
      "kldivergence:   1397.17\n",
      "variational_beta * kldivergence:  0.13972\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31045\n",
      "kldivergence:   1937.37\n",
      "variational_beta * kldivergence:  0.19374\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35339\n",
      "kldivergence:   1670.40\n",
      "variational_beta * kldivergence:  0.16704\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30830\n",
      "kldivergence:   1643.76\n",
      "variational_beta * kldivergence:  0.16438\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31777\n",
      "kldivergence:   1355.61\n",
      "variational_beta * kldivergence:  0.13556\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29934\n",
      "kldivergence:   1289.40\n",
      "variational_beta * kldivergence:  0.12894\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33736\n",
      "kldivergence:   1408.93\n",
      "variational_beta * kldivergence:  0.14089\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28517\n",
      "kldivergence:   1344.97\n",
      "variational_beta * kldivergence:  0.13450\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32182\n",
      "kldivergence:   1323.08\n",
      "variational_beta * kldivergence:  0.13231\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33173\n",
      "kldivergence:   1528.91\n",
      "variational_beta * kldivergence:  0.15289\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28290\n",
      "kldivergence:   1348.67\n",
      "variational_beta * kldivergence:  0.13487\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32974\n",
      "kldivergence:   1451.52\n",
      "variational_beta * kldivergence:  0.14515\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.23842\n",
      "kldivergence:   1314.78\n",
      "variational_beta * kldivergence:  0.13148\n",
      "batch accuracy: 91.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36096\n",
      "kldivergence:   1560.27\n",
      "variational_beta * kldivergence:  0.15603\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29857\n",
      "kldivergence:   1412.13\n",
      "variational_beta * kldivergence:  0.14121\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28010\n",
      "kldivergence:   1579.94\n",
      "variational_beta * kldivergence:  0.15799\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32791\n",
      "kldivergence:   1447.01\n",
      "variational_beta * kldivergence:  0.14470\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32776\n",
      "kldivergence:   1343.58\n",
      "variational_beta * kldivergence:  0.13436\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28915\n",
      "kldivergence:   1264.84\n",
      "variational_beta * kldivergence:  0.12648\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34468\n",
      "kldivergence:   1592.49\n",
      "variational_beta * kldivergence:  0.15925\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32887\n",
      "kldivergence:   1708.15\n",
      "variational_beta * kldivergence:  0.17081\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32585\n",
      "kldivergence:   1439.57\n",
      "variational_beta * kldivergence:  0.14396\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33972\n",
      "kldivergence:   1500.97\n",
      "variational_beta * kldivergence:  0.15010\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35121\n",
      "kldivergence:   1259.14\n",
      "variational_beta * kldivergence:  0.12591\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30474\n",
      "kldivergence:   1333.97\n",
      "variational_beta * kldivergence:  0.13340\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31429\n",
      "kldivergence:   1347.74\n",
      "variational_beta * kldivergence:  0.13477\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37877\n",
      "kldivergence:   1754.21\n",
      "variational_beta * kldivergence:  0.17542\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31440\n",
      "kldivergence:   1354.09\n",
      "variational_beta * kldivergence:  0.13541\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31827\n",
      "kldivergence:   1347.87\n",
      "variational_beta * kldivergence:  0.13479\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.26839\n",
      "kldivergence:   1265.39\n",
      "variational_beta * kldivergence:  0.12654\n",
      "batch accuracy: 90.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31506\n",
      "kldivergence:   1476.86\n",
      "variational_beta * kldivergence:  0.14769\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32329\n",
      "kldivergence:   1407.59\n",
      "variational_beta * kldivergence:  0.14076\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32711\n",
      "kldivergence:   1450.03\n",
      "variational_beta * kldivergence:  0.14500\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30117\n",
      "kldivergence:   1993.10\n",
      "variational_beta * kldivergence:  0.19931\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29475\n",
      "kldivergence:   1452.96\n",
      "variational_beta * kldivergence:  0.14530\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36109\n",
      "kldivergence:   1486.68\n",
      "variational_beta * kldivergence:  0.14867\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31040\n",
      "kldivergence:   1425.05\n",
      "variational_beta * kldivergence:  0.14250\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30034\n",
      "kldivergence:   1693.98\n",
      "variational_beta * kldivergence:  0.16940\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33400\n",
      "kldivergence:   1456.26\n",
      "variational_beta * kldivergence:  0.14563\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30003\n",
      "kldivergence:   1353.00\n",
      "variational_beta * kldivergence:  0.13530\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36350\n",
      "kldivergence:   1432.02\n",
      "variational_beta * kldivergence:  0.14320\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33047\n",
      "kldivergence:   1313.15\n",
      "variational_beta * kldivergence:  0.13131\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.39162\n",
      "kldivergence:   1553.67\n",
      "variational_beta * kldivergence:  0.15537\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32478\n",
      "kldivergence:   1291.77\n",
      "variational_beta * kldivergence:  0.12918\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29674\n",
      "kldivergence:   1486.80\n",
      "variational_beta * kldivergence:  0.14868\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33379\n",
      "kldivergence:   1487.69\n",
      "variational_beta * kldivergence:  0.14877\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29711\n",
      "kldivergence:   1347.93\n",
      "variational_beta * kldivergence:  0.13479\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28287\n",
      "kldivergence:   1366.90\n",
      "variational_beta * kldivergence:  0.13669\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.38911\n",
      "kldivergence:   1637.78\n",
      "variational_beta * kldivergence:  0.16378\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34114\n",
      "kldivergence:   1416.13\n",
      "variational_beta * kldivergence:  0.14161\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36904\n",
      "kldivergence:   1543.41\n",
      "variational_beta * kldivergence:  0.15434\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30770\n",
      "kldivergence:   1619.64\n",
      "variational_beta * kldivergence:  0.16196\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29819\n",
      "kldivergence:   1359.50\n",
      "variational_beta * kldivergence:  0.13595\n",
      "batch accuracy: 90.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31276\n",
      "kldivergence:   1347.83\n",
      "variational_beta * kldivergence:  0.13478\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30605\n",
      "kldivergence:   1397.91\n",
      "variational_beta * kldivergence:  0.13979\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32550\n",
      "kldivergence:   1450.10\n",
      "variational_beta * kldivergence:  0.14501\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30405\n",
      "kldivergence:   1623.32\n",
      "variational_beta * kldivergence:  0.16233\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36610\n",
      "kldivergence:   1918.24\n",
      "variational_beta * kldivergence:  0.19182\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31617\n",
      "kldivergence:   1668.28\n",
      "variational_beta * kldivergence:  0.16683\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36352\n",
      "kldivergence:   1657.34\n",
      "variational_beta * kldivergence:  0.16573\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28196\n",
      "kldivergence:   1308.41\n",
      "variational_beta * kldivergence:  0.13084\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31847\n",
      "kldivergence:   1610.83\n",
      "variational_beta * kldivergence:  0.16108\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32810\n",
      "kldivergence:   1538.19\n",
      "variational_beta * kldivergence:  0.15382\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37492\n",
      "kldivergence:   1440.20\n",
      "variational_beta * kldivergence:  0.14402\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30526\n",
      "kldivergence:   1440.59\n",
      "variational_beta * kldivergence:  0.14406\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30268\n",
      "kldivergence:   1390.77\n",
      "variational_beta * kldivergence:  0.13908\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37613\n",
      "kldivergence:   1601.96\n",
      "variational_beta * kldivergence:  0.16020\n",
      "batch accuracy: 86.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33283\n",
      "kldivergence:   1487.36\n",
      "variational_beta * kldivergence:  0.14874\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32275\n",
      "kldivergence:   1540.27\n",
      "variational_beta * kldivergence:  0.15403\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34653\n",
      "kldivergence:   1390.44\n",
      "variational_beta * kldivergence:  0.13904\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33095\n",
      "kldivergence:   1504.03\n",
      "variational_beta * kldivergence:  0.15040\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31042\n",
      "kldivergence:   1504.19\n",
      "variational_beta * kldivergence:  0.15042\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34459\n",
      "kldivergence:   1542.24\n",
      "variational_beta * kldivergence:  0.15422\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28671\n",
      "kldivergence:   1348.21\n",
      "variational_beta * kldivergence:  0.13482\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29363\n",
      "kldivergence:   1552.68\n",
      "variational_beta * kldivergence:  0.15527\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29978\n",
      "kldivergence:   1397.03\n",
      "variational_beta * kldivergence:  0.13970\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33290\n",
      "kldivergence:   1493.77\n",
      "variational_beta * kldivergence:  0.14938\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28774\n",
      "kldivergence:   1705.22\n",
      "variational_beta * kldivergence:  0.17052\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36996\n",
      "kldivergence:   1610.87\n",
      "variational_beta * kldivergence:  0.16109\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30921\n",
      "kldivergence:   1469.26\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31197\n",
      "kldivergence:   1480.05\n",
      "variational_beta * kldivergence:  0.14800\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29978\n",
      "kldivergence:   1322.09\n",
      "variational_beta * kldivergence:  0.13221\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34134\n",
      "kldivergence:   1456.04\n",
      "variational_beta * kldivergence:  0.14560\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34414\n",
      "kldivergence:   1565.55\n",
      "variational_beta * kldivergence:  0.15656\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31123\n",
      "kldivergence:   1265.76\n",
      "variational_beta * kldivergence:  0.12658\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32518\n",
      "kldivergence:   1632.76\n",
      "variational_beta * kldivergence:  0.16328\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34892\n",
      "kldivergence:   1457.67\n",
      "variational_beta * kldivergence:  0.14577\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36116\n",
      "kldivergence:   1506.55\n",
      "variational_beta * kldivergence:  0.15066\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31430\n",
      "kldivergence:   1549.66\n",
      "variational_beta * kldivergence:  0.15497\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34148\n",
      "kldivergence:   1655.03\n",
      "variational_beta * kldivergence:  0.16550\n",
      "batch accuracy: 88.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29323\n",
      "kldivergence:   1405.74\n",
      "variational_beta * kldivergence:  0.14057\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31142\n",
      "kldivergence:   1503.53\n",
      "variational_beta * kldivergence:  0.15035\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35779\n",
      "kldivergence:   1547.31\n",
      "variational_beta * kldivergence:  0.15473\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28112\n",
      "kldivergence:   1403.68\n",
      "variational_beta * kldivergence:  0.14037\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27286\n",
      "kldivergence:   1331.91\n",
      "variational_beta * kldivergence:  0.13319\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27461\n",
      "kldivergence:   1522.95\n",
      "variational_beta * kldivergence:  0.15230\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30966\n",
      "kldivergence:   1557.47\n",
      "variational_beta * kldivergence:  0.15575\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31146\n",
      "kldivergence:   1505.66\n",
      "variational_beta * kldivergence:  0.15057\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34252\n",
      "kldivergence:   1522.48\n",
      "variational_beta * kldivergence:  0.15225\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36646\n",
      "kldivergence:   1749.19\n",
      "variational_beta * kldivergence:  0.17492\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31805\n",
      "kldivergence:   1472.91\n",
      "variational_beta * kldivergence:  0.14729\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33120\n",
      "kldivergence:   1612.02\n",
      "variational_beta * kldivergence:  0.16120\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33760\n",
      "kldivergence:   1623.82\n",
      "variational_beta * kldivergence:  0.16238\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30425\n",
      "kldivergence:   1529.72\n",
      "variational_beta * kldivergence:  0.15297\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29440\n",
      "kldivergence:   1567.73\n",
      "variational_beta * kldivergence:  0.15677\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29240\n",
      "kldivergence:   1423.62\n",
      "variational_beta * kldivergence:  0.14236\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29674\n",
      "kldivergence:   1584.40\n",
      "variational_beta * kldivergence:  0.15844\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31416\n",
      "kldivergence:   1651.94\n",
      "variational_beta * kldivergence:  0.16519\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34192\n",
      "kldivergence:   1638.15\n",
      "variational_beta * kldivergence:  0.16381\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33466\n",
      "kldivergence:   1519.24\n",
      "variational_beta * kldivergence:  0.15192\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33187\n",
      "kldivergence:   1467.87\n",
      "variational_beta * kldivergence:  0.14679\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32711\n",
      "kldivergence:   1585.45\n",
      "variational_beta * kldivergence:  0.15855\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31362\n",
      "kldivergence:   1520.57\n",
      "variational_beta * kldivergence:  0.15206\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27064\n",
      "kldivergence:   1459.27\n",
      "variational_beta * kldivergence:  0.14593\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.26990\n",
      "kldivergence:   1513.26\n",
      "variational_beta * kldivergence:  0.15133\n",
      "batch accuracy: 90.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32711\n",
      "kldivergence:   1443.83\n",
      "variational_beta * kldivergence:  0.14438\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28825\n",
      "kldivergence:   1304.94\n",
      "variational_beta * kldivergence:  0.13049\n",
      "batch accuracy: 90.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33933\n",
      "kldivergence:   1463.98\n",
      "variational_beta * kldivergence:  0.14640\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37685\n",
      "kldivergence:   1801.67\n",
      "variational_beta * kldivergence:  0.18017\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30134\n",
      "kldivergence:   1390.76\n",
      "variational_beta * kldivergence:  0.13908\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29826\n",
      "kldivergence:   1370.26\n",
      "variational_beta * kldivergence:  0.13703\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33664\n",
      "kldivergence:   1304.76\n",
      "variational_beta * kldivergence:  0.13048\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29858\n",
      "kldivergence:   1499.76\n",
      "variational_beta * kldivergence:  0.14998\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35523\n",
      "kldivergence:   1502.90\n",
      "variational_beta * kldivergence:  0.15029\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37722\n",
      "kldivergence:   1511.96\n",
      "variational_beta * kldivergence:  0.15120\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33738\n",
      "kldivergence:   1555.22\n",
      "variational_beta * kldivergence:  0.15552\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35568\n",
      "kldivergence:   1514.49\n",
      "variational_beta * kldivergence:  0.15145\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33770\n",
      "kldivergence:   1585.52\n",
      "variational_beta * kldivergence:  0.15855\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28118\n",
      "kldivergence:   1681.56\n",
      "variational_beta * kldivergence:  0.16816\n",
      "batch accuracy: 90.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29478\n",
      "kldivergence:   1590.16\n",
      "variational_beta * kldivergence:  0.15902\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30955\n",
      "kldivergence:   1643.92\n",
      "variational_beta * kldivergence:  0.16439\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30200\n",
      "kldivergence:   1812.45\n",
      "variational_beta * kldivergence:  0.18124\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32340\n",
      "kldivergence:   1445.34\n",
      "variational_beta * kldivergence:  0.14453\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37211\n",
      "kldivergence:   1740.82\n",
      "variational_beta * kldivergence:  0.17408\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33812\n",
      "kldivergence:   1513.54\n",
      "variational_beta * kldivergence:  0.15135\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33843\n",
      "kldivergence:   1591.04\n",
      "variational_beta * kldivergence:  0.15910\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36528\n",
      "kldivergence:   1587.35\n",
      "variational_beta * kldivergence:  0.15874\n",
      "batch accuracy: 87.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30203\n",
      "kldivergence:   1662.44\n",
      "variational_beta * kldivergence:  0.16624\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32431\n",
      "kldivergence:   1540.62\n",
      "variational_beta * kldivergence:  0.15406\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30267\n",
      "kldivergence:   1640.63\n",
      "variational_beta * kldivergence:  0.16406\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29586\n",
      "kldivergence:   1499.27\n",
      "variational_beta * kldivergence:  0.14993\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29986\n",
      "kldivergence:   1627.90\n",
      "variational_beta * kldivergence:  0.16279\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35928\n",
      "kldivergence:   1446.87\n",
      "variational_beta * kldivergence:  0.14469\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36351\n",
      "kldivergence:   1484.90\n",
      "variational_beta * kldivergence:  0.14849\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37195\n",
      "kldivergence:   1483.60\n",
      "variational_beta * kldivergence:  0.14836\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31842\n",
      "kldivergence:   1415.92\n",
      "variational_beta * kldivergence:  0.14159\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34453\n",
      "kldivergence:   1579.66\n",
      "variational_beta * kldivergence:  0.15797\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30878\n",
      "kldivergence:   1424.57\n",
      "variational_beta * kldivergence:  0.14246\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27717\n",
      "kldivergence:   1556.44\n",
      "variational_beta * kldivergence:  0.15564\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37703\n",
      "kldivergence:   1787.21\n",
      "variational_beta * kldivergence:  0.17872\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33337\n",
      "kldivergence:   1480.86\n",
      "variational_beta * kldivergence:  0.14809\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33563\n",
      "kldivergence:   1481.87\n",
      "variational_beta * kldivergence:  0.14819\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.37925\n",
      "kldivergence:   1531.14\n",
      "variational_beta * kldivergence:  0.15311\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34751\n",
      "kldivergence:   1416.65\n",
      "variational_beta * kldivergence:  0.14166\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33315\n",
      "kldivergence:   1474.84\n",
      "variational_beta * kldivergence:  0.14748\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35365\n",
      "kldivergence:   1441.73\n",
      "variational_beta * kldivergence:  0.14417\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29580\n",
      "kldivergence:   1297.63\n",
      "variational_beta * kldivergence:  0.12976\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30357\n",
      "kldivergence:   1643.53\n",
      "variational_beta * kldivergence:  0.16435\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30058\n",
      "kldivergence:   1353.11\n",
      "variational_beta * kldivergence:  0.13531\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33378\n",
      "kldivergence:   1311.69\n",
      "variational_beta * kldivergence:  0.13117\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33611\n",
      "kldivergence:   1539.30\n",
      "variational_beta * kldivergence:  0.15393\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28003\n",
      "kldivergence:   1403.30\n",
      "variational_beta * kldivergence:  0.14033\n",
      "batch accuracy: 90.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28418\n",
      "kldivergence:   1507.14\n",
      "variational_beta * kldivergence:  0.15071\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33581\n",
      "kldivergence:   1528.60\n",
      "variational_beta * kldivergence:  0.15286\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32613\n",
      "kldivergence:   1530.53\n",
      "variational_beta * kldivergence:  0.15305\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29799\n",
      "kldivergence:   1346.89\n",
      "variational_beta * kldivergence:  0.13469\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.40230\n",
      "kldivergence:   1589.61\n",
      "variational_beta * kldivergence:  0.15896\n",
      "batch accuracy: 86.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34366\n",
      "kldivergence:   1576.51\n",
      "variational_beta * kldivergence:  0.15765\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33225\n",
      "kldivergence:   1548.98\n",
      "variational_beta * kldivergence:  0.15490\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33375\n",
      "kldivergence:   1395.83\n",
      "variational_beta * kldivergence:  0.13958\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.36255\n",
      "kldivergence:   1433.36\n",
      "variational_beta * kldivergence:  0.14334\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27949\n",
      "kldivergence:   1457.33\n",
      "variational_beta * kldivergence:  0.14573\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35035\n",
      "kldivergence:   1559.65\n",
      "variational_beta * kldivergence:  0.15597\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30075\n",
      "kldivergence:   1628.31\n",
      "variational_beta * kldivergence:  0.16283\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34394\n",
      "kldivergence:   1384.22\n",
      "variational_beta * kldivergence:  0.13842\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.34764\n",
      "kldivergence:   1493.23\n",
      "variational_beta * kldivergence:  0.14932\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28637\n",
      "kldivergence:   1373.34\n",
      "variational_beta * kldivergence:  0.13733\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29409\n",
      "kldivergence:   1536.63\n",
      "variational_beta * kldivergence:  0.15366\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30822\n",
      "kldivergence:   1501.14\n",
      "variational_beta * kldivergence:  0.15011\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29523\n",
      "kldivergence:   1418.33\n",
      "variational_beta * kldivergence:  0.14183\n",
      "batch accuracy: 90.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31715\n",
      "kldivergence:   1535.20\n",
      "variational_beta * kldivergence:  0.15352\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.29666\n",
      "kldivergence:   1510.81\n",
      "variational_beta * kldivergence:  0.15108\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.26697\n",
      "kldivergence:   1473.13\n",
      "variational_beta * kldivergence:  0.14731\n",
      "batch accuracy: 90.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31191\n",
      "kldivergence:   1458.38\n",
      "variational_beta * kldivergence:  0.14584\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27551\n",
      "kldivergence:   1517.16\n",
      "variational_beta * kldivergence:  0.15172\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.30217\n",
      "kldivergence:   1348.11\n",
      "variational_beta * kldivergence:  0.13481\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.35119\n",
      "kldivergence:   1432.21\n",
      "variational_beta * kldivergence:  0.14322\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31510\n",
      "kldivergence:   1549.68\n",
      "variational_beta * kldivergence:  0.15497\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32364\n",
      "kldivergence:   1436.81\n",
      "variational_beta * kldivergence:  0.14368\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.27632\n",
      "kldivergence:   1324.64\n",
      "variational_beta * kldivergence:  0.13246\n",
      "batch accuracy: 90.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.33233\n",
      "kldivergence:   1598.77\n",
      "variational_beta * kldivergence:  0.15988\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.28046\n",
      "kldivergence:   1308.51\n",
      "variational_beta * kldivergence:  0.13085\n",
      "batch accuracy: 90.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.31344\n",
      "kldivergence:   1552.43\n",
      "variational_beta * kldivergence:  0.15524\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.32192\n",
      "kldivergence:   1497.68\n",
      "variational_beta * kldivergence:  0.14977\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #59\n",
      "reconstruction loss: 0.39054\n",
      "kldivergence:   1738.62\n",
      "variational_beta * kldivergence:  0.17386\n",
      "batch accuracy: 87.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.38970\n",
      "kldivergence:   1333.86\n",
      "variational_beta * kldivergence:  0.13339\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.57811\n",
      "kldivergence:   1492.86\n",
      "variational_beta * kldivergence:  0.14929\n",
      "batch accuracy: 83.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.45393\n",
      "kldivergence:   1399.60\n",
      "variational_beta * kldivergence:  0.13996\n",
      "batch accuracy: 86.28\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.41140\n",
      "kldivergence:   1328.23\n",
      "variational_beta * kldivergence:  0.13282\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.50409\n",
      "kldivergence:   1531.04\n",
      "variational_beta * kldivergence:  0.15310\n",
      "batch accuracy: 85.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.54203\n",
      "kldivergence:   1534.31\n",
      "variational_beta * kldivergence:  0.15343\n",
      "batch accuracy: 84.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.34584\n",
      "kldivergence:   1208.78\n",
      "variational_beta * kldivergence:  0.12088\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.48524\n",
      "kldivergence:   1416.11\n",
      "variational_beta * kldivergence:  0.14161\n",
      "batch accuracy: 85.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.52863\n",
      "kldivergence:   1529.32\n",
      "variational_beta * kldivergence:  0.15293\n",
      "batch accuracy: 83.72\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.43722\n",
      "kldivergence:   1377.56\n",
      "variational_beta * kldivergence:  0.13776\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.41436\n",
      "kldivergence:   1357.04\n",
      "variational_beta * kldivergence:  0.13570\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.44348\n",
      "kldivergence:   1378.98\n",
      "variational_beta * kldivergence:  0.13790\n",
      "batch accuracy: 85.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.42999\n",
      "kldivergence:   1367.16\n",
      "variational_beta * kldivergence:  0.13672\n",
      "batch accuracy: 86.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.49388\n",
      "kldivergence:   1477.10\n",
      "variational_beta * kldivergence:  0.14771\n",
      "batch accuracy: 84.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.48658\n",
      "kldivergence:   1352.35\n",
      "variational_beta * kldivergence:  0.13524\n",
      "batch accuracy: 85.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.46680\n",
      "kldivergence:   1346.54\n",
      "variational_beta * kldivergence:  0.13465\n",
      "batch accuracy: 85.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.48151\n",
      "kldivergence:   1442.06\n",
      "variational_beta * kldivergence:  0.14421\n",
      "batch accuracy: 84.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.41981\n",
      "kldivergence:   1389.20\n",
      "variational_beta * kldivergence:  0.13892\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.48855\n",
      "kldivergence:   1509.50\n",
      "variational_beta * kldivergence:  0.15095\n",
      "batch accuracy: 84.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.36292\n",
      "kldivergence:   1243.25\n",
      "variational_beta * kldivergence:  0.12432\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.42284\n",
      "kldivergence:   1376.48\n",
      "variational_beta * kldivergence:  0.13765\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.40807\n",
      "kldivergence:   1364.76\n",
      "variational_beta * kldivergence:  0.13648\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.46917\n",
      "kldivergence:   1399.33\n",
      "variational_beta * kldivergence:  0.13993\n",
      "batch accuracy: 85.48\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.53337\n",
      "kldivergence:   1436.69\n",
      "variational_beta * kldivergence:  0.14367\n",
      "batch accuracy: 84.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.50634\n",
      "kldivergence:   1347.98\n",
      "variational_beta * kldivergence:  0.13480\n",
      "batch accuracy: 84.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.40677\n",
      "kldivergence:   1295.69\n",
      "variational_beta * kldivergence:  0.12957\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.49725\n",
      "kldivergence:   1496.89\n",
      "variational_beta * kldivergence:  0.14969\n",
      "batch accuracy: 85.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.38510\n",
      "kldivergence:   1290.56\n",
      "variational_beta * kldivergence:  0.12906\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.40274\n",
      "kldivergence:   1308.51\n",
      "variational_beta * kldivergence:  0.13085\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.50142\n",
      "kldivergence:   1386.01\n",
      "variational_beta * kldivergence:  0.13860\n",
      "batch accuracy: 85.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.46930\n",
      "kldivergence:   1398.68\n",
      "variational_beta * kldivergence:  0.13987\n",
      "batch accuracy: 85.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.48404\n",
      "kldivergence:   1421.34\n",
      "variational_beta * kldivergence:  0.14213\n",
      "batch accuracy: 85.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.48144\n",
      "kldivergence:   1395.75\n",
      "variational_beta * kldivergence:  0.13957\n",
      "batch accuracy: 86.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.52604\n",
      "kldivergence:   1480.76\n",
      "variational_beta * kldivergence:  0.14808\n",
      "batch accuracy: 84.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.52439\n",
      "kldivergence:   1521.18\n",
      "variational_beta * kldivergence:  0.15212\n",
      "batch accuracy: 83.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.51873\n",
      "kldivergence:   1412.34\n",
      "variational_beta * kldivergence:  0.14123\n",
      "batch accuracy: 83.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.47810\n",
      "kldivergence:   1376.86\n",
      "variational_beta * kldivergence:  0.13769\n",
      "batch accuracy: 85.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.47511\n",
      "kldivergence:   1448.88\n",
      "variational_beta * kldivergence:  0.14489\n",
      "batch accuracy: 85.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.47491\n",
      "kldivergence:   1421.34\n",
      "variational_beta * kldivergence:  0.14213\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.49666\n",
      "kldivergence:   1444.86\n",
      "variational_beta * kldivergence:  0.14449\n",
      "batch accuracy: 84.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.46547\n",
      "kldivergence:   1442.52\n",
      "variational_beta * kldivergence:  0.14425\n",
      "batch accuracy: 85.57\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.46016\n",
      "kldivergence:   1329.66\n",
      "variational_beta * kldivergence:  0.13297\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.43037\n",
      "kldivergence:   1346.25\n",
      "variational_beta * kldivergence:  0.13462\n",
      "batch accuracy: 87.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.41143\n",
      "kldivergence:   1284.17\n",
      "variational_beta * kldivergence:  0.12842\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.45713\n",
      "kldivergence:   1392.05\n",
      "variational_beta * kldivergence:  0.13920\n",
      "batch accuracy: 86.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.39549\n",
      "kldivergence:   1350.99\n",
      "variational_beta * kldivergence:  0.13510\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.44575\n",
      "kldivergence:   1353.34\n",
      "variational_beta * kldivergence:  0.13533\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.54258\n",
      "kldivergence:   1418.33\n",
      "variational_beta * kldivergence:  0.14183\n",
      "batch accuracy: 84.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.45212\n",
      "kldivergence:   1387.26\n",
      "variational_beta * kldivergence:  0.13873\n",
      "batch accuracy: 85.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.44683\n",
      "kldivergence:   1433.97\n",
      "variational_beta * kldivergence:  0.14340\n",
      "batch accuracy: 86.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.35080\n",
      "kldivergence:   1241.60\n",
      "variational_beta * kldivergence:  0.12416\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.46447\n",
      "kldivergence:   1500.73\n",
      "variational_beta * kldivergence:  0.15007\n",
      "batch accuracy: 85.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.40255\n",
      "kldivergence:   1263.09\n",
      "variational_beta * kldivergence:  0.12631\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.46664\n",
      "kldivergence:   1415.87\n",
      "variational_beta * kldivergence:  0.14159\n",
      "batch accuracy: 86.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.38623\n",
      "kldivergence:   1329.30\n",
      "variational_beta * kldivergence:  0.13293\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.43419\n",
      "kldivergence:   1385.42\n",
      "variational_beta * kldivergence:  0.13854\n",
      "batch accuracy: 86.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.43442\n",
      "kldivergence:   1348.34\n",
      "variational_beta * kldivergence:  0.13483\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.43288\n",
      "kldivergence:   1348.64\n",
      "variational_beta * kldivergence:  0.13486\n",
      "batch accuracy: 85.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.45867\n",
      "kldivergence:   1457.23\n",
      "variational_beta * kldivergence:  0.14572\n",
      "batch accuracy: 85.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.37104\n",
      "kldivergence:   1271.85\n",
      "variational_beta * kldivergence:  0.12718\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.46494\n",
      "kldivergence:   1305.82\n",
      "variational_beta * kldivergence:  0.13058\n",
      "batch accuracy: 86.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #59\n",
      "reconstruction loss: 0.32952\n",
      "kldivergence:   1285.48\n",
      "variational_beta * kldivergence:  0.12855\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "epoch # 59 : train loss is [175.97687424852066] and validation loss is [0.09925153440521749] \n",
      "Epoch [60 / 150] average reconstruction error: 0.474331\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.37680\n",
      "kldivergence:   1500.26\n",
      "variational_beta * kldivergence:  0.15003\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35174\n",
      "kldivergence:   1428.55\n",
      "variational_beta * kldivergence:  0.14285\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35175\n",
      "kldivergence:   1539.83\n",
      "variational_beta * kldivergence:  0.15398\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35764\n",
      "kldivergence:   1377.18\n",
      "variational_beta * kldivergence:  0.13772\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28553\n",
      "kldivergence:   1369.65\n",
      "variational_beta * kldivergence:  0.13697\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30853\n",
      "kldivergence:   1486.84\n",
      "variational_beta * kldivergence:  0.14868\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30484\n",
      "kldivergence:   1415.40\n",
      "variational_beta * kldivergence:  0.14154\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29207\n",
      "kldivergence:   1430.57\n",
      "variational_beta * kldivergence:  0.14306\n",
      "batch accuracy: 90.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33269\n",
      "kldivergence:   1299.02\n",
      "variational_beta * kldivergence:  0.12990\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29447\n",
      "kldivergence:   1555.34\n",
      "variational_beta * kldivergence:  0.15553\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32403\n",
      "kldivergence:   1560.75\n",
      "variational_beta * kldivergence:  0.15607\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30411\n",
      "kldivergence:   1502.29\n",
      "variational_beta * kldivergence:  0.15023\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32277\n",
      "kldivergence:   1538.92\n",
      "variational_beta * kldivergence:  0.15389\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29688\n",
      "kldivergence:   1364.30\n",
      "variational_beta * kldivergence:  0.13643\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36824\n",
      "kldivergence:   1589.36\n",
      "variational_beta * kldivergence:  0.15894\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31161\n",
      "kldivergence:   1412.10\n",
      "variational_beta * kldivergence:  0.14121\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32251\n",
      "kldivergence:   1316.00\n",
      "variational_beta * kldivergence:  0.13160\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29291\n",
      "kldivergence:   1359.97\n",
      "variational_beta * kldivergence:  0.13600\n",
      "batch accuracy: 90.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32641\n",
      "kldivergence:   1625.08\n",
      "variational_beta * kldivergence:  0.16251\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34179\n",
      "kldivergence:   1395.99\n",
      "variational_beta * kldivergence:  0.13960\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29886\n",
      "kldivergence:   1488.29\n",
      "variational_beta * kldivergence:  0.14883\n",
      "batch accuracy: 89.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36308\n",
      "kldivergence:   1504.97\n",
      "variational_beta * kldivergence:  0.15050\n",
      "batch accuracy: 87.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27417\n",
      "kldivergence:   1339.15\n",
      "variational_beta * kldivergence:  0.13391\n",
      "batch accuracy: 90.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29017\n",
      "kldivergence:   1456.22\n",
      "variational_beta * kldivergence:  0.14562\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32726\n",
      "kldivergence:   1395.81\n",
      "variational_beta * kldivergence:  0.13958\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29135\n",
      "kldivergence:   1348.39\n",
      "variational_beta * kldivergence:  0.13484\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36623\n",
      "kldivergence:   1649.57\n",
      "variational_beta * kldivergence:  0.16496\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32527\n",
      "kldivergence:   1514.66\n",
      "variational_beta * kldivergence:  0.15147\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32493\n",
      "kldivergence:   1434.20\n",
      "variational_beta * kldivergence:  0.14342\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32208\n",
      "kldivergence:   1392.34\n",
      "variational_beta * kldivergence:  0.13923\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28216\n",
      "kldivergence:   1517.33\n",
      "variational_beta * kldivergence:  0.15173\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34904\n",
      "kldivergence:   1735.33\n",
      "variational_beta * kldivergence:  0.17353\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30459\n",
      "kldivergence:   1427.73\n",
      "variational_beta * kldivergence:  0.14277\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28351\n",
      "kldivergence:   1255.67\n",
      "variational_beta * kldivergence:  0.12557\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28273\n",
      "kldivergence:   1370.85\n",
      "variational_beta * kldivergence:  0.13709\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36644\n",
      "kldivergence:   1473.80\n",
      "variational_beta * kldivergence:  0.14738\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.25744\n",
      "kldivergence:   1294.84\n",
      "variational_beta * kldivergence:  0.12948\n",
      "batch accuracy: 91.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30601\n",
      "kldivergence:   1389.82\n",
      "variational_beta * kldivergence:  0.13898\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.38470\n",
      "kldivergence:   1448.62\n",
      "variational_beta * kldivergence:  0.14486\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36103\n",
      "kldivergence:   1483.32\n",
      "variational_beta * kldivergence:  0.14833\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35268\n",
      "kldivergence:   1602.44\n",
      "variational_beta * kldivergence:  0.16024\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30429\n",
      "kldivergence:   1348.00\n",
      "variational_beta * kldivergence:  0.13480\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30318\n",
      "kldivergence:   1560.80\n",
      "variational_beta * kldivergence:  0.15608\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31620\n",
      "kldivergence:   1259.96\n",
      "variational_beta * kldivergence:  0.12600\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31449\n",
      "kldivergence:   1491.33\n",
      "variational_beta * kldivergence:  0.14913\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32931\n",
      "kldivergence:   1382.81\n",
      "variational_beta * kldivergence:  0.13828\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34589\n",
      "kldivergence:   1331.30\n",
      "variational_beta * kldivergence:  0.13313\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34262\n",
      "kldivergence:   1470.05\n",
      "variational_beta * kldivergence:  0.14700\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30153\n",
      "kldivergence:   1440.10\n",
      "variational_beta * kldivergence:  0.14401\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30842\n",
      "kldivergence:   1285.25\n",
      "variational_beta * kldivergence:  0.12852\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.25653\n",
      "kldivergence:   1287.98\n",
      "variational_beta * kldivergence:  0.12880\n",
      "batch accuracy: 90.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33403\n",
      "kldivergence:   1552.97\n",
      "variational_beta * kldivergence:  0.15530\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33672\n",
      "kldivergence:   1479.90\n",
      "variational_beta * kldivergence:  0.14799\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29633\n",
      "kldivergence:   1358.77\n",
      "variational_beta * kldivergence:  0.13588\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35037\n",
      "kldivergence:   1676.78\n",
      "variational_beta * kldivergence:  0.16768\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34355\n",
      "kldivergence:   1357.35\n",
      "variational_beta * kldivergence:  0.13574\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30848\n",
      "kldivergence:   1472.73\n",
      "variational_beta * kldivergence:  0.14727\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35831\n",
      "kldivergence:   1645.45\n",
      "variational_beta * kldivergence:  0.16455\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34272\n",
      "kldivergence:   1748.00\n",
      "variational_beta * kldivergence:  0.17480\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31281\n",
      "kldivergence:   1348.97\n",
      "variational_beta * kldivergence:  0.13490\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27897\n",
      "kldivergence:   1606.41\n",
      "variational_beta * kldivergence:  0.16064\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30271\n",
      "kldivergence:   1549.65\n",
      "variational_beta * kldivergence:  0.15497\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.38234\n",
      "kldivergence:   1615.58\n",
      "variational_beta * kldivergence:  0.16156\n",
      "batch accuracy: 86.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34430\n",
      "kldivergence:   1622.67\n",
      "variational_beta * kldivergence:  0.16227\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30193\n",
      "kldivergence:   1629.44\n",
      "variational_beta * kldivergence:  0.16294\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29618\n",
      "kldivergence:   1374.95\n",
      "variational_beta * kldivergence:  0.13750\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27279\n",
      "kldivergence:   1351.13\n",
      "variational_beta * kldivergence:  0.13511\n",
      "batch accuracy: 90.89\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30944\n",
      "kldivergence:   1517.15\n",
      "variational_beta * kldivergence:  0.15171\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34989\n",
      "kldivergence:   1441.54\n",
      "variational_beta * kldivergence:  0.14415\n",
      "batch accuracy: 87.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34275\n",
      "kldivergence:   1355.05\n",
      "variational_beta * kldivergence:  0.13551\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34867\n",
      "kldivergence:   1559.47\n",
      "variational_beta * kldivergence:  0.15595\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33114\n",
      "kldivergence:   1657.46\n",
      "variational_beta * kldivergence:  0.16575\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32362\n",
      "kldivergence:   1583.80\n",
      "variational_beta * kldivergence:  0.15838\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36525\n",
      "kldivergence:   1814.55\n",
      "variational_beta * kldivergence:  0.18145\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28851\n",
      "kldivergence:   1411.76\n",
      "variational_beta * kldivergence:  0.14118\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31780\n",
      "kldivergence:   1848.69\n",
      "variational_beta * kldivergence:  0.18487\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.38055\n",
      "kldivergence:   1531.17\n",
      "variational_beta * kldivergence:  0.15312\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33325\n",
      "kldivergence:   1713.53\n",
      "variational_beta * kldivergence:  0.17135\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30546\n",
      "kldivergence:   1698.36\n",
      "variational_beta * kldivergence:  0.16984\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29415\n",
      "kldivergence:   1473.91\n",
      "variational_beta * kldivergence:  0.14739\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31231\n",
      "kldivergence:   1531.44\n",
      "variational_beta * kldivergence:  0.15314\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28973\n",
      "kldivergence:   1488.72\n",
      "variational_beta * kldivergence:  0.14887\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30038\n",
      "kldivergence:   1556.48\n",
      "variational_beta * kldivergence:  0.15565\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35381\n",
      "kldivergence:   1631.02\n",
      "variational_beta * kldivergence:  0.16310\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31625\n",
      "kldivergence:   1491.60\n",
      "variational_beta * kldivergence:  0.14916\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36239\n",
      "kldivergence:   1620.35\n",
      "variational_beta * kldivergence:  0.16203\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27778\n",
      "kldivergence:   1402.61\n",
      "variational_beta * kldivergence:  0.14026\n",
      "batch accuracy: 90.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32214\n",
      "kldivergence:   1463.29\n",
      "variational_beta * kldivergence:  0.14633\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28579\n",
      "kldivergence:   1533.11\n",
      "variational_beta * kldivergence:  0.15331\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31893\n",
      "kldivergence:   1482.61\n",
      "variational_beta * kldivergence:  0.14826\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34124\n",
      "kldivergence:   1747.52\n",
      "variational_beta * kldivergence:  0.17475\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29897\n",
      "kldivergence:   1437.73\n",
      "variational_beta * kldivergence:  0.14377\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30769\n",
      "kldivergence:   1793.48\n",
      "variational_beta * kldivergence:  0.17935\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33574\n",
      "kldivergence:   1651.02\n",
      "variational_beta * kldivergence:  0.16510\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27962\n",
      "kldivergence:   1754.72\n",
      "variational_beta * kldivergence:  0.17547\n",
      "batch accuracy: 90.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33680\n",
      "kldivergence:   1672.84\n",
      "variational_beta * kldivergence:  0.16728\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31013\n",
      "kldivergence:   1532.03\n",
      "variational_beta * kldivergence:  0.15320\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32917\n",
      "kldivergence:   1631.03\n",
      "variational_beta * kldivergence:  0.16310\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28879\n",
      "kldivergence:   1560.80\n",
      "variational_beta * kldivergence:  0.15608\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29927\n",
      "kldivergence:   1405.26\n",
      "variational_beta * kldivergence:  0.14053\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30337\n",
      "kldivergence:   1386.61\n",
      "variational_beta * kldivergence:  0.13866\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35514\n",
      "kldivergence:   1533.05\n",
      "variational_beta * kldivergence:  0.15330\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32723\n",
      "kldivergence:   1490.77\n",
      "variational_beta * kldivergence:  0.14908\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35164\n",
      "kldivergence:   1321.03\n",
      "variational_beta * kldivergence:  0.13210\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35466\n",
      "kldivergence:   1579.81\n",
      "variational_beta * kldivergence:  0.15798\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33644\n",
      "kldivergence:   1539.86\n",
      "variational_beta * kldivergence:  0.15399\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34473\n",
      "kldivergence:   1363.43\n",
      "variational_beta * kldivergence:  0.13634\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30846\n",
      "kldivergence:   1314.42\n",
      "variational_beta * kldivergence:  0.13144\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.39712\n",
      "kldivergence:   1494.33\n",
      "variational_beta * kldivergence:  0.14943\n",
      "batch accuracy: 86.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34603\n",
      "kldivergence:   1590.02\n",
      "variational_beta * kldivergence:  0.15900\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35282\n",
      "kldivergence:   1653.15\n",
      "variational_beta * kldivergence:  0.16531\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30573\n",
      "kldivergence:   1449.62\n",
      "variational_beta * kldivergence:  0.14496\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35435\n",
      "kldivergence:   1915.91\n",
      "variational_beta * kldivergence:  0.19159\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36506\n",
      "kldivergence:   1434.40\n",
      "variational_beta * kldivergence:  0.14344\n",
      "batch accuracy: 87.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29836\n",
      "kldivergence:   1496.88\n",
      "variational_beta * kldivergence:  0.14969\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34094\n",
      "kldivergence:   1533.08\n",
      "variational_beta * kldivergence:  0.15331\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36046\n",
      "kldivergence:   1554.10\n",
      "variational_beta * kldivergence:  0.15541\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29839\n",
      "kldivergence:   1558.23\n",
      "variational_beta * kldivergence:  0.15582\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34970\n",
      "kldivergence:   1572.85\n",
      "variational_beta * kldivergence:  0.15728\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31066\n",
      "kldivergence:   1373.03\n",
      "variational_beta * kldivergence:  0.13730\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33440\n",
      "kldivergence:   1525.25\n",
      "variational_beta * kldivergence:  0.15252\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34392\n",
      "kldivergence:   1544.77\n",
      "variational_beta * kldivergence:  0.15448\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31324\n",
      "kldivergence:   1477.50\n",
      "variational_beta * kldivergence:  0.14775\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31075\n",
      "kldivergence:   1719.03\n",
      "variational_beta * kldivergence:  0.17190\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.37152\n",
      "kldivergence:   1427.92\n",
      "variational_beta * kldivergence:  0.14279\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34283\n",
      "kldivergence:   1716.71\n",
      "variational_beta * kldivergence:  0.17167\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33073\n",
      "kldivergence:   1564.57\n",
      "variational_beta * kldivergence:  0.15646\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31377\n",
      "kldivergence:   1616.06\n",
      "variational_beta * kldivergence:  0.16161\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31327\n",
      "kldivergence:   1430.20\n",
      "variational_beta * kldivergence:  0.14302\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33901\n",
      "kldivergence:   1500.69\n",
      "variational_beta * kldivergence:  0.15007\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32484\n",
      "kldivergence:   1451.74\n",
      "variational_beta * kldivergence:  0.14517\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27035\n",
      "kldivergence:   1246.91\n",
      "variational_beta * kldivergence:  0.12469\n",
      "batch accuracy: 90.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31823\n",
      "kldivergence:   1476.24\n",
      "variational_beta * kldivergence:  0.14762\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.26627\n",
      "kldivergence:   1225.80\n",
      "variational_beta * kldivergence:  0.12258\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31600\n",
      "kldivergence:   1641.27\n",
      "variational_beta * kldivergence:  0.16413\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34654\n",
      "kldivergence:   1433.57\n",
      "variational_beta * kldivergence:  0.14336\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29056\n",
      "kldivergence:   1558.62\n",
      "variational_beta * kldivergence:  0.15586\n",
      "batch accuracy: 90.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.39185\n",
      "kldivergence:   1856.29\n",
      "variational_beta * kldivergence:  0.18563\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28366\n",
      "kldivergence:   1550.27\n",
      "variational_beta * kldivergence:  0.15503\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27904\n",
      "kldivergence:   1406.43\n",
      "variational_beta * kldivergence:  0.14064\n",
      "batch accuracy: 90.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.43717\n",
      "kldivergence:   1792.20\n",
      "variational_beta * kldivergence:  0.17922\n",
      "batch accuracy: 85.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28984\n",
      "kldivergence:   1436.77\n",
      "variational_beta * kldivergence:  0.14368\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32276\n",
      "kldivergence:   1523.36\n",
      "variational_beta * kldivergence:  0.15234\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36209\n",
      "kldivergence:   1490.01\n",
      "variational_beta * kldivergence:  0.14900\n",
      "batch accuracy: 87.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34253\n",
      "kldivergence:   1425.06\n",
      "variational_beta * kldivergence:  0.14251\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32744\n",
      "kldivergence:   1455.37\n",
      "variational_beta * kldivergence:  0.14554\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30491\n",
      "kldivergence:   1330.77\n",
      "variational_beta * kldivergence:  0.13308\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31220\n",
      "kldivergence:   1479.00\n",
      "variational_beta * kldivergence:  0.14790\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29807\n",
      "kldivergence:   1716.06\n",
      "variational_beta * kldivergence:  0.17161\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34423\n",
      "kldivergence:   1498.58\n",
      "variational_beta * kldivergence:  0.14986\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33441\n",
      "kldivergence:   1540.18\n",
      "variational_beta * kldivergence:  0.15402\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.24647\n",
      "kldivergence:   1328.63\n",
      "variational_beta * kldivergence:  0.13286\n",
      "batch accuracy: 91.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35883\n",
      "kldivergence:   1467.56\n",
      "variational_beta * kldivergence:  0.14676\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31734\n",
      "kldivergence:   1552.54\n",
      "variational_beta * kldivergence:  0.15525\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32824\n",
      "kldivergence:   1452.03\n",
      "variational_beta * kldivergence:  0.14520\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30370\n",
      "kldivergence:   1252.49\n",
      "variational_beta * kldivergence:  0.12525\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32579\n",
      "kldivergence:   1363.82\n",
      "variational_beta * kldivergence:  0.13638\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34959\n",
      "kldivergence:   1583.64\n",
      "variational_beta * kldivergence:  0.15836\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.39225\n",
      "kldivergence:   1530.22\n",
      "variational_beta * kldivergence:  0.15302\n",
      "batch accuracy: 87.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36399\n",
      "kldivergence:   1361.13\n",
      "variational_beta * kldivergence:  0.13611\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32287\n",
      "kldivergence:   1534.18\n",
      "variational_beta * kldivergence:  0.15342\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34106\n",
      "kldivergence:   1467.72\n",
      "variational_beta * kldivergence:  0.14677\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32926\n",
      "kldivergence:   1446.65\n",
      "variational_beta * kldivergence:  0.14467\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35817\n",
      "kldivergence:   1554.37\n",
      "variational_beta * kldivergence:  0.15544\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34322\n",
      "kldivergence:   1460.18\n",
      "variational_beta * kldivergence:  0.14602\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31755\n",
      "kldivergence:   1668.72\n",
      "variational_beta * kldivergence:  0.16687\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28493\n",
      "kldivergence:   1540.62\n",
      "variational_beta * kldivergence:  0.15406\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32441\n",
      "kldivergence:   1498.66\n",
      "variational_beta * kldivergence:  0.14987\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33680\n",
      "kldivergence:   1593.35\n",
      "variational_beta * kldivergence:  0.15934\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30937\n",
      "kldivergence:   1430.52\n",
      "variational_beta * kldivergence:  0.14305\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.26821\n",
      "kldivergence:   1374.14\n",
      "variational_beta * kldivergence:  0.13741\n",
      "batch accuracy: 90.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32252\n",
      "kldivergence:   1549.59\n",
      "variational_beta * kldivergence:  0.15496\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33985\n",
      "kldivergence:   1648.05\n",
      "variational_beta * kldivergence:  0.16481\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30706\n",
      "kldivergence:   1682.79\n",
      "variational_beta * kldivergence:  0.16828\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36315\n",
      "kldivergence:   1722.37\n",
      "variational_beta * kldivergence:  0.17224\n",
      "batch accuracy: 86.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36230\n",
      "kldivergence:   1716.91\n",
      "variational_beta * kldivergence:  0.17169\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.38469\n",
      "kldivergence:   1818.61\n",
      "variational_beta * kldivergence:  0.18186\n",
      "batch accuracy: 86.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32481\n",
      "kldivergence:   1641.04\n",
      "variational_beta * kldivergence:  0.16410\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27108\n",
      "kldivergence:   1349.76\n",
      "variational_beta * kldivergence:  0.13498\n",
      "batch accuracy: 91.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33629\n",
      "kldivergence:   1509.35\n",
      "variational_beta * kldivergence:  0.15093\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31952\n",
      "kldivergence:   1616.18\n",
      "variational_beta * kldivergence:  0.16162\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29970\n",
      "kldivergence:   1770.49\n",
      "variational_beta * kldivergence:  0.17705\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28130\n",
      "kldivergence:   1459.41\n",
      "variational_beta * kldivergence:  0.14594\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35031\n",
      "kldivergence:   1759.44\n",
      "variational_beta * kldivergence:  0.17594\n",
      "batch accuracy: 88.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33856\n",
      "kldivergence:   1501.75\n",
      "variational_beta * kldivergence:  0.15018\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34050\n",
      "kldivergence:   1560.38\n",
      "variational_beta * kldivergence:  0.15604\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33504\n",
      "kldivergence:   1560.00\n",
      "variational_beta * kldivergence:  0.15600\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31040\n",
      "kldivergence:   1466.48\n",
      "variational_beta * kldivergence:  0.14665\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30544\n",
      "kldivergence:   1369.52\n",
      "variational_beta * kldivergence:  0.13695\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32481\n",
      "kldivergence:   1414.81\n",
      "variational_beta * kldivergence:  0.14148\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32602\n",
      "kldivergence:   1617.72\n",
      "variational_beta * kldivergence:  0.16177\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31570\n",
      "kldivergence:   1574.76\n",
      "variational_beta * kldivergence:  0.15748\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31661\n",
      "kldivergence:   1432.45\n",
      "variational_beta * kldivergence:  0.14325\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34790\n",
      "kldivergence:   1742.50\n",
      "variational_beta * kldivergence:  0.17425\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30453\n",
      "kldivergence:   1529.93\n",
      "variational_beta * kldivergence:  0.15299\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34165\n",
      "kldivergence:   1556.63\n",
      "variational_beta * kldivergence:  0.15566\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33175\n",
      "kldivergence:   1557.74\n",
      "variational_beta * kldivergence:  0.15577\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33166\n",
      "kldivergence:   1385.05\n",
      "variational_beta * kldivergence:  0.13851\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33298\n",
      "kldivergence:   1423.30\n",
      "variational_beta * kldivergence:  0.14233\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.38628\n",
      "kldivergence:   1633.04\n",
      "variational_beta * kldivergence:  0.16330\n",
      "batch accuracy: 86.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33671\n",
      "kldivergence:   1597.71\n",
      "variational_beta * kldivergence:  0.15977\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34659\n",
      "kldivergence:   1658.59\n",
      "variational_beta * kldivergence:  0.16586\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31190\n",
      "kldivergence:   1527.15\n",
      "variational_beta * kldivergence:  0.15271\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31655\n",
      "kldivergence:   1484.71\n",
      "variational_beta * kldivergence:  0.14847\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34740\n",
      "kldivergence:   1649.51\n",
      "variational_beta * kldivergence:  0.16495\n",
      "batch accuracy: 88.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31625\n",
      "kldivergence:   1447.04\n",
      "variational_beta * kldivergence:  0.14470\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31979\n",
      "kldivergence:   1352.96\n",
      "variational_beta * kldivergence:  0.13530\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34350\n",
      "kldivergence:   1728.27\n",
      "variational_beta * kldivergence:  0.17283\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29286\n",
      "kldivergence:   1503.70\n",
      "variational_beta * kldivergence:  0.15037\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29731\n",
      "kldivergence:   1547.46\n",
      "variational_beta * kldivergence:  0.15475\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.26549\n",
      "kldivergence:   1373.51\n",
      "variational_beta * kldivergence:  0.13735\n",
      "batch accuracy: 91.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35602\n",
      "kldivergence:   1514.29\n",
      "variational_beta * kldivergence:  0.15143\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35240\n",
      "kldivergence:   1484.03\n",
      "variational_beta * kldivergence:  0.14840\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30127\n",
      "kldivergence:   1516.59\n",
      "variational_beta * kldivergence:  0.15166\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31925\n",
      "kldivergence:   1345.50\n",
      "variational_beta * kldivergence:  0.13455\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33429\n",
      "kldivergence:   1499.21\n",
      "variational_beta * kldivergence:  0.14992\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30224\n",
      "kldivergence:   1385.99\n",
      "variational_beta * kldivergence:  0.13860\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32189\n",
      "kldivergence:   1514.48\n",
      "variational_beta * kldivergence:  0.15145\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30182\n",
      "kldivergence:   1319.49\n",
      "variational_beta * kldivergence:  0.13195\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34703\n",
      "kldivergence:   1316.51\n",
      "variational_beta * kldivergence:  0.13165\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31285\n",
      "kldivergence:   1439.93\n",
      "variational_beta * kldivergence:  0.14399\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30811\n",
      "kldivergence:   1496.77\n",
      "variational_beta * kldivergence:  0.14968\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31146\n",
      "kldivergence:   1394.87\n",
      "variational_beta * kldivergence:  0.13949\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28875\n",
      "kldivergence:   1161.37\n",
      "variational_beta * kldivergence:  0.11614\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27225\n",
      "kldivergence:   1262.06\n",
      "variational_beta * kldivergence:  0.12621\n",
      "batch accuracy: 90.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33998\n",
      "kldivergence:   1555.53\n",
      "variational_beta * kldivergence:  0.15555\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29122\n",
      "kldivergence:   1468.36\n",
      "variational_beta * kldivergence:  0.14684\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32953\n",
      "kldivergence:   1319.05\n",
      "variational_beta * kldivergence:  0.13191\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30895\n",
      "kldivergence:   1631.29\n",
      "variational_beta * kldivergence:  0.16313\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34534\n",
      "kldivergence:   1318.47\n",
      "variational_beta * kldivergence:  0.13185\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28900\n",
      "kldivergence:   1426.65\n",
      "variational_beta * kldivergence:  0.14267\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33094\n",
      "kldivergence:   1581.58\n",
      "variational_beta * kldivergence:  0.15816\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36676\n",
      "kldivergence:   1688.96\n",
      "variational_beta * kldivergence:  0.16890\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.40504\n",
      "kldivergence:   1604.57\n",
      "variational_beta * kldivergence:  0.16046\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33494\n",
      "kldivergence:   1426.11\n",
      "variational_beta * kldivergence:  0.14261\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34712\n",
      "kldivergence:   1643.27\n",
      "variational_beta * kldivergence:  0.16433\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30222\n",
      "kldivergence:   1333.08\n",
      "variational_beta * kldivergence:  0.13331\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32663\n",
      "kldivergence:   1537.63\n",
      "variational_beta * kldivergence:  0.15376\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33083\n",
      "kldivergence:   1635.96\n",
      "variational_beta * kldivergence:  0.16360\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33891\n",
      "kldivergence:   1532.70\n",
      "variational_beta * kldivergence:  0.15327\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30051\n",
      "kldivergence:   1399.91\n",
      "variational_beta * kldivergence:  0.13999\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.25708\n",
      "kldivergence:   1194.07\n",
      "variational_beta * kldivergence:  0.11941\n",
      "batch accuracy: 91.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35148\n",
      "kldivergence:   1593.94\n",
      "variational_beta * kldivergence:  0.15939\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31048\n",
      "kldivergence:   1402.34\n",
      "variational_beta * kldivergence:  0.14023\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33188\n",
      "kldivergence:   1477.70\n",
      "variational_beta * kldivergence:  0.14777\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34192\n",
      "kldivergence:   1418.88\n",
      "variational_beta * kldivergence:  0.14189\n",
      "batch accuracy: 88.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30997\n",
      "kldivergence:   1617.33\n",
      "variational_beta * kldivergence:  0.16173\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33834\n",
      "kldivergence:   1379.78\n",
      "variational_beta * kldivergence:  0.13798\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28457\n",
      "kldivergence:   1413.06\n",
      "variational_beta * kldivergence:  0.14131\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32014\n",
      "kldivergence:   1451.96\n",
      "variational_beta * kldivergence:  0.14520\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29917\n",
      "kldivergence:   1399.02\n",
      "variational_beta * kldivergence:  0.13990\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33241\n",
      "kldivergence:   1412.53\n",
      "variational_beta * kldivergence:  0.14125\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.37795\n",
      "kldivergence:   1575.24\n",
      "variational_beta * kldivergence:  0.15752\n",
      "batch accuracy: 87.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33747\n",
      "kldivergence:   1579.47\n",
      "variational_beta * kldivergence:  0.15795\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.26228\n",
      "kldivergence:   1295.85\n",
      "variational_beta * kldivergence:  0.12958\n",
      "batch accuracy: 91.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30895\n",
      "kldivergence:   1493.32\n",
      "variational_beta * kldivergence:  0.14933\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.37344\n",
      "kldivergence:   1539.02\n",
      "variational_beta * kldivergence:  0.15390\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33522\n",
      "kldivergence:   1506.29\n",
      "variational_beta * kldivergence:  0.15063\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33113\n",
      "kldivergence:   1542.95\n",
      "variational_beta * kldivergence:  0.15429\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30910\n",
      "kldivergence:   1368.38\n",
      "variational_beta * kldivergence:  0.13684\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30829\n",
      "kldivergence:   1486.91\n",
      "variational_beta * kldivergence:  0.14869\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31510\n",
      "kldivergence:   1348.73\n",
      "variational_beta * kldivergence:  0.13487\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29989\n",
      "kldivergence:   1550.18\n",
      "variational_beta * kldivergence:  0.15502\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31036\n",
      "kldivergence:   1447.82\n",
      "variational_beta * kldivergence:  0.14478\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31506\n",
      "kldivergence:   1563.58\n",
      "variational_beta * kldivergence:  0.15636\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35606\n",
      "kldivergence:   1730.03\n",
      "variational_beta * kldivergence:  0.17300\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27786\n",
      "kldivergence:   1438.84\n",
      "variational_beta * kldivergence:  0.14388\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.38045\n",
      "kldivergence:   1477.51\n",
      "variational_beta * kldivergence:  0.14775\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33021\n",
      "kldivergence:   1437.82\n",
      "variational_beta * kldivergence:  0.14378\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30045\n",
      "kldivergence:   1508.11\n",
      "variational_beta * kldivergence:  0.15081\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33747\n",
      "kldivergence:   1450.61\n",
      "variational_beta * kldivergence:  0.14506\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34979\n",
      "kldivergence:   1511.55\n",
      "variational_beta * kldivergence:  0.15115\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27419\n",
      "kldivergence:   1443.07\n",
      "variational_beta * kldivergence:  0.14431\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30506\n",
      "kldivergence:   1621.99\n",
      "variational_beta * kldivergence:  0.16220\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33383\n",
      "kldivergence:   1475.50\n",
      "variational_beta * kldivergence:  0.14755\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30675\n",
      "kldivergence:   1411.76\n",
      "variational_beta * kldivergence:  0.14118\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36882\n",
      "kldivergence:   1555.32\n",
      "variational_beta * kldivergence:  0.15553\n",
      "batch accuracy: 87.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.37076\n",
      "kldivergence:   1667.52\n",
      "variational_beta * kldivergence:  0.16675\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31461\n",
      "kldivergence:   1468.57\n",
      "variational_beta * kldivergence:  0.14686\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.27331\n",
      "kldivergence:   1378.77\n",
      "variational_beta * kldivergence:  0.13788\n",
      "batch accuracy: 90.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33191\n",
      "kldivergence:   1441.49\n",
      "variational_beta * kldivergence:  0.14415\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31669\n",
      "kldivergence:   1467.73\n",
      "variational_beta * kldivergence:  0.14677\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31786\n",
      "kldivergence:   1493.06\n",
      "variational_beta * kldivergence:  0.14931\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29124\n",
      "kldivergence:   1292.99\n",
      "variational_beta * kldivergence:  0.12930\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31002\n",
      "kldivergence:   1507.44\n",
      "variational_beta * kldivergence:  0.15074\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32199\n",
      "kldivergence:   1511.95\n",
      "variational_beta * kldivergence:  0.15120\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29232\n",
      "kldivergence:   1371.58\n",
      "variational_beta * kldivergence:  0.13716\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32130\n",
      "kldivergence:   1393.79\n",
      "variational_beta * kldivergence:  0.13938\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36216\n",
      "kldivergence:   1626.45\n",
      "variational_beta * kldivergence:  0.16264\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34727\n",
      "kldivergence:   1540.91\n",
      "variational_beta * kldivergence:  0.15409\n",
      "batch accuracy: 88.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34434\n",
      "kldivergence:   1585.30\n",
      "variational_beta * kldivergence:  0.15853\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36813\n",
      "kldivergence:   1565.27\n",
      "variational_beta * kldivergence:  0.15653\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33267\n",
      "kldivergence:   1593.47\n",
      "variational_beta * kldivergence:  0.15935\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31004\n",
      "kldivergence:   1487.04\n",
      "variational_beta * kldivergence:  0.14870\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33005\n",
      "kldivergence:   1482.53\n",
      "variational_beta * kldivergence:  0.14825\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35678\n",
      "kldivergence:   1409.82\n",
      "variational_beta * kldivergence:  0.14098\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.26150\n",
      "kldivergence:   1345.57\n",
      "variational_beta * kldivergence:  0.13456\n",
      "batch accuracy: 91.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32451\n",
      "kldivergence:   1457.59\n",
      "variational_beta * kldivergence:  0.14576\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36216\n",
      "kldivergence:   1592.82\n",
      "variational_beta * kldivergence:  0.15928\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32495\n",
      "kldivergence:   1453.36\n",
      "variational_beta * kldivergence:  0.14534\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.37741\n",
      "kldivergence:   1596.57\n",
      "variational_beta * kldivergence:  0.15966\n",
      "batch accuracy: 86.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31886\n",
      "kldivergence:   1535.45\n",
      "variational_beta * kldivergence:  0.15355\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32145\n",
      "kldivergence:   1496.38\n",
      "variational_beta * kldivergence:  0.14964\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32450\n",
      "kldivergence:   1636.71\n",
      "variational_beta * kldivergence:  0.16367\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28821\n",
      "kldivergence:   1591.85\n",
      "variational_beta * kldivergence:  0.15919\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34840\n",
      "kldivergence:   1628.53\n",
      "variational_beta * kldivergence:  0.16285\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34346\n",
      "kldivergence:   1446.44\n",
      "variational_beta * kldivergence:  0.14464\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29947\n",
      "kldivergence:   1504.10\n",
      "variational_beta * kldivergence:  0.15041\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31474\n",
      "kldivergence:   1551.28\n",
      "variational_beta * kldivergence:  0.15513\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32632\n",
      "kldivergence:   1430.36\n",
      "variational_beta * kldivergence:  0.14304\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32972\n",
      "kldivergence:   1501.32\n",
      "variational_beta * kldivergence:  0.15013\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34621\n",
      "kldivergence:   1371.26\n",
      "variational_beta * kldivergence:  0.13713\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31885\n",
      "kldivergence:   1529.49\n",
      "variational_beta * kldivergence:  0.15295\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36251\n",
      "kldivergence:   1606.40\n",
      "variational_beta * kldivergence:  0.16064\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30512\n",
      "kldivergence:   1308.12\n",
      "variational_beta * kldivergence:  0.13081\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32534\n",
      "kldivergence:   1310.46\n",
      "variational_beta * kldivergence:  0.13105\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33385\n",
      "kldivergence:   1562.96\n",
      "variational_beta * kldivergence:  0.15630\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31219\n",
      "kldivergence:   1401.68\n",
      "variational_beta * kldivergence:  0.14017\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30340\n",
      "kldivergence:   1316.39\n",
      "variational_beta * kldivergence:  0.13164\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31150\n",
      "kldivergence:   1458.94\n",
      "variational_beta * kldivergence:  0.14589\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34190\n",
      "kldivergence:   1520.91\n",
      "variational_beta * kldivergence:  0.15209\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30005\n",
      "kldivergence:   1341.10\n",
      "variational_beta * kldivergence:  0.13411\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.37156\n",
      "kldivergence:   1723.18\n",
      "variational_beta * kldivergence:  0.17232\n",
      "batch accuracy: 87.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31644\n",
      "kldivergence:   1373.44\n",
      "variational_beta * kldivergence:  0.13734\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29793\n",
      "kldivergence:   1449.38\n",
      "variational_beta * kldivergence:  0.14494\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32288\n",
      "kldivergence:   1541.62\n",
      "variational_beta * kldivergence:  0.15416\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31243\n",
      "kldivergence:   1313.07\n",
      "variational_beta * kldivergence:  0.13131\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33478\n",
      "kldivergence:   1585.44\n",
      "variational_beta * kldivergence:  0.15854\n",
      "batch accuracy: 88.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31232\n",
      "kldivergence:   1359.14\n",
      "variational_beta * kldivergence:  0.13591\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31728\n",
      "kldivergence:   1517.76\n",
      "variational_beta * kldivergence:  0.15178\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30280\n",
      "kldivergence:   1343.86\n",
      "variational_beta * kldivergence:  0.13439\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34029\n",
      "kldivergence:   1452.54\n",
      "variational_beta * kldivergence:  0.14525\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31005\n",
      "kldivergence:   1399.77\n",
      "variational_beta * kldivergence:  0.13998\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32878\n",
      "kldivergence:   1610.96\n",
      "variational_beta * kldivergence:  0.16110\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32592\n",
      "kldivergence:   1606.50\n",
      "variational_beta * kldivergence:  0.16065\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31876\n",
      "kldivergence:   1404.60\n",
      "variational_beta * kldivergence:  0.14046\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30872\n",
      "kldivergence:   1394.98\n",
      "variational_beta * kldivergence:  0.13950\n",
      "batch accuracy: 89.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.35719\n",
      "kldivergence:   1637.61\n",
      "variational_beta * kldivergence:  0.16376\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34666\n",
      "kldivergence:   1505.97\n",
      "variational_beta * kldivergence:  0.15060\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31787\n",
      "kldivergence:   1372.22\n",
      "variational_beta * kldivergence:  0.13722\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32622\n",
      "kldivergence:   1379.58\n",
      "variational_beta * kldivergence:  0.13796\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32166\n",
      "kldivergence:   1546.65\n",
      "variational_beta * kldivergence:  0.15467\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.25691\n",
      "kldivergence:   1354.53\n",
      "variational_beta * kldivergence:  0.13545\n",
      "batch accuracy: 91.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33114\n",
      "kldivergence:   1421.68\n",
      "variational_beta * kldivergence:  0.14217\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.25981\n",
      "kldivergence:   1404.87\n",
      "variational_beta * kldivergence:  0.14049\n",
      "batch accuracy: 91.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.26548\n",
      "kldivergence:   1526.44\n",
      "variational_beta * kldivergence:  0.15264\n",
      "batch accuracy: 91.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31869\n",
      "kldivergence:   1502.87\n",
      "variational_beta * kldivergence:  0.15029\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30829\n",
      "kldivergence:   1434.97\n",
      "variational_beta * kldivergence:  0.14350\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31292\n",
      "kldivergence:   1341.69\n",
      "variational_beta * kldivergence:  0.13417\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31137\n",
      "kldivergence:   1531.21\n",
      "variational_beta * kldivergence:  0.15312\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28165\n",
      "kldivergence:   1427.78\n",
      "variational_beta * kldivergence:  0.14278\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33082\n",
      "kldivergence:   1498.42\n",
      "variational_beta * kldivergence:  0.14984\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30095\n",
      "kldivergence:   1440.82\n",
      "variational_beta * kldivergence:  0.14408\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34208\n",
      "kldivergence:   1863.62\n",
      "variational_beta * kldivergence:  0.18636\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32798\n",
      "kldivergence:   1572.46\n",
      "variational_beta * kldivergence:  0.15725\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.29241\n",
      "kldivergence:   1413.54\n",
      "variational_beta * kldivergence:  0.14135\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.31650\n",
      "kldivergence:   1408.73\n",
      "variational_beta * kldivergence:  0.14087\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34244\n",
      "kldivergence:   1425.04\n",
      "variational_beta * kldivergence:  0.14250\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36164\n",
      "kldivergence:   1520.66\n",
      "variational_beta * kldivergence:  0.15207\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32842\n",
      "kldivergence:   1564.48\n",
      "variational_beta * kldivergence:  0.15645\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30660\n",
      "kldivergence:   1512.56\n",
      "variational_beta * kldivergence:  0.15126\n",
      "batch accuracy: 89.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33985\n",
      "kldivergence:   1418.21\n",
      "variational_beta * kldivergence:  0.14182\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34087\n",
      "kldivergence:   1370.85\n",
      "variational_beta * kldivergence:  0.13709\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.36934\n",
      "kldivergence:   1646.09\n",
      "variational_beta * kldivergence:  0.16461\n",
      "batch accuracy: 87.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.32559\n",
      "kldivergence:   1526.80\n",
      "variational_beta * kldivergence:  0.15268\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.28213\n",
      "kldivergence:   1425.78\n",
      "variational_beta * kldivergence:  0.14258\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.33848\n",
      "kldivergence:   1483.90\n",
      "variational_beta * kldivergence:  0.14839\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30015\n",
      "kldivergence:   1620.33\n",
      "variational_beta * kldivergence:  0.16203\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30494\n",
      "kldivergence:   1559.85\n",
      "variational_beta * kldivergence:  0.15599\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.34295\n",
      "kldivergence:   1337.27\n",
      "variational_beta * kldivergence:  0.13373\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #60\n",
      "reconstruction loss: 0.30393\n",
      "kldivergence:   1443.99\n",
      "variational_beta * kldivergence:  0.14440\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.44101\n",
      "kldivergence:   1381.27\n",
      "variational_beta * kldivergence:  0.13813\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.45125\n",
      "kldivergence:   1417.61\n",
      "variational_beta * kldivergence:  0.14176\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.45573\n",
      "kldivergence:   1481.16\n",
      "variational_beta * kldivergence:  0.14812\n",
      "batch accuracy: 86.06\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.46564\n",
      "kldivergence:   1413.06\n",
      "variational_beta * kldivergence:  0.14131\n",
      "batch accuracy: 85.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.46408\n",
      "kldivergence:   1357.12\n",
      "variational_beta * kldivergence:  0.13571\n",
      "batch accuracy: 86.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.51112\n",
      "kldivergence:   1427.74\n",
      "variational_beta * kldivergence:  0.14277\n",
      "batch accuracy: 84.14\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.44445\n",
      "kldivergence:   1431.07\n",
      "variational_beta * kldivergence:  0.14311\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.42545\n",
      "kldivergence:   1509.95\n",
      "variational_beta * kldivergence:  0.15100\n",
      "batch accuracy: 86.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.43077\n",
      "kldivergence:   1330.57\n",
      "variational_beta * kldivergence:  0.13306\n",
      "batch accuracy: 86.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.45167\n",
      "kldivergence:   1387.37\n",
      "variational_beta * kldivergence:  0.13874\n",
      "batch accuracy: 85.85\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.37619\n",
      "kldivergence:   1341.96\n",
      "variational_beta * kldivergence:  0.13420\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.41051\n",
      "kldivergence:   1347.98\n",
      "variational_beta * kldivergence:  0.13480\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.41118\n",
      "kldivergence:   1345.47\n",
      "variational_beta * kldivergence:  0.13455\n",
      "batch accuracy: 87.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.41424\n",
      "kldivergence:   1537.76\n",
      "variational_beta * kldivergence:  0.15378\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.33362\n",
      "kldivergence:   1185.50\n",
      "variational_beta * kldivergence:  0.11855\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.47538\n",
      "kldivergence:   1468.68\n",
      "variational_beta * kldivergence:  0.14687\n",
      "batch accuracy: 85.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.42466\n",
      "kldivergence:   1338.55\n",
      "variational_beta * kldivergence:  0.13385\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.40302\n",
      "kldivergence:   1364.72\n",
      "variational_beta * kldivergence:  0.13647\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.43093\n",
      "kldivergence:   1389.99\n",
      "variational_beta * kldivergence:  0.13900\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.37472\n",
      "kldivergence:   1290.10\n",
      "variational_beta * kldivergence:  0.12901\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.40410\n",
      "kldivergence:   1323.76\n",
      "variational_beta * kldivergence:  0.13238\n",
      "batch accuracy: 87.16\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.46434\n",
      "kldivergence:   1291.11\n",
      "variational_beta * kldivergence:  0.12911\n",
      "batch accuracy: 86.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.48668\n",
      "kldivergence:   1506.62\n",
      "variational_beta * kldivergence:  0.15066\n",
      "batch accuracy: 85.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.34417\n",
      "kldivergence:   1251.50\n",
      "variational_beta * kldivergence:  0.12515\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.39968\n",
      "kldivergence:   1329.48\n",
      "variational_beta * kldivergence:  0.13295\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.45399\n",
      "kldivergence:   1356.44\n",
      "variational_beta * kldivergence:  0.13564\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.51368\n",
      "kldivergence:   1412.75\n",
      "variational_beta * kldivergence:  0.14128\n",
      "batch accuracy: 84.46\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.49239\n",
      "kldivergence:   1457.51\n",
      "variational_beta * kldivergence:  0.14575\n",
      "batch accuracy: 84.75\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.47486\n",
      "kldivergence:   1392.48\n",
      "variational_beta * kldivergence:  0.13925\n",
      "batch accuracy: 85.39\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.54014\n",
      "kldivergence:   1446.31\n",
      "variational_beta * kldivergence:  0.14463\n",
      "batch accuracy: 84.10\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.48355\n",
      "kldivergence:   1396.06\n",
      "variational_beta * kldivergence:  0.13961\n",
      "batch accuracy: 85.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.49172\n",
      "kldivergence:   1430.86\n",
      "variational_beta * kldivergence:  0.14309\n",
      "batch accuracy: 84.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.41158\n",
      "kldivergence:   1254.57\n",
      "variational_beta * kldivergence:  0.12546\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.41940\n",
      "kldivergence:   1318.72\n",
      "variational_beta * kldivergence:  0.13187\n",
      "batch accuracy: 87.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.53696\n",
      "kldivergence:   1422.00\n",
      "variational_beta * kldivergence:  0.14220\n",
      "batch accuracy: 83.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.41209\n",
      "kldivergence:   1338.86\n",
      "variational_beta * kldivergence:  0.13389\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.52419\n",
      "kldivergence:   1497.15\n",
      "variational_beta * kldivergence:  0.14972\n",
      "batch accuracy: 84.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.48799\n",
      "kldivergence:   1397.89\n",
      "variational_beta * kldivergence:  0.13979\n",
      "batch accuracy: 84.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.45674\n",
      "kldivergence:   1558.25\n",
      "variational_beta * kldivergence:  0.15582\n",
      "batch accuracy: 84.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.46320\n",
      "kldivergence:   1355.11\n",
      "variational_beta * kldivergence:  0.13551\n",
      "batch accuracy: 86.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.44523\n",
      "kldivergence:   1331.94\n",
      "variational_beta * kldivergence:  0.13319\n",
      "batch accuracy: 86.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.43527\n",
      "kldivergence:   1286.76\n",
      "variational_beta * kldivergence:  0.12868\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.45556\n",
      "kldivergence:   1381.00\n",
      "variational_beta * kldivergence:  0.13810\n",
      "batch accuracy: 85.88\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.44245\n",
      "kldivergence:   1299.09\n",
      "variational_beta * kldivergence:  0.12991\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.57678\n",
      "kldivergence:   1639.52\n",
      "variational_beta * kldivergence:  0.16395\n",
      "batch accuracy: 81.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.53289\n",
      "kldivergence:   1534.71\n",
      "variational_beta * kldivergence:  0.15347\n",
      "batch accuracy: 84.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.47359\n",
      "kldivergence:   1312.80\n",
      "variational_beta * kldivergence:  0.13128\n",
      "batch accuracy: 84.60\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.43538\n",
      "kldivergence:   1441.98\n",
      "variational_beta * kldivergence:  0.14420\n",
      "batch accuracy: 86.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.42167\n",
      "kldivergence:   1297.72\n",
      "variational_beta * kldivergence:  0.12977\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.46918\n",
      "kldivergence:   1409.54\n",
      "variational_beta * kldivergence:  0.14095\n",
      "batch accuracy: 86.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.40448\n",
      "kldivergence:   1236.45\n",
      "variational_beta * kldivergence:  0.12364\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.38210\n",
      "kldivergence:   1290.29\n",
      "variational_beta * kldivergence:  0.12903\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.49343\n",
      "kldivergence:   1373.51\n",
      "variational_beta * kldivergence:  0.13735\n",
      "batch accuracy: 85.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.43439\n",
      "kldivergence:   1326.32\n",
      "variational_beta * kldivergence:  0.13263\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.46114\n",
      "kldivergence:   1404.45\n",
      "variational_beta * kldivergence:  0.14044\n",
      "batch accuracy: 85.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.46391\n",
      "kldivergence:   1512.63\n",
      "variational_beta * kldivergence:  0.15126\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.47508\n",
      "kldivergence:   1426.05\n",
      "variational_beta * kldivergence:  0.14260\n",
      "batch accuracy: 84.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.50317\n",
      "kldivergence:   1450.94\n",
      "variational_beta * kldivergence:  0.14509\n",
      "batch accuracy: 84.35\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.35341\n",
      "kldivergence:   1267.51\n",
      "variational_beta * kldivergence:  0.12675\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.44739\n",
      "kldivergence:   1406.70\n",
      "variational_beta * kldivergence:  0.14067\n",
      "batch accuracy: 86.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.45278\n",
      "kldivergence:   1504.36\n",
      "variational_beta * kldivergence:  0.15044\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #60\n",
      "reconstruction loss: 0.46803\n",
      "kldivergence:   1389.33\n",
      "variational_beta * kldivergence:  0.13893\n",
      "batch accuracy: 85.92\n",
      "\n",
      "\n",
      "epoch # 60 : train loss is [175.9914682182617] and validation loss is [0.0986105568214645] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved samples\n",
      "Epoch [61 / 150] average reconstruction error: 0.474371\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34442\n",
      "kldivergence:   1489.03\n",
      "variational_beta * kldivergence:  0.14890\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28972\n",
      "kldivergence:   1571.62\n",
      "variational_beta * kldivergence:  0.15716\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35911\n",
      "kldivergence:   1726.58\n",
      "variational_beta * kldivergence:  0.17266\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35382\n",
      "kldivergence:   1503.56\n",
      "variational_beta * kldivergence:  0.15036\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33883\n",
      "kldivergence:   1584.75\n",
      "variational_beta * kldivergence:  0.15847\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35304\n",
      "kldivergence:   1884.39\n",
      "variational_beta * kldivergence:  0.18844\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.27453\n",
      "kldivergence:   1537.99\n",
      "variational_beta * kldivergence:  0.15380\n",
      "batch accuracy: 90.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32907\n",
      "kldivergence:   1465.53\n",
      "variational_beta * kldivergence:  0.14655\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32710\n",
      "kldivergence:   1566.78\n",
      "variational_beta * kldivergence:  0.15668\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29380\n",
      "kldivergence:   1393.17\n",
      "variational_beta * kldivergence:  0.13932\n",
      "batch accuracy: 90.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31962\n",
      "kldivergence:   1611.71\n",
      "variational_beta * kldivergence:  0.16117\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31080\n",
      "kldivergence:   1866.28\n",
      "variational_beta * kldivergence:  0.18663\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28129\n",
      "kldivergence:   1357.27\n",
      "variational_beta * kldivergence:  0.13573\n",
      "batch accuracy: 90.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26239\n",
      "kldivergence:   1348.84\n",
      "variational_beta * kldivergence:  0.13488\n",
      "batch accuracy: 91.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32743\n",
      "kldivergence:   1459.26\n",
      "variational_beta * kldivergence:  0.14593\n",
      "batch accuracy: 88.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29225\n",
      "kldivergence:   1326.35\n",
      "variational_beta * kldivergence:  0.13264\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30544\n",
      "kldivergence:   1676.74\n",
      "variational_beta * kldivergence:  0.16767\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29336\n",
      "kldivergence:   1306.11\n",
      "variational_beta * kldivergence:  0.13061\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31163\n",
      "kldivergence:   1490.64\n",
      "variational_beta * kldivergence:  0.14906\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.27374\n",
      "kldivergence:   1300.89\n",
      "variational_beta * kldivergence:  0.13009\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.27947\n",
      "kldivergence:   1524.30\n",
      "variational_beta * kldivergence:  0.15243\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31460\n",
      "kldivergence:   1547.45\n",
      "variational_beta * kldivergence:  0.15475\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.24907\n",
      "kldivergence:   1354.04\n",
      "variational_beta * kldivergence:  0.13540\n",
      "batch accuracy: 91.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33962\n",
      "kldivergence:   1539.91\n",
      "variational_beta * kldivergence:  0.15399\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33489\n",
      "kldivergence:   1949.38\n",
      "variational_beta * kldivergence:  0.19494\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35107\n",
      "kldivergence:   1443.84\n",
      "variational_beta * kldivergence:  0.14438\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29886\n",
      "kldivergence:   1447.17\n",
      "variational_beta * kldivergence:  0.14472\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31167\n",
      "kldivergence:   1422.41\n",
      "variational_beta * kldivergence:  0.14224\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28839\n",
      "kldivergence:   1385.04\n",
      "variational_beta * kldivergence:  0.13850\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33242\n",
      "kldivergence:   1631.33\n",
      "variational_beta * kldivergence:  0.16313\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.25496\n",
      "kldivergence:   1501.28\n",
      "variational_beta * kldivergence:  0.15013\n",
      "batch accuracy: 91.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29276\n",
      "kldivergence:   1562.95\n",
      "variational_beta * kldivergence:  0.15630\n",
      "batch accuracy: 90.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29623\n",
      "kldivergence:   1607.78\n",
      "variational_beta * kldivergence:  0.16078\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33580\n",
      "kldivergence:   1453.52\n",
      "variational_beta * kldivergence:  0.14535\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36357\n",
      "kldivergence:   1599.53\n",
      "variational_beta * kldivergence:  0.15995\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.38372\n",
      "kldivergence:   1711.55\n",
      "variational_beta * kldivergence:  0.17116\n",
      "batch accuracy: 87.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26960\n",
      "kldivergence:   1412.84\n",
      "variational_beta * kldivergence:  0.14128\n",
      "batch accuracy: 90.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29558\n",
      "kldivergence:   1327.00\n",
      "variational_beta * kldivergence:  0.13270\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32201\n",
      "kldivergence:   1351.63\n",
      "variational_beta * kldivergence:  0.13516\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30824\n",
      "kldivergence:   1194.77\n",
      "variational_beta * kldivergence:  0.11948\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30802\n",
      "kldivergence:   1369.00\n",
      "variational_beta * kldivergence:  0.13690\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31234\n",
      "kldivergence:   1303.45\n",
      "variational_beta * kldivergence:  0.13034\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33352\n",
      "kldivergence:   1385.65\n",
      "variational_beta * kldivergence:  0.13856\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32194\n",
      "kldivergence:   1532.21\n",
      "variational_beta * kldivergence:  0.15322\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34516\n",
      "kldivergence:   1501.10\n",
      "variational_beta * kldivergence:  0.15011\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32326\n",
      "kldivergence:   1503.27\n",
      "variational_beta * kldivergence:  0.15033\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32829\n",
      "kldivergence:   1546.70\n",
      "variational_beta * kldivergence:  0.15467\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30899\n",
      "kldivergence:   1370.76\n",
      "variational_beta * kldivergence:  0.13708\n",
      "batch accuracy: 89.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31850\n",
      "kldivergence:   1391.93\n",
      "variational_beta * kldivergence:  0.13919\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29504\n",
      "kldivergence:   1311.41\n",
      "variational_beta * kldivergence:  0.13114\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.25186\n",
      "kldivergence:   1582.73\n",
      "variational_beta * kldivergence:  0.15827\n",
      "batch accuracy: 91.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32551\n",
      "kldivergence:   1440.22\n",
      "variational_beta * kldivergence:  0.14402\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29479\n",
      "kldivergence:   1325.89\n",
      "variational_beta * kldivergence:  0.13259\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32625\n",
      "kldivergence:   1418.02\n",
      "variational_beta * kldivergence:  0.14180\n",
      "batch accuracy: 88.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30214\n",
      "kldivergence:   1415.68\n",
      "variational_beta * kldivergence:  0.14157\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30198\n",
      "kldivergence:   1497.19\n",
      "variational_beta * kldivergence:  0.14972\n",
      "batch accuracy: 89.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28720\n",
      "kldivergence:   1398.48\n",
      "variational_beta * kldivergence:  0.13985\n",
      "batch accuracy: 90.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30867\n",
      "kldivergence:   1474.75\n",
      "variational_beta * kldivergence:  0.14747\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36744\n",
      "kldivergence:   1534.01\n",
      "variational_beta * kldivergence:  0.15340\n",
      "batch accuracy: 87.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.38444\n",
      "kldivergence:   1609.27\n",
      "variational_beta * kldivergence:  0.16093\n",
      "batch accuracy: 87.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33285\n",
      "kldivergence:   1396.45\n",
      "variational_beta * kldivergence:  0.13964\n",
      "batch accuracy: 88.64\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33277\n",
      "kldivergence:   1599.30\n",
      "variational_beta * kldivergence:  0.15993\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35031\n",
      "kldivergence:   1477.08\n",
      "variational_beta * kldivergence:  0.14771\n",
      "batch accuracy: 88.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29602\n",
      "kldivergence:   1488.54\n",
      "variational_beta * kldivergence:  0.14885\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35646\n",
      "kldivergence:   1645.12\n",
      "variational_beta * kldivergence:  0.16451\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28886\n",
      "kldivergence:   1434.26\n",
      "variational_beta * kldivergence:  0.14343\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29240\n",
      "kldivergence:   1409.27\n",
      "variational_beta * kldivergence:  0.14093\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35680\n",
      "kldivergence:   1639.80\n",
      "variational_beta * kldivergence:  0.16398\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34997\n",
      "kldivergence:   1668.66\n",
      "variational_beta * kldivergence:  0.16687\n",
      "batch accuracy: 88.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31209\n",
      "kldivergence:   1569.47\n",
      "variational_beta * kldivergence:  0.15695\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26746\n",
      "kldivergence:   1566.98\n",
      "variational_beta * kldivergence:  0.15670\n",
      "batch accuracy: 91.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32050\n",
      "kldivergence:   1617.90\n",
      "variational_beta * kldivergence:  0.16179\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36101\n",
      "kldivergence:   1710.02\n",
      "variational_beta * kldivergence:  0.17100\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30607\n",
      "kldivergence:   1451.62\n",
      "variational_beta * kldivergence:  0.14516\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31085\n",
      "kldivergence:   1619.39\n",
      "variational_beta * kldivergence:  0.16194\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30803\n",
      "kldivergence:   1578.99\n",
      "variational_beta * kldivergence:  0.15790\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29051\n",
      "kldivergence:   1528.51\n",
      "variational_beta * kldivergence:  0.15285\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36630\n",
      "kldivergence:   1615.68\n",
      "variational_beta * kldivergence:  0.16157\n",
      "batch accuracy: 87.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30154\n",
      "kldivergence:   1630.92\n",
      "variational_beta * kldivergence:  0.16309\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35750\n",
      "kldivergence:   1495.11\n",
      "variational_beta * kldivergence:  0.14951\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34887\n",
      "kldivergence:   1624.11\n",
      "variational_beta * kldivergence:  0.16241\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.38231\n",
      "kldivergence:   1680.61\n",
      "variational_beta * kldivergence:  0.16806\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35095\n",
      "kldivergence:   1531.38\n",
      "variational_beta * kldivergence:  0.15314\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34218\n",
      "kldivergence:   1574.66\n",
      "variational_beta * kldivergence:  0.15747\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33156\n",
      "kldivergence:   1542.75\n",
      "variational_beta * kldivergence:  0.15428\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31589\n",
      "kldivergence:   1285.02\n",
      "variational_beta * kldivergence:  0.12850\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33145\n",
      "kldivergence:   1630.46\n",
      "variational_beta * kldivergence:  0.16305\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29505\n",
      "kldivergence:   1302.61\n",
      "variational_beta * kldivergence:  0.13026\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26244\n",
      "kldivergence:   1186.60\n",
      "variational_beta * kldivergence:  0.11866\n",
      "batch accuracy: 90.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30331\n",
      "kldivergence:   1687.78\n",
      "variational_beta * kldivergence:  0.16878\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33134\n",
      "kldivergence:   1494.62\n",
      "variational_beta * kldivergence:  0.14946\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31087\n",
      "kldivergence:   1414.71\n",
      "variational_beta * kldivergence:  0.14147\n",
      "batch accuracy: 89.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30210\n",
      "kldivergence:   1609.76\n",
      "variational_beta * kldivergence:  0.16098\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28455\n",
      "kldivergence:   1422.25\n",
      "variational_beta * kldivergence:  0.14223\n",
      "batch accuracy: 90.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30474\n",
      "kldivergence:   1424.30\n",
      "variational_beta * kldivergence:  0.14243\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34367\n",
      "kldivergence:   1451.23\n",
      "variational_beta * kldivergence:  0.14512\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29859\n",
      "kldivergence:   1531.03\n",
      "variational_beta * kldivergence:  0.15310\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36693\n",
      "kldivergence:   1552.82\n",
      "variational_beta * kldivergence:  0.15528\n",
      "batch accuracy: 87.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33447\n",
      "kldivergence:   1604.65\n",
      "variational_beta * kldivergence:  0.16046\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36146\n",
      "kldivergence:   1530.62\n",
      "variational_beta * kldivergence:  0.15306\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31856\n",
      "kldivergence:   1410.90\n",
      "variational_beta * kldivergence:  0.14109\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31259\n",
      "kldivergence:   1475.18\n",
      "variational_beta * kldivergence:  0.14752\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32269\n",
      "kldivergence:   1429.89\n",
      "variational_beta * kldivergence:  0.14299\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34449\n",
      "kldivergence:   1693.91\n",
      "variational_beta * kldivergence:  0.16939\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29099\n",
      "kldivergence:   1252.31\n",
      "variational_beta * kldivergence:  0.12523\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33817\n",
      "kldivergence:   1599.77\n",
      "variational_beta * kldivergence:  0.15998\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29008\n",
      "kldivergence:   1434.31\n",
      "variational_beta * kldivergence:  0.14343\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32845\n",
      "kldivergence:   1516.76\n",
      "variational_beta * kldivergence:  0.15168\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30639\n",
      "kldivergence:   1544.55\n",
      "variational_beta * kldivergence:  0.15446\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30115\n",
      "kldivergence:   1397.91\n",
      "variational_beta * kldivergence:  0.13979\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.40159\n",
      "kldivergence:   1744.02\n",
      "variational_beta * kldivergence:  0.17440\n",
      "batch accuracy: 86.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30800\n",
      "kldivergence:   1408.38\n",
      "variational_beta * kldivergence:  0.14084\n",
      "batch accuracy: 89.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29801\n",
      "kldivergence:   1546.96\n",
      "variational_beta * kldivergence:  0.15470\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30783\n",
      "kldivergence:   1591.51\n",
      "variational_beta * kldivergence:  0.15915\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35994\n",
      "kldivergence:   1491.60\n",
      "variational_beta * kldivergence:  0.14916\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30088\n",
      "kldivergence:   1541.56\n",
      "variational_beta * kldivergence:  0.15416\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32625\n",
      "kldivergence:   1756.91\n",
      "variational_beta * kldivergence:  0.17569\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29729\n",
      "kldivergence:   1556.38\n",
      "variational_beta * kldivergence:  0.15564\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34280\n",
      "kldivergence:   1676.56\n",
      "variational_beta * kldivergence:  0.16766\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.27809\n",
      "kldivergence:   1556.09\n",
      "variational_beta * kldivergence:  0.15561\n",
      "batch accuracy: 90.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31256\n",
      "kldivergence:   1348.68\n",
      "variational_beta * kldivergence:  0.13487\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29475\n",
      "kldivergence:   1392.94\n",
      "variational_beta * kldivergence:  0.13929\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36054\n",
      "kldivergence:   1764.41\n",
      "variational_beta * kldivergence:  0.17644\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29318\n",
      "kldivergence:   1475.65\n",
      "variational_beta * kldivergence:  0.14756\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34664\n",
      "kldivergence:   1486.38\n",
      "variational_beta * kldivergence:  0.14864\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26581\n",
      "kldivergence:   1361.50\n",
      "variational_beta * kldivergence:  0.13615\n",
      "batch accuracy: 90.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35863\n",
      "kldivergence:   1739.49\n",
      "variational_beta * kldivergence:  0.17395\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30835\n",
      "kldivergence:   1411.22\n",
      "variational_beta * kldivergence:  0.14112\n",
      "batch accuracy: 89.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34743\n",
      "kldivergence:   1607.86\n",
      "variational_beta * kldivergence:  0.16079\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34649\n",
      "kldivergence:   1422.14\n",
      "variational_beta * kldivergence:  0.14221\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29263\n",
      "kldivergence:   1650.06\n",
      "variational_beta * kldivergence:  0.16501\n",
      "batch accuracy: 89.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.27906\n",
      "kldivergence:   1230.51\n",
      "variational_beta * kldivergence:  0.12305\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.39596\n",
      "kldivergence:   1632.82\n",
      "variational_beta * kldivergence:  0.16328\n",
      "batch accuracy: 86.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30349\n",
      "kldivergence:   1472.93\n",
      "variational_beta * kldivergence:  0.14729\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34069\n",
      "kldivergence:   1603.92\n",
      "variational_beta * kldivergence:  0.16039\n",
      "batch accuracy: 88.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33024\n",
      "kldivergence:   1454.74\n",
      "variational_beta * kldivergence:  0.14547\n",
      "batch accuracy: 88.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30995\n",
      "kldivergence:   1670.80\n",
      "variational_beta * kldivergence:  0.16708\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33148\n",
      "kldivergence:   1446.57\n",
      "variational_beta * kldivergence:  0.14466\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30422\n",
      "kldivergence:   1350.92\n",
      "variational_beta * kldivergence:  0.13509\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30070\n",
      "kldivergence:   1439.11\n",
      "variational_beta * kldivergence:  0.14391\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32294\n",
      "kldivergence:   1531.61\n",
      "variational_beta * kldivergence:  0.15316\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32872\n",
      "kldivergence:   1600.07\n",
      "variational_beta * kldivergence:  0.16001\n",
      "batch accuracy: 88.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32511\n",
      "kldivergence:   1482.42\n",
      "variational_beta * kldivergence:  0.14824\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33198\n",
      "kldivergence:   1480.68\n",
      "variational_beta * kldivergence:  0.14807\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.38562\n",
      "kldivergence:   1597.60\n",
      "variational_beta * kldivergence:  0.15976\n",
      "batch accuracy: 86.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.27521\n",
      "kldivergence:   1467.40\n",
      "variational_beta * kldivergence:  0.14674\n",
      "batch accuracy: 90.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34757\n",
      "kldivergence:   1347.03\n",
      "variational_beta * kldivergence:  0.13470\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.37459\n",
      "kldivergence:   1606.21\n",
      "variational_beta * kldivergence:  0.16062\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31894\n",
      "kldivergence:   1436.33\n",
      "variational_beta * kldivergence:  0.14363\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.25341\n",
      "kldivergence:   1457.88\n",
      "variational_beta * kldivergence:  0.14579\n",
      "batch accuracy: 91.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33552\n",
      "kldivergence:   1433.64\n",
      "variational_beta * kldivergence:  0.14336\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.38348\n",
      "kldivergence:   1475.00\n",
      "variational_beta * kldivergence:  0.14750\n",
      "batch accuracy: 87.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29907\n",
      "kldivergence:   1361.05\n",
      "variational_beta * kldivergence:  0.13611\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.37162\n",
      "kldivergence:   1665.66\n",
      "variational_beta * kldivergence:  0.16657\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30286\n",
      "kldivergence:   1450.07\n",
      "variational_beta * kldivergence:  0.14501\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35436\n",
      "kldivergence:   1494.47\n",
      "variational_beta * kldivergence:  0.14945\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31961\n",
      "kldivergence:   1564.29\n",
      "variational_beta * kldivergence:  0.15643\n",
      "batch accuracy: 88.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36996\n",
      "kldivergence:   1574.24\n",
      "variational_beta * kldivergence:  0.15742\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31803\n",
      "kldivergence:   1597.42\n",
      "variational_beta * kldivergence:  0.15974\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29862\n",
      "kldivergence:   1333.52\n",
      "variational_beta * kldivergence:  0.13335\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35156\n",
      "kldivergence:   1507.11\n",
      "variational_beta * kldivergence:  0.15071\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31447\n",
      "kldivergence:   1593.12\n",
      "variational_beta * kldivergence:  0.15931\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30432\n",
      "kldivergence:   1473.49\n",
      "variational_beta * kldivergence:  0.14735\n",
      "batch accuracy: 89.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35287\n",
      "kldivergence:   1645.55\n",
      "variational_beta * kldivergence:  0.16456\n",
      "batch accuracy: 88.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34717\n",
      "kldivergence:   1385.30\n",
      "variational_beta * kldivergence:  0.13853\n",
      "batch accuracy: 88.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28093\n",
      "kldivergence:   1347.83\n",
      "variational_beta * kldivergence:  0.13478\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26973\n",
      "kldivergence:   1491.60\n",
      "variational_beta * kldivergence:  0.14916\n",
      "batch accuracy: 91.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31704\n",
      "kldivergence:   1512.05\n",
      "variational_beta * kldivergence:  0.15120\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32126\n",
      "kldivergence:   1509.16\n",
      "variational_beta * kldivergence:  0.15092\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31788\n",
      "kldivergence:   1550.65\n",
      "variational_beta * kldivergence:  0.15506\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.27119\n",
      "kldivergence:   1363.38\n",
      "variational_beta * kldivergence:  0.13634\n",
      "batch accuracy: 91.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32228\n",
      "kldivergence:   1437.53\n",
      "variational_beta * kldivergence:  0.14375\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.37706\n",
      "kldivergence:   1547.30\n",
      "variational_beta * kldivergence:  0.15473\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32824\n",
      "kldivergence:   1388.26\n",
      "variational_beta * kldivergence:  0.13883\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36802\n",
      "kldivergence:   1634.23\n",
      "variational_beta * kldivergence:  0.16342\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31771\n",
      "kldivergence:   1291.76\n",
      "variational_beta * kldivergence:  0.12918\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.40088\n",
      "kldivergence:   1595.29\n",
      "variational_beta * kldivergence:  0.15953\n",
      "batch accuracy: 86.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35578\n",
      "kldivergence:   1627.28\n",
      "variational_beta * kldivergence:  0.16273\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34979\n",
      "kldivergence:   1413.15\n",
      "variational_beta * kldivergence:  0.14132\n",
      "batch accuracy: 87.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28263\n",
      "kldivergence:   1356.03\n",
      "variational_beta * kldivergence:  0.13560\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29322\n",
      "kldivergence:   1562.15\n",
      "variational_beta * kldivergence:  0.15622\n",
      "batch accuracy: 89.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35286\n",
      "kldivergence:   1470.02\n",
      "variational_beta * kldivergence:  0.14700\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32621\n",
      "kldivergence:   1320.05\n",
      "variational_beta * kldivergence:  0.13200\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32856\n",
      "kldivergence:   1485.38\n",
      "variational_beta * kldivergence:  0.14854\n",
      "batch accuracy: 88.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.39605\n",
      "kldivergence:   1676.56\n",
      "variational_beta * kldivergence:  0.16766\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33805\n",
      "kldivergence:   1488.57\n",
      "variational_beta * kldivergence:  0.14886\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.39635\n",
      "kldivergence:   1739.06\n",
      "variational_beta * kldivergence:  0.17391\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33246\n",
      "kldivergence:   1551.89\n",
      "variational_beta * kldivergence:  0.15519\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31857\n",
      "kldivergence:   1598.57\n",
      "variational_beta * kldivergence:  0.15986\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30145\n",
      "kldivergence:   1340.58\n",
      "variational_beta * kldivergence:  0.13406\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32987\n",
      "kldivergence:   1591.82\n",
      "variational_beta * kldivergence:  0.15918\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26241\n",
      "kldivergence:   1685.82\n",
      "variational_beta * kldivergence:  0.16858\n",
      "batch accuracy: 91.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34067\n",
      "kldivergence:   1489.74\n",
      "variational_beta * kldivergence:  0.14897\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33339\n",
      "kldivergence:   1433.68\n",
      "variational_beta * kldivergence:  0.14337\n",
      "batch accuracy: 88.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32640\n",
      "kldivergence:   1627.50\n",
      "variational_beta * kldivergence:  0.16275\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30194\n",
      "kldivergence:   1288.51\n",
      "variational_beta * kldivergence:  0.12885\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31162\n",
      "kldivergence:   1454.82\n",
      "variational_beta * kldivergence:  0.14548\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31285\n",
      "kldivergence:   1532.95\n",
      "variational_beta * kldivergence:  0.15329\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32334\n",
      "kldivergence:   1405.85\n",
      "variational_beta * kldivergence:  0.14059\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32697\n",
      "kldivergence:   1461.72\n",
      "variational_beta * kldivergence:  0.14617\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32364\n",
      "kldivergence:   1551.18\n",
      "variational_beta * kldivergence:  0.15512\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31434\n",
      "kldivergence:   1648.26\n",
      "variational_beta * kldivergence:  0.16483\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33011\n",
      "kldivergence:   1550.93\n",
      "variational_beta * kldivergence:  0.15509\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.38218\n",
      "kldivergence:   1443.60\n",
      "variational_beta * kldivergence:  0.14436\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31403\n",
      "kldivergence:   1555.96\n",
      "variational_beta * kldivergence:  0.15560\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36121\n",
      "kldivergence:   1610.01\n",
      "variational_beta * kldivergence:  0.16100\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36067\n",
      "kldivergence:   1752.16\n",
      "variational_beta * kldivergence:  0.17522\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30566\n",
      "kldivergence:   1440.67\n",
      "variational_beta * kldivergence:  0.14407\n",
      "batch accuracy: 89.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.38531\n",
      "kldivergence:   1662.20\n",
      "variational_beta * kldivergence:  0.16622\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32380\n",
      "kldivergence:   1399.96\n",
      "variational_beta * kldivergence:  0.14000\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28638\n",
      "kldivergence:   1381.86\n",
      "variational_beta * kldivergence:  0.13819\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32841\n",
      "kldivergence:   1592.80\n",
      "variational_beta * kldivergence:  0.15928\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33856\n",
      "kldivergence:   1638.56\n",
      "variational_beta * kldivergence:  0.16386\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34594\n",
      "kldivergence:   1520.28\n",
      "variational_beta * kldivergence:  0.15203\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32937\n",
      "kldivergence:   1566.51\n",
      "variational_beta * kldivergence:  0.15665\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32278\n",
      "kldivergence:   1601.08\n",
      "variational_beta * kldivergence:  0.16011\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30711\n",
      "kldivergence:   1397.54\n",
      "variational_beta * kldivergence:  0.13975\n",
      "batch accuracy: 89.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30664\n",
      "kldivergence:   1601.57\n",
      "variational_beta * kldivergence:  0.16016\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32201\n",
      "kldivergence:   1496.29\n",
      "variational_beta * kldivergence:  0.14963\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35154\n",
      "kldivergence:   1657.70\n",
      "variational_beta * kldivergence:  0.16577\n",
      "batch accuracy: 87.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33751\n",
      "kldivergence:   1633.27\n",
      "variational_beta * kldivergence:  0.16333\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28664\n",
      "kldivergence:   1385.30\n",
      "variational_beta * kldivergence:  0.13853\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33106\n",
      "kldivergence:   1386.19\n",
      "variational_beta * kldivergence:  0.13862\n",
      "batch accuracy: 88.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29375\n",
      "kldivergence:   1359.08\n",
      "variational_beta * kldivergence:  0.13591\n",
      "batch accuracy: 90.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33396\n",
      "kldivergence:   1580.76\n",
      "variational_beta * kldivergence:  0.15808\n",
      "batch accuracy: 88.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26921\n",
      "kldivergence:   1300.62\n",
      "variational_beta * kldivergence:  0.13006\n",
      "batch accuracy: 91.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26939\n",
      "kldivergence:   1277.72\n",
      "variational_beta * kldivergence:  0.12777\n",
      "batch accuracy: 91.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30922\n",
      "kldivergence:   1470.32\n",
      "variational_beta * kldivergence:  0.14703\n",
      "batch accuracy: 89.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.37003\n",
      "kldivergence:   1469.25\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 87.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36469\n",
      "kldivergence:   1475.70\n",
      "variational_beta * kldivergence:  0.14757\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29637\n",
      "kldivergence:   1444.51\n",
      "variational_beta * kldivergence:  0.14445\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29300\n",
      "kldivergence:   1461.86\n",
      "variational_beta * kldivergence:  0.14619\n",
      "batch accuracy: 90.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34676\n",
      "kldivergence:   1599.73\n",
      "variational_beta * kldivergence:  0.15997\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30245\n",
      "kldivergence:   1393.06\n",
      "variational_beta * kldivergence:  0.13931\n",
      "batch accuracy: 89.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36677\n",
      "kldivergence:   1481.79\n",
      "variational_beta * kldivergence:  0.14818\n",
      "batch accuracy: 87.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36568\n",
      "kldivergence:   1391.37\n",
      "variational_beta * kldivergence:  0.13914\n",
      "batch accuracy: 88.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35750\n",
      "kldivergence:   1670.01\n",
      "variational_beta * kldivergence:  0.16700\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33465\n",
      "kldivergence:   1574.49\n",
      "variational_beta * kldivergence:  0.15745\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31346\n",
      "kldivergence:   1652.17\n",
      "variational_beta * kldivergence:  0.16522\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35952\n",
      "kldivergence:   1653.15\n",
      "variational_beta * kldivergence:  0.16531\n",
      "batch accuracy: 87.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.38464\n",
      "kldivergence:   1729.25\n",
      "variational_beta * kldivergence:  0.17293\n",
      "batch accuracy: 86.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33841\n",
      "kldivergence:   1533.70\n",
      "variational_beta * kldivergence:  0.15337\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32340\n",
      "kldivergence:   1260.00\n",
      "variational_beta * kldivergence:  0.12600\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36421\n",
      "kldivergence:   1456.18\n",
      "variational_beta * kldivergence:  0.14562\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31686\n",
      "kldivergence:   1363.05\n",
      "variational_beta * kldivergence:  0.13631\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33687\n",
      "kldivergence:   1551.74\n",
      "variational_beta * kldivergence:  0.15517\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29311\n",
      "kldivergence:   1265.33\n",
      "variational_beta * kldivergence:  0.12653\n",
      "batch accuracy: 90.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32190\n",
      "kldivergence:   1430.38\n",
      "variational_beta * kldivergence:  0.14304\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30030\n",
      "kldivergence:   1463.51\n",
      "variational_beta * kldivergence:  0.14635\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30194\n",
      "kldivergence:   1355.61\n",
      "variational_beta * kldivergence:  0.13556\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30946\n",
      "kldivergence:   1442.33\n",
      "variational_beta * kldivergence:  0.14423\n",
      "batch accuracy: 89.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31954\n",
      "kldivergence:   1424.48\n",
      "variational_beta * kldivergence:  0.14245\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31019\n",
      "kldivergence:   1385.63\n",
      "variational_beta * kldivergence:  0.13856\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34595\n",
      "kldivergence:   1512.53\n",
      "variational_beta * kldivergence:  0.15125\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36743\n",
      "kldivergence:   1641.83\n",
      "variational_beta * kldivergence:  0.16418\n",
      "batch accuracy: 87.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30155\n",
      "kldivergence:   1531.18\n",
      "variational_beta * kldivergence:  0.15312\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30033\n",
      "kldivergence:   1496.34\n",
      "variational_beta * kldivergence:  0.14963\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26564\n",
      "kldivergence:   1372.94\n",
      "variational_beta * kldivergence:  0.13729\n",
      "batch accuracy: 91.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33799\n",
      "kldivergence:   1397.99\n",
      "variational_beta * kldivergence:  0.13980\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.37227\n",
      "kldivergence:   1563.56\n",
      "variational_beta * kldivergence:  0.15636\n",
      "batch accuracy: 87.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34303\n",
      "kldivergence:   1467.46\n",
      "variational_beta * kldivergence:  0.14675\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33860\n",
      "kldivergence:   1560.84\n",
      "variational_beta * kldivergence:  0.15608\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36517\n",
      "kldivergence:   1488.91\n",
      "variational_beta * kldivergence:  0.14889\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32048\n",
      "kldivergence:   1437.52\n",
      "variational_beta * kldivergence:  0.14375\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34655\n",
      "kldivergence:   1494.39\n",
      "variational_beta * kldivergence:  0.14944\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33404\n",
      "kldivergence:   1526.18\n",
      "variational_beta * kldivergence:  0.15262\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29132\n",
      "kldivergence:   1564.51\n",
      "variational_beta * kldivergence:  0.15645\n",
      "batch accuracy: 90.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32107\n",
      "kldivergence:   1469.25\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 89.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35611\n",
      "kldivergence:   1545.10\n",
      "variational_beta * kldivergence:  0.15451\n",
      "batch accuracy: 88.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33612\n",
      "kldivergence:   1641.53\n",
      "variational_beta * kldivergence:  0.16415\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36659\n",
      "kldivergence:   1706.15\n",
      "variational_beta * kldivergence:  0.17062\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31453\n",
      "kldivergence:   1480.93\n",
      "variational_beta * kldivergence:  0.14809\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28477\n",
      "kldivergence:   1520.19\n",
      "variational_beta * kldivergence:  0.15202\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32144\n",
      "kldivergence:   1416.86\n",
      "variational_beta * kldivergence:  0.14169\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28512\n",
      "kldivergence:   1404.92\n",
      "variational_beta * kldivergence:  0.14049\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33111\n",
      "kldivergence:   1513.38\n",
      "variational_beta * kldivergence:  0.15134\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.37873\n",
      "kldivergence:   1593.68\n",
      "variational_beta * kldivergence:  0.15937\n",
      "batch accuracy: 86.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32165\n",
      "kldivergence:   1678.60\n",
      "variational_beta * kldivergence:  0.16786\n",
      "batch accuracy: 89.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36359\n",
      "kldivergence:   1743.53\n",
      "variational_beta * kldivergence:  0.17435\n",
      "batch accuracy: 87.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31882\n",
      "kldivergence:   1441.04\n",
      "variational_beta * kldivergence:  0.14410\n",
      "batch accuracy: 89.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30115\n",
      "kldivergence:   1574.25\n",
      "variational_beta * kldivergence:  0.15743\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31934\n",
      "kldivergence:   1474.47\n",
      "variational_beta * kldivergence:  0.14745\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32403\n",
      "kldivergence:   1517.18\n",
      "variational_beta * kldivergence:  0.15172\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30916\n",
      "kldivergence:   1274.05\n",
      "variational_beta * kldivergence:  0.12741\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32728\n",
      "kldivergence:   1441.38\n",
      "variational_beta * kldivergence:  0.14414\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30608\n",
      "kldivergence:   1481.52\n",
      "variational_beta * kldivergence:  0.14815\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.38612\n",
      "kldivergence:   1624.68\n",
      "variational_beta * kldivergence:  0.16247\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29606\n",
      "kldivergence:   1385.56\n",
      "variational_beta * kldivergence:  0.13856\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31808\n",
      "kldivergence:   1542.43\n",
      "variational_beta * kldivergence:  0.15424\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34168\n",
      "kldivergence:   1637.35\n",
      "variational_beta * kldivergence:  0.16373\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32617\n",
      "kldivergence:   1661.93\n",
      "variational_beta * kldivergence:  0.16619\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29615\n",
      "kldivergence:   1697.82\n",
      "variational_beta * kldivergence:  0.16978\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29232\n",
      "kldivergence:   1612.24\n",
      "variational_beta * kldivergence:  0.16122\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35309\n",
      "kldivergence:   1641.56\n",
      "variational_beta * kldivergence:  0.16416\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28782\n",
      "kldivergence:   1303.37\n",
      "variational_beta * kldivergence:  0.13034\n",
      "batch accuracy: 90.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32423\n",
      "kldivergence:   1405.69\n",
      "variational_beta * kldivergence:  0.14057\n",
      "batch accuracy: 88.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30959\n",
      "kldivergence:   1398.15\n",
      "variational_beta * kldivergence:  0.13981\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36030\n",
      "kldivergence:   1469.38\n",
      "variational_beta * kldivergence:  0.14694\n",
      "batch accuracy: 88.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32378\n",
      "kldivergence:   1275.28\n",
      "variational_beta * kldivergence:  0.12753\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31505\n",
      "kldivergence:   1402.62\n",
      "variational_beta * kldivergence:  0.14026\n",
      "batch accuracy: 89.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33404\n",
      "kldivergence:   1455.15\n",
      "variational_beta * kldivergence:  0.14551\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32721\n",
      "kldivergence:   1495.43\n",
      "variational_beta * kldivergence:  0.14954\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29368\n",
      "kldivergence:   1439.63\n",
      "variational_beta * kldivergence:  0.14396\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29354\n",
      "kldivergence:   1542.45\n",
      "variational_beta * kldivergence:  0.15424\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28985\n",
      "kldivergence:   1410.44\n",
      "variational_beta * kldivergence:  0.14104\n",
      "batch accuracy: 90.33\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.37971\n",
      "kldivergence:   1504.83\n",
      "variational_beta * kldivergence:  0.15048\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35762\n",
      "kldivergence:   1447.06\n",
      "variational_beta * kldivergence:  0.14471\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.25650\n",
      "kldivergence:   1484.92\n",
      "variational_beta * kldivergence:  0.14849\n",
      "batch accuracy: 90.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31391\n",
      "kldivergence:   1475.16\n",
      "variational_beta * kldivergence:  0.14752\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31276\n",
      "kldivergence:   1566.31\n",
      "variational_beta * kldivergence:  0.15663\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31659\n",
      "kldivergence:   1419.48\n",
      "variational_beta * kldivergence:  0.14195\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26585\n",
      "kldivergence:   1379.09\n",
      "variational_beta * kldivergence:  0.13791\n",
      "batch accuracy: 91.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29087\n",
      "kldivergence:   1422.66\n",
      "variational_beta * kldivergence:  0.14227\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31369\n",
      "kldivergence:   1379.28\n",
      "variational_beta * kldivergence:  0.13793\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29712\n",
      "kldivergence:   1545.60\n",
      "variational_beta * kldivergence:  0.15456\n",
      "batch accuracy: 89.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32304\n",
      "kldivergence:   1498.33\n",
      "variational_beta * kldivergence:  0.14983\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28645\n",
      "kldivergence:   1505.35\n",
      "variational_beta * kldivergence:  0.15053\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.38928\n",
      "kldivergence:   1557.85\n",
      "variational_beta * kldivergence:  0.15578\n",
      "batch accuracy: 86.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32200\n",
      "kldivergence:   1400.63\n",
      "variational_beta * kldivergence:  0.14006\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28422\n",
      "kldivergence:   1294.10\n",
      "variational_beta * kldivergence:  0.12941\n",
      "batch accuracy: 90.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.24220\n",
      "kldivergence:   1263.76\n",
      "variational_beta * kldivergence:  0.12638\n",
      "batch accuracy: 92.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36279\n",
      "kldivergence:   1481.08\n",
      "variational_beta * kldivergence:  0.14811\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36025\n",
      "kldivergence:   1480.57\n",
      "variational_beta * kldivergence:  0.14806\n",
      "batch accuracy: 87.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35899\n",
      "kldivergence:   1384.08\n",
      "variational_beta * kldivergence:  0.13841\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31092\n",
      "kldivergence:   1499.05\n",
      "variational_beta * kldivergence:  0.14990\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36703\n",
      "kldivergence:   1596.60\n",
      "variational_beta * kldivergence:  0.15966\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33379\n",
      "kldivergence:   1569.23\n",
      "variational_beta * kldivergence:  0.15692\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29667\n",
      "kldivergence:   1386.10\n",
      "variational_beta * kldivergence:  0.13861\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35447\n",
      "kldivergence:   1751.61\n",
      "variational_beta * kldivergence:  0.17516\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35460\n",
      "kldivergence:   1424.81\n",
      "variational_beta * kldivergence:  0.14248\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.27668\n",
      "kldivergence:   1416.27\n",
      "variational_beta * kldivergence:  0.14163\n",
      "batch accuracy: 90.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.25942\n",
      "kldivergence:   1253.51\n",
      "variational_beta * kldivergence:  0.12535\n",
      "batch accuracy: 91.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30336\n",
      "kldivergence:   1348.18\n",
      "variational_beta * kldivergence:  0.13482\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.37474\n",
      "kldivergence:   1838.39\n",
      "variational_beta * kldivergence:  0.18384\n",
      "batch accuracy: 87.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34267\n",
      "kldivergence:   1401.65\n",
      "variational_beta * kldivergence:  0.14017\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30899\n",
      "kldivergence:   1450.21\n",
      "variational_beta * kldivergence:  0.14502\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32214\n",
      "kldivergence:   1353.87\n",
      "variational_beta * kldivergence:  0.13539\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32396\n",
      "kldivergence:   1512.64\n",
      "variational_beta * kldivergence:  0.15126\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33268\n",
      "kldivergence:   1386.53\n",
      "variational_beta * kldivergence:  0.13865\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33616\n",
      "kldivergence:   1546.15\n",
      "variational_beta * kldivergence:  0.15462\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31768\n",
      "kldivergence:   1353.22\n",
      "variational_beta * kldivergence:  0.13532\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31508\n",
      "kldivergence:   1421.45\n",
      "variational_beta * kldivergence:  0.14215\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.26805\n",
      "kldivergence:   1344.21\n",
      "variational_beta * kldivergence:  0.13442\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30945\n",
      "kldivergence:   1641.92\n",
      "variational_beta * kldivergence:  0.16419\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36253\n",
      "kldivergence:   1718.29\n",
      "variational_beta * kldivergence:  0.17183\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36317\n",
      "kldivergence:   1680.59\n",
      "variational_beta * kldivergence:  0.16806\n",
      "batch accuracy: 87.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.37509\n",
      "kldivergence:   1605.17\n",
      "variational_beta * kldivergence:  0.16052\n",
      "batch accuracy: 87.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29060\n",
      "kldivergence:   1392.63\n",
      "variational_beta * kldivergence:  0.13926\n",
      "batch accuracy: 90.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33397\n",
      "kldivergence:   1421.33\n",
      "variational_beta * kldivergence:  0.14213\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33830\n",
      "kldivergence:   1498.70\n",
      "variational_beta * kldivergence:  0.14987\n",
      "batch accuracy: 88.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31907\n",
      "kldivergence:   1467.75\n",
      "variational_beta * kldivergence:  0.14678\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32138\n",
      "kldivergence:   1558.91\n",
      "variational_beta * kldivergence:  0.15589\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.34231\n",
      "kldivergence:   1474.75\n",
      "variational_beta * kldivergence:  0.14747\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.33544\n",
      "kldivergence:   1702.74\n",
      "variational_beta * kldivergence:  0.17027\n",
      "batch accuracy: 88.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32969\n",
      "kldivergence:   1585.24\n",
      "variational_beta * kldivergence:  0.15852\n",
      "batch accuracy: 88.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.35463\n",
      "kldivergence:   1561.05\n",
      "variational_beta * kldivergence:  0.15611\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.29365\n",
      "kldivergence:   1252.59\n",
      "variational_beta * kldivergence:  0.12526\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32962\n",
      "kldivergence:   1447.32\n",
      "variational_beta * kldivergence:  0.14473\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.27526\n",
      "kldivergence:   1362.69\n",
      "variational_beta * kldivergence:  0.13627\n",
      "batch accuracy: 90.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32206\n",
      "kldivergence:   1587.49\n",
      "variational_beta * kldivergence:  0.15875\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.37500\n",
      "kldivergence:   1557.21\n",
      "variational_beta * kldivergence:  0.15572\n",
      "batch accuracy: 87.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32990\n",
      "kldivergence:   1385.05\n",
      "variational_beta * kldivergence:  0.13850\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32346\n",
      "kldivergence:   1351.35\n",
      "variational_beta * kldivergence:  0.13513\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31978\n",
      "kldivergence:   1420.04\n",
      "variational_beta * kldivergence:  0.14200\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31731\n",
      "kldivergence:   1395.61\n",
      "variational_beta * kldivergence:  0.13956\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.31887\n",
      "kldivergence:   1401.95\n",
      "variational_beta * kldivergence:  0.14019\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.30496\n",
      "kldivergence:   1419.81\n",
      "variational_beta * kldivergence:  0.14198\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36869\n",
      "kldivergence:   1569.04\n",
      "variational_beta * kldivergence:  0.15690\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.36864\n",
      "kldivergence:   1542.42\n",
      "variational_beta * kldivergence:  0.15424\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.28957\n",
      "kldivergence:   1493.24\n",
      "variational_beta * kldivergence:  0.14932\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #61\n",
      "reconstruction loss: 0.32666\n",
      "kldivergence:   1546.11\n",
      "variational_beta * kldivergence:  0.15461\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.43244\n",
      "kldivergence:   1319.15\n",
      "variational_beta * kldivergence:  0.13191\n",
      "batch accuracy: 86.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.46552\n",
      "kldivergence:   1429.13\n",
      "variational_beta * kldivergence:  0.14291\n",
      "batch accuracy: 85.61\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.51340\n",
      "kldivergence:   1474.82\n",
      "variational_beta * kldivergence:  0.14748\n",
      "batch accuracy: 83.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.41329\n",
      "kldivergence:   1258.93\n",
      "variational_beta * kldivergence:  0.12589\n",
      "batch accuracy: 87.20\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.49162\n",
      "kldivergence:   1488.43\n",
      "variational_beta * kldivergence:  0.14884\n",
      "batch accuracy: 85.13\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.45464\n",
      "kldivergence:   1465.48\n",
      "variational_beta * kldivergence:  0.14655\n",
      "batch accuracy: 85.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.43275\n",
      "kldivergence:   1309.35\n",
      "variational_beta * kldivergence:  0.13093\n",
      "batch accuracy: 86.26\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.53447\n",
      "kldivergence:   1454.64\n",
      "variational_beta * kldivergence:  0.14546\n",
      "batch accuracy: 83.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.48545\n",
      "kldivergence:   1382.84\n",
      "variational_beta * kldivergence:  0.13828\n",
      "batch accuracy: 85.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.40218\n",
      "kldivergence:   1268.95\n",
      "variational_beta * kldivergence:  0.12689\n",
      "batch accuracy: 87.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.42625\n",
      "kldivergence:   1351.90\n",
      "variational_beta * kldivergence:  0.13519\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.58919\n",
      "kldivergence:   1677.65\n",
      "variational_beta * kldivergence:  0.16776\n",
      "batch accuracy: 81.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.47511\n",
      "kldivergence:   1404.49\n",
      "variational_beta * kldivergence:  0.14045\n",
      "batch accuracy: 84.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.41378\n",
      "kldivergence:   1267.41\n",
      "variational_beta * kldivergence:  0.12674\n",
      "batch accuracy: 87.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.45677\n",
      "kldivergence:   1399.45\n",
      "variational_beta * kldivergence:  0.13994\n",
      "batch accuracy: 86.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.49338\n",
      "kldivergence:   1448.00\n",
      "variational_beta * kldivergence:  0.14480\n",
      "batch accuracy: 84.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.54216\n",
      "kldivergence:   1458.15\n",
      "variational_beta * kldivergence:  0.14582\n",
      "batch accuracy: 83.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.38367\n",
      "kldivergence:   1235.29\n",
      "variational_beta * kldivergence:  0.12353\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.51512\n",
      "kldivergence:   1485.12\n",
      "variational_beta * kldivergence:  0.14851\n",
      "batch accuracy: 84.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.37215\n",
      "kldivergence:   1281.55\n",
      "variational_beta * kldivergence:  0.12815\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.45464\n",
      "kldivergence:   1501.12\n",
      "variational_beta * kldivergence:  0.15011\n",
      "batch accuracy: 85.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.55762\n",
      "kldivergence:   1498.35\n",
      "variational_beta * kldivergence:  0.14983\n",
      "batch accuracy: 83.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.44421\n",
      "kldivergence:   1397.65\n",
      "variational_beta * kldivergence:  0.13976\n",
      "batch accuracy: 86.09\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.48626\n",
      "kldivergence:   1397.19\n",
      "variational_beta * kldivergence:  0.13972\n",
      "batch accuracy: 85.11\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.41042\n",
      "kldivergence:   1320.51\n",
      "variational_beta * kldivergence:  0.13205\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.48839\n",
      "kldivergence:   1444.53\n",
      "variational_beta * kldivergence:  0.14445\n",
      "batch accuracy: 84.73\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.40889\n",
      "kldivergence:   1294.58\n",
      "variational_beta * kldivergence:  0.12946\n",
      "batch accuracy: 87.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.34760\n",
      "kldivergence:   1175.58\n",
      "variational_beta * kldivergence:  0.11756\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.52479\n",
      "kldivergence:   1404.07\n",
      "variational_beta * kldivergence:  0.14041\n",
      "batch accuracy: 84.07\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.51125\n",
      "kldivergence:   1438.55\n",
      "variational_beta * kldivergence:  0.14386\n",
      "batch accuracy: 85.17\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.52467\n",
      "kldivergence:   1417.74\n",
      "variational_beta * kldivergence:  0.14177\n",
      "batch accuracy: 84.38\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.40999\n",
      "kldivergence:   1328.67\n",
      "variational_beta * kldivergence:  0.13287\n",
      "batch accuracy: 87.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.42228\n",
      "kldivergence:   1367.04\n",
      "variational_beta * kldivergence:  0.13670\n",
      "batch accuracy: 86.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.42379\n",
      "kldivergence:   1305.87\n",
      "variational_beta * kldivergence:  0.13059\n",
      "batch accuracy: 86.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.44009\n",
      "kldivergence:   1414.29\n",
      "variational_beta * kldivergence:  0.14143\n",
      "batch accuracy: 86.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.39808\n",
      "kldivergence:   1403.05\n",
      "variational_beta * kldivergence:  0.14030\n",
      "batch accuracy: 87.41\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.38433\n",
      "kldivergence:   1292.42\n",
      "variational_beta * kldivergence:  0.12924\n",
      "batch accuracy: 88.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.37946\n",
      "kldivergence:   1318.77\n",
      "variational_beta * kldivergence:  0.13188\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.38770\n",
      "kldivergence:   1290.57\n",
      "variational_beta * kldivergence:  0.12906\n",
      "batch accuracy: 88.37\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.48590\n",
      "kldivergence:   1465.91\n",
      "variational_beta * kldivergence:  0.14659\n",
      "batch accuracy: 86.04\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.43042\n",
      "kldivergence:   1345.09\n",
      "variational_beta * kldivergence:  0.13451\n",
      "batch accuracy: 86.66\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.42495\n",
      "kldivergence:   1302.48\n",
      "variational_beta * kldivergence:  0.13025\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.37365\n",
      "kldivergence:   1246.59\n",
      "variational_beta * kldivergence:  0.12466\n",
      "batch accuracy: 87.64\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.50894\n",
      "kldivergence:   1469.01\n",
      "variational_beta * kldivergence:  0.14690\n",
      "batch accuracy: 84.15\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.47044\n",
      "kldivergence:   1420.86\n",
      "variational_beta * kldivergence:  0.14209\n",
      "batch accuracy: 85.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.45432\n",
      "kldivergence:   1301.73\n",
      "variational_beta * kldivergence:  0.13017\n",
      "batch accuracy: 85.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.54551\n",
      "kldivergence:   1542.08\n",
      "variational_beta * kldivergence:  0.15421\n",
      "batch accuracy: 83.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.52502\n",
      "kldivergence:   1452.24\n",
      "variational_beta * kldivergence:  0.14522\n",
      "batch accuracy: 84.54\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.49259\n",
      "kldivergence:   1390.96\n",
      "variational_beta * kldivergence:  0.13910\n",
      "batch accuracy: 85.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.37286\n",
      "kldivergence:   1281.42\n",
      "variational_beta * kldivergence:  0.12814\n",
      "batch accuracy: 88.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.48271\n",
      "kldivergence:   1396.41\n",
      "variational_beta * kldivergence:  0.13964\n",
      "batch accuracy: 85.74\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.43899\n",
      "kldivergence:   1289.69\n",
      "variational_beta * kldivergence:  0.12897\n",
      "batch accuracy: 86.83\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.42621\n",
      "kldivergence:   1428.63\n",
      "variational_beta * kldivergence:  0.14286\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.38641\n",
      "kldivergence:   1310.48\n",
      "variational_beta * kldivergence:  0.13105\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.43188\n",
      "kldivergence:   1337.58\n",
      "variational_beta * kldivergence:  0.13376\n",
      "batch accuracy: 86.49\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.39798\n",
      "kldivergence:   1403.77\n",
      "variational_beta * kldivergence:  0.14038\n",
      "batch accuracy: 86.84\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.59715\n",
      "kldivergence:   1510.34\n",
      "variational_beta * kldivergence:  0.15103\n",
      "batch accuracy: 83.00\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.48385\n",
      "kldivergence:   1399.88\n",
      "variational_beta * kldivergence:  0.13999\n",
      "batch accuracy: 85.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.49137\n",
      "kldivergence:   1388.05\n",
      "variational_beta * kldivergence:  0.13881\n",
      "batch accuracy: 84.82\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.49488\n",
      "kldivergence:   1356.61\n",
      "variational_beta * kldivergence:  0.13566\n",
      "batch accuracy: 84.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.41232\n",
      "kldivergence:   1352.66\n",
      "variational_beta * kldivergence:  0.13527\n",
      "batch accuracy: 87.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #61\n",
      "reconstruction loss: 0.36436\n",
      "kldivergence:   1318.45\n",
      "variational_beta * kldivergence:  0.13185\n",
      "batch accuracy: 88.40\n",
      "\n",
      "\n",
      "epoch # 61 : train loss is [175.99712365374972] and validation loss is [0.09931889684240033] \n",
      "Epoch [62 / 150] average reconstruction error: 0.474386\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32007\n",
      "kldivergence:   1690.12\n",
      "variational_beta * kldivergence:  0.16901\n",
      "batch accuracy: 88.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34884\n",
      "kldivergence:   1715.35\n",
      "variational_beta * kldivergence:  0.17153\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.25398\n",
      "kldivergence:   1622.89\n",
      "variational_beta * kldivergence:  0.16229\n",
      "batch accuracy: 91.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.37936\n",
      "kldivergence:   1645.82\n",
      "variational_beta * kldivergence:  0.16458\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.38866\n",
      "kldivergence:   1496.42\n",
      "variational_beta * kldivergence:  0.14964\n",
      "batch accuracy: 87.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31624\n",
      "kldivergence:   1544.98\n",
      "variational_beta * kldivergence:  0.15450\n",
      "batch accuracy: 89.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30645\n",
      "kldivergence:   1417.60\n",
      "variational_beta * kldivergence:  0.14176\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31891\n",
      "kldivergence:   1395.15\n",
      "variational_beta * kldivergence:  0.13952\n",
      "batch accuracy: 89.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.24834\n",
      "kldivergence:   1620.45\n",
      "variational_beta * kldivergence:  0.16204\n",
      "batch accuracy: 91.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30215\n",
      "kldivergence:   1397.29\n",
      "variational_beta * kldivergence:  0.13973\n",
      "batch accuracy: 89.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33702\n",
      "kldivergence:   1514.42\n",
      "variational_beta * kldivergence:  0.15144\n",
      "batch accuracy: 88.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32080\n",
      "kldivergence:   1487.45\n",
      "variational_beta * kldivergence:  0.14874\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36462\n",
      "kldivergence:   1545.36\n",
      "variational_beta * kldivergence:  0.15454\n",
      "batch accuracy: 87.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32793\n",
      "kldivergence:   1383.51\n",
      "variational_beta * kldivergence:  0.13835\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33022\n",
      "kldivergence:   1572.76\n",
      "variational_beta * kldivergence:  0.15728\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29661\n",
      "kldivergence:   1468.34\n",
      "variational_beta * kldivergence:  0.14683\n",
      "batch accuracy: 90.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29014\n",
      "kldivergence:   1400.13\n",
      "variational_beta * kldivergence:  0.14001\n",
      "batch accuracy: 89.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31700\n",
      "kldivergence:   1462.09\n",
      "variational_beta * kldivergence:  0.14621\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32768\n",
      "kldivergence:   1512.61\n",
      "variational_beta * kldivergence:  0.15126\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35697\n",
      "kldivergence:   1449.63\n",
      "variational_beta * kldivergence:  0.14496\n",
      "batch accuracy: 88.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34467\n",
      "kldivergence:   1519.97\n",
      "variational_beta * kldivergence:  0.15200\n",
      "batch accuracy: 88.10\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28399\n",
      "kldivergence:   1451.51\n",
      "variational_beta * kldivergence:  0.14515\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36871\n",
      "kldivergence:   1648.80\n",
      "variational_beta * kldivergence:  0.16488\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33132\n",
      "kldivergence:   1538.40\n",
      "variational_beta * kldivergence:  0.15384\n",
      "batch accuracy: 88.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32795\n",
      "kldivergence:   1594.15\n",
      "variational_beta * kldivergence:  0.15942\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30840\n",
      "kldivergence:   1449.29\n",
      "variational_beta * kldivergence:  0.14493\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32584\n",
      "kldivergence:   1484.30\n",
      "variational_beta * kldivergence:  0.14843\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36396\n",
      "kldivergence:   1432.04\n",
      "variational_beta * kldivergence:  0.14320\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27062\n",
      "kldivergence:   1271.78\n",
      "variational_beta * kldivergence:  0.12718\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31520\n",
      "kldivergence:   1195.46\n",
      "variational_beta * kldivergence:  0.11955\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31238\n",
      "kldivergence:   1419.04\n",
      "variational_beta * kldivergence:  0.14190\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33485\n",
      "kldivergence:   1518.81\n",
      "variational_beta * kldivergence:  0.15188\n",
      "batch accuracy: 88.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36405\n",
      "kldivergence:   1646.84\n",
      "variational_beta * kldivergence:  0.16468\n",
      "batch accuracy: 87.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31713\n",
      "kldivergence:   1596.36\n",
      "variational_beta * kldivergence:  0.15964\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.40856\n",
      "kldivergence:   1823.48\n",
      "variational_beta * kldivergence:  0.18235\n",
      "batch accuracy: 85.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34309\n",
      "kldivergence:   1659.63\n",
      "variational_beta * kldivergence:  0.16596\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32057\n",
      "kldivergence:   1617.96\n",
      "variational_beta * kldivergence:  0.16180\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30280\n",
      "kldivergence:   1562.15\n",
      "variational_beta * kldivergence:  0.15621\n",
      "batch accuracy: 89.80\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35579\n",
      "kldivergence:   1514.73\n",
      "variational_beta * kldivergence:  0.15147\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28516\n",
      "kldivergence:   1566.90\n",
      "variational_beta * kldivergence:  0.15669\n",
      "batch accuracy: 90.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29981\n",
      "kldivergence:   1519.94\n",
      "variational_beta * kldivergence:  0.15199\n",
      "batch accuracy: 89.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36310\n",
      "kldivergence:   1640.72\n",
      "variational_beta * kldivergence:  0.16407\n",
      "batch accuracy: 87.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30934\n",
      "kldivergence:   1415.24\n",
      "variational_beta * kldivergence:  0.14152\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31310\n",
      "kldivergence:   1365.95\n",
      "variational_beta * kldivergence:  0.13660\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31422\n",
      "kldivergence:   1660.15\n",
      "variational_beta * kldivergence:  0.16601\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32080\n",
      "kldivergence:   1363.14\n",
      "variational_beta * kldivergence:  0.13631\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31915\n",
      "kldivergence:   1497.84\n",
      "variational_beta * kldivergence:  0.14978\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28477\n",
      "kldivergence:   1403.37\n",
      "variational_beta * kldivergence:  0.14034\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34430\n",
      "kldivergence:   1699.58\n",
      "variational_beta * kldivergence:  0.16996\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32863\n",
      "kldivergence:   1563.58\n",
      "variational_beta * kldivergence:  0.15636\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.37568\n",
      "kldivergence:   1595.04\n",
      "variational_beta * kldivergence:  0.15950\n",
      "batch accuracy: 87.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27886\n",
      "kldivergence:   1315.98\n",
      "variational_beta * kldivergence:  0.13160\n",
      "batch accuracy: 90.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31760\n",
      "kldivergence:   1404.02\n",
      "variational_beta * kldivergence:  0.14040\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32194\n",
      "kldivergence:   1555.78\n",
      "variational_beta * kldivergence:  0.15558\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27716\n",
      "kldivergence:   1398.09\n",
      "variational_beta * kldivergence:  0.13981\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31655\n",
      "kldivergence:   1489.87\n",
      "variational_beta * kldivergence:  0.14899\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30795\n",
      "kldivergence:   1366.76\n",
      "variational_beta * kldivergence:  0.13668\n",
      "batch accuracy: 89.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30092\n",
      "kldivergence:   1574.49\n",
      "variational_beta * kldivergence:  0.15745\n",
      "batch accuracy: 89.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30040\n",
      "kldivergence:   1416.81\n",
      "variational_beta * kldivergence:  0.14168\n",
      "batch accuracy: 89.64\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32772\n",
      "kldivergence:   1453.02\n",
      "variational_beta * kldivergence:  0.14530\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28862\n",
      "kldivergence:   1310.19\n",
      "variational_beta * kldivergence:  0.13102\n",
      "batch accuracy: 90.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31963\n",
      "kldivergence:   1290.97\n",
      "variational_beta * kldivergence:  0.12910\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27776\n",
      "kldivergence:   1501.20\n",
      "variational_beta * kldivergence:  0.15012\n",
      "batch accuracy: 90.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33786\n",
      "kldivergence:   1337.31\n",
      "variational_beta * kldivergence:  0.13373\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30036\n",
      "kldivergence:   1306.60\n",
      "variational_beta * kldivergence:  0.13066\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29043\n",
      "kldivergence:   1394.74\n",
      "variational_beta * kldivergence:  0.13947\n",
      "batch accuracy: 90.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31576\n",
      "kldivergence:   1357.62\n",
      "variational_beta * kldivergence:  0.13576\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32528\n",
      "kldivergence:   1394.44\n",
      "variational_beta * kldivergence:  0.13944\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30826\n",
      "kldivergence:   1308.93\n",
      "variational_beta * kldivergence:  0.13089\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33591\n",
      "kldivergence:   1374.49\n",
      "variational_beta * kldivergence:  0.13745\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.40294\n",
      "kldivergence:   1584.83\n",
      "variational_beta * kldivergence:  0.15848\n",
      "batch accuracy: 86.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31209\n",
      "kldivergence:   1842.80\n",
      "variational_beta * kldivergence:  0.18428\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.37543\n",
      "kldivergence:   1566.69\n",
      "variational_beta * kldivergence:  0.15667\n",
      "batch accuracy: 87.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.26973\n",
      "kldivergence:   1327.62\n",
      "variational_beta * kldivergence:  0.13276\n",
      "batch accuracy: 90.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31370\n",
      "kldivergence:   1578.16\n",
      "variational_beta * kldivergence:  0.15782\n",
      "batch accuracy: 89.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.38060\n",
      "kldivergence:   1450.76\n",
      "variational_beta * kldivergence:  0.14508\n",
      "batch accuracy: 88.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32888\n",
      "kldivergence:   1528.37\n",
      "variational_beta * kldivergence:  0.15284\n",
      "batch accuracy: 88.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30305\n",
      "kldivergence:   1330.64\n",
      "variational_beta * kldivergence:  0.13306\n",
      "batch accuracy: 90.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32678\n",
      "kldivergence:   1515.25\n",
      "variational_beta * kldivergence:  0.15153\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27743\n",
      "kldivergence:   1279.89\n",
      "variational_beta * kldivergence:  0.12799\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35365\n",
      "kldivergence:   1444.67\n",
      "variational_beta * kldivergence:  0.14447\n",
      "batch accuracy: 87.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32210\n",
      "kldivergence:   1557.29\n",
      "variational_beta * kldivergence:  0.15573\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30629\n",
      "kldivergence:   1440.19\n",
      "variational_beta * kldivergence:  0.14402\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33969\n",
      "kldivergence:   1412.21\n",
      "variational_beta * kldivergence:  0.14122\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31347\n",
      "kldivergence:   1649.56\n",
      "variational_beta * kldivergence:  0.16496\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35034\n",
      "kldivergence:   1652.89\n",
      "variational_beta * kldivergence:  0.16529\n",
      "batch accuracy: 87.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29730\n",
      "kldivergence:   1600.81\n",
      "variational_beta * kldivergence:  0.16008\n",
      "batch accuracy: 89.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29412\n",
      "kldivergence:   1465.34\n",
      "variational_beta * kldivergence:  0.14653\n",
      "batch accuracy: 90.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29629\n",
      "kldivergence:   1511.85\n",
      "variational_beta * kldivergence:  0.15118\n",
      "batch accuracy: 89.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35010\n",
      "kldivergence:   1571.86\n",
      "variational_beta * kldivergence:  0.15719\n",
      "batch accuracy: 88.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33140\n",
      "kldivergence:   1587.56\n",
      "variational_beta * kldivergence:  0.15876\n",
      "batch accuracy: 88.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36059\n",
      "kldivergence:   1574.35\n",
      "variational_beta * kldivergence:  0.15744\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33976\n",
      "kldivergence:   1716.07\n",
      "variational_beta * kldivergence:  0.17161\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27460\n",
      "kldivergence:   1617.80\n",
      "variational_beta * kldivergence:  0.16178\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30000\n",
      "kldivergence:   1396.27\n",
      "variational_beta * kldivergence:  0.13963\n",
      "batch accuracy: 89.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31625\n",
      "kldivergence:   1727.24\n",
      "variational_beta * kldivergence:  0.17272\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31904\n",
      "kldivergence:   1417.39\n",
      "variational_beta * kldivergence:  0.14174\n",
      "batch accuracy: 89.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30175\n",
      "kldivergence:   1615.99\n",
      "variational_beta * kldivergence:  0.16160\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31477\n",
      "kldivergence:   1536.47\n",
      "variational_beta * kldivergence:  0.15365\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28601\n",
      "kldivergence:   1474.22\n",
      "variational_beta * kldivergence:  0.14742\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29044\n",
      "kldivergence:   1263.53\n",
      "variational_beta * kldivergence:  0.12635\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30478\n",
      "kldivergence:   1435.23\n",
      "variational_beta * kldivergence:  0.14352\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34500\n",
      "kldivergence:   1451.71\n",
      "variational_beta * kldivergence:  0.14517\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29065\n",
      "kldivergence:   1615.54\n",
      "variational_beta * kldivergence:  0.16155\n",
      "batch accuracy: 89.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34278\n",
      "kldivergence:   1569.26\n",
      "variational_beta * kldivergence:  0.15693\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33732\n",
      "kldivergence:   1390.34\n",
      "variational_beta * kldivergence:  0.13903\n",
      "batch accuracy: 88.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28892\n",
      "kldivergence:   1410.07\n",
      "variational_beta * kldivergence:  0.14101\n",
      "batch accuracy: 90.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32469\n",
      "kldivergence:   1418.29\n",
      "variational_beta * kldivergence:  0.14183\n",
      "batch accuracy: 88.78\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29191\n",
      "kldivergence:   1746.80\n",
      "variational_beta * kldivergence:  0.17468\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35920\n",
      "kldivergence:   1580.27\n",
      "variational_beta * kldivergence:  0.15803\n",
      "batch accuracy: 87.87\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30533\n",
      "kldivergence:   1481.34\n",
      "variational_beta * kldivergence:  0.14813\n",
      "batch accuracy: 89.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27887\n",
      "kldivergence:   1657.72\n",
      "variational_beta * kldivergence:  0.16577\n",
      "batch accuracy: 90.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28078\n",
      "kldivergence:   1326.57\n",
      "variational_beta * kldivergence:  0.13266\n",
      "batch accuracy: 90.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32255\n",
      "kldivergence:   1365.35\n",
      "variational_beta * kldivergence:  0.13653\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34762\n",
      "kldivergence:   1592.27\n",
      "variational_beta * kldivergence:  0.15923\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30521\n",
      "kldivergence:   1319.82\n",
      "variational_beta * kldivergence:  0.13198\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34268\n",
      "kldivergence:   1449.32\n",
      "variational_beta * kldivergence:  0.14493\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31390\n",
      "kldivergence:   1444.94\n",
      "variational_beta * kldivergence:  0.14449\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30355\n",
      "kldivergence:   1472.39\n",
      "variational_beta * kldivergence:  0.14724\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35676\n",
      "kldivergence:   1591.75\n",
      "variational_beta * kldivergence:  0.15918\n",
      "batch accuracy: 87.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30834\n",
      "kldivergence:   1764.78\n",
      "variational_beta * kldivergence:  0.17648\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29295\n",
      "kldivergence:   1518.83\n",
      "variational_beta * kldivergence:  0.15188\n",
      "batch accuracy: 90.17\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29116\n",
      "kldivergence:   1449.90\n",
      "variational_beta * kldivergence:  0.14499\n",
      "batch accuracy: 89.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29674\n",
      "kldivergence:   1928.17\n",
      "variational_beta * kldivergence:  0.19282\n",
      "batch accuracy: 89.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34829\n",
      "kldivergence:   1477.83\n",
      "variational_beta * kldivergence:  0.14778\n",
      "batch accuracy: 88.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29106\n",
      "kldivergence:   1413.99\n",
      "variational_beta * kldivergence:  0.14140\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34165\n",
      "kldivergence:   1619.81\n",
      "variational_beta * kldivergence:  0.16198\n",
      "batch accuracy: 88.23\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32470\n",
      "kldivergence:   1577.39\n",
      "variational_beta * kldivergence:  0.15774\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28337\n",
      "kldivergence:   1275.25\n",
      "variational_beta * kldivergence:  0.12753\n",
      "batch accuracy: 90.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32918\n",
      "kldivergence:   1367.15\n",
      "variational_beta * kldivergence:  0.13671\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28779\n",
      "kldivergence:   1545.81\n",
      "variational_beta * kldivergence:  0.15458\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35224\n",
      "kldivergence:   1423.42\n",
      "variational_beta * kldivergence:  0.14234\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31904\n",
      "kldivergence:   1616.44\n",
      "variational_beta * kldivergence:  0.16164\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31160\n",
      "kldivergence:   1361.78\n",
      "variational_beta * kldivergence:  0.13618\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31428\n",
      "kldivergence:   1427.01\n",
      "variational_beta * kldivergence:  0.14270\n",
      "batch accuracy: 89.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31632\n",
      "kldivergence:   1404.46\n",
      "variational_beta * kldivergence:  0.14045\n",
      "batch accuracy: 89.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.26923\n",
      "kldivergence:   2083.50\n",
      "variational_beta * kldivergence:  0.20835\n",
      "batch accuracy: 90.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33081\n",
      "kldivergence:   1470.82\n",
      "variational_beta * kldivergence:  0.14708\n",
      "batch accuracy: 88.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32823\n",
      "kldivergence:   1466.16\n",
      "variational_beta * kldivergence:  0.14662\n",
      "batch accuracy: 89.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30504\n",
      "kldivergence:   1383.51\n",
      "variational_beta * kldivergence:  0.13835\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36976\n",
      "kldivergence:   1624.08\n",
      "variational_beta * kldivergence:  0.16241\n",
      "batch accuracy: 87.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34445\n",
      "kldivergence:   1378.50\n",
      "variational_beta * kldivergence:  0.13785\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33707\n",
      "kldivergence:   1364.85\n",
      "variational_beta * kldivergence:  0.13648\n",
      "batch accuracy: 88.67\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32264\n",
      "kldivergence:   1287.36\n",
      "variational_beta * kldivergence:  0.12874\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32443\n",
      "kldivergence:   1447.70\n",
      "variational_beta * kldivergence:  0.14477\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32954\n",
      "kldivergence:   1471.64\n",
      "variational_beta * kldivergence:  0.14716\n",
      "batch accuracy: 88.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36640\n",
      "kldivergence:   1492.25\n",
      "variational_beta * kldivergence:  0.14922\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33319\n",
      "kldivergence:   1462.01\n",
      "variational_beta * kldivergence:  0.14620\n",
      "batch accuracy: 88.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30043\n",
      "kldivergence:   1402.84\n",
      "variational_beta * kldivergence:  0.14028\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35532\n",
      "kldivergence:   1582.13\n",
      "variational_beta * kldivergence:  0.15821\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29387\n",
      "kldivergence:   1493.99\n",
      "variational_beta * kldivergence:  0.14940\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30804\n",
      "kldivergence:   1343.79\n",
      "variational_beta * kldivergence:  0.13438\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31130\n",
      "kldivergence:   1474.43\n",
      "variational_beta * kldivergence:  0.14744\n",
      "batch accuracy: 90.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.38710\n",
      "kldivergence:   1590.00\n",
      "variational_beta * kldivergence:  0.15900\n",
      "batch accuracy: 87.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.38574\n",
      "kldivergence:   1514.03\n",
      "variational_beta * kldivergence:  0.15140\n",
      "batch accuracy: 87.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32623\n",
      "kldivergence:   1774.23\n",
      "variational_beta * kldivergence:  0.17742\n",
      "batch accuracy: 89.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30906\n",
      "kldivergence:   1434.62\n",
      "variational_beta * kldivergence:  0.14346\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28912\n",
      "kldivergence:   1384.47\n",
      "variational_beta * kldivergence:  0.13845\n",
      "batch accuracy: 90.01\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34240\n",
      "kldivergence:   1423.89\n",
      "variational_beta * kldivergence:  0.14239\n",
      "batch accuracy: 88.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31890\n",
      "kldivergence:   1469.93\n",
      "variational_beta * kldivergence:  0.14699\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31854\n",
      "kldivergence:   1508.94\n",
      "variational_beta * kldivergence:  0.15089\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33044\n",
      "kldivergence:   1774.53\n",
      "variational_beta * kldivergence:  0.17745\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31218\n",
      "kldivergence:   1384.29\n",
      "variational_beta * kldivergence:  0.13843\n",
      "batch accuracy: 89.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34652\n",
      "kldivergence:   1868.22\n",
      "variational_beta * kldivergence:  0.18682\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28898\n",
      "kldivergence:   1469.26\n",
      "variational_beta * kldivergence:  0.14693\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36739\n",
      "kldivergence:   1749.50\n",
      "variational_beta * kldivergence:  0.17495\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28504\n",
      "kldivergence:   1376.55\n",
      "variational_beta * kldivergence:  0.13765\n",
      "batch accuracy: 90.45\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32586\n",
      "kldivergence:   1389.29\n",
      "variational_beta * kldivergence:  0.13893\n",
      "batch accuracy: 88.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.38391\n",
      "kldivergence:   1533.11\n",
      "variational_beta * kldivergence:  0.15331\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35869\n",
      "kldivergence:   1512.54\n",
      "variational_beta * kldivergence:  0.15125\n",
      "batch accuracy: 88.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33560\n",
      "kldivergence:   1617.37\n",
      "variational_beta * kldivergence:  0.16174\n",
      "batch accuracy: 88.44\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.38096\n",
      "kldivergence:   1452.64\n",
      "variational_beta * kldivergence:  0.14526\n",
      "batch accuracy: 86.92\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32723\n",
      "kldivergence:   1491.90\n",
      "variational_beta * kldivergence:  0.14919\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31513\n",
      "kldivergence:   1583.04\n",
      "variational_beta * kldivergence:  0.15830\n",
      "batch accuracy: 88.93\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31617\n",
      "kldivergence:   1469.13\n",
      "variational_beta * kldivergence:  0.14691\n",
      "batch accuracy: 89.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.25697\n",
      "kldivergence:   1314.16\n",
      "variational_beta * kldivergence:  0.13142\n",
      "batch accuracy: 91.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30465\n",
      "kldivergence:   1474.03\n",
      "variational_beta * kldivergence:  0.14740\n",
      "batch accuracy: 89.47\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32091\n",
      "kldivergence:   1393.81\n",
      "variational_beta * kldivergence:  0.13938\n",
      "batch accuracy: 89.22\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30702\n",
      "kldivergence:   1595.45\n",
      "variational_beta * kldivergence:  0.15955\n",
      "batch accuracy: 89.48\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31927\n",
      "kldivergence:   1461.63\n",
      "variational_beta * kldivergence:  0.14616\n",
      "batch accuracy: 89.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32652\n",
      "kldivergence:   1498.90\n",
      "variational_beta * kldivergence:  0.14989\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32434\n",
      "kldivergence:   1598.87\n",
      "variational_beta * kldivergence:  0.15989\n",
      "batch accuracy: 89.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34140\n",
      "kldivergence:   1465.64\n",
      "variational_beta * kldivergence:  0.14656\n",
      "batch accuracy: 88.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34769\n",
      "kldivergence:   1572.45\n",
      "variational_beta * kldivergence:  0.15724\n",
      "batch accuracy: 88.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36448\n",
      "kldivergence:   1502.80\n",
      "variational_beta * kldivergence:  0.15028\n",
      "batch accuracy: 87.73\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32228\n",
      "kldivergence:   1465.57\n",
      "variational_beta * kldivergence:  0.14656\n",
      "batch accuracy: 89.05\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34428\n",
      "kldivergence:   1516.51\n",
      "variational_beta * kldivergence:  0.15165\n",
      "batch accuracy: 88.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30949\n",
      "kldivergence:   1348.87\n",
      "variational_beta * kldivergence:  0.13489\n",
      "batch accuracy: 89.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31084\n",
      "kldivergence:   1453.35\n",
      "variational_beta * kldivergence:  0.14533\n",
      "batch accuracy: 89.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31406\n",
      "kldivergence:   1530.80\n",
      "variational_beta * kldivergence:  0.15308\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31187\n",
      "kldivergence:   1557.03\n",
      "variational_beta * kldivergence:  0.15570\n",
      "batch accuracy: 89.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31659\n",
      "kldivergence:   1419.68\n",
      "variational_beta * kldivergence:  0.14197\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28166\n",
      "kldivergence:   1546.96\n",
      "variational_beta * kldivergence:  0.15470\n",
      "batch accuracy: 90.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30652\n",
      "kldivergence:   1598.70\n",
      "variational_beta * kldivergence:  0.15987\n",
      "batch accuracy: 89.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27934\n",
      "kldivergence:   1370.86\n",
      "variational_beta * kldivergence:  0.13709\n",
      "batch accuracy: 90.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27992\n",
      "kldivergence:   1502.30\n",
      "variational_beta * kldivergence:  0.15023\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31268\n",
      "kldivergence:   1360.36\n",
      "variational_beta * kldivergence:  0.13604\n",
      "batch accuracy: 89.36\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.26889\n",
      "kldivergence:   1351.06\n",
      "variational_beta * kldivergence:  0.13511\n",
      "batch accuracy: 90.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34119\n",
      "kldivergence:   1412.48\n",
      "variational_beta * kldivergence:  0.14125\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31584\n",
      "kldivergence:   1479.70\n",
      "variational_beta * kldivergence:  0.14797\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31892\n",
      "kldivergence:   1456.72\n",
      "variational_beta * kldivergence:  0.14567\n",
      "batch accuracy: 89.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.37327\n",
      "kldivergence:   1675.59\n",
      "variational_beta * kldivergence:  0.16756\n",
      "batch accuracy: 87.72\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36744\n",
      "kldivergence:   1451.76\n",
      "variational_beta * kldivergence:  0.14518\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30434\n",
      "kldivergence:   1600.29\n",
      "variational_beta * kldivergence:  0.16003\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29602\n",
      "kldivergence:   1454.21\n",
      "variational_beta * kldivergence:  0.14542\n",
      "batch accuracy: 89.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32049\n",
      "kldivergence:   1448.84\n",
      "variational_beta * kldivergence:  0.14488\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36591\n",
      "kldivergence:   1461.19\n",
      "variational_beta * kldivergence:  0.14612\n",
      "batch accuracy: 87.57\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31645\n",
      "kldivergence:   1312.24\n",
      "variational_beta * kldivergence:  0.13122\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29570\n",
      "kldivergence:   1322.21\n",
      "variational_beta * kldivergence:  0.13222\n",
      "batch accuracy: 90.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36444\n",
      "kldivergence:   1621.18\n",
      "variational_beta * kldivergence:  0.16212\n",
      "batch accuracy: 87.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27714\n",
      "kldivergence:   1282.07\n",
      "variational_beta * kldivergence:  0.12821\n",
      "batch accuracy: 90.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32544\n",
      "kldivergence:   1740.20\n",
      "variational_beta * kldivergence:  0.17402\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33971\n",
      "kldivergence:   1508.05\n",
      "variational_beta * kldivergence:  0.15080\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.39498\n",
      "kldivergence:   1672.64\n",
      "variational_beta * kldivergence:  0.16726\n",
      "batch accuracy: 86.63\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31036\n",
      "kldivergence:   1502.09\n",
      "variational_beta * kldivergence:  0.15021\n",
      "batch accuracy: 89.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30665\n",
      "kldivergence:   1515.12\n",
      "variational_beta * kldivergence:  0.15151\n",
      "batch accuracy: 89.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36303\n",
      "kldivergence:   1478.74\n",
      "variational_beta * kldivergence:  0.14787\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.38428\n",
      "kldivergence:   1584.57\n",
      "variational_beta * kldivergence:  0.15846\n",
      "batch accuracy: 86.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34395\n",
      "kldivergence:   1390.10\n",
      "variational_beta * kldivergence:  0.13901\n",
      "batch accuracy: 88.88\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32957\n",
      "kldivergence:   1535.87\n",
      "variational_beta * kldivergence:  0.15359\n",
      "batch accuracy: 89.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30404\n",
      "kldivergence:   1397.35\n",
      "variational_beta * kldivergence:  0.13974\n",
      "batch accuracy: 89.74\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.37057\n",
      "kldivergence:   1439.10\n",
      "variational_beta * kldivergence:  0.14391\n",
      "batch accuracy: 87.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35673\n",
      "kldivergence:   1673.28\n",
      "variational_beta * kldivergence:  0.16733\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34280\n",
      "kldivergence:   1640.03\n",
      "variational_beta * kldivergence:  0.16400\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29137\n",
      "kldivergence:   1434.91\n",
      "variational_beta * kldivergence:  0.14349\n",
      "batch accuracy: 90.27\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36088\n",
      "kldivergence:   1575.67\n",
      "variational_beta * kldivergence:  0.15757\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32092\n",
      "kldivergence:   1471.33\n",
      "variational_beta * kldivergence:  0.14713\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34778\n",
      "kldivergence:   1522.34\n",
      "variational_beta * kldivergence:  0.15223\n",
      "batch accuracy: 88.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33251\n",
      "kldivergence:   1445.99\n",
      "variational_beta * kldivergence:  0.14460\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33932\n",
      "kldivergence:   1463.83\n",
      "variational_beta * kldivergence:  0.14638\n",
      "batch accuracy: 88.32\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30146\n",
      "kldivergence:   1607.66\n",
      "variational_beta * kldivergence:  0.16077\n",
      "batch accuracy: 89.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32426\n",
      "kldivergence:   1631.33\n",
      "variational_beta * kldivergence:  0.16313\n",
      "batch accuracy: 88.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32397\n",
      "kldivergence:   1590.40\n",
      "variational_beta * kldivergence:  0.15904\n",
      "batch accuracy: 89.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.26409\n",
      "kldivergence:   1429.81\n",
      "variational_beta * kldivergence:  0.14298\n",
      "batch accuracy: 91.20\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30577\n",
      "kldivergence:   1479.13\n",
      "variational_beta * kldivergence:  0.14791\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.37432\n",
      "kldivergence:   1437.26\n",
      "variational_beta * kldivergence:  0.14373\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34675\n",
      "kldivergence:   1490.49\n",
      "variational_beta * kldivergence:  0.14905\n",
      "batch accuracy: 88.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32002\n",
      "kldivergence:   1402.38\n",
      "variational_beta * kldivergence:  0.14024\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31703\n",
      "kldivergence:   1646.01\n",
      "variational_beta * kldivergence:  0.16460\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.38872\n",
      "kldivergence:   1632.89\n",
      "variational_beta * kldivergence:  0.16329\n",
      "batch accuracy: 86.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29029\n",
      "kldivergence:   1469.87\n",
      "variational_beta * kldivergence:  0.14699\n",
      "batch accuracy: 90.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32698\n",
      "kldivergence:   1661.50\n",
      "variational_beta * kldivergence:  0.16615\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31384\n",
      "kldivergence:   1431.49\n",
      "variational_beta * kldivergence:  0.14315\n",
      "batch accuracy: 89.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36020\n",
      "kldivergence:   1543.43\n",
      "variational_beta * kldivergence:  0.15434\n",
      "batch accuracy: 87.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31829\n",
      "kldivergence:   1459.58\n",
      "variational_beta * kldivergence:  0.14596\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31443\n",
      "kldivergence:   1434.01\n",
      "variational_beta * kldivergence:  0.14340\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35857\n",
      "kldivergence:   1551.98\n",
      "variational_beta * kldivergence:  0.15520\n",
      "batch accuracy: 88.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.38908\n",
      "kldivergence:   1495.06\n",
      "variational_beta * kldivergence:  0.14951\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35619\n",
      "kldivergence:   1541.61\n",
      "variational_beta * kldivergence:  0.15416\n",
      "batch accuracy: 88.41\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33989\n",
      "kldivergence:   1465.85\n",
      "variational_beta * kldivergence:  0.14659\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29184\n",
      "kldivergence:   1345.54\n",
      "variational_beta * kldivergence:  0.13455\n",
      "batch accuracy: 90.55\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36774\n",
      "kldivergence:   1810.85\n",
      "variational_beta * kldivergence:  0.18108\n",
      "batch accuracy: 87.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28808\n",
      "kldivergence:   1469.11\n",
      "variational_beta * kldivergence:  0.14691\n",
      "batch accuracy: 90.40\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32572\n",
      "kldivergence:   1603.64\n",
      "variational_beta * kldivergence:  0.16036\n",
      "batch accuracy: 89.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34252\n",
      "kldivergence:   1478.97\n",
      "variational_beta * kldivergence:  0.14790\n",
      "batch accuracy: 88.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30333\n",
      "kldivergence:   1385.32\n",
      "variational_beta * kldivergence:  0.13853\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31705\n",
      "kldivergence:   1454.15\n",
      "variational_beta * kldivergence:  0.14541\n",
      "batch accuracy: 89.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.25591\n",
      "kldivergence:   1615.69\n",
      "variational_beta * kldivergence:  0.16157\n",
      "batch accuracy: 91.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36637\n",
      "kldivergence:   1688.59\n",
      "variational_beta * kldivergence:  0.16886\n",
      "batch accuracy: 87.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27487\n",
      "kldivergence:   1485.13\n",
      "variational_beta * kldivergence:  0.14851\n",
      "batch accuracy: 90.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27446\n",
      "kldivergence:   1369.83\n",
      "variational_beta * kldivergence:  0.13698\n",
      "batch accuracy: 90.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29027\n",
      "kldivergence:   1327.47\n",
      "variational_beta * kldivergence:  0.13275\n",
      "batch accuracy: 90.53\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.26172\n",
      "kldivergence:   1550.63\n",
      "variational_beta * kldivergence:  0.15506\n",
      "batch accuracy: 90.97\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31227\n",
      "kldivergence:   1591.05\n",
      "variational_beta * kldivergence:  0.15910\n",
      "batch accuracy: 89.69\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29765\n",
      "kldivergence:   1423.69\n",
      "variational_beta * kldivergence:  0.14237\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32416\n",
      "kldivergence:   1512.86\n",
      "variational_beta * kldivergence:  0.15129\n",
      "batch accuracy: 88.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36389\n",
      "kldivergence:   1505.80\n",
      "variational_beta * kldivergence:  0.15058\n",
      "batch accuracy: 87.91\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32849\n",
      "kldivergence:   1500.17\n",
      "variational_beta * kldivergence:  0.15002\n",
      "batch accuracy: 88.82\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.24134\n",
      "kldivergence:   1298.44\n",
      "variational_beta * kldivergence:  0.12984\n",
      "batch accuracy: 91.71\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30037\n",
      "kldivergence:   1388.00\n",
      "variational_beta * kldivergence:  0.13880\n",
      "batch accuracy: 90.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36280\n",
      "kldivergence:   1609.54\n",
      "variational_beta * kldivergence:  0.16095\n",
      "batch accuracy: 87.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33537\n",
      "kldivergence:   1453.58\n",
      "variational_beta * kldivergence:  0.14536\n",
      "batch accuracy: 88.54\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32668\n",
      "kldivergence:   1478.87\n",
      "variational_beta * kldivergence:  0.14789\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29470\n",
      "kldivergence:   1585.76\n",
      "variational_beta * kldivergence:  0.15858\n",
      "batch accuracy: 90.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30397\n",
      "kldivergence:   1663.17\n",
      "variational_beta * kldivergence:  0.16632\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33029\n",
      "kldivergence:   1378.08\n",
      "variational_beta * kldivergence:  0.13781\n",
      "batch accuracy: 88.52\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28016\n",
      "kldivergence:   1290.23\n",
      "variational_beta * kldivergence:  0.12902\n",
      "batch accuracy: 90.39\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27192\n",
      "kldivergence:   1411.15\n",
      "variational_beta * kldivergence:  0.14111\n",
      "batch accuracy: 90.59\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31873\n",
      "kldivergence:   1509.35\n",
      "variational_beta * kldivergence:  0.15094\n",
      "batch accuracy: 89.35\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30702\n",
      "kldivergence:   1502.70\n",
      "variational_beta * kldivergence:  0.15027\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33220\n",
      "kldivergence:   1403.30\n",
      "variational_beta * kldivergence:  0.14033\n",
      "batch accuracy: 88.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31188\n",
      "kldivergence:   1642.84\n",
      "variational_beta * kldivergence:  0.16428\n",
      "batch accuracy: 89.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.26621\n",
      "kldivergence:   1335.48\n",
      "variational_beta * kldivergence:  0.13355\n",
      "batch accuracy: 90.85\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29699\n",
      "kldivergence:   1396.59\n",
      "variational_beta * kldivergence:  0.13966\n",
      "batch accuracy: 90.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31263\n",
      "kldivergence:   1484.58\n",
      "variational_beta * kldivergence:  0.14846\n",
      "batch accuracy: 89.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35878\n",
      "kldivergence:   1606.91\n",
      "variational_beta * kldivergence:  0.16069\n",
      "batch accuracy: 88.16\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31892\n",
      "kldivergence:   1530.79\n",
      "variational_beta * kldivergence:  0.15308\n",
      "batch accuracy: 89.42\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30335\n",
      "kldivergence:   1490.83\n",
      "variational_beta * kldivergence:  0.14908\n",
      "batch accuracy: 89.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32293\n",
      "kldivergence:   1441.47\n",
      "variational_beta * kldivergence:  0.14415\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32678\n",
      "kldivergence:   1569.62\n",
      "variational_beta * kldivergence:  0.15696\n",
      "batch accuracy: 89.04\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32519\n",
      "kldivergence:   1456.22\n",
      "variational_beta * kldivergence:  0.14562\n",
      "batch accuracy: 89.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33367\n",
      "kldivergence:   1459.03\n",
      "variational_beta * kldivergence:  0.14590\n",
      "batch accuracy: 88.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35138\n",
      "kldivergence:   1493.09\n",
      "variational_beta * kldivergence:  0.14931\n",
      "batch accuracy: 87.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33068\n",
      "kldivergence:   1358.11\n",
      "variational_beta * kldivergence:  0.13581\n",
      "batch accuracy: 88.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28225\n",
      "kldivergence:   1271.73\n",
      "variational_beta * kldivergence:  0.12717\n",
      "batch accuracy: 90.50\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28601\n",
      "kldivergence:   1483.08\n",
      "variational_beta * kldivergence:  0.14831\n",
      "batch accuracy: 90.30\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.40836\n",
      "kldivergence:   1478.58\n",
      "variational_beta * kldivergence:  0.14786\n",
      "batch accuracy: 86.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32231\n",
      "kldivergence:   1583.36\n",
      "variational_beta * kldivergence:  0.15834\n",
      "batch accuracy: 88.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33538\n",
      "kldivergence:   1506.68\n",
      "variational_beta * kldivergence:  0.15067\n",
      "batch accuracy: 88.66\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32441\n",
      "kldivergence:   1336.07\n",
      "variational_beta * kldivergence:  0.13361\n",
      "batch accuracy: 89.38\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34762\n",
      "kldivergence:   1572.03\n",
      "variational_beta * kldivergence:  0.15720\n",
      "batch accuracy: 88.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34946\n",
      "kldivergence:   1441.17\n",
      "variational_beta * kldivergence:  0.14412\n",
      "batch accuracy: 88.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.39001\n",
      "kldivergence:   1630.85\n",
      "variational_beta * kldivergence:  0.16308\n",
      "batch accuracy: 87.26\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32428\n",
      "kldivergence:   1461.72\n",
      "variational_beta * kldivergence:  0.14617\n",
      "batch accuracy: 89.25\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29843\n",
      "kldivergence:   1558.84\n",
      "variational_beta * kldivergence:  0.15588\n",
      "batch accuracy: 89.83\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34966\n",
      "kldivergence:   1376.05\n",
      "variational_beta * kldivergence:  0.13760\n",
      "batch accuracy: 88.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34638\n",
      "kldivergence:   1491.06\n",
      "variational_beta * kldivergence:  0.14911\n",
      "batch accuracy: 88.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35364\n",
      "kldivergence:   1495.90\n",
      "variational_beta * kldivergence:  0.14959\n",
      "batch accuracy: 88.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36602\n",
      "kldivergence:   1580.03\n",
      "variational_beta * kldivergence:  0.15800\n",
      "batch accuracy: 87.28\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32591\n",
      "kldivergence:   1485.98\n",
      "variational_beta * kldivergence:  0.14860\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27515\n",
      "kldivergence:   1468.99\n",
      "variational_beta * kldivergence:  0.14690\n",
      "batch accuracy: 90.46\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35547\n",
      "kldivergence:   1643.61\n",
      "variational_beta * kldivergence:  0.16436\n",
      "batch accuracy: 88.08\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36661\n",
      "kldivergence:   1799.97\n",
      "variational_beta * kldivergence:  0.18000\n",
      "batch accuracy: 88.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30827\n",
      "kldivergence:   1639.70\n",
      "variational_beta * kldivergence:  0.16397\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31550\n",
      "kldivergence:   1540.53\n",
      "variational_beta * kldivergence:  0.15405\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33402\n",
      "kldivergence:   1463.71\n",
      "variational_beta * kldivergence:  0.14637\n",
      "batch accuracy: 88.79\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30627\n",
      "kldivergence:   1536.92\n",
      "variational_beta * kldivergence:  0.15369\n",
      "batch accuracy: 90.07\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30377\n",
      "kldivergence:   1465.33\n",
      "variational_beta * kldivergence:  0.14653\n",
      "batch accuracy: 89.29\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30580\n",
      "kldivergence:   1608.66\n",
      "variational_beta * kldivergence:  0.16087\n",
      "batch accuracy: 89.11\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31751\n",
      "kldivergence:   1493.65\n",
      "variational_beta * kldivergence:  0.14936\n",
      "batch accuracy: 89.03\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36102\n",
      "kldivergence:   1518.15\n",
      "variational_beta * kldivergence:  0.15181\n",
      "batch accuracy: 87.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32177\n",
      "kldivergence:   1395.80\n",
      "variational_beta * kldivergence:  0.13958\n",
      "batch accuracy: 89.18\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32495\n",
      "kldivergence:   1409.26\n",
      "variational_beta * kldivergence:  0.14093\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28008\n",
      "kldivergence:   1610.92\n",
      "variational_beta * kldivergence:  0.16109\n",
      "batch accuracy: 90.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31787\n",
      "kldivergence:   1502.18\n",
      "variational_beta * kldivergence:  0.15022\n",
      "batch accuracy: 89.37\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33680\n",
      "kldivergence:   1455.59\n",
      "variational_beta * kldivergence:  0.14556\n",
      "batch accuracy: 88.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32230\n",
      "kldivergence:   1666.52\n",
      "variational_beta * kldivergence:  0.16665\n",
      "batch accuracy: 88.76\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31055\n",
      "kldivergence:   1475.27\n",
      "variational_beta * kldivergence:  0.14753\n",
      "batch accuracy: 89.81\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27817\n",
      "kldivergence:   1260.87\n",
      "variational_beta * kldivergence:  0.12609\n",
      "batch accuracy: 90.68\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.27242\n",
      "kldivergence:   1287.28\n",
      "variational_beta * kldivergence:  0.12873\n",
      "batch accuracy: 91.02\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29517\n",
      "kldivergence:   1576.78\n",
      "variational_beta * kldivergence:  0.15768\n",
      "batch accuracy: 89.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33192\n",
      "kldivergence:   1511.25\n",
      "variational_beta * kldivergence:  0.15112\n",
      "batch accuracy: 88.77\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32905\n",
      "kldivergence:   1421.21\n",
      "variational_beta * kldivergence:  0.14212\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29599\n",
      "kldivergence:   1257.39\n",
      "variational_beta * kldivergence:  0.12574\n",
      "batch accuracy: 89.95\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34651\n",
      "kldivergence:   1665.86\n",
      "variational_beta * kldivergence:  0.16659\n",
      "batch accuracy: 88.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33291\n",
      "kldivergence:   1565.07\n",
      "variational_beta * kldivergence:  0.15651\n",
      "batch accuracy: 88.90\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29185\n",
      "kldivergence:   1410.27\n",
      "variational_beta * kldivergence:  0.14103\n",
      "batch accuracy: 90.09\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32221\n",
      "kldivergence:   1570.17\n",
      "variational_beta * kldivergence:  0.15702\n",
      "batch accuracy: 89.06\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31281\n",
      "kldivergence:   1444.91\n",
      "variational_beta * kldivergence:  0.14449\n",
      "batch accuracy: 89.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32872\n",
      "kldivergence:   1563.71\n",
      "variational_beta * kldivergence:  0.15637\n",
      "batch accuracy: 88.75\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36129\n",
      "kldivergence:   1466.00\n",
      "variational_beta * kldivergence:  0.14660\n",
      "batch accuracy: 88.15\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29724\n",
      "kldivergence:   1406.47\n",
      "variational_beta * kldivergence:  0.14065\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31455\n",
      "kldivergence:   1401.57\n",
      "variational_beta * kldivergence:  0.14016\n",
      "batch accuracy: 89.49\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33468\n",
      "kldivergence:   1529.50\n",
      "variational_beta * kldivergence:  0.15295\n",
      "batch accuracy: 88.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.24893\n",
      "kldivergence:   1382.02\n",
      "variational_beta * kldivergence:  0.13820\n",
      "batch accuracy: 91.66\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.37826\n",
      "kldivergence:   1456.12\n",
      "variational_beta * kldivergence:  0.14561\n",
      "batch accuracy: 87.70\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30146\n",
      "kldivergence:   1342.07\n",
      "variational_beta * kldivergence:  0.13421\n",
      "batch accuracy: 90.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28203\n",
      "kldivergence:   1342.44\n",
      "variational_beta * kldivergence:  0.13424\n",
      "batch accuracy: 90.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30159\n",
      "kldivergence:   1375.29\n",
      "variational_beta * kldivergence:  0.13753\n",
      "batch accuracy: 90.14\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.36041\n",
      "kldivergence:   1718.79\n",
      "variational_beta * kldivergence:  0.17188\n",
      "batch accuracy: 87.58\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31580\n",
      "kldivergence:   1363.07\n",
      "variational_beta * kldivergence:  0.13631\n",
      "batch accuracy: 89.61\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35036\n",
      "kldivergence:   1658.61\n",
      "variational_beta * kldivergence:  0.16586\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.29880\n",
      "kldivergence:   1554.97\n",
      "variational_beta * kldivergence:  0.15550\n",
      "batch accuracy: 89.86\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31989\n",
      "kldivergence:   1463.42\n",
      "variational_beta * kldivergence:  0.14634\n",
      "batch accuracy: 89.34\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35524\n",
      "kldivergence:   1511.38\n",
      "variational_beta * kldivergence:  0.15114\n",
      "batch accuracy: 87.98\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33940\n",
      "kldivergence:   1542.67\n",
      "variational_beta * kldivergence:  0.15427\n",
      "batch accuracy: 88.19\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35768\n",
      "kldivergence:   1454.31\n",
      "variational_beta * kldivergence:  0.14543\n",
      "batch accuracy: 88.21\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34783\n",
      "kldivergence:   1512.74\n",
      "variational_beta * kldivergence:  0.15127\n",
      "batch accuracy: 88.47\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32191\n",
      "kldivergence:   1457.47\n",
      "variational_beta * kldivergence:  0.14575\n",
      "batch accuracy: 89.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30568\n",
      "kldivergence:   1435.63\n",
      "variational_beta * kldivergence:  0.14356\n",
      "batch accuracy: 89.56\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.32013\n",
      "kldivergence:   1457.38\n",
      "variational_beta * kldivergence:  0.14574\n",
      "batch accuracy: 88.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.38945\n",
      "kldivergence:   1771.56\n",
      "variational_beta * kldivergence:  0.17716\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.35948\n",
      "kldivergence:   1627.33\n",
      "variational_beta * kldivergence:  0.16273\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.26428\n",
      "kldivergence:   1554.93\n",
      "variational_beta * kldivergence:  0.15549\n",
      "batch accuracy: 90.99\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.34222\n",
      "kldivergence:   1493.15\n",
      "variational_beta * kldivergence:  0.14932\n",
      "batch accuracy: 88.13\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.28837\n",
      "kldivergence:   1304.47\n",
      "variational_beta * kldivergence:  0.13045\n",
      "batch accuracy: 90.43\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31524\n",
      "kldivergence:   1605.51\n",
      "variational_beta * kldivergence:  0.16055\n",
      "batch accuracy: 89.00\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.33398\n",
      "kldivergence:   1511.65\n",
      "variational_beta * kldivergence:  0.15117\n",
      "batch accuracy: 88.60\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.30136\n",
      "kldivergence:   1285.65\n",
      "variational_beta * kldivergence:  0.12856\n",
      "batch accuracy: 89.84\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.37230\n",
      "kldivergence:   1451.95\n",
      "variational_beta * kldivergence:  0.14520\n",
      "batch accuracy: 87.62\n",
      "\n",
      "\n",
      "train\n",
      "epoch #62\n",
      "reconstruction loss: 0.31545\n",
      "kldivergence:   1454.28\n",
      "variational_beta * kldivergence:  0.14543\n",
      "batch accuracy: 89.24\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.46148\n",
      "kldivergence:   1392.09\n",
      "variational_beta * kldivergence:  0.13921\n",
      "batch accuracy: 85.36\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.41756\n",
      "kldivergence:   1309.91\n",
      "variational_beta * kldivergence:  0.13099\n",
      "batch accuracy: 87.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.41428\n",
      "kldivergence:   1276.04\n",
      "variational_beta * kldivergence:  0.12760\n",
      "batch accuracy: 87.42\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.43332\n",
      "kldivergence:   1341.98\n",
      "variational_beta * kldivergence:  0.13420\n",
      "batch accuracy: 86.19\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.48340\n",
      "kldivergence:   1362.47\n",
      "variational_beta * kldivergence:  0.13625\n",
      "batch accuracy: 84.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.39135\n",
      "kldivergence:   1216.49\n",
      "variational_beta * kldivergence:  0.12165\n",
      "batch accuracy: 87.51\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.39692\n",
      "kldivergence:   1274.66\n",
      "variational_beta * kldivergence:  0.12747\n",
      "batch accuracy: 87.52\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.45153\n",
      "kldivergence:   1329.53\n",
      "variational_beta * kldivergence:  0.13295\n",
      "batch accuracy: 86.29\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.47636\n",
      "kldivergence:   1391.14\n",
      "variational_beta * kldivergence:  0.13911\n",
      "batch accuracy: 85.94\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.34385\n",
      "kldivergence:   1170.38\n",
      "variational_beta * kldivergence:  0.11704\n",
      "batch accuracy: 89.12\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.41322\n",
      "kldivergence:   1304.25\n",
      "variational_beta * kldivergence:  0.13043\n",
      "batch accuracy: 87.05\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.47641\n",
      "kldivergence:   1313.43\n",
      "variational_beta * kldivergence:  0.13134\n",
      "batch accuracy: 86.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.50122\n",
      "kldivergence:   1432.55\n",
      "variational_beta * kldivergence:  0.14325\n",
      "batch accuracy: 84.40\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.41238\n",
      "kldivergence:   1250.95\n",
      "variational_beta * kldivergence:  0.12509\n",
      "batch accuracy: 86.89\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.39277\n",
      "kldivergence:   1301.88\n",
      "variational_beta * kldivergence:  0.13019\n",
      "batch accuracy: 88.33\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.48902\n",
      "kldivergence:   1321.36\n",
      "variational_beta * kldivergence:  0.13214\n",
      "batch accuracy: 85.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.43707\n",
      "kldivergence:   1275.52\n",
      "variational_beta * kldivergence:  0.12755\n",
      "batch accuracy: 86.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.41682\n",
      "kldivergence:   1295.78\n",
      "variational_beta * kldivergence:  0.12958\n",
      "batch accuracy: 87.31\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.56587\n",
      "kldivergence:   1481.59\n",
      "variational_beta * kldivergence:  0.14816\n",
      "batch accuracy: 83.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.48087\n",
      "kldivergence:   1449.01\n",
      "variational_beta * kldivergence:  0.14490\n",
      "batch accuracy: 85.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.40909\n",
      "kldivergence:   1274.83\n",
      "variational_beta * kldivergence:  0.12748\n",
      "batch accuracy: 87.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.48283\n",
      "kldivergence:   1311.02\n",
      "variational_beta * kldivergence:  0.13110\n",
      "batch accuracy: 85.22\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.43423\n",
      "kldivergence:   1406.17\n",
      "variational_beta * kldivergence:  0.14062\n",
      "batch accuracy: 86.53\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.39351\n",
      "kldivergence:   1214.89\n",
      "variational_beta * kldivergence:  0.12149\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.43644\n",
      "kldivergence:   1303.40\n",
      "variational_beta * kldivergence:  0.13034\n",
      "batch accuracy: 85.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.42779\n",
      "kldivergence:   1350.19\n",
      "variational_beta * kldivergence:  0.13502\n",
      "batch accuracy: 86.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.47879\n",
      "kldivergence:   1360.41\n",
      "variational_beta * kldivergence:  0.13604\n",
      "batch accuracy: 85.78\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.45954\n",
      "kldivergence:   1356.43\n",
      "variational_beta * kldivergence:  0.13564\n",
      "batch accuracy: 85.81\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.52148\n",
      "kldivergence:   1389.33\n",
      "variational_beta * kldivergence:  0.13893\n",
      "batch accuracy: 84.21\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.38313\n",
      "kldivergence:   1273.26\n",
      "variational_beta * kldivergence:  0.12733\n",
      "batch accuracy: 87.44\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.43103\n",
      "kldivergence:   1383.28\n",
      "variational_beta * kldivergence:  0.13833\n",
      "batch accuracy: 87.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.46836\n",
      "kldivergence:   1378.58\n",
      "variational_beta * kldivergence:  0.13786\n",
      "batch accuracy: 86.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.39886\n",
      "kldivergence:   1412.24\n",
      "variational_beta * kldivergence:  0.14122\n",
      "batch accuracy: 87.63\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.52899\n",
      "kldivergence:   1351.60\n",
      "variational_beta * kldivergence:  0.13516\n",
      "batch accuracy: 84.71\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.45120\n",
      "kldivergence:   1378.70\n",
      "variational_beta * kldivergence:  0.13787\n",
      "batch accuracy: 85.68\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.44947\n",
      "kldivergence:   1407.11\n",
      "variational_beta * kldivergence:  0.14071\n",
      "batch accuracy: 86.98\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.49900\n",
      "kldivergence:   1385.00\n",
      "variational_beta * kldivergence:  0.13850\n",
      "batch accuracy: 85.80\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.49352\n",
      "kldivergence:   1379.77\n",
      "variational_beta * kldivergence:  0.13798\n",
      "batch accuracy: 85.50\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.45039\n",
      "kldivergence:   1494.42\n",
      "variational_beta * kldivergence:  0.14944\n",
      "batch accuracy: 86.03\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.42076\n",
      "kldivergence:   1350.41\n",
      "variational_beta * kldivergence:  0.13504\n",
      "batch accuracy: 86.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.41603\n",
      "kldivergence:   1290.39\n",
      "variational_beta * kldivergence:  0.12904\n",
      "batch accuracy: 86.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.46900\n",
      "kldivergence:   1393.22\n",
      "variational_beta * kldivergence:  0.13932\n",
      "batch accuracy: 85.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.46606\n",
      "kldivergence:   1336.71\n",
      "variational_beta * kldivergence:  0.13367\n",
      "batch accuracy: 85.79\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.46539\n",
      "kldivergence:   1397.25\n",
      "variational_beta * kldivergence:  0.13972\n",
      "batch accuracy: 85.65\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.54490\n",
      "kldivergence:   1502.89\n",
      "variational_beta * kldivergence:  0.15029\n",
      "batch accuracy: 83.23\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.42614\n",
      "kldivergence:   1304.01\n",
      "variational_beta * kldivergence:  0.13040\n",
      "batch accuracy: 86.99\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.50855\n",
      "kldivergence:   1471.05\n",
      "variational_beta * kldivergence:  0.14710\n",
      "batch accuracy: 84.43\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.48618\n",
      "kldivergence:   1320.21\n",
      "variational_beta * kldivergence:  0.13202\n",
      "batch accuracy: 85.58\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.54948\n",
      "kldivergence:   1620.72\n",
      "variational_beta * kldivergence:  0.16207\n",
      "batch accuracy: 82.69\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.49044\n",
      "kldivergence:   1453.68\n",
      "variational_beta * kldivergence:  0.14537\n",
      "batch accuracy: 84.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.38390\n",
      "kldivergence:   1235.13\n",
      "variational_beta * kldivergence:  0.12351\n",
      "batch accuracy: 87.76\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.44324\n",
      "kldivergence:   1514.65\n",
      "variational_beta * kldivergence:  0.15147\n",
      "batch accuracy: 86.08\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.48701\n",
      "kldivergence:   1322.21\n",
      "variational_beta * kldivergence:  0.13222\n",
      "batch accuracy: 84.76\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.45600\n",
      "kldivergence:   1391.50\n",
      "variational_beta * kldivergence:  0.13915\n",
      "batch accuracy: 86.00\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.48314\n",
      "kldivergence:   1510.90\n",
      "variational_beta * kldivergence:  0.15109\n",
      "batch accuracy: 84.93\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.48856\n",
      "kldivergence:   1429.18\n",
      "variational_beta * kldivergence:  0.14292\n",
      "batch accuracy: 84.90\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.47459\n",
      "kldivergence:   1361.64\n",
      "variational_beta * kldivergence:  0.13616\n",
      "batch accuracy: 85.34\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.42720\n",
      "kldivergence:   1309.25\n",
      "variational_beta * kldivergence:  0.13092\n",
      "batch accuracy: 86.01\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.49266\n",
      "kldivergence:   1388.06\n",
      "variational_beta * kldivergence:  0.13881\n",
      "batch accuracy: 84.55\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.49516\n",
      "kldivergence:   1496.09\n",
      "variational_beta * kldivergence:  0.14961\n",
      "batch accuracy: 84.95\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.50313\n",
      "kldivergence:   1429.15\n",
      "variational_beta * kldivergence:  0.14291\n",
      "batch accuracy: 84.77\n",
      "\n",
      "\n",
      "val\n",
      "epoch #62\n",
      "reconstruction loss: 0.52012\n",
      "kldivergence:   1470.11\n",
      "variational_beta * kldivergence:  0.14701\n",
      "batch accuracy: 84.70\n",
      "\n",
      "\n",
      "epoch # 62 : train loss is [175.63629410657563] and validation loss is [0.09948870814155163] \n",
      "Epoch [63 / 150] average reconstruction error: 0.473413\n",
      "train\n",
      "epoch #63\n",
      "reconstruction loss: 0.34063\n",
      "kldivergence:   1466.83\n",
      "variational_beta * kldivergence:  0.14668\n",
      "batch accuracy: 88.65\n",
      "\n",
      "\n",
      "train\n",
      "epoch #63\n",
      "reconstruction loss: 0.39960\n",
      "kldivergence:   1709.46\n",
      "variational_beta * kldivergence:  0.17095\n",
      "batch accuracy: 86.96\n",
      "\n",
      "\n",
      "train\n",
      "epoch #63\n",
      "reconstruction loss: 0.35665\n",
      "kldivergence:   1660.67\n",
      "variational_beta * kldivergence:  0.16607\n",
      "batch accuracy: 87.94\n",
      "\n",
      "\n",
      "train\n",
      "epoch #63\n",
      "reconstruction loss: 0.31310\n",
      "kldivergence:   1360.65\n",
      "variational_beta * kldivergence:  0.13607\n",
      "batch accuracy: 89.31\n",
      "\n",
      "\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_vae.py\", line 148, in <module>\n",
      "    for batch in dataloader:\n",
      "  File \"/project/6007383/shimash/env-python3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/project/6007383/shimash/env-python3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 385, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/project/6007383/shimash/env-python3.6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/project/6007383/shimash/env-python3.6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/project/6007383/shimash/model_zoo/CelebAMask-HQ/MaskGAN_demo/data/vae.py\", line 232, in __getitem__\n",
      "    image = Image.open(self.images[index]).convert(\"RGB\")\n",
      "  File \"/project/6007383/shimash/env-python3.6/lib/python3.6/site-packages/PIL/Image.py\", line 934, in convert\n"
     ]
    }
   ],
   "source": [
    "! python train_vae.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
